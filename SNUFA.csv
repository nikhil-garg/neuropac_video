link,Year,Event,Speaker,Organization,About,Category,Transcript,Summary,Source of Summary,Topic 1,Sub-topic 1-1,Sub-topic 1-2,Sub-topic 1-3,Topic 2,Sub-topic 2-1,Sub-topic 2-2,Sub-topic 2-3
https://www.youtube.com/watch?v=DkbzAOkI2bE&list=PL09WqqDbQWHFjkkXiQdOYC1wAdgSUMGxQ&index=1,2022,SNUFA Workshop,Priya Panda,Yale,Algorithm-Hardware Co-design for Efficient and Robust Spiking Neural Networks,Neuromorphic-compatible algorithms,(148) Priya Panda - Algorithm-Hardware Co-design for Efficient and Robust Spiking Neural Networks - YouTube https://www.youtube.com/watch?v=DkbzAOkI2bE Transcript: (00:03) thank you okay I think we're we're live now so I will um go ahead and introduce our next speaker so I'm Katie Schuman I'm an assistant professor at the University of Tennessee um and I'm very excited to introduce our first invited speaker of uh this year's Workshop um Priya Panda uh Priya is an assistant professor at Yale University and she leads the intelligent Computing lab there and we're very excited to hear her talk today so Priya I'll hand it over to you thank you so much Katie and first of all (00:43) a big thanks to the organizers for uh inviting me uh to this exciting workshop and today I'll be giving you an overview of some of our works that we have done in the co-design space for enabling scalable spike-based machine intelligence and before I move on I have to acknowledge my students who have done the Crux of the work and I get this opportunity to present their work um so I think I want to know today like you know deep neural networks they are achieving massive feeds uh in terms of doing a lot of tasks from recognition to (01:15) natural language processing uh but the question Still Remains is at what cost um uh so here I'm just giving you an example a deep neural network which is doing Simple uh object detection on uh back in GPU it expands on the order of like you know a couple of hundred watts of power on the other hand the human brain we perform impressive feeds not just recognition movement control planning decision making all of that uh but with a very uh a small power budget of 20 watts and whatever little we know of the brain we know that it is the (01:47) spike driven computation and communication between neurons and synapses in the brain uh as well as the fact that the brain has this 3D structure where neurons and synapses are co-located and probably these two things are what uh allows the brain to do these impressive feeds with such a low power budget so in uh in uh in the field of neuromorphic computing in general what we are trying to do is from an algorithmic end in order to harness some of these Spike driven computations and Communications we are trying to use (02:20) spiking neural networks uh in order to integrate these cues such that we can not only harness energy efficiency for intelligent tasks but also get some interesting improved learning capability because of these temporal computations and on the other end of the hardware end we are going uh beyond the standard CMOS architecture space we are looking into more emerging non-volatile memory based analog Computing architectures that can help us further accelerate these computations and come up with more efficient uh spike-based machine (02:49) intelligence so before I go forward I just want to kind of you know I'm sure all the entire Community here will be aware of it but just want to highlight some of the fundamental differences between an SN and an a n and mainly as you can see here from a structure perspective snns can have the same structure a fully connected or convolutional structure uh however uh the inputs and the outputs to an snn are of course binary spikes which come over a period of time and given that we are have processing these binary inputs over (03:19) time we need to definitely have a very different neuronal functionality that can take into account some of these uh temporal correlations and in snls today at least the works that I will be talking about uh the most the neuronal model that we use is this leaky integrate fire neuronal model wherein you have this membrane potential shown in blue that has this integrate and leak behavior in the presence or absence of spikes and whenever the membrane potential process a certain threshold that is an indication of the generation (03:51) of an output Spike and this output spike is then communicated to the rest of the network so this is all good we have a good neuronal model we have a structure but the problem is this thresholding functionality as we all know that whenever there is a thresholding functionality the activation function becomes discontinuous or non-differentiable so you cannot use the standard gradient descent techniques we have to modify the gradient descent techniques so that you can come up with a gradient so that you can actually (04:18) train these spiking neural networks from scratch so there's a lot of work that has happened over the past decade um in terms of how do you efficiently train deep spiking neural networks and kind of scale them up to some realistic tasks and to that effect like you know there is a good amount of work that exists in the standard HTTP learning field or Spike them independent plasticity learning but turns out that while this is a very good unsupervised local learning rule uh uh scaling up models towards more realistic (04:48) large-scale not only recognition but detection tasks uh turns out to be a problem so they are very much Limited in terms of the kind of accuracy as well as you cannot really have very large networks trained using sddp uh similarly then like you know people went on moved on to the conversion technique which is very much widely used today there's a good amount of work coming up uh in a lot of interesting conferences and here are the the good thing about conversion is that it takes advantage of standard a n and training so you take a pre-trained (05:18) a n model and transfer the statistics of that pre-training and model into an snn but turns out in order to have a lossless conversion between an A and an snn you need to show the input for longer time steps so the latency during the conversion process has to be long enough for you to have this good accuracy and that latency will automatically result in higher energy also at the end so today like at least in our lab what we have been focusing on is training from scratch so essentially thinking about what type of back (05:49) propagation or back propagation variants can you come up with such that you can leverage the time statistics in the input time statistics of these LIF neurons very well and can come up with a spiking neural network that not only has lower latency but can be scaled up to Large Scale Models such that you can do more realistic tasks and we want to leverage this back propagation through uh time learning rules in order to not only get efficiency higher accuracy but also some interesting robustness benefits so one of the first things that we did (06:22) in our lab that allowed us to do some kind of scalable uh from scratch training is this learning rule called batch Norm through time now what is this um through time it's basically trying to modulate your batch Norm layer that exists in every a n that you train today but instead of having us a constant learnable parameter given that your input to an snn comes over a period of time so it made sense for us that this learnable parameter attached with the bachelor should also vary or should also uh change over a period of time so it (06:56) turns out like you know the implementation of it is pretty standard you attach this DNT layer um before your convolutional operations coming into an LIF neuron and what I want to just give you more insights rather than the implementation retails and maybe if you have any questions I can pick them in the Q a but interestingly now one of the first things we try to do is that once you take this train model we wanted to see how what kind of Spike activity do you see with a bntt trained model as compared to previous conversion models (07:26) or you know your standard surrogate gradient disentering models and we finally found out that previous models like conversion and surrogate BP when you look at the spike rate across different layers there is this kind of you know initially there is not a lot of Spike activity and after a period of time uh it sort of has the saturating activity so all layers Spike at a saturated rate after a period of time whereas in case of a bntt trained model you have this kind of a gaussian train wherein the spike activity Rises and (07:56) then falls down right so we wanted to understand this further and it turns out that this kind of a rise and fall is actually associated with the uh learned bntt parameter so what we see is this gamma parameter that is learned over a period of time uh there is this time shift of the maximum gamma so here in this color chart I'm showing you what is the gamma learned for different layers of the spiking neural network up and you find that the first layer has the maximum gamma at the first time step uh second layer at a later time step and so (08:27) on and so forth so what and if you know that if gamma is high means that your spiking neuron will have a higher chance of spiking so the rate of activity will be higher so what we see is that there is this interesting temporal propagation of Spike information as we go deeper and Gamma is actually the learnable gamma parameter is able to capture this kind of a temporal uh propagation and if you think about it it makes intuitive sense right early layer should Spike first and then the later layer should spy so with (08:55) the help of BNT we were able to achieve this kind of intuitive Behavior so coming back like you know given that we have these learnable internal uh parameters that capture the temporal propagation of spikes it turns out that as soon as we attach bntt we were able to Now train uh snns much deeper snns going beyond that five layers nine layers Etc and we were able to train your standard 16 lead or 20 layered assonance from scratch with very low latency of like 10 or 20 to 30 time steps and again the latency component (09:26) was able to be reduced because now given that we have this learnable gamma it was able to capture the temporal statistics in the input very well as a result of which it was able to give us high accuracy at lower latency and here I'm just showing you an example result of a tiny imaginary model trained using uh PLT and we find that the pntt model uh was able to train uh was able to get good accuracy as compared to a conversion model at almost one tenth of the latency so given that we were able to deploy bntt we went ahead and started to think (10:00) of you know can we apply bntt to beyond recognition like you know your standard image classification tasks so certain things that we did was applying bnjt for image segmentation now that is even a more difficult task because now you have to go ahead and like you know classify each and every pixel in your input to figure out you know which regions of Interest are present in the input and we actually looked at like you know a DBS data set in this case and we found out that we got really state-of-the-art performance as compared to you know your (10:30) previous snn methods and we also not only did that we also found out that especially when we look at DBS data sets of these neuromorphic data sets which have very sparse information coming over a period of time you can actually come up with some interesting data augmentation schemes that only are very specifically fine-tuned for DBS data are not really really amenable with your RGB sensor data and and again using a entity like learning rule we um with the right kind of augmentation schemes we were again able to get really (11:00) state-of-the-art performance uh and uh get almost 30 improvement over previous works on these uh DBS data sets so accuracy yes we were able to achieve using this from scratch training rule but the question was are we also able to get Energy Efficiency and turns out yes because of the fact that now bntt captures this interesting temporal statistics we found out and I'm just showing you the spike rate here of the entity model as compared to your conversion and your standard silicate gradient descent cream model and we (11:34) found out that the overall Spike rate of the uh overall Spike activity of these networks also reduced when you're using uh learning rule that captures the temporal statistics very well so we found that the entity reduces the spike rate by more than 50x at 10x and of course if you have a reduced Spike activity that means there is overall higher activation sparsity and with the right kind of Hardware you can take advantage of that sparsity in order to give you energy efficiency now an interesting side effect that we (12:02) found using this bntt trained model was we were even more adversarly robust as compared to other models now this is something that uh a lot of other uh authors or other researchers have also shown that snls turn out to be more adversarially robust um than ANS as you can see here that as I increase the strength of the attack of the adversarial attack uh um the surrogate gradient trained snn is more robust as compared to an a n uh but what we find is that a BLT trained SNL is even more resilient like there is hardly (12:37) any uh change in accuracy uh in this kind of medium range of attacks and if you go beyond this medium range and start attacking in a more stronger manner even the accuracy drop that we observe was less than 5 so it turns out that you know there is a good amount of advantages to leverage as soon as you start thinking of how do you interpret time statistics very very well so um given that we were able to capture bntt we then thought about as I said we not only went for Beyond image classification scenarios but we wanted (13:08) to really deploy snns for more diverse learning scenarios as I'm showing you here we went ahead and came up with some interesting interpretability tool to understand why are snns more robust we also applied assonance in privacy preserving distributed learning scenarios and this is something uh very very much amenable with snns we have been talking about snns for more Edge Computing so it turns out that you know if you apply snns to Federated learning or privacy preserving distributed learning scenarios they do give you some (13:38) interesting advantages so I'm just going to talk about the Federated learning part right now and show you some of the interesting results we get and just uh what is the framework of Federated learning the Federated learning is basically a cloud system talking to multiple devices and these devices instead of sharing their data with the cloud what they share is their model parameters right so each of these individual devices is being trained on their own data sets and instead of sharing the data because you don't want (14:06) to share data between any application maintain the privacy of the data set so you instead of share the model parameters right so you're just communicating the gradients of the model parameters and there is this back and forth that happens between the cloud and these devices that are being individually trained and this is a pretty standard Federated learning setup what we did was that because we know already that we are motivated snns do have a low power alternative and they can be since we can now train them from (14:35) scratch using this kind of learning rules uh what we thought was like why don't we train an snn in a Federated learning Paradigm wherein this on device local training of the snn was done using bntt and of course we were using the standard Federated averaging in order to do this communication of gradients and aggregation of gradients at the server now I want to sort of talk to you about like some of the interesting uh results that we found so what we found is that smns turned out that if you see the graph here I'm just showing you the (15:04) accuracy you see that when you have a low client configuration that means when you have just one or five or ten clients communicating with the server then snls accuracy is lower as compared to an an accuracy but as soon as the number of clients go beyond 100 right as you see here the snns accuracy starts becoming much better by almost 30 to 40 percent as compared to that of an an and turns out that this Federated snn training is actually robust to all aspects of Federated learning which is means that if you have heterogeneity in (15:37) terms of data you have some stragglers that means some of the devices when they are communicating to the cloud are being dropped off or maybe you may have some noise during the communication process and all of that snls are much more resilient as compared to ANS so this again tells us that at the end of the day there is this assonance not only have a low power alternative but they can do more scalable learning especially in the distributed Paradigm and of course like you know we have to still measure the Energy Efficiency and see (16:06) that actually when we are doing this online training and inference alongside with these multiple devices are we actually getting an Energy Efficiency and turns out this is an analytical energy estimation we did on 45 nanometer CMOS process and we found out that an a n as compared to an SN and um consumes more than 5x energy for doing this kind of this distributed Federated inference in these kind of scale devices so moving on now we wanted to think about like you know yes we are able to reduce the sparsity uh in case of an snn (16:42) but is Pike rate reduction um uh just is is that the only goal or can we further specify the SNL in order to get even more improvements so what we wanted to then further look into was can we have some interesting weight and temporal sparsity and to that effect what we looked at is pruning like pruning is a very widely used technique today and we all have heard about this lottery ticket hypothesis which allows us to get very interesting sub networks from dense initializations and we essentially investigated lottery ticket hypothesis (17:17) for SN and pruning techniques and in terms of lottery ticket hypothesis what we found out is that in case of an sln we not only can prune the weight Dimension which is the space Dimension but we can also prune the time Dimension that means when we are searching for these Spar sub networks inside this is dense Network we not only can we not only need to search the network with longer times this but we can search the network with shorter time steps so these winning tickets can be drawn from a network trained with a smaller number of (17:48) time steps and after you have found out this part sub Network you can of course train it and find tune it with the number of time steps that is initially assigned to you so this was again another thing that you know there is two degrees of freedom in terms of pruning that you can apply to snns and get even better results so turns out that you know when we did this early time we called this method early time ticket and this work was presented two weeks ago in PCC we and we found out that you know we were really able to reduce the search (18:15) time of these um uh Spar sub Network finding by almost 40 to 50 depending upon the type of uh initial lottery ticket hypothesis method you're using and again we were able to maintain a very good accuracy um uh while uh observing a sparsity of almost 97 to 98 in terms of weights so the key takeaway from here is that when you're thinking about pruning you don't only think about spatial pruning but also you can think about temporal pruning when you're looking into spiky neural networks so so far I have sort of (18:49) kind of hopefully uh talked to you about like the fact that you know from scratch training techniques that use temporal statistics can definitely make a difference in widening the use of snns for diverse applications but the question is is better training optimization the only way to enable spike-based machine intelligence well the question is let's try and look at the uh full picture so if you look at fundamental differences between an snn and a n that I have already highlighted there is an LIF versus a relu structural (19:19) difference there is a temporal information processing versus a static input processing functional difference but despite of these differences we always till now so far whatever results I have shown I have always used a n and architectures like vggs or the resonates but the question is you know because there is this kind of a difference that might actually result in a sub-optimal solution so the question was can we find more SN and specific architectures and what we did in our recent work uh was we applied a mass algorithm to search for (19:51) some suitable architectures that snns might prefer so we applied this Nas algorithm so one of the first things that we wanted to think of was which Nas algorithm will be suitable for snns given that snns have a significantly slower training process so we cannot apply you know your standard gradient descent based Nas algorithms we can came up with this zero shot Nas training inspired from one of these icml 2021 works and again um in terms of the search space architecture that we were looking at we not only were trying to allow the SNL to (20:25) search for the type of you know convolutional kernel but also the type of connection in terms of scape no connection and in in addition to both for in addition to forward connections we also started looking for backward connections and turns out uh and I'm just highlighting the results here that snms actually prefer backward connections and get even better accuracy as compared to an SN and that is restricted to search only for forward connections and when I say backward connection what does that mean it means (20:55) that the computation of this neuron is influenced by the computation of this neuron and in so the competition of this neuron at a current time step is influenced by the computation of this neuron from a previous time step so there is this past from later layers trying to influence means the current in the early layers and this sort of interesting temporal Dynamic that is being captured by the backward connections uh is something that you know snls are preferring and you know we can come up with even better architecture search techniques and one (21:27) other thing I also want to talk about is the fact that these searched architectures were transferable across data sets that means a CFA tray a FIFA 10 trained architecture was transferable to a c500 or a tiny imagenet and as I said given that we were using this kind of a zero shot training algorithm uh we were able to find these best architectures at very less search time of less than two GPU hours and the gpus I'm talking about are very simple RTX gpus so moving on like you know I have talked to you about the algorithmic perspective (21:58) and in the last uh you know five six minutes I just want to give you a brief idea about the hardware perspective to just really uh like you know give you some thoughts around are residents truly efficient when implemented on Hardware so when we started thinking about the hardware perspective first thing we wanted to talk about was like you know can we actually Benchmark some of our algorithms and turns out when we last started looking at benchmarking tools for snns they were missing there were a lot of benchmarking tool available for a (22:27) NS in both the crossbar space as well as the systolic array space but when perfecting tool for snls were missing and so to that effect in our group we developed these two different types of benchmarking accelerators uh one was called Spike Sim which is a crossbar based accelerator and one was called SATA which is a systolic array base accelerator for SNL training whereas Spike Sim was for SN and inference and I'm not going to the details of state it is a standard systolic array design which has um uh functionality to do LIF neuron do (23:00) the weight fetches Etc but I just want to highlight some of the interesting um details about this training accelerator we found out in terms of results we found out that when we are not considering the sparseity at all we between an A and an snn of course our SNL consumes more energy as compared to an A in it but when we do consider sparsity that means the sparsity of value neuron is considered sparsity of SN and neuron is also considered a spiking neuron is also considered it turns out even after considering (23:28) sparsity the training energy of SNL remains higher than an so the reason was that like you know first of all we found out that like you know time steps it turns out that does play an important role if you have very large time steps you really cannot win over an a n in terms of computations and that is because every time you keep on fetching these uh weights these membrane potentials back and forth between the dram to the memory array or to the PE array you are losing out a lot of in terms of losing out a lot in terms of (24:01) energy consumption so this expensive memory access does prohibit snn training the other thing that we also found out which was an interesting finding was that there is a lot of potential for you to increase the sparsity of gradient so specifically there is this gradient of membrane potential that will play a big role in terms of training and turns out by controlling the sparsity of this membrane potential you can go to a regime where snns will have lower energy as compared to an an so in this case we found that you know if you're scarcity (24:33) in this membrane potential is more than 88 percent then snn starts to win over ANS so basically this encourages you know possible direction of new algorithm designed for resonance with more sparsity in these gradients and we want to use further in the future we want to use Theta as a platform or Baseline to measure the energy efficient efficiency again of new algorithms for SNL with Spike same similarly again it's a hardware evaluation tool for in memory Computing not going into the details because I want to keep some time for Q a (25:04) uh but I just want to highlight some main results when we try to Benchmark these snns on these in memory Computing Crossfire based accelerators it turns out one thing we found out was that there is a huge area overhead that snns have because of the lifif neuron and module and why is that so because in remembrance potentials over a period of time such that we can do the processing of the spiking neuron and this is absolutely absent in a case of an a n because in an a n and a value is a simple comparator functionality so you (25:36) know the thing was that what can we do so what we found out was by just doing some simple topological modifications wherein we reduce started reducing the depth of these first layers or second layers in the spiking neural network we were able to get some interesting area minimizations and that further led to interesting uh energy and latency minimization size you can see so you know this benchmarking further allowed us to think about what new algorithm designs we can do or what new architecture designs we can do and again (26:06) as I said like you know here when I compared an snn to an a n on this kind of a benchmarking tool we found out uh and here I'm doing a comparison between a four bit weight snn with one bit Spike activation and a four bit uh weight 4-bit activation a n we found out that snns with time steps less than four can only achieve lower latency and energy at ISO accuracy as compared to that of an an anytime we go beyond four the uh energy latency of that sln starts getting higher and higher as compared to an a n so again anchor we need to have (26:41) snn algorithms with low time step count and finally uh this is an interesting work again when we are looking into these crossbars or any of these hardware tools we need to bring in variability and turns out whenever you bring in variability the fact that you're doing multi-time step competition anytime you have variability in the hardware because of multi-time Step competition you will have a compounded effect and that compounded effect will lead to a huge accuracy drop on the hardware so as you can see here even though my snn was in (27:13) on the software Baseline it was 99 accurate at the end of the day when you put it on the hardware Baseline the hardware level accuracy is going to drop down all the way to 10 percent because of again these multi-time step computations so turns out you have to come up with some kind of you know a post training adaptation or post training uh conservation techniques in order to help you manage these variabilities once you have mapped these snns on hardware and I'm not going to go again I'm not going into the details uh (27:42) this work was presented islpd this year which won the best paper award but interestingly enough variabilities also play an important role when it comes to multi-time step competitions so to conclude uh what I want to to Showcase here is that Energy Efficiency is of course a primary advantage we get with snns but it still remains to be seen that whether the current Hardware that we are developing are the amenable with the time step multiple time step computations and the redundancies that happens because of these multiple time (28:12) step computations alongside snns and True Hardware implementation is very necessary for us to understand and truly reap the benefits of these even driven snls and even architect new algorithms and of course algorithm Hardware Core Design will be necessary for Next Generation neural Computing so with that I would like to thank you all for your attention and open the floor to some questions thank you thank you Priya that was great talk um a lot of a lot of questions in the uh so far please feel free to continue (28:41) entering questions um as we go through we have plenty of time for a q a um so I'll go ahead and start with the questions uh from the audience um is there a bio plausible explanation for how bntt might be implemented oh that's a good question yes so if you think about like you know we never actually went from a bio plausible site we were really thinking about given that bachnom was such a popular technique that uh Allah that uh allowed to enabled accelerated training in the in space we thought that it should have a similar (29:19) kind of uh effect if used in the correct way in the snn space now interestingly enough as I showed you that when we actually trained the model using bntt we found that there is this kind of interesting temporal propagation of spikes right that means the first layer spiked first then die down and then the later layers take those spikes and then Spike later so I think um from a bio plausible site maybe what I think the batch num parameters are capturing in the input distribution uh is this kind of you know that there is (29:51) this layer wise time earlier wise time propagation of information um which probably even in our visual cortex might be happening right like you know first your V1 and V2 will Spike and then they will carry forward that information to the later uh layers and also one thing you see in that vntt model which I never had a time to talk about is that after a while like even though you train the network if you even if you give it like an entire time Horizon of let's say 25 time steps right it turns out that the network figures (30:20) out that you know I may not need fully 25 time steps the bntd layer it turns out that you know after 20th time step or so all the layers have zero activity so even the network tries to figure out during this learning procedure is to even though I give it long time steps it tries to figure out what is the actual activity do I need in order to do my classification and then the network just sort of you know stop spiking all together and as a result of that you know in that work in vntt work we actually proposed this temporal early (30:50) exit that means after the bntt has died down we don't need to really expend any more effort in the later time steps uh so I don't know if that uh answered the question but I felt like this temporal propagation of Spike information is something that automatically the learning optimization rule captures which is a very uh interesting uh bioplastic technique so continuing on the theme of the um uh bntt so BN can be absorbed in the preceding convolutional layer at inference time um the the question says I suspect that (31:25) this is not true for bntt because the coefficients change with time do you see that as a problem for implementation on Hardware so that's a good question actually yes so it's not a problem for Hardware because after we let's say train the model so we store the Gamma One let's say if your time steps is 25 then during the training I learn the gamma for every time step right Gamma 1 gamma 2 gamma three so after the training has been done whatever Rama I have learned for these 25 time steps you know Gamma One (31:55) gamma do I kind of store it in an array so literally like you know on a hardware perspective let's say you know when we were looking at Spike Sim or even SATA with bntt we literally had like a batch non-storage uh like a little SRAM that you can push inside the PE wherein during inference every time a new gamma is being fetched inside each processing engine uh so basically as you would have done with an a n where after training you store the gamma values per layer here you not only store the gamma values (32:24) per layer but also per time step so per layer per time step so there will be a little bit of overhead in terms of storage memory of Bachelor parameters but again the time steps that we are talking about is like you know 30 to 25 so it's not really much as compared to what you would have stored um so another question from the audience will bntt work with recurrent networks as well or just feed fold that's a very good question so yes I think we uh the recurring models that you are talking about can be different (32:56) right like uh would you would the entity work with something like a Transformer attention like model versus an lstm like model uh so we actually uh try to apply bntt on our Transformer model uh not a recurrent model because of the fact that uh you know um and there is this Theory going on that you know spiking neurons are inherently recurrent in nature right because they have this membrane potential being stored over time and computed over time so they have some inherent records so we wanted to take advantage of that and see if we can (33:28) build better attention models uh now that is work under progress we are hitting some problems there and that is because if you see these attention models that we have in Transformers they don't have a lot of activation layers they have more of these matrix multiplication layers uh so there uh you know a batch Norm can really really um you know um derail some of these the query key value the attention map capturing uh we have not I have not yet applied The Entity on lstm or you know your gated recurrent units kind of model (34:03) so that would be something uh could be interesting uh to see how that performs so we have a couple questions about the the Federated learning um uh results that you you talked about um I think you touched a little bit on on the energy usage uh later in the talk but um but a question from Dan is the Federated learning process feasible for spiking neural networks um the forward passes for snns is usually relatively low power but the backward pass as you presented is very expensive yeah yeah so when I did Federated learning it was fully with SN (34:36) and strained from scratch so like literally local on device training was done uh using bntt and then we were doing Federated aggregation of these Spike based gradients all of that it and we would we would we were able to as I showed we were able to scale it up to 200 300 devices talking to this server right it was slow it will be much slower as compared to an a n because again we are doing multi-times of computations so that energy when I showed that snns were 5x more energy efficient as compared to anus that was all inference estimation (35:06) not the training estimation uh what I think I right now we are looking at in the Federated learning space is combining these uh the sparse models that we found using these lottery ticket hypothesis where you can like you know do temporal and spatial pruning and apply them to distributed learning space so that's where probably we can still get some interesting advantages uh having said that yes training is something we really need to figure out as to uh how many as I've as I showed uh later on like you know with that SATA (35:36) benchmarking we found that until unless you started for the gradients or you are in the limited time step regime you will never be able to get an snn which is uh lower in terms of training cost as compared to an a n right and that that is um that extends to on device training all of that uh so we really need to think of bringing in more sparsity not only in terms of Weights in terms of gradients uh and further minimizing the time step count uh so what I showed in the Federated learning results that was all done with snns but the energy (36:08) results that I estimated was only during inference but yes we need to take some of these techniques that we have done and we need to apply it in the Federated scenario so hopefully dad that answers the question um so uh another question and I'm actually going to jump in also after this with a question from me selfishly as an organizer um so uh this is uh about the the nas approaches that you applied could you elucidate a little bit further which architectures you were performing NASA over um the results you showed were for (36:38) comdets with uh comp backward connections or fully connected so what sort of architectures were you actually looking at for the the NASA implementations so we took away when we were searching for these uh neurologic when we were doing the neural architecture search we took a cell based architecture right so each cell will have so when I showed that Circle it's basically a cell which can have this array of operation choices right a skip connection a one plus one at uh three cross three or five cross five and all of that uh so it will (37:08) choose um it never searches for a fully connected like you know in the search space design search space uh these were that was our search space inside each cell so it's sort of like every cell somehow is a convolution operation which could be skipped connected to the next cell uh and it could choose like multiple convolutional layers in some way right it's not like it will always prefer a one cross one it can prefer one cross one and three cross three together so sort of like you know like you know um (37:35) multiple convolutional layer architecture in some way um and uh so that was our architecture now you can tell me I so we initialize this kind of a cell based supernet and we try to sample subnets and as I said we when we were trying to figure out uh how do you sample the best subnet we use this Hamming distance based technique because we did not want to come up with a darts or proxiliousness like technique where you know they they not only train the weights but they also train the architecture parameter so there was no (38:06) gradient base search done we literally used some statistical techniques like Hamming distance measure uh wherein the spike so we initialize the supernet and the um uh Spike activity of that initialized supernet by measuring the spike activity and doing some kind of statistical Hamming distance analysis we were able to find that which subnets that we sample from the supernets might have a better accuracy and again that this statistical measurement it was theoretically proven by the dysml 2021 work and we took it and we modified it (38:40) for the spiking neural network uh so literally there was no gradient base search done it was a fully like you know statistical search of you know you know in a sampling way you just figure out which network may have better accuracy and then you train that Network to the to convergence and figure out what's the best accuracy if you want so hopefully that answers the question so we are looking into convolutional architectures and this kind of a gradientless search okay this is where I'm selfishly going (39:05) to jump in with my question so you uh with the NASA and with the really nice tools you presented for um energy uh analysis um have you considered doing a multi-objective Nas where you can Target high accuracy but also very low uh energy usage yes the SKT that's a good question that's really work in the progress right now we are targeting a DAC paper in two weeks and literally this is like you know co-optimization because that was as you said like you know it is um pretty much the next thing to do that now that we have a (39:36) benchmarking tool we will append it with the nas Search tool there and we'll have this kind of a network architecture Hardware search optimization all together excellent excited to see that um okay so another question from the audience in the Energy Efficiency experiments you compare a n and SN and energy consumption on static data um so you're turning the static data into temporal data for snns and if uh when you're doing that what sort of technique are you using so we like most of the yes uh here most of the time I (40:07) have been using either direct coding or Raid coding uh when we I when I say rate coding it means that each image is converted into a each pixel in the image is converted into a spike train wherein the pixel intensity is proportional to the frequency of the spike train that is rate coding but turns out that sometimes when you go very deep with these 16 layer 19 layered architectures it's always better to feed the image as it is which is RGB image and at the first layer software you go through the first conv operation you will have a LIF unit (40:37) and that LIF unit will anyways produce spikes and so there are two types of coding which is today very popular one is direct and rate and we look at both of them um temporal coding wherein you know you restrict one Spike per neuron uh across all time strips that is something we have not yet explored it is it is something that could further um you know give you more efficiency but there are certain problems when you want to scale it up so we are trying to figure that out but yes at this point of time it's only direct coding and read (41:05) coding that we have great okay so um this is a very popular question from the audience um for anyone interested in running SNS on Hardware which platform do you recommend to use and how can we gain access to that yes so I have shown you all like you know all codes available on my labs GitHub website so spikesim and SATA are available there uh we are because of the fact that uh Sita was accepted very recently we are trying to kind of you know come up with the entire tool flow so all of it it spikes them and say that both are available and uh (41:39) we are still updating that platform as and when students are coming up with questions around how to do this how to do that but both of these platforms are available in terms of benchmarking tools uh some of you who may have access to lower he can or first do that we are also trying to uh get some energy comparisons done between let's say spike Sim and SATA and Luigi given there is a different type of an architecture space there but at least you know first hand you can take some of these tools to sit and uh and spikes them and develop your (42:09) algorithms on top of it okay and a last question from the audience this is your last chance audience members to to get in uh q a before we we move on to the next talk um what was the motivation to link Federated learning with spiking neural networks yeah so so basically at the end of the day the neck like you know Federated learning if you think about it at the end of the day the inference is done on my device itself so we need to during inference have an extremely low power uh model that is being used in order to uh do the (42:45) inference so and we wanted to do Federated learning because you know it it kind of captures this idea about privacy preserving distributed learning where you don't share data and all so from a training perspective of course Federated learning with snns will be inefficient and unless you kind of import those techniques of sparsity in Radiance and sparsity and weights Etc and temporal pruning special pruning you really cannot like you know go uh you cannot really have a lot of efficiency but our motivation was very much (43:15) directed towards Energy Efficiency during inference after you have come up with this Federated framework and then you're doing on device inference across these different models uh will it show efficiency and we found out yes it does like you know I showed you some analytical estimations where it was 5x more efficient so it was completely motivated from inference efficiency okay great um and I have one last question uh for you um so uh you talked about the the robustness um of these uh approaches I I think and (43:46) I could have missed it I think it was specifically in the context of um uh to device noise and and uh issues that might occur on Chip have you also uh considered looking at it in terms of like adversarial attacks on the the input or a sensor issues yeah yeah so uh yes uh the device I showed you towards the end right very very quickly uh I showed you but there was this slide when I talked about that with bntt we find that already like you know snns are more efficient uh more adversely resilient and we found that (44:17) with bntt trained models the adversarial resilience was even better uh so yes we do have when I talk about robustness we not only look at noisy inputs or uh noise statistics coming from the hardware but also the noise statistics coming from these adversarial attacks and we found that snns are more robust more robust and if you have proper uh temporal statistics leverage inside your training rule that will impact in Impact give more robustness to the finally trained model which is what we showed you with the bntt result also (44:50) fantastic thank you so much Priya I think we are moving on to the next session now there's a few more questions here but um but thank you so much for your amazing talk and uh we'll see you in the next session everybody thank you,"Priya Panda is an assistant professor at Yale University and leads the Intelligent Computing Lab there. In her talk, she discussed the use of ""spiking neural networks"" (SNNs) as a way to achieve energy-efficient and robust machine intelligence. She explained that SNNs are different from traditional ""artificial neural networks"" (ANNs) in that they process binary input spikes over time, which requires a different type of neuronal functionality. Panda also discussed the challenges of training and scaling up SNNs for realistic tasks and mentioned some of the recent works that have been done in the field of neuromorphic computing.",ChatGPT,,,,,,,,
https://www.youtube.com/watch?v=YA-m5DmrZng&list=PL09WqqDbQWHFjkkXiQdOYC1wAdgSUMGxQ&index=2,2022,SNUFA Workshop,Thomas Limbacher,TU Graz,Memory-enriched computation & learning in SNNs through Hebbian plasticity,Learning,(148) Thomas Limbacher - Memory-enriched computation & learning in SNNs through Hebbian plasticity - YouTube https://www.youtube.com/watch?v=YA-m5DmrZng Transcript: (00:04) all right everybody Welcome to um our our next talk in uh the workshop and so uh this talk will be presented by Thomas limbacher from TU gross uh Thomas take it away so thanks yeah so this talk uh is about a model for associative memory implemented by heavy implasticity so why should we study having plasticity well happy on uh plasticity is believed to play a central role in biological memory and virtually any task faced by humans demands some form of memory so and while uh most models focus on working memory many tasks require a memory mechanism (00:52) that acts on a longer time scale and often also require a more associative type of memory for example if we are introduced to someone and after some time we meet this person again and want to recall her or his name and yeah and today I'd like to present a spiking neural network model that is equipped with a header associative memory that is subject to Heaven plasticity so here is a schematic of our model it consists of standard Leaf neurons simulated in discrete time and at the core of our Network model is (01:33) a hetero-associative uh memory which is a single layer Spike angle Network and here neurons set key in the key layer projects a neurons set value in the value layer via these Association synopsis W Asic and here we have a recreation for the weight changes in the synopsis here the heavy and term strengthens the connections between co-workative neurons in the key and value layer a couple here is just the exponential activity trace of these neurons and the first term in the equation implements the upper bound on the weights (02:15) and the last term strengthens coax current associations and weakness old ones so in this simple hetero associative memory architecture is motivated from the hippocampus where rapid plasticity was found between aerial ca3 and ca1 in normal uh the key layer would correspond to cl3 and the value layer to ca1 so and only the association synopsis are subject to Heaven plasticity the remaining weights in our model are trained using back propagation Through Time so how does it work our model takes a sequence of inputs (03:06) here we have an example in this example we have sentences as input which are Mary went to the bathroom John moved to the hallway and where is Mary and each input can either be a fact or a query in this example X1 and X2 effects and X3 is a query to which a network should respond with an answer and the inputs are encoded as a spike frame but it's input encoder here and if the input is fact then these neurons set s encoding are active while neurons that are encoding are inactive and these neurons that s encoding (03:50) projects the key layer into the value layer and their activity will initiate a store operation and if the input is a query then neurons set our encoding are active while a neuronset s encoding are inactive and these neurons here said our encoding projects to the key layer where their activity will initiate a recoloration so for the first sentence in this example the model could learn to associate Mary to bathroom here the activity in the key layer would represent Mary and similar the bathroom would be represented by by the (04:39) activity of one or more neurons in the value layer so in the sketch this neuron is active for Mary and this neuron is selected for bathroom and since they are co-active the synaptic weight between these neurons is increased and similar for the next sentence uh the model could learn to associate Chong with hallway so here we have the neuron representing charm and this neuron in the belly layer represents a hallway and again we have a weight increase between these neurons and now for the query the model could learn to use some (05:22) representation of Mary to perform a memory recall and ideally um the same neuron in the key layer that was previously active for input one for Mary should now be also active in this recall step and since we have increased synaptic rate between this neuron here and the neuron in the value layer which was previously active for bathroom this neuron can activate then this path from neuron here and finally the value layer projects to an output circuit which then generates uh the final output of the model so and then some tasks it can be (06:09) beneficial to um include information about the recalled value in the recall itself and that's why we have included this feedback loop from the value layer to the key layer and in this way the recalled information can influence the recall itself after some feedback delay right so in the first task our model was required to store associations between random float vectors and integer labels so in each instance of the task we have generated n random float vectors and assigned an integer label to them and these Vector label pairs were (06:58) sequentially presented as facts after that the network received a query vector and the query Vector was equal to one of the previously presented vectors so in this example a vector is level two and the network had to Output the label of the query so here's the network activity for this example but what we have found is that our model outperforms lstm and Ellison networks in this task so here we have the test accuracy for various sequence length so various Vector label pairs number effectively repairs and the (07:43) accuracy of our model uh is above 90 for up to 50 Vector label pairs while uh the performance of the Allison then and lsdm uh quickly decreases with increasing uh sequence length we've also found that our model shows Superior General generalization capabilities so what we did here is we've trained the models with a sequence length of five Vector label Pairs and then tested with short and longer sequences so and while both models here the lstm and our model in this case generalized to Shorter sequences our (08:30) model showed a superior generalization to longer sequences so in this next task we applied our model to the problem of one shot classification of the omnicular data set here we generated input sequences of omnichlids so images of omnicular classes so we we randomly sampled five omnicular classes and then generated this input uh so each uh Tuple here or each pair in the sequence contained one randomly uh sampled uh omnic load image of these five classes and are labeled from one to five and this uh image label pairs were (09:24) presented to the network as facts and then the network received a query image and this query image showed another randomly sampled instance of one of these five omnicular classes and the network had to Output the label of this image and this setup corresponds to 105 way classification so for the only cloud images we use the CNN as input encoder in this task and we have created the CNN with a prototypical loss and then converted it to a spiking CNN by using the threshold balancing algorithm so here is the tsne visualization of the embeddings (10:12) learned by the CNN and we see there are only a few misclassified characters shown in red here and overall our model achieves an accuracy of 92.2 percent in this 200540 classification task of Novel characters um I'm not aware of any spiking neural network model that was successfully applied um to the task so there is one model uh share it all and they are spiking neural network model achieved 83. (10:49) 8 percent but on a variant of this standard omnic task that we will considering so in this task the network was required to memorize associations between an audio input and an image so here we again generate the input sequences showing uh one how do you sample from the free spoke digit data set and one mnist image of the same digit so we presented three pairs and after that the network received another audio query of one of those digit previously presented and the task was to generate um the mnist image that was Associated to the audio query so to the same digit (11:51) as the audio query and we found that the reconstructed images are not just typical images for the digit class but rather that they are pretty similar to the images that appeared uh with the audio queue and overall the mean squared different between the reconstructed image and the target image was 0.03 so and we next tested our model on the baby data set this data set contains 20 different question answering tasks and each task contains a sequence of statements a followed by a question and each of these tasks require (12:48) different reasoning so here we compare our model to the spiking relational network and to the hmm model so hmm is a non-speaking memory Network and remember we had this feedback loop in our model and what we found is that our model struggled with some tasks if you use direct feedback of with a delay of one milliseconds uh and some tasks could be solved if we increased the feedback delay to 30 milliseconds and overall our model failed on four of uh 20 tasks in this baby data set and finally we applied our model (13:47) to um an episodic reinforcement learning task so here we used the popular children game memory it is played with the deck of n pairs of cards and initially the cards are shuffled and laid out face down and a player has to flip over any two cards and if the match they are removed from the board and the current player moves again if they don't match their turn face down again and the next player proceeds and the player that collects more cards wins so we consider one player version of this game where the object objective is (14:34) simply to um find all matching pairs with as few card flips as possible and instead of using images we use random vectors arranged on a one-dimensional grid of cells and our agent was trained with proximal policy optimization so here are example game moves uh for a game with four cards and so in contrast to the other task tasks we were considering here are very always presented some facts followed by a query here the agent how to figure out the figure out by itself um when the store and recall information based only on the current observation (15:21) lecture and the observation Vector contains a three components so the state of cells a state can either be empty can the interface up or a phase down code then the last action taken by the agent and the face of the card the agent had turned in the previous time step so we have tested our model with a game of four and six cars so here in this figure in the middle we see the number of uh flips required to finish a game over the number of games during training and the figure on the right shows the histogram of card flips at test time for (16:05) random agent our agent and an optimal agent so for the four card game we reached Optimal Performance the six card game was a bit harder to train but the agent uh still was close to Optum so to conclude uh our model integrates heavy and plasticity in its Network Dynamics and we found that this memory enrichment render the model surprisingly flexible so it and out our model was up with the ability for out of distribution generalization wanted learning cross model associations language processing and memory dependent reward-based (16:57) learning so this suggests that having plasticity is a central component of information processing in the brain but also in artificial spade-based Computing systems and since heavy implasticity can easily be implemented in Hardware this also suggests that powerful cognitive neuromorphic systems could be built based on this principle so finally I'd like to thank the Institute of theoretical computer science based in clouds awesome and my supervisor Robert lingerstein and thank you for listening thanks Thomas for (17:40) Thomas Finn for a one or two questions um so from the audience is there anything that spiking buys you in this model or is it mainly added for plausibility reasons uh it's um mainly added for plausibility reasons I would say yeah I mean yeah yeah no it's it's mainly for plausibility so yeah um and uh to get just another quick question and how relevant is the quality of the spike patterns for different inputs so they have to be clearly separable or is there a winner take all mechanism implemented in the plasticity (18:23) yeah so optimally uh the they should I mean uh the the representation of the key and value uh should be orthogonal right um so this there should be clearly separable um otherwise it won't work so this whole recall mechanism then and also the associations so yeah all right well thank you very much Thomas for your talk um and we will move on to the next contributed talk session thank you,"The talk is about a model for associative memory implemented using Hebbian plasticity in spiking neural networks (SNNs). Hebbian plasticity is believed to play a central role in biological memory, and the model focuses on a type of memory that acts on a longer time scale and requires a more associative type of memory. The model consists of standard leaky neurons simulated in discrete time, and at the core of the network model is a hetero-associative memory which is a single layer spike angle network. The model takes a sequence of inputs (facts or queries) and encodes them as a spike frame, and if the input is a fact, the encoded neurons project to the key layer, initiating a store operation. If the input is a query, the encoded neurons project to the key layer, initiating a recollection operation. The weights in the model are trained using backpropagation through time, and only the association synapses are subject to Hebbian plasticity.",ChatGPT,,,,,,,,
https://www.youtube.com/watch?v=irxtUINGMWM&list=PL09WqqDbQWHFjkkXiQdOYC1wAdgSUMGxQ&index=3,2022,SNUFA Workshop,William Podlaski,Champalimaud Research,Univ func approx in balanced SNNs through convex-concave boundary composition,Neuromorphic-compatible algorithms,(148) William Podlaski - Univ func approx in balanced SNNs through convex-concave boundary composition - YouTube https://www.youtube.com/watch?v=irxtUINGMWM Transcript: (00:05) foreign [Music] science and is interested in neural data analysis and spike-based computations uh Bill we are looking forward to YouTube okay so thanks very much for the introduction and thanks to the organizers for giving me the chance to speak about my work today um so I'm going to be talking about this work this joint work with Christian muffins and using excitatory inhibitory spiking networks for Universal function approximation so uh so we've already seen a bunch of of uh approaches towards spike-based (00:56) computation in this conference and I guess generally they can fall into one of two categories so we have rate coding um where uh we're using the average number of spikes that a spiking around will fire in a given time as an input output function and that can be used for things like converting a deep net to a spiking net and then we have this sort of umbrella term temporal coding which would correspond to wherever we have kind of uh time varying Spike patterns uh things like Spike latency will fit into that or anything with precise Spike (01:27) timing so in this talk I'm going to be talking about a different approach Spike coding which I think kind of Falls somewhere in between these two we've already seen some examples in the conference of this there was the this talk by McKelly narden yesterday on uh doing nine non-linear dynamical systems and then there's this work from Guillermo Martin Sanchez on applying this to the hippocampus so uh just to contextualize this work I think Spike coding networks uh so they this was started by Sophie genev and (01:59) later continued by Christian mukins and many other people and there's often this criticism that they they only work with toy models um such as you know doing Auto encoding encoding a signal X and reading it out again and then uh they have been applied to some more General problems more Universal computations but uh such as this work in felmeyer at all but when that when that when that happens you kind of lose the what what I think is one of the benefits of Spike coding which is the their interpretability so here in this talk I'm going to be I'm (02:30) going to be talking about how we can do Universal function approximation with just vanilla spiking neurons and we get all of the interpretability and geometric intuitions that we would get from uh normal Spike coding Networks okay so I'm going to start with a generic integrated fire Network this network is receiving a signal C in which could be spikes but here it's a continuous signal here are some spike trains of the network which I'm modeling as direct deltas and then we have the typical voltage equation of the integrating fire (03:00) neuron which is integrating its inputs and then receiving also feedback spikes um so for the rest of the talk I it's convenient to think about this integrated fire neuron in a different form which is the interval form so this is similar to the spike response model from gerstner if you're familiar with it but it's essentially just uh considering that the membrane of the neuron is essentially doing a low pass filtering so we can have this this kernel H and we we can then transform the inputs C in into a new variable X which is a low (03:32) pass filtered version of that and then the spikes into R which are low pass filtered spikes so if we do that we can then rewrite the voltage equation in this form where the voltage at any given time is just going to be a weighted combination of this input X and then the feedback of the filtered spikes okay so now I'm going to introduce an important uh assumption into our model which is that we're going to consider low rank connectivity for Simplicity for the sake of this talk it's going to be rank one so this is (04:03) something that's that's quite common in in network models in the spiking domain for example the neural engineering framework from eliasmith uses this and also more recently in rate networks this work from Master Giuseppe and a subject also uses it um and also for those of you familiar with with previous work on Spike coding networks the autoencoder also uses this but it's a very particular constraint of this low rank connectivity where we have a decoding Matrix and that decoding Matrix basically specifies the recurrent (04:31) weights the feed forward weights and everything so here we're going to generalize that and we're going to consider that the recurrent weights are are the product of two different matrices or vectors depending on the rank e and D which basically stand for an encoder and a decoder and these are going to be distinct from the feed forward weights so it turns out this generalization is is uh it has very very interesting uh implications for computation so now I'm just going to plug this assumption into our voltage equation so (05:02) we can replace the W with Ed and we see that we have now a sum of inputs that this neuron is receiving from other neurons and it only depends on D so I'm going to define a latent variable here called Y which is going to be exactly equal to the sum so Y is basically a linear readout of the network it's going to be the linear combination of filtered spikes and then I'm going to plug that into our voltage equation so now we have this very simple form of a voltage of each neuron in the network which is basically a weighted sum of (05:32) feed forward inputs and this latent variable feedback so this this readout we can imagine that this is the this is the variable interest that we want to read out from the network it's going to fluctuate as uh with with spikes in the network and then it's going to Decay to zero when there's no spikes um so overall basically what I've told you so far is so I started with a generic integrated and fire Network I then added this rank one assumption to the recurrent connectivity and I arrive at this this network that does a (06:04) one-dimensional transformation of x to y EP and so for the rest of the talk I'm going to basically show you what we can get from this sort of transformation so what what kind of function of approximation capabilities do we get so again we have this transformation X to Y I'm going to remind you that Y is a linear readout of filtered spikes and now I'm going to add a constraint that the elements of of this connectivity e and D are all going to be positive and then we're going to play around with (06:34) excitation and inhibition as just uh assign an overall sign on this feedback so we have inhibition uh where each neuron is receiving negative feedback and excitation where each NR is receiving positive feedback from the latent variable so let's start with inhibition um so here we have our input output space um and this simplified form of the voltage basically allows us to visualize each neuron's voltage in this space so we can visualize the areas of the space where the neuron is above threshold and we'll spike in areas where (07:04) it's below threshold so here I'm plotting one neuron's threshold which is basically this is the point where the voltage is equal to the threshold and this delineates two two areas of the space so we have a super threshold space where the neuron will fire a spike and then the sub threshold space and we can see that uh as the latent variable increases the neuron is receiving more negative feedback so it's going to be more sub threshold it's going to be hydropolarized here I'm adding a second neuron which (07:31) has different parameters so it has a different boundary and this will further delineate this area of the super threshold space so this is where at least one and one neuron is about threshold and then the sub threshold is where all the neurons are below threshold so we can quickly go through an example of the Dynamics of this network um so imagine that we that our input is zero and here is the latent readout so it's in the sub threshold area which means that there's no spikes so this latent variable will decay (07:59) and it will keep decaying until we get to one of these boundaries so this is essentially that one of these neurons is being driven its voltage is being driven to threshold and it will fire a spike here and then the latent variable will increment upwards and we can see here that uh the interpretation of this as an inhibitory Network so this neuron uh when it when it spikes it's dragging the readout away from its own threshold so it's inhibiting itself which is effectively the Neural Reset and then it's also driving the readout (08:28) away from the other neurons boundary so it's also inhibiting the other neuron so we have a null inhibitory Network so depending uh regardless of what the input is we essentially have this type of Dynamics so we end up getting this uh this kind of uh v-shaped input output function which is convex and it turns out that this generalizes so we can basically Define any arbitrary convex function y equals F convex of f x and we can approximate that through a bunch of neural boundaries and we end up getting this convex attracting input (09:00) output function um so this type of all inhibitory network was previously explored in the lab by uh Alan menku and Sandra kimink this was published in the Reps in 2020 um and so in this in this uh talk for the rest of the talk I'm going to consider now what happens when we add excitation so let's go to the excitatory network so here again we can add a couple neural boundaries in this space but because the feedback is now positive this kind of inverts the areas of the space where we have super threshold and sub threshold (09:30) voltages so now as the latent variable increases the neurons are are receiving more positive feedback so they'll be uh and they're more likely to be in the Super threshold area so if we again consider a particular example we have x equals zero here um when the readout is in the sub threshold area it's simply going to Decay to zero now it's decaying away from the neural boundaries um but if it starts excuse me if it starts above one of the neurons thresholds it's going to fire a spike and unlike the inhibitory Network (10:01) it's now going to drive the readout further into its own Super threshold area so it effectively doesn't have a reset anymore and it's basically going to continue to fire uncontrollably it's also going to drive the readout into the other neurons boundary and it's basically going to excite the other neuron to fire spikes as well um so essentially what we have now is this unstable boundary where either the readout is going to Decay to zero or it's going to explode um and it turns out this also (10:25) generalizes to any arbitrary concave function in this case for excitation so we can define a concave function and we can delineate a piecewise approximation to that piecewise linear approximation with excitatory neurons okay so it looks like excitation on its own is not very useful because it produces an unstable boundary which is something that we sort of already knew from a lot of research in Neuroscience but we know that we can couple excitation and inhibition to do something useful so that's the next step (10:54) so now I'm going to couple these two populations um so both populations are doing this transformation of x to y um and to couple them I'm going to give each population its own independent readout so we have y i for inhibition and Y E for excitation and now when I couple them together I get uh basically a 3D space so now these neural boundaries are surfaces in 3D and they the properties of convex and concave functions still apply so now the inhibitory boundary is now convex as a function of X and the recurrent input (11:27) from y e and I'm kind of representing this as a smooth boundary but you can imagine that this is being approximated in a piecewise linear Way by a bunch of neurons um and similarly the excitatory boundary is now concave as a function of X and the recurrent input from inhibition so ideally we want to visualize these these two boundaries in the same space but it's a bit difficult so for the moment I'm going to remove X we're going to assume that X is fixed and I'm just going to consider a slice through these (11:55) two boundaries so now we can visualize y i as a function of y e for fixed x and y e as a function of y i for fixed X and now we get curves very similar to what we had before so inhibition is this convex function and excitation is this concave function and now if I flip the excitatory boundary I can then put it in the same space as inhibition and the resulting plot is this one so now we have the excitatory boundary in red the inhibitory boundary in blue um we have areas of the space where both populations have neurons above threshold (12:28) we have areas where all the neurons are below threshold and then we have some mixtures in between so it turns out that this crossing point of the two boundaries ends up being a stable fixed point of the system and what's more is that it it yields neurons that are balanced and have ai activity so we end up getting activity that's pretty similar to to a cortical uh excitatory inhibitory activity furthermore uh I guess some of you might might look at this picture and think about uh rate Dynamics so like Wilson (12:59) Cohen like milk lines um and it turns out that we also have a connection to those types of Networks so uh so then maybe some of you are are wondering at this point okay what did we gain from this basically I've I've started from a spiking Network and it seems like now I've just rederived rate equations but I'll remind you that um we actually in this case we have full control over these boundaries so they're not really no clients but we can arrange the neurons in uh whatever way we would like uh (13:30) provided that they still have these convex and concave constraints to make this boundary Crossing wherever we want and once we add X back we see that actually these Dynamics are part of a Continuum so as we change X we end up having a different we can potentially have a different Crossing of these boundaries and we can get a particular input output function as a function of x so really what we're interested in is how does the how do these eni boundaries change uh their Crossing as a function of X this yields the input output (14:02) function of the network and I don't really have time to get into it here but essentially this type of formalism can can be used for Universal function approximation so in a nutshell it's essentially that uh the the readouts end up being compositions of convex and concave functions um and there's a lot of work in math mathematics to to show that such compositions yield uh Universal approximations to functions okay so in the last minute of the talk I'll show you a very simple toy example of this so we have this desired function (14:34) which is this saw like function which is quite complicated it's non-convex and we want to approximate this with a spiking Network so what we can do is just arrange some neurons in this space so that their boundary Crossings will approximate this so we actually only need three excitatory and three inhibitory neurons to do this and we see that each of these each of these colored planes corresponds to one neuron and they're arranged such that as a function of X the boundary Crossings will delineate this function (15:03) so we can simulate this in the spiking Network and here I'm providing the input X varying from 0 to 10 over time we see we have three excitatory three inhibitory neurons that are firing spikes and the latent readouts so we have the excitatory readout in red the inhibitory readout in blue and from the simulation the spikes are yielding the excitatory readout to follow this this particular function um okay so you'll have to take my word that this also uh can be expanded to higher dimensions and it turns out that (15:34) it's quite a it's quite a powerful approach because it actually maps onto a particular optimization problem a Minimax optimization problem and this has a lot of connections to different things in the field uh I think I'm running a bit out of time so uh I will skip over that but uh but essentially um we think that this this is a promising approach for for scaled up computation so with that all summarize um what I've shown you here today is that low rank spiking networks can be seen to represent latent variables (16:03) um and they form different types of boundaries depending on if they're excitatory or inhibitory when we couple excitatory and inhibitory boundaries together we get stable Dynamics and we get uh systems that can do Universal function approximation so in future work we're hoping to scale this up um and we should have a pre-print out about this work very soon I would just like to finish by thanking a couple former members of the machines lab Senator kimik and Alan menku whose work was very inspirational for this as (16:28) well as the rest of the mockings lab and our funding sources and I'll finish there thanks okay thank you very much uh bill so we have a couple of questions okay one is by us four votes by Dean runs I might have missed it but is this is a fixed point uh globally stable or do uh y e and Y I need to be carefully initialized so uh it basically depends on the the overall shapes of these boundaries so here you'll notice that in this picture I I kind of at some point this excitatory boundary becomes a dotted line which is (17:12) basically that we wouldn't want this excitatory boundary to continue and and end up surpassing the inhibitory one so as long as the inhibitory boundary here keeps uh keeps kind of winning out over excitation it will be globally stable so there are essentially there are uh [Music] um probably Dan this is really neat what's what is still required to scale this approach to larger problems uh okay thanks so much for that question because it gives me the opportunity to briefly mention uh some stuff that I that I lost (17:53) over here so so one approach is is basically converting deep Nets to spiking Nets and essentially there we could we could basically use these neural boundaries so we would basically train the Deep net and then use these neural boundaries as function approximators and fit that function but I think a more promising approach is this mapping to an optimization problem so there's a lot of work in in deep learning that that is looking at using deep implicit layers which are basically replacing a deep net layer with an (18:22) implicit function which could be an optimization function or an equilibrium function and you can train directly on that so the idea would be we could actually train on this optimization problem and then we would have a direct mapping to a spiking Network so I think that's the most promising approach for scaling this up okay well uh thank you very much Bill and we have more questions but I think it's time to go to the other uh to the other talk so thank you again for your interesting talk [Music],"In this video, the speaker is discussing their work on using excitatory inhibitory spiking networks for universal function approximation. They propose a new approach called ""spike coding"" which falls between rate coding and temporal coding. Spike coding networks, which were started by Sophie Genev and later continued by Christian Mukins, have been criticized for only working with toy models. However, the speaker argues that this approach offers greater interpretability and geometric intuition compared to other methods. The speaker also introduces an assumption of low rank connectivity in the model, specifically rank one, to simplify the analysis.",ChatGPT,,,,,,,,
https://www.youtube.com/watch?v=haHGLI6Ja4M&list=PL09WqqDbQWHFjkkXiQdOYC1wAdgSUMGxQ&index=4,2022,SNUFA Workshop,Alessandro Galloni,Rutgers,Behavioral Timescale Synaptic Plasticity (BTSP) for credit assignment,Learning,(148) Alessandro Galloni - Behavioral Timescale Synaptic Plasticity (BTSP) for credit assignment - YouTube https://www.youtube.com/watch?v=haHGLI6Ja4M Transcript: (00:04) and hello again back to this next session now with our next speaker Alessandro galloni uh who is at Rutgers and he works on behavioral time scale synaptic plasticity so back to biological plausible here looking forward to your talk great thanks Peterman so hi everyone thanks for joining thanks for the opportunity to present so today I'm going to talk about a synaptic plasticity mechanism which was discovered in the hippocampus called behavioral time scale synaptic plasticity and I'll talk about our efforts to implement an abstract version (00:39) of this that can perform credit assignment in artificial neural networks so kind of one of the the interesting question in learning and memory research is how can the brain propagate outcome or error information between neurons to coordinate plasticity towards Global Network objectives so this is what we refer to as credit assignment uh and in the last few years there have been several recent approaches to doing this biological plausible credit assignment I've just listed kind of a few of the more notable ones here and kind of and (01:11) one of the big Innovations sort of in in this field has been drawing inspiration from pyramidal neurons in cortex and specifically looking at their apical dendrites as a form of specialized compartment that's dedicated to processing error information and as well as combining this with other biological building blocks like somatic or dendritic interneurons um and so by taking inspiration from these biological features um these authors have come up with different rules that that do biologically possible credit assignment (01:46) and in some cases approximate quite closely the weight updates that you would get by using gradient descent and back propagation and and that's generally kind of seen as the goal you know to try to uh as closely as possible approximate back propagation for at least for these previous networks so today I'm going to show you our approach to this problem which is specifically inspired by some more recent experimental findings on how synaptic plasticity works in the hippocampus and I'll sort of describe a little bit (02:14) what's what's different about this approach so I want to start from the biology and I'll start with kind of three key insights that we're going to draw on uh so the in the first one is that in the hippocampus then you can get neurons that have dendritic Plateau potentials and these dendritic Plateau potentials can rapidly produce stimulus selectivity in silent neurons so here we see a recording from a from one of these hippocampal pyramidal neurons and um initially the neuron is silent the inputs are too weak to drive it to fire (02:47) anywhere in this environment now once in in the second lab of this environment we see this large depolarization called the dendritic plateau potential or a calcium Spike and kind of in a single trial in a One-Shot way this has strengthened some of the inputs which make the cell now become stimulus selective for part of this region of this Arena okay Insight number two is that these plateaus can be controlled by both top-down input as well as inhibition from local interneurons so um here we see a recording from a ca1 (03:22) pyramidal cell in which the top down input can act as this a critical trigger for driving this dendritic calcium plus Spike this Plateau potential um and uh and what we see on the right here is that the pla is that the plateau potential can be suppressed if we directly drive a local dendrite targeting interneuron so we can kind of specifically control just the plateau and separately from controlling the activity of the neurons okay and the third point I want to make about from the biology is that the induced (03:52) plasticity is actually bi-directional so you have different synapses that can either potentiate or depress simultaneously and this depends on their initial strength and also on the timing relative to the plateau potential so what we see here is that the same cell as before it has an existing Place field in the center of the arena and now in lab 4 a new pla a new Plateau potential arrives at a different location and this causes two things to happen simultaneously now the first thing is that the inputs that are active close to (04:21) the new Plateau potential they get potentiated and that results in a new place field at this location the second thing is that the previously strong signups is that we're we're driving the cell to fire at the old place field they become the pro they get depressed so that the cell becomes silent in that region and kind of we see a summary of that here on the right where synapse is either potentiate or depress based on timing from this Plateau so if they're close to the plateau they potentiate if they're far they depress (04:50) and this is modulated by the initial weight of the sinuses so weak synapses primarily potentiate whereas synapses that are already very strong have a much uh Stronger bias towards depression um okay so so that's the biological inspiration so how can we model the mechanics of this so one way we can model this is through um as an interaction between like a slow eligibility Trace that's generated by the presynaptic spikes and an instructive signal that's generated by the dendritic plateau so when the delay is large or for (05:28) example if the firing rate is very low now the overlap between these two signals is going to be small and that will favor depression conversely if the overlap between these two signals is high or if for example if the firing rate of the presynaptic neuron is very high that would cause a larger eligibility Trace then that would favor depression um so we might so we might imagine a synapse that is of intermediate strength could experience I both put either potentiation or depression depending on this firing rate a sign up that's very (05:59) weak would would favor potentiation whereas a synapse that's very strong would favor depression um Okay so we've now abstracted these principles into a rule for doing supervised learning in networks with kind of simple two compartment units and the implementation that I'm going to show you today is actually an analog rate neurons but we do think that we could kind of uh export the same principles and make them work in spiking models and that's something that we're planning on doing in the future (06:32) um now like in biology this learning rule depends on pre-synaptic activity it depends uh on the dendritic plateau and it depends on the initial weights so here the the equation that we've derived has two components it has a potentiation process and a depression process and these are modulated by the dendritic plateau as well as by the previous existing weights so as the weights increase then the ratio between the potentiation process and the depression process change and that will favor uh depression or now kind of as proof of principle that (07:10) this can work in a multi-layer setting we've implemented a network with a single hidden layer and units with dendritic compartments and during learning the the output layer learns by having Target activity directly driving Plateau Potentials in the output dendrites now to propagate this error information the plateaus increase the activity of the output units which which then drive the hidden dendrites so this increased feedback drives the hidden dendrites and the local loss at the level of the Hidden units is encoded in this (07:43) dendritic activity which results from a balance between the feedback that they're getting from the output layer and inhibition from a local dendritic interneuron which um uh yeah and so and if this hidden dendrite activity crosses a certain threshold then a plateau is generated and this will induce plasticity in the input to Hidden weights um and so this dendritic interneuron kind of helps regulate the the number of plateaus in the hidden layer and and uh and keep that the learning in the hidden layer and check (08:14) um so I'm going to show you now uh kind of results on a on a toy model but it's a simple one heart Auto encoder task and although this is a simple task it does have some interesting properties uh so for one it it requires effective multi-layer error propagation um because it has a hidden layer and the way we've implemented it is this Auto encoder has a reduced dimension in the hidden layer and this forces the network to learn kind of a compressed represent combinatorial representation uh at the hidden layer so not just the simple (08:48) identity function but it's still small enough that we can kind of easily interpret what's what how the network is learning and what what weights it arrives at so um so for comparison I'm going to show you two models trained with exactly the same architecture one is trained with this btsp learning rule that I've just described and another one is trained with backdrop and so because this is a relatively simple test both networks learn to perform with perfect accuracy relatively quickly and so this is kind of a good (09:22) first validation that our learning world is working as intended um but uh not to understand how the learning rule is working and how it behaves we can then look closer at what Solutions do these networks converge onto and so for example by looking at the final activity representations in the hidden layer we can already see that there are some interesting differences in in this in the final Solutions even though at the level of the output layer they look the same um so let's dig into this a little bit more and so to get a better sense of how the (09:53) networks differ during learning um what I'm going to show you is is how the learning trajectories for the new for the two networks navigate through the last landscape so so this is a dimensionality reduced representation of this High dimensional loss landscape so this is in in weight space and we can see that back prop here this that's using stochastic gradient descent directly follows the gradient straight down the Lost landscape and arrives at some minimum btsp on the other hand actually initially almost seems to move (10:25) in the opposite direction to the gradient but then converges on a local minimum in a different region of the Lost landscape um and you know we can see that these are actually quite different solutions to you know to the same problem uh and you know we can already get a quick sense of that by looking at the distribution of Weights that they converge onto which are quite substantially different which suggests that the btsp learning rule is really doing something that's maybe fundamentally a bit different than (10:52) gradient descent and and I've specifically occupies kind of a narrow region perhaps of the white space the weights are not quite as broadly distributed um well the last result I'm going to show you uh today is kind of a slightly modified version of this same task uh so in this case what we do is we first train the network on only a subset of the inputs and then in the second phase we train the networks again but this time we show only held out patterns so we do so we're sort of doing a simplified continual learning task (11:25) now as before what um the both networks are able to perfectly learn the initial set of training patterns um and get 100 accuracy so but what's interesting is what happens in the second phase so as we train the network on these kind of unseen new unseen patterns um the uh yeah so then back prop actually experiences a substantial amount of catastrophic forgetting of the old patterns as well as interference by the new these new units which are interfering with the representations learned by the old pattern and that and (12:01) that effectively dramatically reduces the overall accuracy of act over the whole set of patterns and btsp on the other hand seems to be much more robust to this and still manages to encode all of the patterns with relatively high accuracy and and this might be kind of a consequence of of perhaps the The increased level of sparsity that that we get in the activities or in the weight matrices of these final learn Solutions um that that decreases the interference between the new learn patterns okay so just to to summarize what I've told you (12:36) uh today I described a biologically plausible learning rule which was inspired by experiments in the hippocampus the way it updates depend on the interaction between existing weights uh presynaptic activity and post-synaptic Plateau potentials and um and the the dendrites encode the local error which is computed by a local microcircuit that involves dendritic interneurons uh and I've shown you a simple implementation that demonstrates learning good representations across hidden layers uh in a in this like rate (13:12) neuron Network um and and finally I've shown you that the this learning rule seems to converge on different solutions than backdrop and that and these different solutions that is 10 that is biased towards might make it more robust to something like catastrophic forgetting during continual learning tasks uh so finally I just want to thank the people who've been involved especially Aaron and AJ who's who've been really uh instrumental in all of this uh okay thank you great thank you um so we have a couple of questions (13:46) um so first question uh is Again by Sandra kimming um neither back prop nor btsp would consistently find the same local minimum for different initializations do they find consistently different solutions across a range of inits that's uh his question and maybe I can just piggyback onto it it's like in your plot it seems like you even the initialization was slightly different so uh sorry here we go um yeah so so the the initialization is slightly different and in fact they do have different preferences for initial (14:21) conditions so I mean it's well known that back prop as well is not immune to to random initializations there there are certain initializations which work a lot better than others that's also true of btsp um and btsp the the preferred initialization seem to be with lower initial starting rates so we've sort of we've tried to find us here some reasonable compromise with their relatively close initializations but still each slightly optimized words the preferred optimization for the given learning rule (14:51) um now they they do converge like the the weights distribution and are quite different but yeah we still need to kind of Explore More all what the what the possible solutions are across a much wider range of initializations but but but actually one thing that I could point out here is that um because in the nature of this learning rule uh let me if I just pull this up is that actually postsynaptic activities in fact not required at all and and you could in principle have a network learn with zero initial weights (15:23) zero initial weight zero initial activities and have just the plateau potentials driving driving the plasticity so that's something that obviously would not work at all in background because if you have zero initial weights then you have zero gradients and the network wouldn't learn so there are kind of some fundamental differences in how and how the kind of initial conditions affect the network performance and so um so yeah so I think I think they would they would be quite quite different uh consistently yeah (15:50) okay um another question by Michaela Nardin is is the lack of catastrophic like actually two questions the first question is is the lack of catastrophic for getting due to the sparsity of the weight matrices and the second question if you start from the same initial conditions would btsb and backpack converge to the same local minimum I guess that one you already answered now because of only the first question is the lack of kind of story for getting due to the sparsity of the weight matrices um yeah so so that is something that (16:19) we're still basically looking into we we suspect that it is that that effectively it converges on solutions that tend to have kind of relies on a smaller subset of Weights so have kind of few strong weights as opposed to many broadly distributed weights that take on many different values um and so we that's that's our suspicion that that is that this is what's kind of underlying the fact that when you introduce new patterns you're less likely to get overlapping overlap between these representations because (16:46) you're relying on a smaller subset of Weights but but uh yeah we need to kind of validate that a little further um but but certainly the solutions do seem to be quite different in terms of the final the final Minima right and then there's another question which kind of perhaps important so that's Jamie Knight asking uh is there a paper the crowdcast talking heads always covered up your references yeah yeah the paper is coming but yeah we have it we haven't published this yet but that's all right is there any any (17:21) references you want to show then you could move your slides right now and then and then they could see but if the paper is coming then maybe they're not so crucial the ones you you yeah no yeah so the paper for this specifically is still coming but yeah we you can we we can have uh just the references for the the experimental stuff that that are like for example here the experiments that these that these paper that these uh principles are based on great very well thanks so then um another question is how does btsp perform on more complex (17:50) tasks so how does it scale or what does scalability compared to back prop and stdp and other yeah um yeah I mean so we are working on on trying to get this to work on like like an emness task for example that is that is sort of maybe one level up in terms in terms of the complexity of the task um and so so now we figured as we first we wanted to verify that that you can actually learn and propagate errors you know in in a network that's so simple that we can easily interpret exactly what's going on in in all we can really (18:22) visualize the weight matrices and and see what's happening and and already basically have a sense for what a good solution would even look like which is you know we can sort of handcraft uh what what uh what one example of an optimal solution could look like and that's something that is a little trickier to do with it with a more complex test so but so now that we've kind of have this validation we can then we can try to scale up so that so hopefully it'll work on on scaling up to larger tasks but that's something we're (18:48) still working on right so that would have been very also entail adding layers in the sense that for one question you want to look at yeah you could I mean usually at least with MNS test you don't the networks don't are you can still get good endless performance on networks with only one or two hidden layers so you don't need you don't need to massively scale up the complexity of the architecture in order to get to to do that yeah and so I have a question that's but maybe you probably can bring up the (19:16) slide in the very beginning again where you show the architecture of your neurons and I was wondering whether you could relate it and maybe point us towards a little bit these commonalities and also the differences of this um algorithm or this learning rule with regard to the work by Sacramento and Walter Zen that you perhaps familiar with sure yeah so um I think it's it's somewhat similar to the Sacramento work in that uh that we do that the dendrites act these Plateau potentials and the dendrites they do they are connected to (19:53) the Soma so they are going to bump up the activity of the level of the Soma uh now one kind of difference is that we're not doing the spike multiplexing that that's like like for example the burst prop papers are doing so where so where there's like an actual um kind of segregated signal for for bursts and and and regular activity uh and and which in theory is based on on this notion of of uh like short-term facilitation and depression at the level of like synaptic terminals uh so we're not we're not doing that we're directly (20:25) propagating actual activity um and and the the difference is that you know here at in the hidden layer um the computation happens in the dendrite thanks to the interneuron which is basically trying to effectively predict the the Baseline activity that's coming from the top down and then trying so it's almost it has a flavor of predictive coding where it's trying to trying to predict and cancel out whatever is coming from the next layer and make it sort of a local prediction of what it expects the feedback to be (20:55) cancel that out and then so when you get this target information coming through that's an unexpected increase in activity and that passes through this filter and and so drives these excessive plateaus um so there so there are kind of yeah some some differences in that respect and then of course the weight update itself is is is different and for example the fact that it's weight dependent um and so on and uh and and actually kind of one thing maybe I could I can point out here is that uh sort of one one way that we envision also the fire (21:25) the like the gradient information going or the kind of the loss information that's trickling through these Plateau potentials that could be you know how do you steer it to go in either positive or negative Direction and kind of one way we envision that is is by thinking about um like the the timing and the fact that you can you can steer a synapse towards potentiation or depression by altering the timing of of the plateau potential so if you could if you delay the paletto potential you know if we if we imagine (21:55) like a spiking implementation you could delay the plateau potential and that would tell the synapse or you have to depress rather than potentiate uh and so so that's how you can get kind of a more modular loss in from Nation going through the the plateau potential in combination with the present integrate okay awesome thank you very much um so thanks a lot for this beautiful talk thanks for the questions unfortunately I think I missed one but please reach out to the speaker to ask the question um so we're at the end of session two so (22:26) it's really been a fun day thanks to all of the speakers um of session two and so we have now again a half an hour break and then the poster session starts uh just a quick reminder sign up for the Eventbrite so you get the emails with link the link is also here on the side right now um and in the chat so Dan just posted it there as worldwide neuro and so in half an hour you can go there with zoom in a zoom to connect and there will be breakout rooms for each poster the poster program is on the snoopa website (23:00) so it's uh snoopa.net 2022 and you will find a list of all abstracts there and then according to the last names you can choose the breakout rooms and basically run the process I hope you enjoy it um and I hope I'll see you there thanks again and for this beautiful talk and um and thanks for a great first day to all the speakers today all right thanks everyone bye,"Alessandro Galloni is a researcher at Rutgers who works on a synaptic plasticity mechanism called behavioral time scale synaptic plasticity (BTSP). In this talk, he discusses efforts to implement an abstract version of BTSP that can perform credit assignment in artificial neural networks. He explains how this approach is inspired by recent experimental findings on how synaptic plasticity works in the hippocampus, and describes three key insights that inform the approach: that dendritic plateau potentials can rapidly produce stimulus selectivity in silent neurons, that these plateaus can be controlled by both top-down input and inhibition from local interneurons, and that the induced plasticity is bi-directional, meaning different synapses can be either potentiated or depressed simultaneously depending on their initial strength and timing relative to the plateau potential.",ChatGPT,,,,,,,,
https://www.youtube.com/watch?v=bJfSevp9g1s&list=PL09WqqDbQWHFjkkXiQdOYC1wAdgSUMGxQ&index=5,2022,SNUFA Workshop,Bojian Yin,IMEC,Training Dynamic Spiking Neural Network via Forward Propagation Through Time,Learning,(148) Bojian Yin - Training Dynamic Spiking Neural Network via Forward Propagation Through Time - YouTube https://www.youtube.com/watch?v=bJfSevp9g1s Transcript: (00:04) all right okay so it is my pleasure to introduce our third speaker the last the last one of the session uh his name is sorry his PhD with Sunday Alberta big name in speaking neural networks and he does research on snn training and with a special emphasis on the neuronal Dynamics we are looking forward to your Talk version okay hi uh hi team yeah uh thanks giving me the chance to present our current work training Dynamics back in neural networks my forward propagations through time this project has been done together with Federico (00:46) karate and sandovalty so in the title we figured out I have two things Dynamics back in your networks how to navigate can be and the second is the fourth propagation store time how can we using these things to train our spec in your network so thanks for the previous talks it's a very informative and interesting so people now they already know what it is back in your networks and how it works so but I would like to briefly go through I mean in my view how the strike in your networks works so we have training neurons in our brain and this (01:20) neurons they communicate with each other using binary spikes and sparsely connected using synapse once a spike came approaching the synapse a series of the biochemical reaction where reason of the membrane potential of this neuron and the number of potential will be transferred along in the neurons during the transformation with the normal potential the normal potential will be leaky as this leaky property had to be determined by many parameters for example the type of a neuron the third the life circle of the neuron or the (01:53) neuron behaviors or it also depends on you are sleeping or not so our neurons is far more complex than what we can imagine and some people they also find they may have some Quantum mechanism inside we do not want to know this deep but we can simplify these mechanisms for calculation to know how can we generate the spec in neural networks just a based a simple leaky integrate and fair neurons where the time constants tall is used to dominant the Leaky property of the normal potential so the spikes come from the different synapse (02:29) at a different time and the number of potential will be accumulated and involved in this procedure once the manual potential reaches the thresholds the neuron can emit a spike and send it out to the next neuron and resets the normal potential so we can easily convert this mechanism into a computational manner so we have the computational figure in this in this way where in the leaf neuron the memory potential shows shows in the self recurrency it involved along with the input along with the time but the time (03:03) constant has been controlled by its time constant or iron in previous papers people use them as a fixed term or learnable term but in our brain it's a far more Dynamic and how can we make them more Dynamic and this module of the specking neurons is equivalent to to what we know is this vanilla recurrency neurons where the hidden States is also involved along with the time but the involving of the Hidden States is determined by the recurrence connections which is the big Matrix but for now we already know that such a spiking neuron (03:39) is a recurrency neurons which much more complex internal circles so if we know that it's back in neural networks is recruiting neural network the answer of how to train in such kind of network is very obvious and clear we can easily using the background back propagation through time which are widely used into training recruits in your networks to training our respecting neural networks with half of the service gradients in last several years it already shows very good result in control tasks like image classification (04:14) sequence classification in some control tasks and even in something about much more complex but um One Way using the bpdt for the spike in your natural training we may facing two main problems first conceptually the bpdt works by unfolding the time steps to calculate the gradient so the greetings calculation requires to store all the hidden States imagine if you have super long sequence the memory you caused on your training will be linearly increasing and it cannot be feasible to training such a spec neural (04:50) network on a single GPU but our brain is much more energy efficient we do not need such a big Ram to train our networks the second problem is because the existence of the sum of the products in the temporal Dimension gradient calculation the image result in the gradient Vanishing and explosion and these two problems is much more serious in the trainings back in your networks because first the spiking neuron will have more hidden States we have members Financial spikes and maybe adaption circuits and other things we want to add (05:26) and the second problem is we have much more complex complex internal circles which may also increase in the risk of the gradient Vanishing and explosion so if we want to training a deeper spec in your networks on a longer sequence for more complex tasks going to looking for a more effective and efficient learning algorithms which able to have which able to train your hours back in neural network in an online manner but we all know that currently in such online learning algorithms are limited to training shallow networks single layers (06:02) are two layers but how can we go deep so in 2021 the cow introduced the axon for propagations or time to training recruit engineer networks here we want to explore can we using this algorithm to train our spec in your Networks so in comparison with the bpdt if you check the compositional figure on the right side you only see the gradient calculation along the spatial Dimension there is no gradient has been calculated along the temporal Dimension so how the network can learn the temporal information without the gradient (06:36) calculation along the time so in their paper they introduce the synaptic weights with synaptic trace for each weight and these Trace are used to store all the past loss summarizations at every time steps when a network wants to update the parameter then extract the loss information from the synaptic trees and feed it into the dynamic Regulators then the network only using the BP to learn both spatial and temporal patterns in the network updates so actually for every time steps we have our loss has two components first is instantaneous (07:18) loss our prediction loss seconds is regular loss we call Dynamic regularization loss which determines how much we want to learn from the previous history so with this kind of mechanism we can train in such a kind of recruiting your network without store the hidden States we just need to extract the historical information from the trees instead of store them so with half of this mechanism which allows us to train in Long large spiking neural networks weighs less GPU cost so it also allows us to training the network on longer (07:55) sequence the second things we got for phrase if you check the computational figure you can say because there is no gradient calculation there is no greetings calculation along with the time so yeah okay you're back uh so there is no greetings calculation alone with the time so the competition figure is much more clear which we can say the gradient calculation is more robust so it's much more friendly for our specular neural networks because the surrogate gradient is approximation of the true gradients (08:30) so here we try to explain more details about these algorithms because the limit of time if we want to know more you can email me or contact me I would like to share my understanding of these arguments but basically the networks Works in this manner for every time for every time steps when you want to update to the network you have Insidious loss and regular laws you updates your network based on this loss and you can base the the current loss and the new weight to update your choices and these three things I used to store the (09:02) historical information to make them our activity works better we introduce a liquid time constants back in neural networks with Dynamic creating in comparison with the traditional Leaf neurons where the time constant is just a fixed number it can be initialized and trained but here we want the neuron can determine the time constant by the inputs and the neuron States itself so we introduce the liquid time constant where the time constants has been calculated based on both inputs and current neuron States so it's a player (09:36) role like kind of a gating mechanism in the constants calculation so it's a player role more like as a group neural networks it gives the spiking neurons more dynamic so we want to verify our idea we're using the adding task as a toy task to verify our LTC news and fptt so in the adding task we have two dimensional inputs the First Dimension is the floating number from 0 to 1 and the second dimension is a binary vectors with only two ones it may look at the two elements we want to add them up at the end so we take the sequence with (10:13) 1000 time steps and using the pptt with rstm as a baseline performance so when we train our traditional adaptive spiking recruiting your network and the liquid time constants back in neural networks with ppdt that converge to the same level as Baseline performance but when we're using our liquid time constant to train with fptd the network converts to near Zero Performance it performs Super good after we verify our idea we want to say how far we can go can we really gaining that kind of memory efficiency on the (10:47) train on the training so we move our eyes on the DVS gesture datasets it has 11 gesture kind of gestures and for each sample in the data set is one second of the action captured by DVS camera So based on the different frequency unsampling frequencies we can convert these videos into different lengths of the sequence from 20 frames to thousand frames for this kind of task we're using a shell Network to verify the memory use so here we're using pptd and fpptd to train in different kind of neural networks you (11:24) can see that for all the neural networks the trained using bpdt are failed to train them on 1000 frames because it's out of the memory on these shadow networks and a second you can also facing there is a performance Decay one we have longer sequence but the performance of both adaptive specular neural network and the liquid time constants back in neural networks it's quite stable and they can even get better performance on longer sequence for the liquid time constants back in your Networks we show the accuracies we (11:56) want to say do we really see in the training memory here we make the plot of the memory cost on the training but we figure out that for both ppdt and fbtt the memory user both increase it's not what we expect we wanted the RPD only using constant amount of memory but why it happened finally we figure out because when we unsampling the data using different frequencies the data sets itself also become larger and larger so we're using another task to verify this we're using the read coded minist where the input datset is a fixed (12:31) the size but you can generate any long sequence you want so in this experiment we can easily say that the amount of the memory required for pptt to train a spec in your network is the linear with the lens of the inputs and that of the Affinity at its constants so it saves a lot of memory maybe we can train it a little different neural networks so here we compared our networks with several online learning Baseline modules but we are using different neural networks so we can easily outperform the other online learning algorithms and we (13:06) also compare our performance with offline social numbers currently using bpdt our networks and everything together could be achieved or excited the near offline accuracies so with this kind of high accuracy and improves the memory efficiency we want to go one step further so we move our eyes to the object detection task the spec in Euro there you have several papers already been done based on the conversion but in the conversion they have two problems the first is like for the conversion the simulation time is quite long the (13:40) network requires hundreds of thousand time steps and the second problem the sparsity of the network cannot be guaranteed so with the improved based on the Improvement on fvdt now we can train in a tracking your method to do this task from scratch so our Network are based on the 10 euro before architecture with 21 convolution layers about the 6. (14:04) 2 meaning neurons with 14 million parameters the network has been trained on four to eight frames and the training memory with fbd is about 14 gigabits so you can imagine if you want to change such kind of task on bptd maybe you need the four or eight gpus but for here we just need a single GPU and our networks achieved a new Sota on the possible VOC data sets so because we know that our networks only takes a full eight frames to draw the Bounty box for this task and in the video they have no big difference in the nearby frames so we can create a (14:41) demo for that and um yeah if we have time finally I can show you the demo but here I can conclude in this paper we introduce the four applications or time for the spec in your natural training which shows the we can use constant amounts of memory to train any lens of the sequence than ppdt we also introduce a liquid time constants back in neural networks which gives mod Dynamic for the specking neurons and together we illustrate that our liquid time constants expecting neural networks with the forward propagations through time are able to (15:16) conduct online learning of a large specular module on a longer sequence with the guarantee of the high performance and even with benefits of the constant training memories if you want to know more welcome to contact me but here I can show you a small demo of the Yule architecture and I turned it into the real speed so here is a wheel of Armstrong you can see that our network is running on the real videos of 4K videos is also quite good but uh the bonding box is not that stable but with the further optimization it can be it (15:55) can be done that's it uh thank you team any question yeah thank you very much very cool talk yes I've seen that we have two two questions first one by Thomas Novotny uh how does fpt is also a forward eligibility traces uh it's a super good question because one way into this field to do the online learning we always want to compare with the eproc the first thing we want to mention is like from now the epro only applied on the shadow neural networks and this network we are local in time and we will be able to train in (16:37) different neural networks but we also believe that the eprop can a can be expanded to training a different neural network but I think they are total different for the rpdt we require the label for every time steps or for every Transitions and we are using kind of common filters try to make the network try to recreate the direction of the width optimizations so it's different from the e-prop it's more closed as a variant of the BP instead of bptt I hope this can answer the problem if not welcome to send an email yeah (17:16) I think it does um we have another question by John Cena just to make sure I understood you correctly with fptt you don't do any gradient computation across time purely in space meaning you can get away with not doing temporal credit assignment at all is that a feature of the additional term in the learning rule or of the LTC neon I think you saw the temple credit assignment don't you yeah it's a kind of solving the temporary in assignment because they are using they store the historical information with the (17:50) approximator of the future laws under the gradient then based on the mathematical works you can convert this kind of traces information into the regulator loss then you can just based on BP which do not serve based on the chasing back but you take the historical information already out of the synergic traces and for the RTC news because uh at the beginning we wanted to work for the traditional adaptives back in neurons it doesn't perform Super well so in adding tasks that doesn't really converge so we introduce we figure out (18:26) that fptd performs much better with the getting mechanism so we introduce the RTC neurons which can perform such kind of a group like Behavior here or the dating mechanism they're working together which have the same performance and like the rstm with the fpg so there's a reason but there's no specific learning rules for the RTC neurons you've just seen using the BP the magic of the auto great yeah okay and we have learned one last question by Michelin Nardin can you extend fptt to others packing your own (19:03) models Beyond leaf data sets um we apply the easing convention neural and oxygen huxo models which are harder to train before we think our FDT now we can train in them to achieve quite a decent number but with much more biological realistic neuron types so we think that because the competition graph is much more clear it's a robust to the gradient calculation so maybe we can use a more biological realistic neurons within futt and yeah the answer is yes yeah okay so short answer yes good well thanks again and I think it's time to to (19:50) stop so so now we have a a 15 minutes break I think and then we have a zoom meeting for the general assembly yeah exactly um do everyone please come along to that I'm just gonna put that in the chat basically just to talk about uh what we can do in this community and maybe how we can make things better ideas for future meetings and things like that and if you don't want to come along to that there is also the next session of talks um which is which is a little bit later than that all right thanks everyone (20:24) okay thanks to all the speakers and see you soon,"The speaker is discussing their research on training dynamic spiking neural networks (SNNs) using forward propagation through time (FPTT). They explain how SNNs function by communicating with each other using binary spikes and sparsely connected synapses. The speaker also touches on the complexity of real neurons in the brain and how they can be simplified for computational purposes. The speaker then explains that because SNNs are recurrent neural networks, the answer for how to train them is obvious and clear using the widely used backpropagation through time (BPTT) method. However, the speaker notes that there are two main problems when using BPTT for training SNNs: conceptually and computationally.",ChatGPT,,,,,,,,
https://www.youtube.com/watch?v=gj67eUlPhG8&list=PL09WqqDbQWHFjkkXiQdOYC1wAdgSUMGxQ&index=6,2022,SNUFA Workshop,Anand Subramoney,Ruhr-Universität Bochum,Beyond Biologically Plausible Spiking Networks for Neuromorphic Computing,Generic introduction,(148) Anand Subramoney - Beyond Biologically Plausible Spiking Networks for Neuromorphic Computing - YouTube https://www.youtube.com/watch?v=gj67eUlPhG8 Transcript:,"Anand Subramoney, a postdoc at the Institute for Neural Computation at Ruhr University Bochum, is discussing the use of spiking neural networks for neuromorphic computing and whether these biologically inspired networks are optimal for deep learning on neuromorphic devices. He argues that in order to achieve optimal performance and energy efficiency, deep learning architectures need to be designed from first principles for neuromorphic devices. He suggests that the essential properties of spiking neural networks, such as sparsity and event-based communication, should be distilled and used to design new architectures. He also mentions that other properties such as asynchrony and arbitrary event dynamics can also be considered in the design of these new architectures.",ChatGPT,,,,,,,,
https://www.youtube.com/watch?v=T3s-R4vXtZs&list=PL09WqqDbQWHFjkkXiQdOYC1wAdgSUMGxQ&index=7,2022,SNUFA Workshop,Panayiota Poirazi,FORTH Hellas,Why dendrites matter for biological and artificial circuits,Theory,(148) Panayiota Poirazi - Why dendrites matter for biological and artificial circuits - YouTube https://www.youtube.com/watch?v=T3s-R4vXtZs Transcript:,"The speaker in the video is discussing the importance of dendrites in biological and artificial neural networks. They explain that dendrites play a crucial role in cognitive abilities and are responsible for over 90% of synaptic connections in excitatory neurons. They also mention that dendrites have the ability to generate non-linear regenerative events, called spikes, which can be mediated by different types of ions. The speaker also mentions that dendrites have the capability to integrate incoming signals in complex ways and have been suggested to serve as independent computing units. They also briefly mention a software that has been developed in the speaker's lab that allows for the easy implementation of dendrites in artificial neural networks.",ChatGPT,,,,,,,,
https://www.youtube.com/watch?v=J90TF8OZ61w&list=PL09WqqDbQWHFjkkXiQdOYC1wAdgSUMGxQ&index=8,2022,SNUFA Workshop,Charlotte Frenkel,TU Delft,Merging insights from artificial and bio NNs for neuromorphic intelligence,Generic introduction,(148) Charlotte Frenkel - Merging insights from artificial and bio NNs for neuromorphic intelligence - YouTube https://www.youtube.com/watch?v=J90TF8OZ61w Transcript: (00:00) all right okay hi everyone uh welcome to the last session of three talks for stupid this year um we have uh Charlotte Frankel from dieselft who uh is basically in her talk title trying to hit every single topic that we're interested in in sniffer so we've got artificial neural network which we've got biological neural networks and we've got neuromorphic all in one talk so uh yeah so this is going to be pretty cool and perfect for this community I think Charlotte please go ahead thank you plan for this great (00:31) introduction uh so indeed in this talk I'm going to talk about how to merge insights from artificial and biological neural networks for neuromorphic Edge intelligence and more specifically we are going to cover three main questions so the first one is how should we exploit and make the best of the synergies between neuroscience and Ai and more specifically what is the right perspective and the right starting point to make the best of these series the second point is why should we bother at all with Neuroscience actually and the (00:57) third point is how can we move these questions into interesting engineering Solutions so we'll go all the way from science to engineering so with this playing in this menu let's start with the first point uh how to explore the synergies between your science and Ai and more specificities look at the perspective so we have this bi-directional interaction between neuroscience and AI so there are really two ways to go the first one is from Neuroscience to Ai and basically the goal is to identify what are the brain computational Primitives (01:27) what are the key ones and how to scale them to AI oriented workloads so this is really an approach that is grounded on science and for example what we have seen yesterday with the dendritic approach it's very much aligned with this way to go from Neuroscience to and how to scale it to AI um but actually there's also another way to go which is to start from existing AI algorithms so for example backdrop and how to align it with Neuroscience inside so this this is not really about engineering so you are going to engineer (01:54) your algorithm in order to align with neuroscience and this is for example the whole field of bio-inspired backpro uh but the problem is that it's still quite unclear what is the right perspective on to what is the best way to go should we go for science or the engineering part and I think uh we we miss a perspective and the standpoint that we'll take in this talk is actually that Hardware forms a very interesting middle ground to shift some light as to how should we make the best of Neuroscience in ER (02:24) um and so let's look at the synergies from AI to Hardware we have an obvious scenery that is that AI without Hardware isn't sustainable so most of you are probably familiar with this kind of graph showing how the training computes requirements scale over time for popular AI workloads um so we were used to a scaling of about 15 times more compute every two years but now even with the Transformer models now it's even going about 700 times every two years which is completely unsustainable because when (02:55) you look in more slow you gain from technology progress only about Factor two every two years so the only way to scale is completely and sustainable it's about scaling the size of the GPU server forms and if we do not take Hardware into account and make Hardware more specific to support the scaling at some point the scaling will have to establish your economic constraints so that's one way to go this is the obvious Synergy between Ai and hardware and actually there are also synergies between neuroscience and hardware and this these (03:22) are less obvious so they deserve a second point in this presentation why should we bother at all with neuroscience and let's recover what are the synergies between your science and hallway so I told you there are two ways to go so let's start from the first way to go uh going from Neuroscience to hardware so here we'll focus on one specific case which is synaptic plasticity and this will take Neuroscience as a starting point so when we talk about cinematic elasticity usually the main starting point is stdp or spy timing dependent (03:51) plasticity whether it's the right starting point is another question but for the sake of this goal for now let's focus on this TDP so sddp is just postulating that every time you have a pre-synaptic spike before a postsynaptic spike uh you have that the relationship is causal and you will potentiate your synapse if it's anticosal so the postsynaptic spike comes before the presynaptic spike then you will have to depress your weight so this is about the cinematitis in between these two neurons and this is a (04:17) local learning rule and there's actually another way to formulate a quite similar learning model which is Spike dependent synaptic plasticity or sdsp for short focusing this paper so the figure itself is not very important what you have to remember is that now the mechanism is that for every presynaptic Spike you look into the state of the postsynaptic neuron at the time of the presynaptic spike so this is also a local learning rule and so what we have is that we have slightly different mechanisms but both (04:44) of these learning walls typically have the same learning performance and so how should we choose whether we go for one or the other and so here comes my point so let's switch to Hardware investigate a little bit what it looks like on this site so some of you might not be familiar with Hardware that's not a big deal on the left you have a digital implementation of an stdp synapse on the right we have a digital implementation of an sdstp synapse and what you have to see is that for CDP synapse you have to compute (05:09) inside every single synapse a Time window in order to remember what is the spike time difference between the pre and the postsynaptic neuron and you have to do that inside every single synapse and there are 100 to 10 000 synapses per neuron so this is really expensive to do on the other hand you have the sdsp synapse and you do not have to do such computations you just need to look at the state of the postsynaptic neuron every time you get a presynaptic spike so that leads to huge savings and now that we come back to Neuroscience thanks (05:38) to Hardware we can shed some light into this question uh the fact that both learning rules are local is not the end of the story they are both local in space but only as DSP is local in time you do not need to compute the time difference there and that leads to huge silicon savings that can also hint to more bioplausible mechanisms for example if you look into this paper you can see that voltage-based learning rules are more bio plausible than learning rules that are purely based on the timing of spikes so here is an example of how (06:06) going back and forth between neuroscience and Hardware can guide us to what is more bioplausible and more Hardware efficient so let's go the other way around now now let's start from the AI algorithms and move with bioplausibility now as the end goal so if we talk now about neural network training we look at the most uh most common starting point is back prop because it's just a standard Workhorse of deep learning so let's see how to align backdrop with more bioplausible learning algorithms you have two big (06:36) problems with background one is the weight transport you need to access the transpose of the weight Matrix during the during the backward path and that is not bioplausible because that implies that synapses would be bi-directional and this is not this is really not possible the other problem is that for example before updating this weight Matrix you need to do the full forward path and then the full backward path before you can update it so this is known as update locking you can really not do anything about this weight Matrix (07:04) before you do full forward and then the full backward path and this is not bioplausible because that implies two phases in learning which the brain doesn't do all the synapses learn in parallel and in real time in the brain so let's work on solving these two issues so a quite famous algorithm is feedback alignment and it just replaces the transpose of the weight Matrix and backward path by a fixed random connectivity Matrix and the algorithm is this learning algorithm is still able to learn useful representations it actually (07:33) figures out how to propagate useful error information through this fixed random productivity Matrix there is another variant that is called direct feedback alignment and now you just use fixed random predictions of the final error in order to as a surrogate for the for the Relay wise gradients and what you can see is that both of these algorithms release the weight transport but they do not release of developing you still have to do this full forward password by full backward path and same here you have to do the full forward (08:00) passing although here you have that the latency the backward path you have this shortcut path here so it's shortened but it's still there and so we got an ID we thought about okay what if we just use the sign of the error here instead of the error itself and then you have a very nice property for classification problems is that it's this allows to release update login why because for classification problems the target signal here is just in one hot encoding of the classification label that is one for the correct class and (08:29) zero for the incorrect class so here's the definition of the error that is the Target in the Target Vector minus the network output which is usually selected as a for example soft match which is strictly bounded between 0 and 1. so if you compute the error you have one minus something that is strictly bounded between zero and one so it's always positive for the correct class and similarly it is always negative for the incorrect classes so what that means is that the sign of the error is known in advance for classification problems and (08:56) if it is known in advance it means that you do not need to do the full forward pass before you get this information so you can use this property to release update locking and this leads to all direct random Target rejection algorithm which just use fixed random connectivity um projections of this target vector so what you can see is that actually interestingly now if you look into Neuroscience you can see that the RTP can align with output independent Target signals in the dendritic path uh digital instructive Pathways of cortical (09:24) intermediary units what that means is that the rtb can align with some of the mechanisms that are used in the brain I'm not saying that there will be the mechanism that the brain uses but it aligns with some of these mechanisms but even more interestingly because now we made back prop more bioplausible we also made it more Hardware efficient because if you go from here to there you really release computational and memory costs and for example we demonstrate this with a chip that embeds the drtp algorithm (09:51) and we demonstrated that there's only a 15 overhead Empire in an area compared to the inference on the network so we really demonstrate that this is a cheap learning algorithm that can Implement on chip so what I would like to convey in case I lost you for this uh for for this slide uh is that Hardware efficiency in bioplausibility are often two sides of the same coin we have seen first with a more science-driven approach that designing efficient Hardware hints toward bioplausible mechanisms why for the more AI driven approach we have seen (10:20) that bringing AI closer to Neuroscience actually leads to more Hardware efficiency so these two sides of the same coin is actually this nice Synergy that was hinted before as a question mark this is a natural Synergy between neuroscience and Hardware but we still haven't answered what is the right starting point so for this perspective we have seen that Hardware brings a nice uh a nice light into these three energies but what is the right starting point should we go from science or should we go for engineering so we have seen uh just (10:51) before in this presentation that okay we have followed a science approach that is really what we call bottom up so it's about analysis by synthesis it's about understanding by building for example this is about this stdp syner that we try to replicate in Silicon and then we can better understand and infer how the brain is processing but the problem is that and I'll come back I'm coming back to a remark that I have been in the beginning of my talk as to whether stdp is the right starting point it is very (11:16) difficult to scale efficiently such bioplausible learning rules the real word problem you can for example scale stdp to end this but beyond that is extremely difficult so now comes the engineering approach and now it is called the top-down engineering driven approach so what is nice here is that you really start from the working solution to real world problems because you start from back prop but the question is that which salt and pepper from Neuroscience should you take in order to lead to more efficient learning algorithms that can outperform (11:44) conventional approaches because this is really the question that you would like to answer with bio-inspired AI algorithms and so the second standpoint that we'll take in this talk is that actually to achieve what we call neuromorphic intelligence you should use this top-down engineering driven approach and it should be fed by Insight from science and a more bottom-up approach so let's see now by using this approach how we can move these questions into engineering into interesting engineering Solutions (12:12) so because we are now transitioning to engineering we need a use case and so the question that we'll uh focus on is entrep learning and so let's see why we need on-chip learning you have that for every inference device so for example your Smartwatch that wants to do so you want to do some keyword spotting uh you provide some data you need and you receive some decision and the performance is going to be within the specifications only if the input data follows the distribution that we use during training as soon as we get out of (12:41) distribution data you have that your performance will drop and so where does this out of distribution data come coming where is it coming from it can come from different users and environment features that you haven't predicted ahead and even from task requirements that need to evolve over time so for example you would like to program your device to learn a new keyboard how do you do that and and so what is worse is that okay typically decision can be within the performance boundaries at the beginning of the (13:07) lifetime of the device But as time evolves you have that these features can evolve over time and you will get more out of distribution data uh over time so how to solve this problem you can always use more training Data before deployment to cover more cases but the problem is that this has a cost to gather and curates such massive amounts of data and that's never robustness and flexibility quarantine in the long term the second thing that you can do is typically what it's done actually is a data exchange with the cloud the problem (13:36) is that you have to consume energy from your battery to do so so if you have a very tiny device battery operated devices typically uh can be very expensive and also you might be uh you might need to leak a user specific data to the cloud and therefore this comes with the Privacy issue so that is why it is interesting to investigate on chip training and will make it bioinspired and end to end by end to end I mean there's no external memory because in Hardware design accessing external memory success extremely expensive power (14:07) wise so we would like everything to happen on chip so okay uh so far so good but the problem is that we still haven't identified or real use case is that because achieving on-chip training for such temporal data so for example video or speech is still an open problem and why is it an open problem is that for uh temporal data the Workhorse a deep learning is by propagation Through Time and the problem here is that let's suppose you have temporal data lasting one second with the temporal resolution of one millisecond so that means you (14:39) have a thousand data samples and for this 1000 data samples you need to store a copy of the network Dynamics for every sample until you get the final error and you can finally back propagate the gradients through the whole network Dynamics so this is a process that is known as enrolling in time and at least actually to very uh very big big effective depth for the network so for example here that would lead in the xm4 that I just shown about 1000 layers and to give you an order of magnitude current integrated circuits that can (15:09) perform on-chip training are limited to about three layers so there's uh there that's really leading to intractable memory and latency requirements and this is why no end to end on-chip solution has been proposed to date to deal with temporal data so this is really the key challenge that we look at on-chip learning over long time skills while keeping a fine-grained temporal resolution so what now we come to a hint uh obviously the brain doesn't do backpack through time and hopefully uh the bojian (15:38) just before it has nicely introduced this problem before um so we have that the the standard for bipart3 time is a backward mode training where you need to keep a copy of all time steps there are also forward mode training algorithms so wooden has presented uh for uh forward propagation through time and indeed now in this talk I'm going to talk about e-com that was also addressed in the Q a so eprop or eligibility propagation was proposed in this paper and the key idea of eprub is that it approximates the background (16:05) real-time gradients as a product of two terms one is an error-based learning signal that is available locally in time so that is the main assumption that is done by eprop is that these error based learning signal is available locally in time and this is what is shown here uh and the second term is what is called an eligibility trace a synaptic eligibility Trace that basically represents the importance of every single synapse onto the network output and what is nice that these eligibility traces are computed (16:32) exclusively forward in time and they are not error based so this is really a trace of activity that we keep over time and what is the super nice property that we only need to store the current timestamp we can perform this learning online and we do not need to wait for the final error and to buffer all the network States before you before we can apply the updates so going from one to the other we can actually see that the bio and the biological plausibility is increasing especially because eligibility traces (16:57) are supported by biological evidence space and time locality go up and we have seen in the HTTP example that space and time locality are everything for both of course neuroscience and Hardware efficiency and therefore this completely slashes the onshape memory requirements because you only need to keep in mind the current time step to perform this learning the challenge though is that eprop is still not fully amendable to a full and and to an on-chip Hardware implementation due to a few remaining challenges and this is what we'll focus (17:27) on in the remaining part of the talk but before that let's just quickly summarize what is the network model that we select so here we take a neural network of spiking mirrors uh so he here comes another question why spikes is because eprop was proposed as a bioplausible alternative to a back property time but so for now we'll select spikes for the sake of bioplausibility but we'll see that from an engineering point of view there are some nice properties that Spikes have um for which we we want to select them (17:57) but I'll come back to that shortly so for now we need a spiking Neuron model in the recurrent layer for example the Leaky integrated fire near that has been covered quite extensively already so I'm just denoting here this Alpha term is the leakage the leakage Factor here the Theta is firing threshold as soon as you reach it you fire a spike and you reset what is the output neural model is exactly the same except that we remove the firing mechanism and the reset so it's just a leaky integrator and why no (18:23) spikes at the outputs is just to avoid ill-defined spike-based error definitions and the output next we need a tags to monitor or algorithmic requirements and so a nice task is this delay supervision navigation task also sometimes called queue accumulation this is a typical text of Neuroscience so you have a rodent moving along Corridor it sees queues on its left and right so here represented by small squares in the first phase it will see the cues so here you see for example there are focus on the left of the road and then three quiz (18:54) on the right then it will Traverse a q less phase and that it has to decide to turn left or right depending on the direction which is it has seen the most cues so in this case the good solution is that the rodent should turn left so it really has to maintain a working memory of what happened in the past in order to make the right decision so this is taking place with short-term Dynamics over second long time scale so this is exactly the use case that we are looking at and interestingly this is a complex task because if you take vanilla (19:23) background through time with a standard leaky integrating fire neon with a bioplausible leakage type concept of 20 milliseconds you have that this network is completely unable to learn to solve the tasks so even with vanilla backpack Through Time but interestingly if you just use a slightly more complex neural model such as the Adaptive leak integrine fire near where you have threshold adaptation then suddenly the network is able to to learn to pick up the Dynamics and learn to solve the task so why is it so it is (19:53) because for the standard leak integrating fire neon you only have a short time concept of about 20 20 milliseconds of leakage in biology while for the Adaptive leaky integrating Pioneer which is arguably more bioplausible it embeds threshold adaptation over hundreds over hundreds of milliseconds and this is indeed sufficient to induce long temporal dependencies in the network Dynamics and to learn to solve the task with network Through Time with the price to pay is that I told you eligibility traces are dependent on the selected Neuron model (20:22) uh and eligibility traces are really simple for the sender leak in the green fire engine it's just a simple activity low pass filtering nothing more to do but for the Adaptive leaky integrating fire and iron then it becomes completely intractable and this is already difficult enough for GPU so forget about dedicated however about this this leads to a complex personal apps multi-time scale filtering so we really do not want to do that so that's the first challenge that we need to solve for e-proc in order to make that amenable to a (20:50) non-chip implementation what Neuron model should we select and here actually it's time to depart from neuroscience and go to a more engineering approach we will take a non-bioplasible neural model so we just take the leak integrated fire neural model but now we'll make the leakage the membrane leakage time constant flexible for milliseconds to seconds so going uh with a membrane potential leakage of up to seconds is not bio bioplausible but we can get the best of both words we can get this flexibility in the time (21:20) constant you can have long-term row Dynamics and you can keep very simple to complete eligibility traces which are just a simple activity low pass filtering so this is the first step that we do second step we can now write the e-prop equations for the leak integrating fire engineer so we write here the equations for the output weights recurrent weights and input weights are as defined here so I told you before the eprop is about the product of a learning signal that is error based and then eligibility Trace so the learning learning signals here (21:50) you see the error definition and for the recurrent input weight you need a projection from the output readout Matrix but indeed the learning signals are just an error based term uh first problem with vmc is this some term here it requires what we call a dedicated gradient memory what it does is that you actually need to sum all the updates that are computed by eprop over all time steps before applying them so in Hardware that's difficult because you need to a dedicated memory to store all these updates before you can apply them (22:18) but that's also not bioplausible your brain does not store all the updates uh in a specific part and then carry out the updates at once uh as a second as a second phase so you again they have this Duality between neuroscience and Hardware so what we can do is to just cut this term and perform per time step updates so we perform the updates at every time step and that will work just fine as long as the learning rate is small enough so now we got three of the first problem now let's look as to what is inside (22:47) eligibility traces you have actually three things the first one is what I mentioned the pre-synaptic activity low pass filtering term and you see that the filtering terms depending on the leakage of the neuron hence why if you get a long leakage you get a long time scale eligibility Trace the second term is this postsynaptic stray through estimator also called sometimes surrogate gradient for the activation function so this is just a smoothened uh activation Spike spiking activation function derivative um and the third thing is that actually (23:20) the problem with eprop is that you have a temporal coupling of these pre and postsynaptic terms and this is actually very expensive to compute because you need to remember the product of these terms of the time so what we can show is that compared to the assumptions already done in the original eprap algorithm this temporal complete this temporal coupling term can be safely neglected so what actually we end up with with the modified propagation that we propose we have a learning signal we have the three to estimator term so this circuit the (23:48) circuit gradient that is a postsynaptic term and you have this activity low pass filtering and presynaptic side so what you can see is that now we achieve this full space and time locality that we have seen before for HTTP is really key for both Hardware efficiency bioplausibility and that allows us to completely decouple the pre and the postsynaptic terms and why is it nice is that storage and computation wise now you can everything scales with the number of neurons and not anymore with the number of synapses and (24:17) therefore you can really cut the memory overhead of this algorithm third thing that we need to do and I will uh for the sake of time ask quickly on this we need to quantize the weight resolution to minimize the hardware requirements and then we show that 8 Bits is a sweet spot if you combine that with stochastic weight updates so that's just for your information now we can look at the results here in Black you have your all modified e-prop algorithm and with a two second leakage time constant of this Leaf nearly pre-propos (24:45) so this is actually issued from Chip measurements first thing that we can do that we can see is that it's competitive with the backpack Through Time train with network with uh of alif neurons which was our Baseline the second thing is that we can do this with only about one person memory overhead compared to the inference only Network so you take your inference on the model you add one person memory overhead and you are able to learn the second long time skills so this is uh the main takeaway but now in case you lost a little track of it (25:15) let's go back to the big picture um I have mentioned that neuromorphic intelligence um you should start from the engineering approach and feed it by by Insight from neuroscience so we have taken as a starting point backward three times the main challenges that we have encountered is that uh it's not tractable Hardware wise and it's about not bioplausible so let's look into Neuroscience Neuroscience tells us okay eligibility Trace might be a thing and indeed it leads to the epoch algorithm that solves these two issues (25:46) but eprop still not fully amenable to a hardware to a hardware efficient implementation and it's not by default able to learn very long time skills you need to combine that with a powerful neural model and so what Neuroscience tells us here is that you have you need to have threshold adaptation but it's still not Hardware efficient so we leave neuroscience and go to an engineering approach we take a configurable integrating pioneering and this combined with a simplification of e-proc for space and time locality we end up with (26:14) this simplified e profile algorithm so this is the schematic correspondence of this approach that we propose so now this simplified ePub algorithm we can Implement that on a chip so here is a cute cheap micro photograph where everything has been um implemented in less than half a millimeter squared of silicon so this is a tiny chip um and so indeed you have half a millimeter square of silicon and what I would like you to remember is that there is no external memory so everything happened happens inside the chip (26:47) and so here is the kind of high level overview you have here the chip itself and it communicates with spikes with any kind of sensor so it can be a spiky new morphic retina it can be used by a spiking cochlear the chip doesn't need to know anything about the sensor as long as it talks with Spike the people figure out how to learn with these spikes and so I'm coming back uh to something that I have mentioned earlier why should we use spikes so oftentimes spikes are selected because they are even driven they allow for even driven (27:15) in sparsity where computation but they also allow and that's what we show here for sense or agnostic raw data processing and if we combine that with a learning algorithm that is agnostic to the spike code AS eprop is you you end up with a task agnostic processing and learning kit so everything is open source actually if you would like to prototype the tip yourself using an fpga you can in order to demonstrate this task I'm going to sleep processing and learning we need different kinds of benchmarks for example we can demonstrate that with (27:43) a vision data set such as the IBM DBS gestures data sets for example you have 10 classes of rolling arms clapping hands rotating left and right arms uh air drums and then our guitar and this involves over six seconds with about a five millisecond temporal resolution as we have selected here you can select the notation data set to do some keyword spotting for example and here you can take the spiking Heidelberg digits data set so what we show here is that every digits is about half a millimeter half a second in length and (28:14) here on the y-axis you have the different channels and with the lower channels representing lower frequencies so for example this is a six and you see that's index represent the higher order frequencies and this is a seven uh a third data set that we can choose this one you are already familiar with now uh is the delayed supervision that a q accumulation task is in this proxy for the navigation use case and we have that for all of these tasks from scratch and without external memory our chip has been able to learn to (28:40) perform them with a quite reasonable accuracy so 87 for this Vision task 91 for this keyboard spotting task in about above 96 percent for this navigation task and what you have to see is that for all of these tasks for real-time learning you need less than 50 micro watts to perform this real-time learning so to give an order of magnitude and one milliwatts is the kind of low power for for your phone so if you go to my the microwatt range this starts becoming uh adequate to perform user adaptation in wearables for example where the battery (29:12) size is really critical so in terms of the key messages that you should remember you have that following this nice blending of AI algorithm neuroscience and Hardware we've demonstrated the reckon chip which is able to perform end-to-end on-chip learning over second long time skills while keeping a millisecond temporal resolution which is a yet and solved engineering challenge the second thing is that we provide a local solution thanks to this just because we require less than one person memory overhead so less than half a (29:43) millimeter squared in Silicon area and less than 50 microwatts for training at 0.5 volts third thing is that we can demonstrate task agnostic learning which opens new doors for user customization and even full chip repurposing at the edge so that outlines an exciting future for nomorphic intelligence so that's a good opportunity to thank my former mentors and colleagues and because now I'm actually working hard on forming my own team into udafed in case you would like to explore um also in the future of metamorphic (30:13) intelligence you're very much welcome to drop me an email because I'll be looking for some new team members very soon and that's it for me uh you have here a few references the links through to all um open source repositories as well as the way to contact me so thank you for your attention,"In this talk, the speaker, Charlotte Frenkel, discusses how to merge insights from artificial and biological neural networks for neuromorphic Edge intelligence. She covers three main questions: how to exploit and make the best of the synergies between neuroscience and AI, why we should bother with neuroscience at all, and how to move these questions into interesting engineering solutions. She argues that hardware forms a middle ground to shift some light on how to make the best of neuroscience in AI, and explains that AI without hardware is not sustainable. She also discusses the synergies between neuroscience and hardware, which are less obvious but deserve attention.",ChatGPT,,,,,,,,
https://www.youtube.com/watch?v=qFEtyIsothk&list=PL09WqqDbQWHFjkkXiQdOYC1wAdgSUMGxQ&index=9,2022,SNUFA Workshop,Zhenrui Liao,Columbia University,A biologically plausible inhibitory plasticity rule for world-model learning in SNNs,Learning,(148) Zhenrui Liao - A biologically plausible inhibitory plasticity rule for world-model learning in SNNs - YouTube https://www.youtube.com/watch?v=qFEtyIsothk Transcript: (00:04) brilliant uh well thank you uh zenary it's it's uh it's great to have you here um I if I'm right that you're doing an MD PhD is that right Columbia I am yes yeah very impressive thing to be doing it blows my mind that people are gonna do that so um yeah so is anybody's gonna talk to us um about uh inhibitory plastic which is uh which is a really cool thing that uh that we should talk about more go ahead all right well thank you Dan for the very nice introduction and thank you for the uh invitation to speak here today so (00:41) um I'm gonna be talking about my work my recent modeling work and some new predictions for the role of interneurons and learning in the hippocampus and this is uh work that I've done in collaboration with the verital and collaborator Darian hajibati at Stanford okay so just to start I want you to recall the specific experience of you getting to where you physically are right now today whether that's from your bed to your desk or from your house to your workplace whatever it might be I'm still at home but if I were at lab I (01:11) would have gotten uh but yesterday for instance I got on the subway at 168th Street I got off the train at 125th street I said hi to my friend Darian uh who I saw just in passing and then I arrived in lab and this is a sequence many of our experiences and therefore our memories are sequential in nature this happened and then this happened and then this happened and the hippocampus which I study is very good at learning sequences like this it's very well known that when an animal explores a trap with spatial cues (01:45) Place cells including locations along the track these are these colored rows will fire spikes in the order that that the cues the spatial locations are encountered and then when BM was at rest later the same sequence will be replayed during Shockwave ripples which are a signature of a particular type of activity in the campus but the question is do these replay events actually replay specific experiences or some deeper conserved structure of the world I get on and off the subway at the same stations every day but I'm probably not going to run (02:14) into Darien on the street at the same time in the same place every day and so my very talented colleagues Satoshi Toyota design an elegant set of experiments to test this in which he exposed the mouse to just such a 1B linear treadmill with special cues uh like the subway stations that I encounter as well as these random distractor cues like seeing a person you don't see every day while performing a large scale two Photon calcium Imaging pass of ca3 outputs in the hippocampus in ca1 and recording these lfp (02:45) signatures in order to tease these two hypotheses apart do does the hippocampus require specific experience or this abstracted version of the world and so online during the experiment we found a robust representation of space which was one unit as well as these random cues odor Visual and reward as the animal was exploring the belt and then during rest We examined these Shark Wave ripples these uh signatures of memory recall and find that prior to exposure to this task the ca3 units are the cells coding for random cues this (03:24) odor visual reward are indistinguishable from units coding for spatial cues in the recruitment by these shrubway ripples but then during experience uh the recruitment of CA of these random Q units in red is not only um they're not not only are they not recruited but they're actually actively suppressed and this is a durable effect that persists after the task as performed um and this is an effect that accumulates with experience so with more exposures with more lapse on this uh trial on this on this spatial belt the (04:00) animal gradually learns to suppress the activity of these random Cube stimuli so we're basically at the limit of what we can do experimentally here I don't want to understand how difficult these experiments are but I wanted to know if we could make some more progress on this question with modeling so we started just by building a network model of C3 spiking Network model drawing inspiration from a couple recent papers so 8 000 Primal neurons a few hundred interneurons and the distinguishing feature of the three regions of Campus (04:32) is recurrence so we added this dense recurrence about 10 random pyramidal parametal cell connectivity and then we fed the network with both place and random queue input with input just allocated ran away to cells so some cells receive Place input some cells receive two inputs some cells received both and then we trained both the excitatory and the inhibitory weights uh here represented by these arrows with a symmetric svbp rule which has been previously reported in this brain region and the principal innovation of our work (05:05) is that we're training both the inhibitory as well as the excitatory synapses using this rule so keep that in mind because that's going to be important later so let's take a look at what this looks like so this is the simulated behavior of the animal the animal is running down this 1D linear track that gets teleported back to the beginning and then runs uh down and again this is like a simulation now and these uh these orange arrows represent where the cues are arriving so this is a red strip plot of the (05:41) network during learning and I've sorted the the spiking of the cells in such a way as to reveal that the network robustly represents both the animal's spatial position which you can see in the black spikes as well as these random sensory cues which you can see with the uh with the orange things on in the online period or the simulated online period then we can look during rest when the simulated animal is not uh behaving not receiving this online input and the cells instead only receive unstructured random poisson spiking inputs and we (06:16) find that replay spontaneously emerges in the network consists that with what some other people have found as well so these same cells we find these sequences just spontaneously emerge at a random points in the network now the Q cells uh curiously are not being activated during these times so they are being activated at other times so I want to come back to what is the significance of this strange inhibitory plasticity which hasn't been the subject of much experimental study in hippocampus and generally not much in (06:48) the in the brain at all and uh again what you see is that the network undergoes the spontaneous replay events and during these events the cells that were coding for random stimuli are suppressed even though they're very active elsewhere but when you take away this inhibitory plasticity it's completely different story now you see that the spontaneous replay is ablated and instead this that work enters kind of this high frequency pathological oscillatory activity regime and the Q cells are kind of just like (07:19) constitutively active you don't see these these gaps and you also I don't see any of these uh nice sequences so you could think well this is kind of trivial right because we've taken away inventory plasticity so there's just like some kind of perturbed inhibition and excitatory balance and then the network enters some kind of uh you know some kind of instability um but turns out that it's something to do with these randomly occurring stimuli uh that's actually happening here because if you take away these two cells (07:53) and replace them instead with Place cells so you have exactly the same amount of excitation exactly the same EI balance instead instead you get beautiful uh replay happening so it's something about subtracting suppressing distractors or distractions that you need you need an Android plasticity for and that leads us to the major prediction of our work which is that it's this inner non-plasticity that implements this distractor suppression process and thereby supports the consolidation of the structure of the (08:28) world abstracted from specific experience and the ca3 region of the hippocampus and although Darren couldn't be here today I want to give a shout out to his work which is really his contribution to this project which has been really fundamental and beautiful as well so he took this kind of abstract leaky Integra Empire quitting around model and built a very detailed very beautiful biophysically biophysically detailed model of hippocampal error sca3 so now we're looking at both at multiple input streams to the hippocampus These are 3D (09:08) reconstructed neurons um with a pyramidal cell activity as well as pvbc internal activity and the same plasticity pattern so the plasticity of both excitatory as well as inhibitory synapses um along these multiple input strains and what he finds is first of all that uh you organize robust spatial sequences in the ca3 region of the hippocampus uh training the biophysically detailed model in this way so you get good place cells just kind of spontaneously training the network using stdp and then in the offline stage uh you (09:48) again see these uh Shrek weight ripple-like dynamics that are coupled to replay like Dynamics so you see some when the network is not receiving these structured spatial inputs you see that the network kind of spontaneously replays sequences in compressed uh time periods which are the same sequences that it saw in the online stage uh and in a very fantastic agreement with uh our previous results found that if you just add in hematory plasticity this is enough to suppress these Q cells during the during uh these offline truck (10:28) labor hole period so when you do have inventory plasticity then you have this you can even see these uh negative deflections negative hyperpolarizations of the of somatic potentials during uh during Shockwave uh ripples in the in the simulation but when you don't have inhibitory plasticity uh then you see that these ripples are are dirty in some sense these two cells are just always becoming active uh and this is this reflects some kind of failure to suppress the irrelevant information when you're replaying when you're replaying (11:06) the uh the experiences that you had and what are the predictions of this model a very important prediction in my opinion is that there's enhanced feed forward inhibition specifically onto the Q cells and this is the mechanism by which the Q cells become suppressed and clean quote unquote replay is allowed to happen in the network so let's try to understand on a normal level what stdp which is kind of this Black Box is doing to this network so we have this uh so we can kind of abstract away some of the (11:45) details of this model and I want you to just think of a simple world where you only have these four these four things so the subway stations this random distractor and and work so in the ideal world you only ever observe the world structure you don't ever explore uh observe distractors so Darion never says hi to me on the street observe the same sequence every time and if I sort the synaptics weight matrix by Place field in this toy model where each one of these uh there's a one-to-one correspondence between stimuli and the (12:19) outside world and stimuli in in place cells in the brain what I find is that adjacent Place cells learn connections uh Place cells representing adjacent locations so blue snaps is onto red red snaps is up to in yellow yellow snaps is up to green and you see this diagonal form in the synaptic weight Matrix which is consistent with what we see in simulations and then during the replay the sequence is just reinstated so you randomly excite one of these neurons and then you just follow the follow the diagonal it (12:52) excites its successor and then it's it's accessor and so on and so on but now say you get both relevant and irrelevant information and I think it's pretty clear what the problem is here because you're getting this random distractor represented by Orange um off diagonal synapses start to get potentiated and under stdp these Q cells are representing these destructive stimuli become very tightly coupled together and this creates aberrant path through the network during replay so if you just again randomly excite one cell (13:29) the cell can either excited successor in the sequence or one of the distractors and then the distractor can kind of excite anything leading to arbitrary order activation which abolishes replay and not only that but encourages you to enter this kind of pathological oscillatory state and so what's the solution to that I think it's actually pretty intuitive it's simply to suppress the irrelevant representation during the offline period and therefore and if you do that that even if the distractor cells represented (14:02) by orange develop many synapses that prevented from exciting anybody else and so your clean structural replay sequences are restored and I think this actually gives some very nice intuition into why it's in hematoid plasticity in particular that's necessary rather than just you know Global rays and ambition because the brain can't know our priori which cells are the cells that need to be suppressed a cell coding for the same stimulus they'd be a distractor in one context and a sequence cell a structural (14:35) cell and the other and so where are we going with this work uh we're trying to now test some of these predictions using uh using different tasks uh using different virtual reality and calcium Imaging tasks because This lends itself to a very natural model I think in which sgdp embeds a graph into the synaptic weight Matrix of the ca3 region of the campus and uh using now we can experimentally test what are the kinds of models what are the kinds of Worlds that this simple mechanism is able to learn and uh with that I want to thank my very (15:20) talented collaborator Darian as well as the other people who have been involved in the projects um Satoshi uh who discovered this mechanism uh who discovered this phenomenon rather experimentally as well as my Pi atollova chancy uh our funders the NIH um the medical scientists training program uh I want to give a shout out to Dan who created the Brian package which we used in this project and as of this week this uh a preprint is on by archives so if you're more interested in this please check it out brilliant thank you so much (15:55) um yeah no really interesting talk and I feel like uh some of the questions suggest that other people feel the same way as me which is like I want to know more details so um so yeah I'll kick off with the first from Bill Pulaski which is uh have you have you explored what kind of structure is learned in the inhibitory weights um are they learning to suppress particular groups of cells does it more more like Global inhibition what's what are they doing uh yeah absolutely so um it seems like the inhibitory weights (16:25) are are learning uh specific suppression onto the Q cells the cells that are representing these random cues and this is something that accumulates over time so um so it's so this is I think another intuition for why it's inhibitory plasticity plasticity of the gabaergic synapse that's necessary uh as opposed to maybe the other way around you could imagine an alternative mechanism where you uh enhance Global inhibition by enhancing excitatory synapses onto inhibitory cells but then you don't have (16:59) the specificity you just like raise the level of inhibition throughout the network and you can imagine there are also other negative effects you get from that like they're now unable to do a lot of computations but instead you selectively Target just the just the cells that are uh creating these dirty these dirty representations so to speak cool uh and and Thomas asked something that I was also uh wondering about which is are there replay sequences in the model going in both directions and and is this also something you see in the (17:28) experiments yes they are going in both directions and um this is something that uh is experimentally verified as well so I think the I kind of glossed over this for time reasons but the intuition for why that happens is because the plasticity rule we use is a symmetric plasticity rule meaning uh you have bi-directional uh potentiation as opposed to the classic stdp differentiation of differentiation in the positive direction and differentiation in the negative Direction which basically allows the model which basically creates this (18:03) cement diagonally symmetric weight Matrix um that you can follow in either direction okay so you can imagine going forward or or backward s okay yeah cool uh we have a possibly related question from Ezekiel Williams who's asking what's the intuition for why the model replace sequence is faster than You observe them in the data um yeah that's a that's a really good question so I think like uh a few different papers have um have looked at this but what I would say is probably that in the offline period you have uh less (18:46) inhibition in uh from coming from certain brain areas which allows which allows a signal to be transmitted along the network uh faster along along synapses but this is something that uh we're still exploring it's not uh there's not yet consensus on why why this happens cool great uh there's a ton more questions but I think we are at the time for the next talk to start so I should better stop right now um but yeah maybe maybe whoever's asked questions can uh can follow up with you by email or something afterwards (19:20) cool great thank you very much again today and uh yeah Let's uh let's move on to the next session,"The speaker is discussing their research on inhibitory plasticity in the hippocampus, a region of the brain that is known for its role in learning and memory. They describe an experiment in which mice were exposed to a linear treadmill with both spatial cues (like ""subway stations"") and random distractor cues (like seeing a person you don't see every day). The speaker's team found that during the experiment, the hippocampus robustly represented both types of cues, but during rest, the activity of the random cues was actively suppressed in a durable effect that accumulated with experience. The speaker suggests that this inhibitory plasticity may play a role in the hippocampus learning deeper, abstracted versions of the world rather than specific experiences.",ChatGPT,,,,,,,,
https://www.youtube.com/watch?v=WyJx9CM_cqA&list=PL09WqqDbQWHFjkkXiQdOYC1wAdgSUMGxQ&index=10,2022,SNUFA Workshop,Christopher Currin,IST Austria,Bridging the gap between artificial models and cortical circuits,Biomedical applications,(148) Christopher Currin - Bridging the gap between artificial models and cortical circuits - YouTube https://www.youtube.com/watch?v=WyJx9CM_cqA Transcript: (00:04) okay hello everyone uh welcome to the last talk of snooper 2022 um and of course we've saved the best till last so um here we're going to have uh Christopher Cohen who has got quite a an intriguing uh reversal of the normal order of things in this talk I think so uh yeah do you want to tell us about the strange different way of approaching artificial and artificial models and political circuits let's take it away yeah uh hey everyone it's really great to be here and uh what I'll be presenting is Bridging the Gap between (00:40) artificial models and cortical circuits uh there'll be two main sections and I'm going to focus on number one is uh we have a promising personalized medicine approach for understanding and treating individuals with epilepsy and the second part I will be talking about are nations approach for linking spiking your networks with human brains for the further understanding of birth so it's been a wonderful two days of conferencing at snoofer with people from all sorts of backgrounds and such interesting projects so it's only right (01:11) for me to start by saying thank you it's a great opportunity to be here to present my work I'm very excited to share what I've done and a thank you to my collaborators who make me a better scientist as well as my friends and colleagues the Virgos group who make me a better person and having seen so many spike in neural networks over the past two days I'm going to start with a important reflective question that I think we should ask ourselves and that is how close are our models to the brain and (01:41) how can we reconcile differences for example in spike in your networks we principally have two neuron types inhibitory and excitatory in biological cortical circuits we often have many many more in terms of Simplicity some S and ends are termed too simple and biology is often too complex in terms of tools we've spent decades building technical impressive tools to understand both of these Networks but how compatible are they with with each other it feels like sometimes they're talking within within that field (02:17) next in terms of Dynamics spike in your networks are certainly complex even if they are simple and the the brain is certainly very complex but again how do we relate these complexities and these dynamics that come out of it it's it's tough to think um but with all these differences many current approaches aim to make more complex models which I think is absolutely great and we often add extra bio biologically plausible mechanisms to achieve that but there's another way to what if I told you you could have more simple (02:51) biology okay in this project I will be demonstrating what we have done making and studying simple biological cortical networks and I will also touch briefly on the complementary components of building data driven models so one of the very special things about this project is that we get to study human cortex now a very simple human cortex which we view as a benefit because a lot of the really like beautiful but burdensome aspects of the human brain's complexity is distilled down okay so what's the recipe for building (03:25) our very simple human cortex so we can start with a person any person and non-invasively get some skin cells okay these skin cells can be reprogrammed into induced pluripotent stem cells which means that they have the potential to become almost any other type of cell with the right ingredients so as neuroscientists we care about the brain but we want to make biology that closely mimics our established theoretical models so we make just two types of neurons I'm just going to call them excitatory and inhibitory you can (03:58) choose the genetic markers these ones are more like cortical neurons and yes these are real human neurons from Wild type I say wild type it's somewhat mean but technically accurate for humans without an overt disease condition but seriously try getting human neurons from a person without surgery by asking nicely and see how that goes so here we have an opportunity to grow human neurons without any surgical interventions okay so these differentiated neurons are seated or grown on high density multi-electrode (04:31) arrays now every wall has about 26 000 electrodes of which a thousand can be recorded from simultaneously at any time in terms of neuron numbers this can vary but we would choose about 200 220 000 neurons in total of which between 15 and 25 are inhibitory and um because the the mirror the high density Model T electrode array uses extracellular potentials but is high density we can use a technique called Spike sourcing in order to extract um which neuron spiked when based on each neuron's unique spatial temporal (05:11) pattern picked up by the mirror so it output some spike times for individual neurons so after Spike sorting this results in us having raster plots Spike times for these human neurons and this is the results I'll be showing in this presentation where I will have just two time points for for the purpose here to constrain it a bit and also each person had their skin cells reprogrammed and differentiated twice so two clones that's where the term clone comes from in this case and this in itself is a very technically (05:48) complex process and many aspects of this are Fields within themselves and what's making this possible now is that there are new advancements in human induced pluripotent stem cells in order to grow your neurons feasibly in a dish and once they're growing in a dish we can record from thousands of them simultaneously and for many hours at a time okay now this overall is very complex and Technical and this process had a very high throughput so it's hugely data intensive and when I say it's data intensive and you might be (06:25) like well how how big how much come on so in the data set that I have so far it's about 986 billion spikes in our data set but we're still adding more and these in our data set we have human neurons from both epilepsy patients and from Wildside so we really are looking at people with epilepsy and in fact for the purpose of this talk I'm only going to be looking at a small subset of people where they have a gene alteration that has already been linked to epilepsy and we can start to understand this a bit more (07:01) so we have three families that we look at and in it within each family there will be a person with epilepsy and a person without because it's non-invasive and we have seven subjects 78 recordings 390 minutes of time recorded 49 000 neurons about 44 million spikes detected in this data set and about 400 000 Birds analyzed so I've told you the stats but what does it actually look like okay one more pause and then I'll show you it's just to elaborate on X is the time in seconds y as neurons if you black (07:36) dots is a spike and at the top in blue will be the population firing rate so here's the activity over five minutes and the cultural neurons tend to have asynchronous irregular firing activity with oscillatory or bursting behavior and in this case there are actually quite a few base now it's informative to compare this raster plot versus another one and say that there are clear differences between people with and without epilepsy so these are from different people same family different people and yeah you can (08:09) see clear differences the one on top clearly has a generally higher activity and more oscillations uh uh but okay I actually haven't told you which patient had epilepsy which didn't and weirdly the one on top is from Wild type uh who's a close family member of the one below and the genetic Arts the the gene that's altered in these these subjects is SLC 13a5 we're just going to call it SLC for the rest of the talk but this really demonstrates that well maybe a five minute raster plot isn't (08:45) the way to classify a difference between uh people with and without epilepsy okay 500 acid plots on the way perhaps looking at the Dynamics of the network will be more insightful and particularly the bursting Behavior because live Theory says that uh yeah people with epilepsy tend to have seizures seizures are large personal activity over time so that's also could be an important component so let's look at some measures and metrics of of this activity and the one we're going to start with of course is (09:17) the inter-spike interval timing between two spikes it's going to form a foundation for a lot of the future work um and from this you can look over time per neuron for neuronal activity such as the average fine rate the skew or the coefficient of variation you could also look at the slides vertically and look at the population and this could give you the peak rate of activity at the moment in time or if you wonder it a bit more you can do the cumulative moving average and this cumulative moving average is a (09:47) key determiner in our algorithm for detecting both which is also a reference down below um and so some simple measures of Earth's include the duration the number of neurons involved the amplitude um and then some simple measures yeah and then uh some simple measures as well can also be between the bursts as well like the interval or how often a bursts aspects like that now part of our burst detection algorithm is also assigning burst properties per neuron in the burst so we can get a sense of uh the inter-spike (10:21) interval in the burst how often that neuron contributed to the population activity in total and then a burst spikes as a portion of the total spikes okay which I will come back to that point at least a bit later so so the points of all of this measure aspects is that we can extract these metrics of the networks Dynamics and pull summarize and compare better than just the raw rest of plots that are that are shared on the screen okay so and indeed per person we have multiple recordings and the multiple clones or differentiated neurons that we (10:56) can pull from and here are some examples multiple browser plots from Wild type on the left and SLC on the right and from the same people but different clones different recordings so live duplicates uh yeah and if we look at the inter-spike interval the most humble of the measures we have stacked histograms to compare well maybe not a clear and obvious difference between them maybe the wild type has slightly more activity overall okay but these recordings are from three weeks and previous work has shown that it takes longer than that for these (11:32) these cultures to mature so let's look at six weeks and okay it becomes quite striking you can see a difference the SRC activity the insta Spike interval overall it's greatly increased okay I'm just going to overlap them just to highlight the difference between the two everything's all scaled appropriately and um yeah there's clearly a difference in the Isis after six weeks so this is great clear difference after six weeks so these subjects 11 and 12 amazing code names uh are from a single family and we (12:03) can imagine that differences also occur for other families right so let's look at the family another family over here and we can see somewhat differences but maybe not in the direction that we wanted all right uh family three wild type seems to have great segativity overall and so for RSI it doesn't seem to be a super clear pattern of like this is the determining factor that can differentiate okay so maybe isi is not the measure to base our comparisons on so we just have to find the right metric right so here for example in each of these (12:39) graphs is the proportion of burst spikes or number of spikes in the burst out of all possible spikes sorry not all possible spikes for that neuron in the recording so yeah uh and these are distributions because it's on a pure uh per neuron level so if we focus on the six weeks which is where they are more mature we can see that the SRC has a large proportion of burst spikes for family two but wild type Hazard for family three and just as an intuition for what burst bikes look like here are two examples this is the first one it says well (13:13) there's not much activity overall but when there is a burst a lot of neurons are involved so it's going to be a high proportion of both spikes out of total spikes but and then on the other side a very low proportion would be well just not match bursting activity at all so out of the 30 or so metrics that we have none seem obviously like a key indicator of whether a culture is from a person with epilepsy or from Wild type so what is the right metric to choose and honestly right now we don't know we're actively working on it and in fact (13:47) one of the more promising Avenues is building personalized baseball cards for each person that represent a snapshot of their unique Network Dynamics this combines study plus measures over time that we aim to understand an individual better and motivate for improved treatment options before the usual trial and error approach of current Pharmaceuticals for example we can look at the inter-spike interval which we've seen before the isi coefficient of variation average firing rate skew and then also some burst properties like spikes per (14:21) burst and burst duration and into Spike into burst intervals sorry and many more and we can do this for every person in our data set sorry that's just a snapshot because for every person our daughter said they are just three just to as an example but this is certainly not to say that we're done uh the experimental design is certainly an iterative process so we still have a wish list of things that we are currently doing and that is we're going to add more time points and the Fuller data set we Journal time (14:51) points but for the current one that I uh and it's been about now they were we always chose two for demonstration but we do want also more fine-grained time points maybe daily instead of weekly we want longer recordings we want smarter electrode choice of those thousand electrodes you can choose on from sorry 26 000 you can choose from let's choose a thousand a bit more clearly let's do some dimensionality reduction on the metrics for some clustering and see which ones are the most important and then there's some algorithms classes of (15:23) algorithms called locality sensitive sensitive hashing and this can potentially be used for classification of whether a person is epileptic or not and then the final one that I'm going to consider Morton's talk is a personalized model of uh Dynamics with the goal of understanding the data more as well as probing our general model assumptions further okay so let's talk about what a personal personalized model means and here we call let's affectionately a digital twin the premise is that it's a dollar driven (15:55) model that allows rapid and reproducible reproducible probing of Dynamics so of course they're going to be many open questions some fundamental ones are well what model do we choose the large scale unit or or yet also a personalized spacing of the data it's an open question and then the interpretation of models in order to conduct meaningful experiments that tell us more about the data and the model okay so how do we create a data driven model so different models come with different assumptions and these different assumptions can lead (16:30) to different conclusions so we want models that are informative and explain the data across individuals while enough to provide insight into possible mechanisms some examples of model assumptions that can also also provide mechanistic insights are the relatively recent conductance based adaptive exponential liquid integrated fire model as well as short-term plasticity models which can consider neurotransmitter utilization and depletion so both of these can display oscillatory or bursting Dynamics as well as provide experimentation in (17:05) Pharmacy pharmacological interventions for example by having Gaba or neurotransmitter depletion okay so from the data we have measures of the activity that we want to fit so fitting is hard but the most promising approach right now is something called simulation based inference and as an iterative faulting to models with desired features and we don't care about exact Spike times we care more about distributions of the activity it doesn't have to be exactly the same certainly our data from time points to time points (17:36) is not okay from this SBR simulation based inference come a large pool of candidate models so this yeah um they all these kind of models would fit the constraints that we iteratively process down um and they could be different clouds that uh that are slightly different to each other but we don't quite know how different yet and that leads to the next aspect of well the space of possible models creates predictions about how both the data and the model responds to perturbations these the generate Solutions in these (18:12) different spheres different aspects uh could respond differently and we have the capability in experimental setup in order to apply chemical or electrical stimulations that we can perform to narrow down this model space and that brings us back to the data and telling us more about how biological human neurons work as well as the type of neurons that best match the biology themselves and that brings me to the end so here's a summary but please forgive me if some Figures were a bit rough as the the last minute habits of generating (18:46) refined figures a few days before was halted because of a ransomware attack which has now been rectified unfortunately our work is intact so we really do look forward to the promising and exciting future directions of this project so thanks for following me along for the ride I really appreciate you your time and your energy thank you very much Christopher um we ran over a little bit so I'll keep the questions relatively short and I have to apologize that a a rather snugily wrote a question that everyone (19:19) upvoted to the top which is uh um maybe based on the definition of this dish brain which is not the definition that I would tend to default to so I would not consider these as sentient yeah I think I'll I'll agree with that um Michaela Nadine asks is the proportion of inhibitory cells higher than in the real cortex and uh so is that sorry is the genetic alteration expressed in all cell types or only especially in the two growth uh right so and the first aspect um yeah it's a similar proportion they (19:58) are obviously the brain is highly variable and even when you do some seeding the amounts of inhibitory neurons that survive tend to be uh less than than the exciting one so you do get like a drop off a little bit between what the initial proportion you place it is on uh but it does you can do some checks after a few weeks or months but the check is kind of like you're done with the culture at that point um so yeah it's a similar proportion there is they have also been some really cool recent uh results with a similar setup (20:31) where they've changed this proportion to see how the network would respond and in fact they look pretty normal with like 80 inhibitory neurons uh that's not to say that's what the aquatics is but it's so interesting to look at yeah someone relatedly from Bill but last year I'm not sure if I missed it but what makes these these cultures cortical is it the the neuron or differentiation controlled to get a particular neuron types so yeah that's right the ingredients we sprinkle uh to differentiate the ipses but the with the (21:02) right molecular markers at the end that we check afterwards yeah or what we want and then double check cool all right um well I think I probably better end it though because we're a few minutes over already um and I don't know if Friedman wants to come on to uh to to to close out the um to close out significance that was the the end of the last talk um so from my point uh thank you so much everyone for coming and for making this such a an amazing event um Friedman do you do you want to add anything not really no also thanks from my side (21:40) and this is it and I would say uh this was a lot of fun let's do it again next year yeah I think we'll definitely do it again next year and let us know if there's any particular ideas about how we should do it again next year okay exactly yeah so thanks Chris for this nice talk and thanks to all the speakers and one big thanks again to Tim and Katie again for helping us with the program selection and all of uh the moderation today and we'll be in touch um for starting the same thing the next year in a similar point (22:18) thanks so much bye bye-bye,"The speaker, Christopher Currin, is discussing a project that aims to bridge the gap between artificial models and cortical circuits. The project focuses on using a personalized medicine approach to understanding and treating individuals with epilepsy, and also linking spiking neural networks with human brains to better understand brain function. He discusses the difficulties in comparing artificial models to the brain, and suggests that instead of making more complex models, using simple biological networks can be beneficial. He also mentions that the project involves reprogramming skin cells into induced pluripotent stem cells, which have the potential to become almost any other type of cell, and using these cells to create simple human cortical networks that closely mimic established theoretical models.",ChatGPT,,,,,,,,
https://www.youtube.com/watch?v=Z0V2Xxjpwjg&list=PL09WqqDbQWHFjkkXiQdOYC1wAdgSUMGxQ&index=11,2022,SNUFA Workshop,Michele Nardin,IST Austria,Nonlinear computations in spiking neural networks through multiplicative synapses,Neuromorphic-compatible algorithms,(148) Michele Nardin - Nonlinear computations in spiking neural networks through multiplicative synapses - YouTube https://www.youtube.com/watch?v=Z0V2Xxjpwjg Transcript: (00:04) okay we're moving on to our next invited talk um this talk is by Michaela nardeen from ISD Austria take it away thank you thank you very much um okay so well uh thank you I want to thank the the organizers for organizing this super cool meeting and today I want to talk about uh no linear computations in spiking neural networks so uh why do we think that they are important well uh we know that the brain is formed by networks of neurons and together they solve complicated tasks for example uh well something is wrong okay I have for (00:48) example Locomotion but there are many other examples the hypothesis here is that the brain represents low dimensional signals and computation is implemented within these signals in the form of a non-linear dynamical system now from a single cell perspective we know that there are many sources of non-linearities for example coincidence detectors filters and amplifications but it is hard in general to pinpoint exactly how these local non-linearities combine together to carry out Network computations now from a theoretical perspective (01:25) especially within the world of artificial neural networks it is known that recurrent neural networks with continuous units and nonlinear transfer functions can be trained so as to approximate any given Dynamic on the other side spiking neural networks are a bit trickier but also they are using either a non-linear dendrites or non-linear transfer functions and some specialized training techniques one can train the the network so that the readout resembles the solution to Any Given dynamical system now uh these approaches are are General (02:04) but uh they lack a principled derivation of the network components and of the non-linearity moreover they need supervised learning so it is in general a bit hard to precisely interpret the resulting connectivity so what we wanted to do here was to derive from first principles a fully interpretable Sparky neural network that implements non-linear dynamical systems and I want to take just a minute here to explain the the setting a bit more in detail and what we want is a network of spiky neurons in this example you can see the (02:45) the voltages and the spikes the spikes that happen whenever the voltage goes above a certain threshold and we assume that something is wrong sorry and we assume that we can use the filtered Spike trains weighted through a decoding Matrix d something is wrong with my slides I'm really sorry about that okay can you can you see my slides uh yes we can see the slides but anyway I will try to continue I'm so sorry about this um so what um what we have what we assume is that we can use the filtered Spike trains weighted through a decoding (03:32) Matrix D to read out the activity of the network that is generally called X hat what we want is uh the network readout to resemble the solution of a certain dynamical system and can we do that and yes we know how to do that if the dynamical system is linear and in fact if you start from the assumptions that the readout is linear and that the network is efficient in the sense that um a neuron will Spike only if it reduces the decreases the error between Target and readout signal you can derive the equations of a network of spiky (04:14) neurons whose output resembles the solution to the given that linear dynamical system now this network requires two types of synapses to work the fast type which as you can see in this schematic takes its name from from the fact that a pre-synaptic spike for example of the red neuron that you can see here has a very fast effect on the postsynaptic voltage of the connected blue neuron and on the other side this low synapses which have a slower and longer effect on postsynaptic voltage as you can see from this from this uh (04:51) small cartoon here this synapses are very important because they are the ones that are responsible for computation and from the fact that these networks can compute they got the name Spike coding networks or they are also known as efficient balance networks in the in the literature they have many cool properties for example they have they show tight excitator inhibitory balance they have realistic activity patterns and they are very robust to noise and cell death now the question is can we extend this derivation so as to include (05:28) non-linear dynamical systems for example in the form of a second degree polynomial and I just want to open a small parenthesis on notation here this notation means a Chronicle product applied D times if you've never heard of it you can think of a Chronicle product as a generalization of the outer product for for matrices so uh starting from the same assumptions as before and using some properties of the chronicle product we derived the equations for a network of spiking neurons that implements dynamical systems with second degree polynomial (06:05) interactions now this is very cool because you can derive every single connection from scratch and you don't need any training but more importantly our derivation predicts the existence of an additional set of synapses that we call multiplicative synapses in the sense that they effectively implement the multiplication among each pair of inputs so as you can see from from this schematic if each one of the presynaptic neurons fires in isolation then nothing happens whereas if both of these presynaptic neurons fire together you're (06:41) gonna have an effect on the postsynaptic voltage of of the postsynaptic neuron so you can think a bit of this synapses coincidence detectors and these are the synapses that effectively Implement nonlinear computations in in our Network so the first takeaway from these slides is that under our assumptions the necessity for a multiplicative synapses emerges from derivation moreover this shows exactly how to combine local non-linearities to achieve Network computations so uh this is very cool in theory but you might ask me do these networks (07:22) actually work in practice and the answer is yes I want to show a couple of examples here the first thing that we implemented was the the Lawrence system which is very interesting because it has second second degree polynomials and due to its um chaotic nature it requires a very very precise implementation and we implemented it in two different ways one with the new leader right multiplicative synapses and the other with some optimally trained non-linear dendrites that resembles previous approaches so if you look at the at the results you (07:58) can see that both implementations work and you can see by eye that they look quite good but if you look in detail at the network output and you compare it to the real solution you can notice that the network with multiplicative synapses can stick to the real solution for much longer so this already suggests that our implementation is more accurate and there is a essentially a standard ways to analyze the Precision of the of the the lorenza tractor essentially which is by plotting consecutive Peaks and this consecutive Peaks if you scatter plot (08:35) them they should follow a specific pattern that is plotted here in black this kind of like upward facing arrow and you can notice that the network with non-linear dendrites can follow this pattern quite easily although yeah the overlap is not perfect whereas if you do the same analysis for our multiplicative interactions the overlap is much much nicer so before jumping to conclusions here one could argue that maybe you know in our non-linear dendrite case we didn't use enough neurons or maybe our implementation is not really good enough (09:09) and this is probably the case right although um we have to say that a similar thing was observed in the talmeyer 2016 paper where they used thousands of neurons and better non-linearities so what we can conclude from this small experiment is that uh when a dynamical system is fully specified by second degree polynomials we have a significant Improvement in Precision moreover I want to briefly show you that these networks are also extremely robust in fact if you if you kill up to 90 percent of the units you still have a very very good very good (09:50) output so as a second takeaway from these slides you can see that the multiplicative spy coding networks are very precise and similarly to the original Spy coding networks they are also robust and efficient now you rightly might ask me we have seen second order second degree polynomials right how do we Implement arbitrary dynamical systems and to do this well we know that um polynomials can be used to approximate any bounded function to a arbitrary Precision so again starting from a polynomial dynamical system of any order (10:30) and under the same assumptions as before we expanded on our previous derivations and found a solution that essentially requires um higher order multiplicative synapses this means as you can see in this schematics here that um you essentially need synapses that can sense three four or even more coincidence presynaptic neurons that Spike together so this is very nice in theory and you can implement it and it works very well but the reason that this might be a bit unfeasible from a biological or a neuromorphic perspective so the question (11:10) here is um can we avoid them can we avoid this higher interactions and it turns out that we can the details here get a bit more technical but the idea is that one can derive networks of neurons that approximate non-linear transformations of their inputs and these networks can start can be stuck together so that you can use only pairwise multiplications to carry out High degree polynomials and I want to show them in action here I just want to show a small example we can Implement a double pendulum for small angles which is in an approximation that (11:49) requires third order multiplications and we implemented it with two networks that have only pairwise synapses and you can see in these plots essentially the the network output tracks the theoretical solution very very well so um the third and final takeaway from these slides is that we can approximate non-linear computations using only second order multiplications but these cons at the cost of stacking multiple networks together so uh this is nice and good in theory and we have also seen that they work very well but you might wonder how (12:28) feasible are these multiplicative networks from a biological perspective because uh you know in fact from a from a biological perspective there might be some concerns starting from the fact that you need the existence of multiplicative interactions right and here I'm just giving you some uh experimental reports describing that have described effective multiplicative interactions among neurons and there are also some potential mechanisms that are known about how this might be implemented to another potentially thorny aspect is (13:05) the connectivity density which is generally you know when you derive them is usually all to all and it turns out that these requests can be relaxed quite dramatically if you allow the decoding Matrix to be a bit sparse and I invite you here to to read our paper where you can find many more details on that and the last final aspect is the necessity of having multiple connections among pairs of neurons this is something that has been reported again in experimental and reconstruction studies so it seems to be not too unreasonable (13:43) so to conclude this part I would say that our multiplicative networks seem to be fairly reasonable from a biological perspective and we think that they could lead to understanding of computations in a real biological Networks so uh to conclude I want to leave you with some Food For Thoughts uh the first is that um we think of these multiplicative Spike coding networks as representing the ideal interactions for non-linear computations and they give us an idea of the put the potentials the potential computations that can be implemented in (14:24) spike in neural networks and the limit on their accuracy but more importantly they Define exactly how um how you can combine local non-linearities to achieve Network computations and this was fully derived from first principles and finally we think that this sort of networks could be interesting from a neuromorphic perspective due to uh well the many cool properties that we talked about and since we mentioned neuromorphic implementations I want to leave you with a small mention of some future Avenues uh some ongoing work about controlling (15:04) dynamical systems and many many more projects that are coming from the camping club at donders so with this I want to leave you I want to thank James who was a student with me with the uh during the 2019 computational summer school and we worked under the brilliant supervision of Bill and sander on this project that eventually went through a peer Community revision and we are very proud and happy to to share this work so please feel free to to get in touch and thank you very much for your attention yeah thank you very much for the great (15:43) talk um I believe our top question uh has been answered but I'll go ahead and and reiterate it um I'm thinking of biological counterparts for the synapses for excitatory glutamatergic ones fast ampa slow nmda multiplicative you talked a little bit about what the biological counterparts can you comment a little bit more on that yes yes um yes so there are um am I still screen screen can I go back to that to that slide uh yes you're still screen sharing okay okay so um yes there are there are some known (16:21) mechanisms right and for example well synaptic clustering chanting inhibition here um there are there are several uh biophysics models and also there are several um uh reports and I invite you to to look at this at these papers they are very very nice uh what I can say about the the biological implementations is that um essentially what we are requiring here is a very very precise multiplication right so from a biological perspective you might run into troubles right uh because the multiplications that have been shown in (17:05) in experiments are essentially very approximate experiment multiplications so um something that is also an ongoing project is to see if we can you know essentially Implement these networks using some more realistic multiplicative synapses great thank you um so another one of our questions from the audience um so you talked about going from a dynamical system to the snn that can um that can learn it can you do the other direction if you have a specific snn what are the dynamical systems that it can learn right um (17:44) so what are the dynamical systems that it can learn so in this in our case we are not learning anything we are really deriving everything from scratch but still um essentially in in our in our implementation how we are implementing these networks you can essentially uh Implement any sort of uh dynamical system that is defined fully defined by polynomials so essentially uh anything that you know involves any degree polynomial you can implement it from scratch if you get the the activity of the network and you want to do the (18:26) opposite process you want to see which uh dynamical system was implemented that's probably a bit trickier you might do it by looking at the connectivity Maybe by doing that the connectivity you could work on that but to be honest I don't have a very a very good answer for this question okay and I think you you hinted at this towards the end but uh a last question from the audience um your network can Implement almost any dynamical system and that's impressive how about solving a real world yes yes so um this is of course I mean (19:04) uh our our networks are essentially almost toy models right so that's that's true that's very true uh we've been working on on um essentially implementing some Kalman filters or implemented implementing some control dynamical systems for example the the last small thing that I was showing was to control a double pendulum to essentially you kind of mimic the the behavior of the legs right you can give it a push and then you can Implement some some uh some limits right you don't want your shin to go above your knee or (19:41) things like that right so there is potential there is potential and that's uh ongoing work and a lot of ongoing work is going on in the camping club but at donors and I invite you to well get in touch with him and and you know stay tuned for upcoming projects okay thank you very much for the Fantastic talk thank you that is the end of our our first session um we are going on a a 30 minute break now but we'll resume with session two um in about 30 minutes uh freedom and I don't know if you have anything else to (20:17) add um no I don't have anything to add thank you very much to all the speakers of the first session thanks very much Katie for moderating uh and thanks everybody for staying on time and we meet back here for Utah for your eyes this talk five minutes past the hour and whatever time zone you are thank you very much bye bye,"The speaker is discussing how nonlinear computations can be implemented in spiking neural networks through the use of multiplicative synapses. The speaker argues that the brain is made up of networks of neurons that solve complicated tasks and that these tasks are represented by low dimensional signals. The speaker then goes on to explain that it is difficult to pinpoint exactly how these local non-linearities combine together to carry out network computations. The speaker then explains that they have derived a fully interpretable spiking neural network that implements non-linear dynamical systems, using filtered spike trains and a decoding matrix. The network requires two types of synapses: fast synapses which have a quick effect on postsynaptic voltage, and slow synapses which have a longer effect and are responsible for computation. The network is called Spike Coding Network.",ChatGPT,,,,,,,,
https://www.youtube.com/watch?v=n0x6LJ-F2sI&list=PL09WqqDbQWHFjkkXiQdOYC1wAdgSUMGxQ&index=12,2022,SNUFA Workshop,Yonghong Tian,Perking University,Spiking Deep Learning with SpikingJelly,Software and tools,(148) Yonghong Tian - Spiking Deep Learning with SpikingJelly - YouTube https://www.youtube.com/watch?v=n0x6LJ-F2sI Transcript:,"The speaker is discussing a development framework called SpikingJelly, which is designed for the second generation of neural networks that use sequential and discrete spikes to communicate between layers. These networks, called neuromorphic networks, are more power efficient than traditional deep learning networks, but are currently limited in size and performance. The speaker notes that the main challenge in developing these networks is finding learning algorithms that are both biologically plausible and computationally efficient. They mention that traditional learning rules such as backpropagation and Hebbian learning are not suitable for neuromorphic networks and alternative methods such as the secret gradient method and the n2sn conversion have been proposed. They also mention that most existing neural network frameworks are not designed for neuromorphic networks, which makes it difficult for researchers to combine advanced deep learning methods with neuromorphic networks.",ChatGPT,,,,,,,,
https://www.youtube.com/watch?v=0hWIHDtEKZI&list=PL09WqqDbQWHEqm1_3a620tKUKnC6FgBrG&index=2,2021,SNUFA Workshop,Tara Hamilton,UT Sydney,Unsupervised Spiking Neural Networks,Learning,(148) 02 Tara Hamilton - Unsupervised Spiking Neural Networks - YouTube https://www.youtube.com/watch?v=0hWIHDtEKZI Transcript: (00:07) hello everybody and welcome to this first session of the neufo workshop um it's really my pleasure to invite and introduce tara julia hamilton to give the first lecture of the of the workshop tara is first of all a friend and then a brilliant scientist and she's now working as a society professor of the school of electrical and data engineering at the university of technology sydney um she did a lot of things and i think that what is relevant is that in her education there's both you know engineering but also um (00:46) economics and marketing and i think this is very important to create research that has really an impact in our lives and in fact she has been working both in academia and in industry and technology identity industry to create devices for mainly for health and biomedical applications so relevant to these workshops she works in microelectronics and neuromorphic engineering to develop devices that using fighting neural network and learning can impact in biomedical applications and auditory systems mostly so uh the stage is yours i'm really looking (01:28) forward to your presentation thank you for coming thanks very much kiara thank you everyone um it's uh it's great to be here um all the way from uh sydney australia um so uh today i'm going to talk about unsupervised spike in neural networks that i've basically that that's sort of the main type of spiking neural network that i've been working on for a number of years um but you know it's full of challenges so mostly i'll talk to you about challenges today and hopefully that will inspire (02:04) some discussions and things so um let me go on so firstly just a little bit about me here i kind of covered a lot of it i i started my life as an analog integrated circuit designer um and my first job was actually a cochlear that make the the cochlear implants and that sort of led to being interested in biology and things and then got interested in neuromorphic engineering so i've been doing neuromorphic engineering since 2004 and i started work with silicon cochleas um and then silicon neurons and both of those two things sort of uh posed (02:43) challenges as a circuit designer mainly because of the nonlinear dynamics it's sort of something that as straight circuit designer isn't used to these circuits that behave weirdly in particular um operating regimes um i've probably i tried to work this out but it's probably been since 2009 that i've been looking at spiking neural networks um and we started looking at sort of extreme learning machine type networks with spikes and then i got more interested in unsupervised networks and and how we can do kind of (03:20) unsupervised learning um i've been kind of keeping a low profile because i had some twins and that's kind of kept me busy keep my hands full but now i'm looking at edge computing and sensors and looking at incorporating learning at the edge so spiking networks are really great for for that application um so um so in this talk i'm gonna talk about uh unsupervised spiking neural networks firstly why why are they interesting um and then i'm gonna be talking about two different types of networks that i've (04:00) been playing with so firstly the franken rhythms um and i'll explain what that is later and secondly principled spiking neural networks where we really uh sort of dive in and uh hope to to use um principles of neuroscience to make our networks and then sort of uh what what happens next um type thing so why spike in neural networks are probably preaching to the converted here but um there is something very uh i don't know like it's it's hard to look at biology any biology a simple insect all the way up to complex life and not (04:42) be kind of wowed by that and the capabilities in terms of computation that comes with that um as i said before one of the real reasons for me as a sort of hardware engineer person is is looking at edge computing and looking at building sensor networks and sensors that have the ability to learn at the sensor we're kind of living in this world of lots of data and the traditional machine learning methods require data to be labeled um someone to kind of process the pre-processing of the data um and it makes it very inefficient on so many levels so a (05:25) more biological approach i think is is definitely the way we need to go um there's also like from a from an engineering point of view a lot of security to be had from encoding and computation in spikes because it's really hard to work backwards and work out what it's what all that data is so it does have a nice sort of inherent security aspect there's obviously if you're using sparse spiking networks where power is a huge issue and then as i said before being able to deal with data that's not (06:03) labeled and and trying to sift through that without the extra overhead i think is a challenge that we all need to get our heads around so why unsupervised um it's kind of my my big nightmare um my phd was looking at a non-linear model of the cochlea and the cochlear is sort of poised on a bifurcation so it gets this amazing gain and compressive effect from being a non-winning system but building that thing and having so many things to tune i just have nightmares about lots of turning lots of notes so um unsupervised (06:53) learning ways to kind of self-organize um you know networks and circuits without having to twist all the knobs is is what i aim for in my life um it's basically some sort of traumatic experience that i i just i need to get the uh the uh i need to get rid of all the knobs so that's that's the main reason i kind of look at standard machine learning i feel very sorry for everyone having to tune parameters and so i've kind of made up my life my life's mission to avoid parameter tuning um at all costs (07:30) um franken rhythms um this is a term that a colleague of mine has uh coined and i sort of run with it because uh it sort of explains what was certainly what i did earlier and what i still kind of do now so we all know that getting the biology right is really hard um it's hard because we don't have all the answers yet we're still finding out things about the brain um and it's hard because we've got sort of von neumann computers that when we're dealing with large heavily connected networks we're really limited (08:11) but we've also got these hardware advantages with really cheap um reconfigurable hardware that runs at lightning speed and so sometimes it's hard to justify working on a slow spiking network um that you're not really sure whether it's going to work very well or it's not going to work to the same level as a deep network um and so yeah when you're trying to work out what network to use and what's going to be the best for your solution it's sometimes hard to go with the straight principled spiking network (08:50) certainly at this point as we still sift through how to make those things work so the franken rhythms are really biologically inspired but they're really about tailoring solutions that will benefit a particular application and it's great for applications where i can't just put a deep network on an fpga and let it run in the wild um it's not going to work so it's this nice sort of balance between the two so early work on franken rhythms um was with my students sayed and richard um and we designed the scan algorithm (09:30) which is nice this sort of uh fun algorithm that was designed very much for hardware digital hardware and was able to learn timing between spikes so if you encode your data as spikes then you could learn the timing between spikes um and it it uses sort of an adaptive threshold um method where you basically can think of you start off with a wide um receptive field um and as you get more presentations of the um the spike interval that you're interested in the network tunes itself closer and closer to learning that particular (10:14) spike interval and you have a larger network of these and you use inhibition once somebody's caught a a spike time then that neuron has that time and you can have a bunch of neurons in line different times and this this um you know it worked quite well um for particular applications um completely unsupervised which was really nice and really easy to implement on fpga hardware and it used sort of biological principles in terms of having weights having an adaptive threshold and using inhibition to allow multiple (10:57) neurons to learn some of the problems it had though was that timing was difficult if you had a stream of uh inputs coming in too fast you'd either have to drop them or the whole thing would sort of fall over um it didn't really scale very well um it was good for sort of a first pass on data but then having subsequent layers we ran into a lot of the problems that other spiking neural networks run into that i'll talk about a little bit later um so yeah so this has been adapted further um but you know it has problems but it it (11:37) was good for what it did um so it was really easy to set up a simple uh this is in the paper that we did learning different hand signs it was easy very simple low power fpga completely unsupervised anyone could get in front of it and the network would train on them and the interesting thing about it was that even though it was really dead easy um it's it had this these bayesian inference properties so it actually um it it had this uh you know early receptive field that grew to collect um the the second spike and then (12:22) um zoomed in around that so it was it was really um it was really kind of fell out of of the network rather than being designed into it which was kind of an interesting uh concept so um just on the franken rhythms um the idea is really just starting with an application so what do you need an unsupervised network for um if it's a well-bounded problem like the problem that i've been looking at now which is uh cardiac monitoring um it's bounded well in time there's a minimum heart rate that a person can (13:03) have and a maximum before they're dead either way and so you kind of know what what your signals are going to look like and that helps you then tailor a network around it and then in an application like cardiac monitoring requiring low power and thinking about where the application is going to be used we've been working with collaborators in india and looking at rural areas and you know compliance and infrastructure availability and all that needs to be kind of built in to your design and then um for health monitoring making it so that (13:48) it's personalized and secure are really important aspects so i just see that there's some discussion over um over the security aspects i can't read that now but um i guess uh yeah we can debate whether it actually is more secure or not but uh as a first pass it probably is slightly more secure than a numerical um encoding um so for our solution here we're trying to build a wearable cardiac monitor that people can that has a long life battery life that people in remote areas can use for their cardiac health (14:33) and so on that we kind of want to build a system that learns the individual person and compares their normal with any anomalies from from that normal reading so the network is comprised of a neuromorphic adc which is basically doing the feature extraction so we use populations of neurons with around different thresholds so that we can catch different features in a qrs complex of a cardiac signal and these neurons are sort of standard integrating fire neurons with some threshold adaptation and this also reduces the need for (15:17) pre-processing so when we have large populations of neurons we can actually use them to where they correlate we can use them to remove um constant noise so here a 50 hertz noise is present in a in a signal and we can use neurons to [Music] transform that signal into spikes and then correlations between those spikes we can then subtract that from our signal and find very small signals inside that so we're just using populations basically lots of numbers lots of numbers that are spread out um to to give us a a good way of getting rid of constant (16:09) noise which is what we often have in um in in medical devices so um so yeah so this sort of solution is looking at using a kind of stochastic approach to analog to digital conversion or analog spike conversion um and it then also has the added benefit of giving us different features um of of the of the ecg signal and then we have a learning network which is not too dissimilar from scan except it's not handicapped by the timing issues i discussed and this basically we once we receive this bike on one channel uh we have a sort of (16:51) decaying a linear decay weight uh when the next bike comes in we kind of learn what those addition of those two spikes are and then we set the threshold so we we end up learning sort of a tight ring around our spike times um and well the ring can be tied or loose so a person's normal ecg it varies across the course of a day so you might have several channels that learn you know when you're resting or when you're running or when you're watching a scary movie or something and then other channels that can pick up (17:33) very quickly if there's an anomaly so this is a ecg i was trying to get the balance right it's hard to zoom in on an ecg and also show the larger detail but this is an ecg with st elevation um and one of the channels picks up very quickly that there's some sort of anomaly on this and this could then alert a health professional or something like that so the franken rhythms are these sort of mashed up spiking networks that are quite useful for specific tasks and it has elements of biological um neurons but it also is (18:14) very much tailored to particular applications so this we can put on a very low cost fpga because of the neuromorphic adc taking features and the kind of stochastic population coding that we're using we can reduce the amount of pre-processing we need as well so all in all it's a fairly good engineering problem for a solution to a very kind of constrained problem so um the other aspect of the research that i've been doing is looking at principles biking neural networks and this came about having a conversation with someone at a (18:57) computational neuroscience um conference here in australia and um just [Music] the frustration that we haven't got spike in your networks sorted um and it's difficult because you know deep networks and other types of machine learning are so successful right now so it's hard to get people on board with the idea of spiking networks is something that can really um you know really take over or actually be better than than what we currently have with conventional networks um so we kind of call them stuns um (19:40) spike timing unsupervised neural networks um we do have a little bit of an obsession with getting uh acronyms that say something um but stuns are basically using spiking neurons uh looking at spike time coding uh and incorporating a lot of the things that we know are important ingredients so sparsity um spa spiking and sparse connectivity um stdp for for unsupervised learning and basically an approach that is more um aimed at looking at the principles in biology rather than you know a franken rhythms approach or uh (20:25) looking at how deep networks work and trying to work out how how spikes fit into that so it's it's sort of uh it's a slow approach i can certainly say that so we kind of started off very simply looking at auto encoding and anomaly detection and we actually trained on moby dick if anyone's ever read moby dick it's very long-winded book um but it's an interesting thing that you can actually get pretty good auto encoding using a spiking network with not many bells and whistles this one we we didn't (21:02) really we weren't down the rabbit hole yet um but it was already kind of encouraging because the amount of data that you need to train a spiking network is significantly lower than for a conventional deep network and that was already apparent in this work so this is the most interesting picture from the paper but basically it's not nothing here is surprising so as you as you train on more characters um you your audio encoding improves but your anomaly detection you know it's terrible because you're basically (21:46) just learning everything um and and then there's this sweet spot where you're kind of doing pretty well um on your auto encoding and picking up anomalies but it's that wasn't really the most interesting part this was a three-layer network um stdp synapses uh spas connectivity um and with some inhibition laterally um and that's that's about it um and i guess the most interesting thing was the the lack of data required to start getting results um so really what we've been focusing on is there are (22:31) some known problems with uh spiking neural networks so there's the there's this there's the vanishing spike problem which is uh as you move through layers in a spiking network you lose spikes um there's the issue with spikes being impulses and therefore analytically solving some sort of mathematical framework that tells you how they work is not really possible without making lots of assumptions and without having you know whiteboards full of math um the lack of an objective function so knowing that your network has trained (23:18) um you know there's not really an error signal in a in an unsupervised network so how do you how do you deal with that um the perceived inability of unsupervised learning to solve sort of logical not or xor like problems and then there's sort of the the thing that i think everyone is starting to look at but combining us by time coding with unsupervised learning and that's rather challenging and often we sort of skip to a rate coding solution or um some sort of hybrids um solution so these are the kind of things (24:00) that that we've been looking at so the vanishing spike problem is sort of shown in this picture here so if we have um a number of layers where we've got some random spiking and then we then we have uh the blue layer and that goes into that feeds into the orange and the green and so forth we either get vanishing spikes signal stops propagating and that's usually because we have leaky neurons and leaky neurons if the input is less than the leak it doesn't matter if the input is going in forever it's never going to create a spike (24:40) um or we have this sort of discontinuity with spikes where if we have a input that's greater than the threshold then we're gonna keep spiking and so we see these cascades of bursting spikes um that you know is just due to some some randomness that then gets um amplified through the network so we either get vanishing spikes so we get bursty behavior um and this is this is a problem that lots of people probably lots of people here have noted um and it sort of stops us from looking at really deep um spiking networks (25:22) um so what we want is is something like this and we've kind of been playing around with different aspects so that we can we can get this um sort of behavior from our networks um and and a lot of that is just looking at biology as the exemplar and the different ways that biology deals with sparsity and balance and inhibition and using those parts of the recipe to to get the network to to to get out of these sort of uh spiking no spiking or spiking crazy sort of discontinuities um so i've already talked about the trouble (26:09) with non-linear systems um and that's really the issue we're trying to get get to an analytical solution of spiking networks um and the issue is that we're up against machine learning where there's real analytical proofs on how they work whereas here we're kind of flying blind we know that this is not what happens in biology unless something's wrong um so the question is how what what are the what are the mechanisms to stop this sort of thing from happening in in the biological context and then (26:50) working backwards so that we don't get limit cycles or we get don't get vanishing spikes um so with unsupervised learning when do i know that i know this is uh some hidden hidden layer neurons uh training on mnist um i mean it's nice because we can actually see the numbers here but at what point is the networked learned um at what point is it good enough um and all this is is is completely unsupervised and it's it's doing um you know self-organization um some of these neurons are focusing on ones and nines and so (27:36) without sort of you know god's looking down saying okay we're done how do we know that our system is learned um and how do we know that it's good enough and these are things because we don't have an error signal that we just don't know how to deal with that and do we need to deal with that i mean is it okay to just have a system that's constantly learning and at some points it's um its performance is is is good enough we kind of know with humans we learn we start off not great and then we get (28:09) better so maybe our networks need to just be we need to be okay with errors i guess and more um you know instances given to the network improves its performance over time just like we prefer you know increase our performance at various tasks with with more practice so this is just questions on how how do you benchmark as well when you've got a system that's completely sort of free running and anytime i run this network it could you know different neurons will learn different things and you know it's it's (28:47) completely random there's no way to know uh who's gonna learn what's and um at what point is it is it is it learned i will say that with mnist um the networks tend to not take too long to learn so we we don't we don't we don't we just train on one epoch and it's very very quickly that these neurons self-organize so it is interesting watching them learn in real time because they do settle on something rather quickly um and perhaps some sort of measure of how a an individual hidden neuron is changing might be the way to learn (29:34) when a network is finished learning it's it's sort of a question that's still out there um and i guess the other thing that goes with that is that um the tensorflow or the kind of standard deep learning method this is tensorflow but if i if i put uh if i kind of scan um across a bunch of mnist digits with tensorflow regardless of whether it's on a digital not it'll give you an answer it always gives you an answer you know it's completely you know that's what it does it gives answers so even when there's no digits (30:12) it'll give you an answer um the spiking network though only this is uh sort of scanning across one of our spiking networks that has um learned mnist and it only so where it's uh yellow is where it's sort of given an answer and it only gives an answer when it thinks oh yeah that's that's a that's an eight and that's seven so um the differences in in what a deep network does always giving an answer and the spiking network which because it's not trained to decrease an error it's just learning (30:54) um learning patterns basically and self-organizing um it only um it only says it seems something when it actually sees something um which is kind of i mean this is what we want from our networks i think so it's actually it's good um but it's different and it's a different way of judging how a network works um the xor conundrum is interesting for unsupervised learning because the way we learn using kind of a standard network with a hidden layer is we have an error signal so without an error signal how to learn (31:33) um these things um it's uh you know it's something that that obviously needs to be solved and um you know we know that our brains can get it you know we can get our head around the exhaust so so there must be an answer for how an unsupervised network can do that as well um so so china they go perfect timing um so yeah so just with stuns um the things that are most interesting at this point along with solving those questions about um uh you know spiking networks and the problems we have with them it's also (32:23) looking at recurrence and how do we how do we deal with recurrence in these networks without you know again going into kind of the vanishing um spike problem or into the uh limit cycling problem um we know brain does prediction so how do we leverage prediction out of our networks we should be able to um it should be something that we can definitely do over conventional machine learning and so i think it needs to be something that you know we concentrate on because it has has has a great advantage in speed and (33:02) dealing with uh incomplete and noisy data um and then adaptation so you can leave a network one that's unsupervised and it will adapt and if you're looking for anomalies if you're looking for problems how do you know when it there's a problem or if something's just slowly adapted and changed so these are all questions for dealing with some unsupervised timed networks um so what next so the franken rhythms sort of are useful for very specific applications um there they will continue to sort of gain from (33:44) insight into biology um and the stuns are a really great way of looking at principled understanding and solving some of the problems that we know or issues that we know are with spiking networks and then expanding these further to incorporate prediction and recurrence just acknowledge my um collaborators um pete stratton and andrew webnets and ben essem who have been working on the bit net and the stuns and masame shivanji binzu and gaetano have been helping me with the franken rhythms thank you very much everyone (34:27) thanks a lot i don't know how it works here for uh [Music] so i start from the most voted one that's from then um he's asking did i understand right that you need less data for training with particular networks do you have an intuition as to why why they need less data i think it's the self-organization so um because a a deep network requires the error signal to come back um it can make huge changes to those uh hidden neurons whereas a spiking network is well an unsupervised biking network is is um self-organizing right from the (35:26) start so you because you've got lateral inhibition you're basically every neuron is catching some of that the features in the input and it very quickly uh starts to differ um so i think it's about self-organization of hidden neurons okay then there was another one that was had some uh votes that's related to this question um and it's from some does the data type change uh the smart neural network's advantage over deep neural networks in speed of learning empirically or intuitively so for example maybe (36:15) striking your anecdotes have a natural advantage in temporal anomaly detection but not in other domains yeah i think um i i think yeah i would be cheating to say that spiking neural networks always have the advantage simply because there's a big overhead in converting data into spikes and then working out you know like with mnist you know you can work out a fairly easy timed code but um with more fine-grained data uh you know working out the time code for an input is is quite a big overhead but once it's (36:57) in spikes i think you're always going to get the advantage of of the self-organization and the speed as as long as um as long as you've got a good code for your data um that's in a sort of spike time form then i think it will always have the speed advantage okay uh so a question from finn uh that is actually on beatsnap so it's asking what is this network uh so you presented results i think one of the last years yeah so uh bitnet is uh this one here yeah so bitnet is is the name we give to our spiking network um (37:43) it's it's our kind of little pet name for it um and and basically it's it's a network that's uh what do we call a big net um it's like it we use binned timing so that that's where the bi comes from so it's it's uh yeah so if you've ever seen the saun network the recurrent network it's sort of a feed forward version of that um but yeah big net is basically our stun so it's it's a spike timing unsupervised neural network okay and then um how did you train on moby dick (38:25) did you do next character prediction so i think this was from freedman did you do next character prediction and um related to that please explain what has been learned and could you also explain what the anomaly is in that case from gravity yeah so um yeah so let me go back there um i always put too much in these things so uh yeah so we trained it from you know called me ishmael straight through um and so an anomaly was when we got a wrong character come next so if we put in sort of a bunch of text and then we ask the network what comes (39:21) next um if it gave something that wasn't um really in the text then it's it's an anomaly so so these this measure looks at how good it was at picking those up so um if it was um you know if it was good at finishing off the next word in the next few characters um then it's it's sort of doing well at audio encoding but if it's um if it's giving us the wrong um letter then um wrong character then we it's it's a it's an anomaly okay so there are really lots of questions so i guess this is an indication that the (40:16) talk was really well received and interesting so uh someone let me check the name alexander he's asking should we should we be focusing on one or few shots learning where most of the learning happens in a unsupervised way through self-organization and we intervened right at the end to stick labels on behaviors and categories that have emerged as a result so kind of this body was talking about before yeah yeah that's a great question because we grappled with this ourselves right so we we end up with um we end up with you know hidden neurons (40:53) that do this and then how do we know that it learned anything you know so that so then you read the like for us the way we treat you know like the way we worked out whether this was working or not was using a linear decoder um and then we then we came up with the spike forcing so we had like uh populations of neurons that responded to different um uh digits and whichever population was more active told us that that was most likely the the um but actually it's a really hard thing you either use some sort of decoder at (41:35) the output which is obviously supervised or you um or or the the spike forcing which we used um which we now started to use is actually really good at also giving us you know in mnist there's some digits that look you know that humans get wrong um and the network sort of behaves similarly it's like oh that could be a six or it could be a zero and you sort of see the the neurons um for those uh digits sort of both both those populations spiking a bit so um but it is actually really hard to know how to do that so so the idea of sort of (42:17) doing a very fast unsupervised learning and then supervising at the end is actually a really good way to get a very quick network trained and uh and verified yes i mean if i may add one one question from my side related to these um to me it's not clear um what an anomaly would be in this case would it be something that the letter has not seen before and will be a new category a new visit or um because you don't know how many there are right we know now that we have ten but it could be that we are in a hexadecimal domain (43:00) and we have more uh symbols that we never encountered before is that you know an anomaly misclassification or something new how can you understand that yeah so i mean i guess um i guess here the network doesn't respond at all to things that um like it's not responding so you can imagine we've got a little window that's sort of centered like like an mnist thing and we're just like tripping between like scanning like one pixel at a time across um so if if the network hasn't seen it before it it doesn't it doesn't spike (43:43) there's no um there's no output so you could say the lack of a response from bitnet in this case is indicative of an anomaly um because it it it's it's not a zero to nine it hasn't been trained on um it hasn't been trained on it hasn't seen it before and actually that's the power of this because a kind of street artificial network will always guess you will always give you something interesting these are actually very interesting problems to look into yeah it's down the rabbit hole but i mean it (44:27) is actually lots of fun so you know everyone get on board the unsupervised uh training okay so just to to keep the time i think we have to stop with the questions there are other questions in the in the question list if you want maybe to have a look and answer in the chat this could be a way or i don't know how it could be organized but i think we have to move to the next speaker thank you everyone it's been fun,"Tara Hamilton is a professor of electrical and data engineering at the University of Technology Sydney. She has a background in both engineering and economics/marketing and has worked in academia and industry to develop devices for health and biomedical applications. In this video, she is discussing unsupervised spiking neural networks, which are a type of neural network that she has been working on for several years. She talks about the challenges of working with these networks and describes two different types of networks that she has been experimenting with: Franken rhythms and principled spiking neural networks. She also explains why spiking neural networks are interesting, particularly in the context of edge computing and sensor networks.",ChatGPT,,,,,,,,
https://www.youtube.com/watch?v=ErNtD89C76k&list=PL09WqqDbQWHEqm1_3a620tKUKnC6FgBrG&index=3,2021,SNUFA Workshop,Dominik Dold,Siemens,Spike-based embeddings for multi-relational graph data,Data analysis applications,(148) 03 Dominik Dold - Spike-based embeddings for multi-relational graph data - YouTube https://www.youtube.com/watch?v=ErNtD89C76k Transcript: (00:09) okay so hello again um we now start with the contributed talks from the people who submitted abstracts to the workshop and the first one is dominique salt from asia in germany and um the topic of this talk is spy based and that means for multi-relational graph data state is yours thanks for contributing thank you very much so hello everyone um it's already said my name is dominic first of all i'd like to thank the organizers for organizing this really awesome workshop giving me the opportunity to contribute to it (00:47) and the work that i'm going to present spike based embeddings for multi-relational graph data this is work that i have done at siemens in munich with my colleagues jose victor marcel and thomas currently i'm working at esa in the netherlands actually but i'm also continuing like on this kind of work here at esa so first of all why would we be interested in knowledge graphs or multi-relational graphs and the nice thing about modulation graphs is that it can be used to model a lot of different systems and structures for instance (01:24) molecules can be modeled as graphs social networks well known for anyone here or like medical studies like the relationship between diseases treatments chemicals side effects studies and so on and the question that i want to raise you in this talk or that raised in this work is how can we process such data structures using spikes that's also what i'm going to talk about in the next like 15 minutes now first as a brief introduction what are knowledge graphs or multi-relational graphs they consist of two main building blocks (01:58) the first one being notes these bubbles representing entities and concepts and edges between these nodes representing relations between entities and concepts so as as an example graph you have a graph of like a movie where we have an actor like carrie fisher she can have a professional actor she plays a character which appears in a movie so you can already see it's quite flexible and how we can model different systems here with edges and with notes and a different way to represent this is as a list of triples (02:34) so this is always subject predicate object or like node edge node um like always one of these links here like carrie fisher has profession actor and we can just summarize the whole graph with a list of these triple statements so that's an alternative representation of a knowledge graph so what can we not do with these data structures one thing we can do is ask new questions like based on the knowledge that we have accumulated here um we can ask questions like whether a link should exist or not for instance does carrie fisher appear (03:06) in star wars and the answer to this would be yes of course as since he's playing a character who appears in the movie's hours another thing we can do is no classification where we would look at like the structure of a node like what is it connected to how it does it relate to other nodes and then figure out whether it belongs to a certain class or not for instance is this a real person or a fictional person or not a person at all now a big question is how can we do that how can we do these inference tests on graphs (03:38) a classical approach is to build kind of to do feature engineering to build rules from our graph and to figure out new relationships between our data points this is like engineering filters for image recognition like edge detectors but this is quite hard and doesn't really scale well to big knowledge graphs that are very complex maybe even unclean um and have missing links and so on so a very prominent model nowadays our approach is to find new representation for each entity in the graph so instead of using the symbolic structure we want to find a (04:21) new representation of the graph in a low dimensional vector space so how this looks like is that for each node we want to find a new node embedding like for instance here a two-dimensional vector in a vector space so each node here like these would be the node embeddings and for each node in the graph we'll have like a list here of two dimensional vectors each vector representing or being the new token that we use for this node and we do the same for the relations where each relation type is represented by a vector or something (04:52) else like a matrix again and usually like we couple this with a scoring function theta and this scoring function we can give the node embeddings and relation embeddings for a triple like for a subject for a predicate and for an object and then calculate a scalar value which gives us a likelihood estimate or some metric whether the edge spo like this triple should exist in a graph or not so the two embeddings plus the theta function are our replacement for the knowledge graph and then we have vector replacements here like vector value (05:25) quantities that we can use downstream and machine learning approaches like support vector machines random forests deep neural networks again and yeah so of course when we just randomly illusionize everything this doesn't work uh this will not will have nothing to do with our original graph but we can train these embeddings um to become very good at capturing the information contained in our graph we do this by using the edges that we have available using as a teaching signal and then draining these node and relation (06:02) embeddings using gradient descent and after training we can then use the theater and the embeddings for instance to do the link prediction task simply by swapping here or entering here um the yeah the embeddings are a subject predicate object that we want to evaluate like carrie fisher appears in star wars we'll now get an evaluation based on the knowledge contained in the graph which is now contained in the embeddings whether this should be true or should not be true now the question is can we do something similar with spikes (06:42) and the answer to that is yes so there is a way to do that and there are probably many ways to do that the way we found is that instead of mapping nodes and relation types to continuous valid vectors we want to map them into the spec domain so to spike trains and yeah what we found how you can do this is that nodes can be represented as the first spikes of a population of neurons so this would be one node here represented by for instance three neurons and every neuron can only spike once and the time to the first spike (07:21) like uh like this whole pattern here encodes uh now like this this layer organo node so the temporal pattern represents this element of the graph we can also do this for other elements in the graph and we'll get slightly different patterns depending on how these nodes are related to each other and relations are then represented as spike time differences between these patterns so we take the spike time difference between the first neurons of the populations between the second neurons of the populations between the third neurons of (07:51) the populations and so on and then we compare this to the expected spike time differences that we like the ones that we expect to be true to to see when this relation is true so the organa appears in star wars should be true so these should match of course when we compare it to another relation like has child this doesn't make sense so there should be a mismatch a big mismatch actually so how does this look in practice we implemented this with a simple integrate and fire neuron model which can be solved analytically for the for the (08:28) spike times or like for the time to first spike but you can also use other models um as long as you can calculate the gradients with respect to the spike times like for instance last year there were a few models presented by comsa and girls that are here at this workshop and this year there will also be a talk about gradient descent in spike based system by christian pele tomorrow so we take this model here and these are like our neurons in the neuron populations encoding the nodes so this would be one the the representation of (09:04) one node the representation of an atom node now these bubbles are the neurons of course we have to drive them with some input otherwise they won't do anything so we use fixed spike inputs it's also a population of neurons where each neuron spikes once and weights which can be trained so by training these weights here we can change uh the output spike times and these bike times here now like these patterns represent the the denote embeddings this is what we then use like we take the time differences then (09:35) can we can decode the patterns and see whether compared to the relations and see whether a relation should be true between these two uh populations here or not this is exactly this theta function but now we have the spike times here and again the relation embedding for training we just use a loss function that depends exactly on these scores on the spike times and the training graph of course and then we can optimize the spike times like the spike embeddings and the spike time difference patterns using gradient (10:09) descent what we get then is something like this so here in this graph we have on the x-axis the time on the y-axis are different neurons the black so the spike roster plot the black dots here are the fixed input spikes and between these grey dashed lines other spike times of each like of different populations encoding different notes and we also get the relation embeddings like the expected spike time differences here you can see that we get a variety of temporal patterns emerging that that encode different different relationships between concepts (10:53) in our graph so this can be very very complex like here on the bottom but also something very similar and familiar to all of us like coincidence detection that two two patterns or like the two concepts are very close to each other when the spike time patterns are very close close to each other um you can also see that the here we get actually negative spike time differences and positive ones so the spike time ordering is also important but this depends on how you choose this distance function here so if you choose this to (11:26) be symmetric then you'll also get you know embeddings that only depend on the pure absolute spike time difference so as a small example here we use this on a graph encoding the relationships between countries and geographical regions for instance italy is located in europe would be a triple slovakia is the neighbor of the ukraine slovakia is also in the name of hungary and so on and we can train our yeah our spiking neurons on this data set to get the spike time and paddings and afterwards we can evaluate like new facts (12:07) for instance what are the neighbors of romania so we would ask like this would be subject is romania the predicate would be neighbor and then we would test out all possible predicates like all other countries and region and see how our spectrum embeddings embeddings rank these um like how how good the patterns actually match and we can use the score and the theta function to make a list of sorted um yeah assorted candidates where on the top we have the most likely neighbors and on the bottom we have the least likely neighbors (12:43) so when we do this here are the first five neighbors you can see here on the map these are of course the closest neighbors to romania and when we go further we get neighbors that are a bit further away so this exactly as we wanted and the spike times like our spike patterns encode this information now there is one small detail of course when we do this our graph has to be static so when we have a new node that wasn't present our graph during training we don't have an embedding for it so we cannot do inference with it (13:16) there's a question is there some way to deal with this scenario so what about notes that are not seen during the training and there's a very famous and nowadays often used model that has many nice properties this is only one of the nice properties called graph neural networks that can deal with exactly this kind of challenge so here the idea is that we don't just take the the node embeddings as they are but we squeeze them through like another like a neural layer where we enrich the embeddings and update them (13:51) to get better embeddings which we then use uh for our scoring so this is the graph neural network part where we update each and then embedding like for instance the embedding of this red node by looking at its neighbors the blue nodes we collect the embeddings from the blue nodes average them and use that as the new embedding for the red node and we do this for each node in the graph so we use apply this like a filter mask over the whole graph that's why it's also called graph convolutional network and this way we get an updated and (14:23) enriched embedding for each node in our graph the nice thing is here that we basically collect neighborhood information so our embeddings now know something about its direct neighbors and if we repeat this process we would collect information about neighbors that are further and further away in the graph now when we have a new node will most likely be connected to other nodes in our graph so we can just take the neighbors take their embeddings and calculate an embedding for our node and then use this node embedding (14:57) in in our like further inference pipeline so we did exactly this for or like we tried this out for for our spike based coding scheme so we have this here is a proof of concept so here this is exactly the same architecture as before we have the fixed spike inputs we have the initial spike embeddings now and then we have this kind of like routing neighborhood aggregation layer and this feeds again into another population or like populations of spiking neurons here they follow approximately this dynamics here where (15:37) we have a synaptic kernel we are in averaging over the neighbors n so these are like these initial spike embeddings and we do this separately for every relation so we kind of have a filter mask for every relation that we can train as well so we did this for smaller data sets since it's a bit hard to simulate this efficiently um so the simulations were quite small so we did this on handcrafted smaller data sets but you can already see that the performance here is quite competitive to more like standard graph embedding (16:09) models and it does learn appropriately and the very nice thing here um is that to reference the motor of this workshop that the spikes flow so the whole calculation is completely asynchronous so usually in graph embedding you would first update all like embeddings once to get the orange one and if you continue this like you have layer wise locking but here you can see that some of the final spikes already spike neurons already spike even before we have presented the whole initial embeddings so everything is happening at the same time and this also (16:47) means that not all of these spike times here in the initial layer are needed to update or to get the final spike embeddings so it's a pretty sparse computation um which i think is a very nice and cool feature here so where do i see this going um i think this can be used to learn spy crafts mutations of various complex data structures and we can combine this then with traditional spike neural networks to do neurosymbolic reasoning uh with spikes which i think is a very exciting topic and maybe future direction right now i'm (17:19) working on moving this from single spikes to spike trains and if you have any questions or you have cool ideas how this could be combined with your work or anything else please feel free to reach out and with it i would like to thank you for your for your attention and i'd also thank my colleagues for for the awesome time at siemens and also for the awesome time that i'll have at esa thank you thank you thank you very much i see again lots of questions so the circle is very interesting and i will only ask uh two because we (17:56) need to move to the next video so the first one would be each vertex in a represented knowledge graph requires a population of neurons how many neurons are required in each population for a given precision of predicates relationship types and does this rely on properties of the knowledge graph for example maximum degree um yes so this this really strongly depends on how how large your knowledge graph is so currently each vertex like in the data sets that i used it was something between 12 to 32 to 64 neurons per population (18:37) for bigger data sets like really the state of the art like freebase and wordnet it's sufficient to have like 100 to 200 or even smaller so it strongly depends on on the structure of your knowledge graph how big it is how many entities you have yes this is of course one kind of like in my opinion one downside since it's a bit wasteful to have like 100 neurons and each neuron only spikes once that's exactly why i'm currently looking into replacing this by only having one neuron that spikes several times which booked (19:10) me a much nicer coding approach for this interesting thanks uh then the last one from thomas with the fight based representation is it guaranteed that there are any embeddings that work what is the relationship between the dimension of the embedding and the size of the graph so i think the second part i also partly already answered um the first part so it will always that's not simple to say like you you do principle the same as as a machine learning where you have like a training graph you have your test graph (19:56) um and you have a lot of ambiguity since so there are like two approaches you have the um the close world assumption and the open world to some uh the open world assumption close world meaning that you often you only have a list of triples that are true so you know that this is a fact but there are a lot of triples you can create where you have no idea whether they are true or not not so you can say okay all of these triples are not true this is basically not what we want because then we would have model that we (20:23) cannot do inference with so we assume that the it's undecided for every other triple um so and during training but we doing training we have to generate negative examples so we kind of guess what is true and what is wrong so we're not exactly guaranteed that it will capture everything correctly um about the the most important things like the the the things that you are really interested in um um most often work quite well so the embeddings capture the structure and it generalizes uh well enough that's (21:01) exactly the the reason why people use this or started using these methods because you can really compress information and knowledge graph and uh use that i hope that answered the question because i wasn't entirely sure what the question was okay thanks again so i think we need to move to the next speaker so thanks for for the presentation and i guess you can chat with uh um with a participant um during the other presentations thanks again thank you very much and thanks for the questions,"The talk is about ""spike-based embeddings for multi-relational graph data"" given by Dominik Dold. The speaker is from Siemens in Munich, and currently working at ESA in the Netherlands. He is discussing how knowledge graphs or multi-relational graphs can be used to model different systems and structures, such as molecules, social networks, and medical studies. The talk focuses on how to process such data structures using spikes and how to infer new information from the graph structure. A traditional approach is to build rules and do feature engineering, but this can be difficult and doesn't scale well to large, complex graphs. An alternative approach is to find new representations for each entity in the graph, such as low-dimensional vector spaces, which allows for more efficient processing of the data.",ChatGPT,,,,,,,,
https://www.youtube.com/watch?v=hJyEFc0DgK8&list=PL09WqqDbQWHEqm1_3a620tKUKnC6FgBrG&index=4,2021,SNUFA Workshop,Ulysse Rancon,CNRS,StereoSpike: Depth Learning with a Spiking Neural Network,Sensing,(148) 04 Ulysse Rancon - StereoSpike: Depth Learning with a Spiking Neural Network - YouTube https://www.youtube.com/watch?v=hJyEFc0DgK8 Transcript: (00:04) not the presentation oh yeah like this yes perfect uh hello again so um now we have the second constituted uh suite from our abstract uh the speaker is ud rank from university of bottom in france and the title of salt is serious fight that's learning with the spiky neural network and we are ready to listen to your presentation thank you thank you so much thank you and hello everyone so my name is elise hansson and i will present you my master's thesis that i did with so i'm just graduated and i'm just (00:52) starting my phd so and i would like to thank uh so much the organizing committee of sniff for bringing us all here today so without further ado let's get started so what it will be about is basically spiking neural network architecture for a large scale regression task which is the estimation of depth from neuromorphic even data so it's in the computer vision setting so first of all let me remind you some use cases of spiking your networks so for three years they have been they they we have tackled a lot of (01:29) machine classical machine learning problems with them so because of the emergence of this very effective training rule and training algorithm which is a surrogate gradient descent and so we now have a very effective neural network spiking networks and on imagenet we have deep resonance we also have spiking detector as well i've heard there's a version a spiking version of yellow and also i know that there are some motion segmentation neural network models but as you can see here all of these tasks are more or less in the (02:11) classification uh family of tasks that i i would say because in either case you're doing a classification so here for classical classification you're doing it on the full image or on one part of the image on an object or you're classifying each pixel and it appears that there are there have been very few spiking neural network architectures for the the task of regression and especially at large scale so it it's not so surprising because i i would say that well snns and regression are not a good match (02:51) at first at least because it's very hard to progress real values with a infinite sum of real values so that is a discrete wasted spike train so you have your target value here you can imagine it's the it's it's a target uh potential of a readout neuron and so this output neuron this readout neuron integrates the weighted action potential of its preceding synapses and must match the target value and so it's particularly difficult because so the preceding spike trends are discrete and you have a fixed number of synapses (03:35) so a fixed number of parameters pressing your neuron and if you want to your snn to be effective you so if you want to it to be a sparse and then the number of terms in this sum should be as low as possible and uh so an illustration that i that i like a lot i don't know if you know this game so in france it's called the numbers and letters i think in the uk it's called the countdown but basically a participant it's a tv show so the participant must approximate the the value at the top with a small set of numbers at the bottom (04:16) with by doing some elementary operations and and it's exactly what the snm is doing actually so except it is doing addition so accumulations of spikes or subtraction of if the if the weight is negative but it's doing exactly the same and these numbers are the the synaptic weights so actually the in fact the the snn for regression is playing countdown uh so now with that explained let me just uh remind some of you for for those who don't know what dynamic vision sensor is so um i mean so they also took they are also (04:57) called the even cameras and these are a new kind of sensors which are biologically inspired from the retinal ganglion cells of the virgin nervous system and so they are very promising because they have very interesting features uh in terms of temple resolution energy efficiency and they're very different from conventional cameras because instead of producing a frame at a regular time interval they prod each pixel is independent from the from each other and pixel produce asynchronous spike trains and so it happens that we have online a data (05:38) set which is called the mvsec it was a shot by two of these dvs cameras so natch next to each other [Music] on a moving radar so on a drone on a car and there was also a lidar to to capture a depth at a regular in danvall and that provides a dev ground roof and so here we have all the ingredients necessary for the recipe of supervised depth estimation and so this slide sums pretty well i think uh the scope of our work so we have a natural scene again captured by two of these dvs cameras in in the in the context of (06:18) the the mvsec data set each of these produce a spike train which are funny to a spiking neural network and this spiking neural network tries and estimates a depth so a depth value at each pixel in the scene so well without waiting anymore let me present you so our model which we call the stereo spike so it can can feel a bit overwhelming looking at it first but it's not believe me so it's uh no more no less than the adapted unit architecture so it's an encoder decoder network so the first feature that you will notice is that we have two (07:01) encoders instead of uh of one because we want our network to be binocular and there are other ways to to to implement the binocularity but that was that has been our baseline for us quite some time and so we decided to present it like so uh and so like in any encoder decoder model we have a down sampling path and an up sampling path so the the the convolutions in the encoder they divide the term the spatial resolution by two but double the number of channels and the decoder does the exact opposite we of course because in uh we are in snn (07:45) philosophy uh we have an alternative of weights uh which are floating point answers and binary activations so zero one spikes um and as i suggested before on my previous slide uh the readout paradigm is exactly the same so we have as many output neurons than pixels in the reconstructed scene so um uh so the these these neurons of this neuron problem uh they actually bear the the depth prediction of the whole network so uh let me now introduce you some key features of our of our model so first we used the spiking jelly python library (08:32) which is wonderful we also use the integrate and fire neurons that were trained with surrogate gradient descent so as i said the readout paradigm is that the membrane potentials of the pool of perfect integrator neurons bear the prediction so these neurons do not spike they have an infinite firing threshold and they have they have no leak and so you may have noticed that before but we have some intermediary prediction layers that enable a more faithful and more precise reconstruction than with a regular unit architecture so i'm talking about these (09:12) prediction layers here and i will explain in a moment the interest of these of these layers and additionally our network is we believe argo friendly because it has no bias and no batch norm and we use nearest neighbor of sampling because we believe it's it's more compatible than a billionaire or something in the in the snn philosophy and one important detail that i didn't didn't mention now i'm just mentioning it now but we do a reset of all of our neurons at every time step so we have a sort of fit (09:52) forward or stateless snn it's um okay i see i see some remarks uh incoming and and it is true that we are not leveraging the temporal capabilities of snns by doing that but on the other hand it's interesting in terms of hardware because doing a reset of a membrane potential on a neuromorphic chip it's less costly than applying a leak and we found out that a good potential target hardware from for our model would be the accident ship of branship here is a demonstration of our modelling so we have a input we so the uh our input (10:36) representation is a spike histogram so we accumulate spikes uh every 50 milliseconds uh on a two channel tensor and so we we are we are from a spike train we are going to a more formal and classical computer vision representation which is common with dvs data here is their prediction and the ground proof so the pixelated aspect of our prediction comes from the lowest level prediction layer but as you can see so the the information is encoded pretty well and reconstructed good well as well and more quantitatively we'll report (11:22) some near stage of the art performances compared to a fully fledged analog neural network a n which uses 3d convolutions so again these are some examples we have [Music] we you can you can see that they are doing a good a good reconstruction and we we might be losing the accuracy because of this pixelated aspect that we should fix obviously uh and i i thought that this slide would impress a lot of you because so just we we we tried eq equivalent in architectures with our model so we just replaced uh if new ones by batch (12:09) storm and railway which is common in in conventional deep learning and we found out that the snn was yet certainly performing worse on train data but much much much better on the test data and this was an interesting result and we are very happy and it's to our knowledge when we're if not the first case where especially the neural networks show better performances than ndns on the test set and this suggests that well spikes could be a more generalizable encoding scheme than a floating point tensors as a conclusion (12:48) we present one of the first cases of successful fully spiking neural network model on a large scale regression task which is the estimation the depth from neuromorphic event data we our push our trick to enable a more precise regression than with a standard unit is to have several prediction layers doing a course to find prediction and finally well in this particular setting for this particular problem and this particular architecture we have better performances than equivalent and ns at equivalent levels of complexity (13:30) so space could be a regularization method and it begs us some more research in in this in this regard and as for the perspective for for this particular work uh well of course we want to get rid of this pixelated aspect and get finer grain prediction and exploit this the implicit frequency of spiking neural networks and and their membrane potential to capture temporal dependencies thank you very much i will be happy to answer your question i hope i'm on time thanks a lot i didn't have to to tell you if you were overtime so it (14:12) was perfect and also very well received so we have again a lot of questions so the the most voted one is from nicola could the worst performance on a a n be due to some hyper parameter miss tuning we used actually the the same hyper parameters uh maybe that would that would mean that uh that would not be uh suitable for an inn this the i mean the same hyper parameters would not be suitable uh would be suitable for the snn but not for the nnn but we well that's what we tried we tried the same exactly the same setting the same (14:58) learning rate and that's what we got but uh yes we thank you for serving for this suggestion we have to find what's going on good um the other one is from lia so first of all great work do you expect a better performance with the central dynamics of the leaky integrated fire neurons instead of the integration for neurons even though that might be more hard or expensive so yes so that that's a very good question so uh initially we wanted to do it with leaky integrate and fire neurons and so uh our plan was uh to um (15:37) to have the same radar paradigma we wouldn't be doing any reset at all during uh during in france and uh we uh we found out that it was very difficult to learn actually for the network to learn the depth changes and not the depth so here our network is learning over he is predicting the depth from scratch for from zero potential and if we apply the leak and if our network would not have any reset at all it would only add have to learn the the depth changes which are very slight from one frame to each other but it would be very (16:21) difficult to learn and we we didn't manage to to do it and that's that's why we we turned towards this uh stateless uh snn okay another another question um that i think connects to to the fact that you have a spike in your network so um it's not clear what is the input uh to the model it looks like it's even framed or you mentioned uh spike's histogram so it looks like you're giving a frame as input to your model this is correct it's totally correct and uh it's my bed from for not explaining that uh but (17:05) yes so so dvs cameras they they output so spike trains for each of their peaks each of their pixels and so action potential the spikes coming out from from dvs they have a polarity so on and off depending on the change of luminance that triggered them so what we do is uh in and they have extremely low temporal resolution so what we do we we take a higher temporal resolution so 50 milliseconds which is a lot compared to the temporal resolution of the dds and given one pixel for instance we accumulate into two channels so one for (17:48) the on events and one for the off events we cumulate spikes that that happen in in this time interval so if you have five on spikes that incoming in the 50 milliseconds time window then at this particular location at this particular pixel then the spy frame would have a value of five i hope that was a more okay but how is that then can convert it into a spike the spike that goes as input to the spike in your network so so so it's the the input of our with this representation we have a tensor which is exactly like an image (18:33) but has only two channels instead of three uh for rgb but it's exactly the same so we can do standard techniques of computer vision like convolution and so on and it's not a problem okay okay okay thanks a lot so i think this is the end of the first session of the workbook and we can go and have a break uh to start kind of freshly new for the for the second session in half an hour right yeah so thanks again to all the speakers of this session thanks for freedman and then that we're behind the scenes managing everything to (19:19) run smoothly and we'll meet again at the floor thanks a lot,"The speaker, Elise Hansson, presents their master's thesis on using a spiking neural network (SNN) architecture for a large scale regression task, specifically the estimation of depth from neuromorphic event data in the computer vision setting. They explain that while SNNs have been used to solve many machine learning problems in the past, there have been few SNN architectures for the task of regression and especially at large scale, due to the difficulty in approximating real values with a discrete spike train. They also mention the use of dynamic vision sensors, which are biologically inspired from the retinal ganglion cells of the virgin nervous system, and are promising due to their interesting features in terms of temporal resolution and energy efficiency.",ChatGPT,,,,,,,,
https://www.youtube.com/watch?v=VmCCDkblMvw&list=PL09WqqDbQWHEqm1_3a620tKUKnC6FgBrG&index=5,2021,SNUFA Workshop,Henning Sprekeler,TU Berlin,Optimising spiking interneuron circuits for compartment-specific feedback inhinition,Neuromorphic-compatible algorithms,(148) 05 Henning Sprekeler - Optimising spiking interneuron circuits for compartment-specific feedback inh - YouTube https://www.youtube.com/watch?v=VmCCDkblMvw Transcript: (00:06) and welcome back everybody um so this is session two of sim card gaming 21 and it's my great pleasure to introduce you our first speaker of the session which is now a little bit more focused on computational neuroscience and neuroscience questions and our speaker i just need you for a moment um sorry okay good so i think now that should that should help so um great so henny um is basically somebody who's been working for a long time on striking your network some questions pertaining to plasticity and burning um (00:59) and he did two very successful co-stars with wu from gerstner and richard kempter and he had a stint stay as an as a professor at the university of cambridge and now he's at a technical university in berlin where his lab very much still focuses on learning in uh spiking real networks or neural networks in general and also most recently get increasingly interested in inhibitory interneurons and the role of inhibition in these networks and i'm very much looking forward to your talk henning thank you very much for coming (01:32) and without any further ado please take it away good thank you very much friedman for the nice introduction thanks a lot for for inviting me and for setting up this this beautiful workshop um maybe as a starting point um this is truly a lot more biology than in the last session and so i'll torture you with loads of weird facts about um yeah about the cortex um but so we've come to spike sport the optimization of spiking networks through sort of a completely different path um mainly trying to understand what what how cortical (02:08) circuits work um but in a way the motivation that took us there is very much linked to the one that tara mentioned at the beginning is the one of uh parameter tweaking right because that's something that's a that's a curse and many of you will be familiar with that and if you actually just build models of cortical circuits you very quickly run into that type of problem as well good so um first maybe i should say that of course this is not really my work in the end this is very much the work of johann (02:37) kaiser a phd student in my lab who's just done amazing work um and richard nord who's now of course running his own lab and and and doing amazing stuff over there but i had a i had the luxury of actually having him as a poster for a while working with him as a postdoc in my lab a couple of years back so um as i said we're interested in cortical circuits and so i thought i'd just shock you with this type of image for the beginning as what you see here is is in the center um the good old friend that we all know is the the (03:10) pyramidal cell and the sort of the emblematic cell of the cortex um and those guys are in cortex about 80 of the cells they're excitatory and they're comparatively homogeneous from cell to cell although that's kind of starting to crumble as well and the other 20 are all these colorful guys that are hanging around here and the reason they're so colorful is that they're basically evolutions vengeance for the simplicity of the pyramidal cell they are super diverse cells look very different they do very different things (03:47) they're they're electrophysiologically different they're they're different in their protein expression they're different in where they sit in the cortex and it's just a bit of a mess so it's really hard to understand um what they do now we get more and more data on that um but you know reasoning through complicated circuits is something that i don't know humans are notoriously bad at i think and so it kind of calls for a model so that's what we embarked on doing so because i presume that many of you (04:17) more familiar with sort of the the so the simpler or the more more and more engineering side of it all let me give you a very quick rundown of what these different internals are in which ways they're different and one thing that's very striking is that they target very different places within the circuit okay so basically if you if you look at one of such a pyramidal cell then the sort of textbook idea is that they receive bottom-up input or sort of sensory drive around their soma and then they have these (04:46) beautiful intricate dendrites to to the top and up there in layer one they receive top-down information from other cortical areas things that are very much pertinent to learning etc and so what these interneurons now do is that some of them very much target the soma those are cells that often express pop albumin and they sort of they're they're well suited to suppress spikes a different type of cells targets the dendrites those are these light blue guys up here um and they are sort of that predestines (05:18) them to to suppress sort of active synaptic integration or dendritic integration out there in the dendrite and sort of thereby alter the integration of top-down signals um something that i would like to highlight because i'll come back to that is that these cells not only differ in where they project but also what kind of input they receive so the cells that go for the soma often receive inputs or synapses that are short-term depressing meaning if you have a spike a spike comes right afterwards on these inputs (05:45) and the second spike causes less of a result in the in the inhibitory cell and that's very different for the ones that target the dendrites so you have these somatostatin express and positive cells that expressing cells that target the distal dendrites and they often have facilitating inputs so you have you if you have two spikes in quick succession the second spike is often a lot more effective at driving these cells actually quite strikingly so sometimes the first spike is just silent um so that's something i'll come back to um (06:12) later on um then there are other types of cells like these weird ndnf cells neuroglia form cells sitting in layer 1 and they do something interesting they they just release bulk gaba into the extracellular space and it's known that at least partially they also target sort of presynaptic terminals of other cells um or sort of presynaptic terminals that target for example the the pyramidal cells and thereby suppress synaptic release and finally there are yet other interneurons that basically target not the pyramidal cells but they target (06:42) other interneurons so there's sort of a meta level where you don't have inhibition but dis inhibition or dis dis inhibition you can sort of take that arbitrarily high okay and i think the the thing that you all see is that this is a pretty complicated system um and complicated systems are hard to understand so um maybe once you try to set up some kind of computational model for that and that's what we wanted to do we started with that probably so five or six years ago um and it was initially a nightmare right let's put it that way (07:13) and so i'll focus a little bit on a simpler circuit for the time being but even if you take a comparatively simple circuit you very quickly run into a problem that these circuits have many many parameters and you can imagine that if you have n different cell types and you could take you connect them all in different ways then each of these connections basically need some kind of strength so and the number of these synaptic pathways basically increases like n squared so even if you just have you know three (07:41) cell types like you have them here or maybe you have to worry about the dendrite as well then it's for you end up with something like 16 parameters only just for the connectivity so that's something that just just very quickly explodes and that makes bottom-up modeling basically just sort of you know taking the data and then trying to build up a phenomenological model of that extremely hard and extremely painful and the take-home that we had is that you can make these things do whatever you want right you just choose the parameters and (08:07) then they just do stuff and you can make them do the opposite as well if you choose the parameters the other way and so that's of course sort of obstacle if you try to understand what they do and so the alternative that we started to take then at some point is to just you know optimize the circuits and then take those parameters that we don't know and then just optimize them by basically by gradient descent right and then the resulting circuit that you get out um is then something that you can compare to (08:35) experiments and see if you can explain basically the data in terms of some kind of objective function or some kind of computation and so this is really the so the as i said in the beginning this is very much sort of the approach that tara has has has argued for let's get rid of every single parameter tweaking that we need to do let's do all of this by plasticity or optimization the problem of course that we face then is that um we don't have the luxurious situation that you have in engineering that you know what you would like to do (09:04) right we're in biology so we have these cortical circuits and we have no idea what they really do that's actually what we want to find out right so we have a bit of a chicken egg issue here that we don't know really what the circuits look like but we don't also don't know what they what they actually do and so we have to make some kind of arbitrary choice here um and so the starting point that we chose is one that i personally think is a bit of a straw man objective um and i don't quite know why this (09:30) should be objective at all um but it has turned out to be surprisingly successful and that's really just optimizing these circuits for a balance of excitation and inhibition i'm very happy to chat afterwards why this could be useful um but let's just use it and and go for it okay so excitation inhibition balance is something that's um found very broadly in in cortex and also in many other areas so it's known for for quite a long time that if you record neurons in sensory cortices that they basically (10:03) receive excitatory and inhibitory inputs and that those often share a very similar stimulus tuning so they're kind of co-tuned in stimulus space if you do all sorts of tricks and record excitatory inhibitory inputs at the same time you kind of see by just eyeball metrics that these two things here are very highly correlated this sort of a picture of excitatory inhibitory inputs to that cell so they're correlated in time um if you record from different cells then those cells that receive a lot of inhibition or receive a lot of (10:34) excitation often also receive a lot of inhibition so there's a high correlation from there on to neuron um and other people have you know basically imprinted arbitrary pattern patterns or stimulated arbitrary patterns in the brain and that sort of sort of suggests that there's also a strong correlation between excitation and inhibition across sort of activation patterns that you can generate and so in a way we we kind of know it's there in many ways um and so we can just go ahead and take circuits and optimize them just for (11:03) ei balance not knowing why this should be functionally relevant at all and so we've been a bit on a lucky streak with that if you wish so we've we've been able to show that you can just you know optimize for ei balance and get things like place cells and grid cells a couple of years back you can optimize for ei balance and explain sort of synaptic fine scale circuit structure in in in mouse or mouse visual cortex um you can use that balance thing for excitation inhibition to generate prediction error (11:33) neurons and that's something that that other people have also worked on like julian aguilera has just had a paper i think in e-life that can went in that direction of using inhibitory plasticity to generate prediction errors or to learn prediction error coding and so finally and that's the story that i'm going to talk about here is something really more about sort of generating interneuron classes in cortical circuits basically by balancing excitation and inhibition okay so and the starting point here is is as i said (12:01) this idea that that excitation inhibition could be correlated in space in time in in all sorts of dimensions and the dimension that i will focus on here is sort of the dimension of the extent of the neuron and so as you know these neurons are quite complicated structures morphologically and so the assumption that i will make is that basically excitation and inhibition are not only balanced on average that but that within sort of different subcompartments like maybe the parasomatic domain of the distal dendrites even on that level (12:33) there is a balance of excitation and inhibition okay and so that's basically the thing that i will try to optimize and i'll try to show you where that takes us so maybe a little bit on um what exactly we did or what joram did more precisely right so we have a model of pyramidal cells right and we take not only one of them but we take a population of those um and those neurons are now you know start simple have two different compartments which is basically a somatic compartment and that can generate spikes and it has a dendritic (13:07) compartment these cells have a dendritic compartment up here that can basically also show sort of active processing and generate you know dendritic plateau potentials and they in turn generate bursts in the soma and there's all sorts of fancy stuff happening and i'll show you a little bit more about what exactly is going on there a little bit later now these two these these cells or this population of cells receives two inputs one is bottom-up input or sensory input that targets the perisomatic domain and (13:32) top-down input that goes to the dendrites um and importantly of course for this workshop this is a spiking neuron and so what we did then is basically that we just took a bunch of interneurons they're all the same as you'll see in a second we let them receive input from the pyramidal cells and then they're supposed to provide feedback inhibition to these pyramidal cells and this feedback namely goes to both compartments and what we're try to do is to balance excitation and inhibition in both compartments separately (14:06) and then we just optimize okay and so we do a gradient-based optimization of excitation and inhibition both in the dendrite and in the soma by you know basically optimizing the parameters or the properties of this inhibitory population here trying to see how far we can get towards biology and so just for because this is a technical audience um i'm free to just sell the object the objective function so the idea is really that you have excitatory inputs to the soma you have inhibitory inputs to the to the soma (14:38) those are negative those are positive so you just basically take the difference between excitation inhibition take the mean squared error over time and over neurons and optimize for that and the same thing is just happening on the dendrites okay good now a few things that sets us apart from probably most neuromorphic stuff the pyramidal cells are now you know a complicated structure with two compartments and all sorts of nonlinear dynamics so this is not the vanilla flavor integrated fire neuron um the interneurons are vanilla flavor (15:07) integrating fire neurons the other thing that's also a little bit more more fancy if you wish for more biology is the fact that these synapses here that target um the interneurons now undergo short-term plasticity okay so they're a little bit more complicated than a standard sort of current based or conductance-based synapse so those of you who are not so familiar with short-term plasticity basically i alluded to that earlier and if you basically trigger spikes and some synapse and record the post-synaptic (15:33) response and what you can see is that that basically in some types of synapses you have a very strong first response and then the second third etcetera sort of ease off so the synapse gets less effective with additional spikes and if you let it sit for a while and nice and quietly then it can recover to where it was before so that's a depressing synapse this here would be a facilitating synapse where you'd have the first response being comparatively small and then it's sort of rapidly increasing and (15:59) plateauing at some higher level or maybe even declining again um but initially you basically get a synapse that is getting increasingly effective with time now there's a standard model for that type of thing um that was invented by by michael sudex and henry markham um sometime in the late 90s i won't go into the details of what that model does and i will only sort of highlight the parameter here this is this parameter here u which is um describes something that could one could call the initial release probability and that tells you (16:28) if this is going to be a facilitating or a depressing synapse right so if you make the release probability very high close to one you get a depressing synapse if you make it close to zero you get a facilitating synapse and so what joran then did is he basically optimized the circuit that is the weights of um onto the pyramidal cells and the initial release probability of the incoming signups and i think also the incoming synapses basically to minimize the mean squared error between eni excitation and envision in the soma (16:59) and in the dendrite um basically because this is a recurrence circuit you'll have to back prop through time right nicely this is of course as all of you know by now very simple you just program everything in pi torch and use automatic differentiation and because it's spiking um you also need to basically think about surrogate gradients and at that point we were quite grateful that friedman and a lot of other people had worried about that problem for us and we didn't have to because we probably couldn't have not (17:26) been able couldn't have solved it as nicely as you did right um so that's the setting um everything works so what you see here is basically ce excitation inhibition correlation nicely creeping up over the course of optimization works both on the soma and in the dendrite so for once workshop where i can show learning curves um which is nice but the interesting more interesting thing is of course to see what is the outcome and so let's start with um what we have before learning as i said it's a inhibitory population that's totally (17:58) homogeneous homogeneous right um and so the way i'm plotting this here is that i check for um every neuron in that population how strong its synapses onto the dendrites of the pyramidal cell onto the dendrites are for the parameter cells and how strong its outgoing synapses are onto the soma of the pyramidal cells okay and now and we we initialize this circuit sort of randomly so every cell sort of lies in some random bulk here there's no specialization or so apparent at all um and the other thing that you might (18:32) see here is that all these points are gray that means that the sort of paired pulse ratio which is a measure of whether the synapse is facilitating or depressing is one that means these synapses are basically boring in time right they don't they don't they don't change very much over time um and that's also depicted here in this histogram so basically take home here all the interneurons are the same and then you go ahead and you optimize and there are a few striking things that pop up immediately one thing is that you'll (19:02) see here is that these points here which were previously just a gaussian blob if you wish are now hugging the axes okay that's one thing so you basically have some neurons that very preferentially target the soma and others that very preferentially target the dendrites and they also have obtained color right so that means the ones that target the dendrite now have a paired pulse ratio that's larger than one so they're facilitating and the ones that target the soma are now depressing and so and that's (19:30) something that's very much akin to to to what i what i've what we're seeing in cortex if you look at um the distribution of these pulse ratios you see that this is now very much a bimodal distribution and this is not sort of a continuum of things but there are really two classes of cells one of which is is depressing and one of the one of which is facilitating and if you think back of what i what i what i sort of told you in the beginning about these interneuron circuits this looks very much um like (19:58) these two cell classes pov aldermen and sst cells or somatostatin cells that basically target the soma and the dendrite respectively and have depressing and facilitating synapses and this is something that that i thought was actually quite exciting because um it's it's one thing to take an interneuron circuit with many different cell types and then optimize the parameters in the system um but it's yet another thing to go ahead and basically start with something that does not have that level of differentiation and then (20:24) basically generate that that differentiation into cell classes from scratch right and that's something i found quite exciting um and i and of course that sort of let's say would be the ultimate dream that we we look at these critical complicated circuits and that we don't have to model them by putting in that there are cell classes or what they look like but just say like hey here's the computation and here's the circuit that comes out and it looks exactly like cortex right that would be (20:49) sort of a long-term vision whether that's realistic is i guess a different question okay so um something that might be interesting to some of you as well because um is the question of what the activity patterns in these circuits actually look like and because often when you do optimization in spiking circuits the the outcome is not necessarily very much very brain like right so at least in our hands when we try to train uh spiking networks for decision making or they found weird hacks all right that they really didn't (21:19) look like cortex and in this case it's it's a little bit more more more sort of friendly if you wish um so if you look at the the currents here you see that now excitation inhibition are correlated both on the solenoid and the dendrite but more importantly if you look at the spikes this sort of looks like an asynchronous irregular state for the activity of these of these circuits that we have now optimized now i have to be a little bit careful here because the circuit is very small if you want to backprop through time (21:47) through a recurrent spiking network and you don't want to do that on a supercomputer then you want to keep the circuit comparatively small and so that means we can't really talk about an ai state here because that just requires more neurons but i do know from larger networks that we have run and that's from our work from philippe cruises a postdoc in the lab who's who basically just worked on plasticity we know that if we basically just balance excitation and inhibition through a slightly different objective in dendrite (22:16) and soma separately putting these two cell classes in that we actually get an asynchronous irregular state um and that's basically shown here but i guess you see the raster plots right it kind of is an asynchronous irregular state and not only for spikes um but actually also for for bursting activity in this circuit something that that you'll see is quite important in a second and so the cv of the interspike intervals is somewhere around one and that's something that we've seen quite often that if you go for ei balance that (22:45) this is sort of just a network state that emerges quite robustly and we've known that for probably yeah good ten years from work where freedom also contributed together with tim forwars good so of course as a biologist an important question is to try to understand why this looks like that and so we try to understand what the underlying mechanism is in a way now i'm telling the story a little bit in in in the reverse chronological order because the reason why this emergence is actually something that we we had (23:16) guessed before and that is now work from richard north i saw you're here um great to um to to sort of you know check up on what's going on so the challenge um that the system is facing is the following so you have a bunch of parameter cells they receive input to the soma they receive input to the dendrite and then they just sort of crunch all of that together and and generate output spikes right and i made them green now because of course the output of those neurons you know depends on both this yellow (23:48) stuff and this blue stuff and what comes out is some kind of mixture now the challenge if you now want to balance excitation and inhibition in the soma and in the dendrite is that you basically need to unmix that mixture right because the if you want to balance excitation inhibition in the soma you need an amount of inhibition that is in proportion to the amount of excitation that you've received from the outside and the same thing is true for the dendrite you need an amount of inhibition that is proportional to the (24:18) amount of excitation that you've received from the outside onto the dendrites but now if you want to do that through feedback right basically feedback inhibition through projecting to the interneurons and coming back then the engineering somehow have to find out what the blue stuff and yellow stuff was only knowing the green stuff okay and that's is is is an inherent problem and a problem that we had looked at before basically coming in that direction from a different perspective and that's something (24:47) that that richard multiplexing where these pyramidal cells actually encode both of the yellow and both the yellow and the blue stuff by sort of exploiting spike timing and i'll show you how that works um but to get there we'll have to dig a little bit into intracellular processing in these sort of more extended pyramidal cells so something that is is known for probably a good 25 years or a bit more than 20 20 years now is how this looks if you look at let's say layer five pyramidal cells so there's bottom-up (25:16) input that targets the summer it's top-down input that targets the dendrite and there's some kind of output and so what what matthew larkham has shown in the in the late 90s um is basically the the following phenomenon that if you target the dendrite alone matthew is the master of dendritic patching right so if you just if you just go ahead and and stimulate the distal dendrite then you get these sorts of you know events in the dendrite much weaker in the soma and then if you stimulate the soma alone you can trigger spikes which is nice and (25:48) in the dendrite you see these sort of elevations in the voltage because there's back propagation of the spikes into the distal dendrite which has sort of this little sort of plateau-ish thing at the end but it's still one spike but if you combine these things if you give an input both in the soma and in the dendrite then certainly something magic happens and the dendrite basically crosses some kind of threshold and generates this long sort of plateau potential in the dendrite okay and what this plateau potential (26:17) generates is because it also drives the soma is then a sequence of spikes that emerges from some kind of ping pong between dendrite and soma and so the picture that emerges from that is that you that there is a non-any interaction between soma somatic and dendritic input that can generate these types of bursts now let's abstract that away a little bit into a cortical code or a neural code all right so basically let's take assume that there is a population of these types of cells right and so the assumption i'm making is that (26:50) somatic input generates spikes it's basically this part of the picture here that dendritic input converts these spikes into bursts and i'll assume that there's some kind of background noise so it will do that stochastically so if i can make that assumption then i can basically think about how the population will encode somatic and dendritic input somatic input will generate events those could be either single spikes or bursts right that for some reason have been turned or spikes that have been turned into bursts by (27:25) dendritic input or um and those those are called events and then the dendritic input is basically the proportion of things that happen that are turned into bursts okay so that's basically this assumption that you can turn turn spikes into bursts stochastically and so if that's the case then in the end if i look at the spike trains of that population i can try to find out what the somatic input and what the dendritic input was just looking at sort of the number of events and the well burst probability or proportion of (27:56) events that are actually bursts and so both of these things both the the bottom up input and the top down input are then synchronously encoded by that cell or by that population of cells and that's something that richard north then instantiated nicely in in in simulation um and has has has wonderfully exploited over the last couple of years and so the idea is really that it can be depicted here so if as a function of time somatic input increases um and dendritic input maybe decreases then in the beginning and (28:29) maybe some first time window you have a lot of dendritic input so the spikes will all be converted to burst so you might be getting a burst here in a second time window with kind of half half um you might get one spike a single spike um and you know one one burst potentially so you'd have two events but one of them would be a burst and here in the last time window dendritic input is low so it's mostly spikes so you'd have three or two single spikes and one burst so that's three events one of which is a burst okay so (29:02) if i put this into into the code basically i'm end up ending up with just one burst out of one event which is a birth probability of one hundred percent one out of two one out of three so i get a decline in the proportion of events that are bursts and that's then sort of a mirror image of this dendritic input here and so on the other hand if i don't care about the additional spikes in the bursts and i only count the events then i see that there's one two three events and i get an increase in the amount of (29:30) spiking and that then mirrors the amount of somatic input that's coming in over here okay so that's sort of the idea and if you simulate that then you see that this idea actually works quite well so this is a stimulus to soma and dendrite that's designed such that you basically don't have much signal in the in the so that these two inputs actually vary over time but that the overall firing rate of the cell or of the population doesn't vary very much um but if you now resolve things into bursts (29:58) and events and then you might see that sort of the event rate here it's a very nice mirror image of this somatic input up here and the the burst fraction so the proportion of events that are bursts is a very nice mirror image of this red line up here which is the dendritic input so that means you basically encode both of these things at the same time if you look at the temporal patterns that these neurons actually generate so that's um basically saying that just the biophysics of pyramidal cells basically allow you to encode bottom-up (30:30) and top-down signals simultaneously by sort of you know exploiting spike patterns and that's that's the idea here and so um of course the question is that's just encoding so let's see how decoding works right and i'll promise you to come back to the interneurons later on um so the thing that i think is is is easy to imagine if you have such a population of cells and you would now be interested in the somatic input then that should be basically just the number of events meaning what you have to do is you have (31:01) to count the number of spikes that these neurons emit and discard the additional spikes within bursts okay and the simplest way to do that is just to use a depressing synapse right so you just basically depressing synapse would within a burst count the first spike and then sort of get less and less transmission for the additional spikes in a burst so the postsynaptic current would be a reflection of the event rate rather than the firing rate of that population of cells right and that's something that reshark shows if you (31:30) increase the amount of somatic input and then the population rate of the downstream population of neurons that receives depressing synapses is is basically nice nicely increases with somatic input and these different lines here are different amounts of dendritic input so you see some kind of invariance to dendritic input and which means you're kind of unmixing things and so the other thing of course that you need to decode is the dendritic input and as i said dendritic input generates bursts so and i guess you can (31:59) now already guess what's going to happen so you basically need to be facilitating synapses because if you want to measure bursts then you're not interested in the first bite but you're really only interested in the second right and the second in very short succession is an indication that there was a burst in that specific specific cell and so you'll have to be a little bit more careful so you need a facilitating synapse onto this synapses onto this population of neurons there's a little thing that i won't talk (32:24) about very much is that you at the same time need some kind of feed forward inhibition and may we just postpone the discussion why this is something that is that is useful because it's actually something that we thought for a while um was a divisive normalization i'm no longer so sure about that okay so that's um just the take home here is that you can use short-term plasticity to decode these two streams of input that impinge onto the pyramidal cell population now if i come back to my interneurons then the optimized circuit (32:56) ends up doing exactly that okay so if i have my population of cells and i have one interneuron class that inhibits the soma then it should be active or its activity should reflect the amount of bottom-up input to this population of neurons in order to achieve a balance of excitation and inhibition and that means it should receive depressing synapses okay and similarly if this population here targets the dendrites and it should basically be provide an amount of inhibition that is in proportion to this top-down (33:29) excitation that arrives here then it should be representing just the dendritic input so it should it basically faces the task of decoding from the activity of the pyramidal cells the amount of dendritic input and that is something that you can then do through short-term facilitation okay and this is basically the circuit that we get out through the optimization procedure using surrogate gradients okay little side note this feed forward inhibition we also see which doesn't match so nicely to cortex but that's (34:01) probably more for the aficionados okay um i think it's time to summarize if i'm not mistaken um so what i try to bring across is that you know optimization in spiking networks is sort of a nice way of just restricting parameters not only in terms of you know engineering problems which which which were very much the focus of the last session um but also in terms of just restricting parameters in models of biological circuits right um and so my my my personal hope is that at some point we can get to a situation where (34:37) you can just optimize circuits and then they look in the end like the brain and then that tells us something about what the computation is that the circuit might be doing because of course we have to define the objective in the beginning at the moment the objective that we chose was excitation inhibition balance and as i said i don't believe that is a goal per se i believe that there is a lot of computations that profit from excitation inhibition balance but i think that's a longer debate where um i'm not sure if i (35:06) have converged on my own opinion um second thing is that that's more for the biology people here that you can basically generate the diversification into interneuron classes from you know basically need to decode a multiplex neural code for somatic and dendritic inputs um and maybe something that i didn't touch upon very much and because that's a vishal node's game is what this multiplexing is actually good for right one thing is that you could potentially flexibly combine different signals which (35:36) i think is an interesting path to pursue but something that richard has very very nicely illustrated is that this multiplexing might allow to actually process two information streams in parallel um and specifically bottom-up bottom-up stream of information and a top-down stream of information and all of you are of course familiar with um that type of challenge of back propagation of error for learning which is a backwards sweep right and basically the simultaneous processing of information which is a forward sweep and (36:06) so of course then having two signals that travel through a network in parallel is quite an exciting opportunity and uh with together with alexander payer um and and and quite a few other people have recently illustrated that okay with that um i'm going to close if you want to read more about this and then there are basically three papers out there for you to read one is the the multiplexing story which is now three years old and that that that is in pnas um the the the idea of diversification into interneurons is more recent it's (36:39) still a bio-archive paper we hope that will eventually be out um and sort of balancing and this sort of doubly asynchronous irregular state is recent work from philippe croy so that is um to appear in in plasma plus computational biology and with that i would like to thank you of course first and foremost for your attention and of course all my funding sources and specifically of course joram and and richard who did all that work um and yeah thanks a lot for for inviting me and i wish you all yeah i'm looking forward to your questions (37:11) great thank you so much honey uh so yeah we're a little bit short on time but there's many questions and actually the first question uh is maybe tim you can ask himself actually his question he's on stage right now [Music] yes i can all right uh it's actually the second question with more books the first one was by then i shouldn't be here but okay it's a very simple question but yeah the excitatory inhibitory balance is your objective but i'm surprised it is constraining enough can't you find many (37:49) solutions there are many solutions right but in the end the problem is let's say comparatively low dimensional right because the issue is that of course all the excitatory cells on the inhibitor or all the all the somato of the pyramidal cells basically receive the same input we think of an ensemble of neurons that all code the same thing right and the same thing for the for the dendrites so in the end it's really just a two-dimensional stimulus space um so you can think of these sorts of as homogeneous populations and of course (38:17) every run will do something different in the details right but it's that we're we're basically in a mean field game right so the computation is if you wish a halfway trivial one but making that you know of course a high dimensional input and high dimensional output both on the soma and the dendrites then of course the thing that you're mentioning there could be all sorts of stuff happening and i don't dare to speculate all right answer your question yes you did thanks thank you thanks a lot so yeah the question that (38:47) got most votes is actually dan but i think he cheated by posting it really early into the talk so i'm just quickly going to read it so would you agree with the richards at our deep learning framework for neuroscience paper approach that is at the right level of design is to look at the objective functions learning rules and architectures and objective functions learning rules and architectures um yeah but isn't that almost everything in the end sounds stupid right but in the end what do you mean by architecture (39:22) right i mean the objective function is what the computation is which is of course super interesting that's what we're all interested in um you know the the learning rule is basically a way of getting there um and then the architecture is how much you put in from scratch from biology right and so that's if you wish some kind of inductive bias or so that you would put in um and so the question is where do you stop there right every constraint that comes from biology to me can be sold as architecture so in that sense i can (39:53) agree with that but i'm not sure if that's a very strong statement is that is that is that an answer to your question dan and then it actually has to prepare the next session so okay so we won't be here okay later but i think this answered with yes it seems like you're great but um yeah i think it captures a lot um but i think um yeah i think that should answer those questions so it's great so there was another question by marcus gauche um thanks for the great talk one thing i wasn't sure about was why you preferred (40:23) um a referred to ei balance as a straw man um i refer to it as a strong man because i wouldn't immediately know why there should be evolutionary pressure for excitation inhibition balance right so in the end i think the whole circuit is supposed to do some kind of computation right it's supposed to make decisions control muscles perform sensory inferences or something like that that is something where i can immediately see why there should be some kind of evolutionary pressure to do these things well right and so in the end i think (40:55) that might entail in the end the circuitry that you know exploits excitation inhibition balance for something for some kind of purpose um but it's something that is for me a little bit on the way and i wouldn't even know if it's something that is true everywhere and we know it's not true everywhere right there are systems where ei balance is just not true um so in that sense i think we're we're using something that we see a lot in cortical circuits it is surprisingly effective to get out stuff that looks (41:23) like the rest of cortex and i personally don't quite know why um but it's something that i wouldn't you know use as an objective per se if i wanted to design a system right i mean if if somebody from the engineering perspective comes in and designs a network then excitation inhibition balance is no objective that makes any sense do you know what i mean yes i hope my face also knows what you mean now thank you very much um so there was another question which triggered a large discussion actually by um by chris curran and so what he writes (41:59) is there's recent experimental evidence that by the time inhibitory neurons have migrated and connected the oil rate they already have the genetic expressions of the cell class do you think this is a result of evolution solving the ei balance so that the brain doesn't need to worry about it in its lifetime i would love to pass that question on to joram if i could um because he's actually dug into that very much because it's basically a question that then then sort of relates to nature versus nurture which is of course maybe (42:29) i should point out that the white heron posted extensively yeah i can imagine yeah i mean joram has gone very deep into exactly that type of question but you know you can ask these these questions by by by or try to address these types of questions by saying you know how far back can you go in evolution until sort of a dendrite appeared and how far back can you go in evolution where the first hallmarks of um you know of things like foreign for example synaptic facilitation appeared so you can just try to see if there's some kind (42:59) of co-evolution of these things and it's it's it's it's it's a it's a surprising adventure if you go down that route and and i think that's something we should defer here a little bit because i'm not sure if i can paraphrase joram's inside well enough um i think he has some kind of opinion piece for that in in the early stages of preparation so i hope to be able to answer that question more thoroughly at some point very cool thank you good one and one more quick one to have (43:26) so this is my own question i'll skip that and thomas didn't watch me asked maybe i missed it but what were the assumptions about the homogeneity or otherwise of the pyramidal cells um well they're they're electrophysiologically homogeneous the inputs are homogeneous um apart from noise right you need to add some kind of noise to to generate some kind of fluctuation um what else um what else could be homogeneous well i think that's that's pretty much you can play a little bit with with how you (44:04) constrain certain weights um in terms of how much freedom you you you allow um but that's something that is more a question of how quickly things converge and correct me if i'm wrong johann or if you actually you know how large your search space is if you wish but the restriction of homogeneous input and homogeneous electrophysiology is of course quite a quite a quite an important one and it's clearly not true right cool right so 30 more seconds so i'll squeeze in my question now so you you optimized the u parameter basically of (44:37) the short temperature model which basically gave you the spread between the facilitating and depressing did you also look into optimizing the time constants and do they align with anything that you would expect um the the energy landscapes for the time constants are not very well behaved um so one thing and at least that's the way i remember it when we played with it um your um feel free to add in the chat um but if i remember correctly we tried that but the a don't try to optimize the time constants if at all optimize the rate (45:08) constants right so the inverse time constants that's a little bit better uh but even then you know and in even the short term plasticity itself is something that is in some parameter range is very insensitive to these to the to these time constants so it's not easy to optimize those okay thank you thank you so much there was one more question which i'll copy and post in the chat unfortunately out of time uh so um and maybe you can answer in the chat uh by lewis and rick what's this question so thank you very (45:39) much henny um and thank you very much to the audience for the great questions and now it's time to move on so i'll end this session i will see each other with uh uh in the next talk thanks so much thank you very much,"Henning Sprekeler presented a talk discussing the optimization of spiking networks through understanding how cortical circuits work, and mentioned that the motivation behind this work is related to the problem of parameter tweaking. He also discussed the work of a PhD student and postdoc in his lab, Johann Kaiser and Richard Nord, who have done research on inhibitory interneurons in cortical circuits.",ChatGPT,,,,,,,,
https://www.youtube.com/watch?v=INWP9roEvlo&list=PL09WqqDbQWHEqm1_3a620tKUKnC6FgBrG&index=6,2021,SNUFA Workshop,Viola Priesemann,Max Planck Institute for Dynamics and Self-Organization,Dendritic balance enables local representation learning in spiking neural networks,Learning,(148) 06 Viola Priesemann - Deriving local synaptic learning rules for efficient representations in net... - YouTube https://www.youtube.com/watch?v=INWP9roEvlo Transcript: (00:05) yeah okay hello hello everybody again now in the session with viola crisiman so it's my great pleasure to very briefly introduce her she's a professor at the university of gottingen and she's also the max plant for complex systems and she is going to talk about some more about actually balance so i'm very much looking forward to your talk um so without any further ado please yeah thank you very much for the kind invitation and also for an opportunity to present my talk here and i think it's in terms of topic (00:42) fitting very well i'm presenting today dendritic balance enables local representation learning and spiking neural networks so we concentrate on one work that i did in the past one or two years together with fabian mikolaj and lucas moodlets two very talented and active phd students in my group um you can find it here on archive the so local brands if you look into learning and living in your networks there are a number of challenges those neural systems learn complex statistical relationships in the environment despite (01:13) facing severe constraints the learning at least in part uses locally available information only not the global one compared to artificial networks but it's much easier to bring any information to any point i think that's the old point by now we have neural signaling that is delayed from one urine to the other that's something i would like to stress here because it becomes irrelevant later and complex correlations in the inputs need to be disentangled so if apples and bananas tend to occur very often you don't want (01:42) to have apple banana neuron but you want the apple neuron and the banana neuron individually bluntly saying so the outline or let's say the take-home message here of the talk is the following you look into learning with somatic balance so we will abbreviate it with sb and we'll show as known in the field that it fails when dual activity is correlated because the hidden features of the inputs are then correlated that leads to the correlated neural activity and because the neural transmission delays they tend to fail to regulate the (02:13) heavier learning that makes the connections between neurons stronger what we want to propose is to put the learning from the soma into the generatic compartment that's the short the one sentence summary putting the learning from the soma to the dendritic compartment which means also putting the then the balance to the dendritic compartment and use as before the idea that the local balance represents the error signal and that this error signal then is used locally for the update of the weight this is all i want you to (02:45) take home and now we go into the details so the solution is that dendritic balance enables local error computation in each dendritic compartment and this implements the exact gradient whereas the somatic balance is an approximation so learning an image spiking representation of neural inputs one typically goes ahead with that by minimizing some decoder loss between the stimulus and the estimated version of the stimulus and in spiking neural networks we want to keep the average firing rate fixed to some reasonable value a implementation (03:23) you might know the figure here from the neighf and machines is to have for example feed forward excitatory neurons and some lateral local inhibition and that then leads to the required properties which is precise temporal inc coordination of the spikes what does this classic paper show it shows that a stimulus axia if it increases can be represented by a group of neurons and the lateral inhibition makes sure that they don't spike all at the same time but they coordinate such that then the population rate of that (03:53) group of neurons follows very well that that teacher signal so the second part that we also know and have a lot of aspects and knowledge about this is how to learn the regularities of high dimensional inputs since the 90s literature is really out on that but the challenge that we are often meeting is that of implementing and accounting for delays there um so if we now dive a bit more into here this schematic of a neuron that local lateral inhibition how does it look like so this should be a neuron now it should be red obviously we have some (04:31) lateral inhibition and at the soma then the lateral inhibition that comes in together with the feet forward input in red they should cancel each other that's that's a goal that one has to for optimal representation the feed forward we indicate with f or feet forward these other weights will feed forward the lateral inhibition by w throughout and here we do have the tight somatic excitatory inhibitory balance because uh that then encodes at least approximately the arrow as long as um yeah because it basically has an average (05:09) of all the neurons that are representing the activity and the encoding of the entire stimulus um so how does the learning then work here on the right hand side you see the development of the decoder loss over time for this extremely simple mnist part if we start with completely naive network which means random synapses then the feed forward weights are randomly drawn and we have some starting value of our decoder loss the representation these are basically the synaptic um these are the feed forward weights and these are then the optimal readouts you (05:46) see that the representations are not very disentangled there's this mixtures of twos and zeros for this example we only represented zeros and twos for the heck of simple representation but it can obviously generalize to more patterns than that then at some point uh or we we put on the feed forward input with the heavy and type of learning that leads to a reduction of the decoder loss the representation becomes better but it's still not very or not perfectly disentangled if one in addition then learns the lateral (06:19) uh if one sorry this is for the the the recurrent learning if but in addition then learns the feed forward weights here optimal in a heavy like manner which means the neurons really become selective for specific type of features then both the feed forward and also the decoder and show a fairly good representation of our zeros ones and twos this is the standard way of how many of these networks are learning so where is the challenge the challenge is as i said in the correlated input features apples and bananas occurring (06:53) too often together and in the transmission delays and therefore we extended that picture of the um of the somatic balance to the dendritic balance and in principle the entire derivation i decided not to go into the details of all derivations but they are done exactly in the same manner as you would do it here for the somatic balance you minimize your loss you project it to the the um compartment but instead of projecting it to the soma by projecting it to a local compartment here can bring together the weights and you have way more degrees of (07:30) freedom to then represent at every single dendrite the arrow that you have from the feed forward weight in relation to the representations that all the other lateral neurons basically have and the lateral neurons and various some inhibition represent what they are encoding if we have such a local representation then this is a exact gradient for f that we can for the feed forward weights that we can represent while somatic balance proper has and is by definition approximation that approximation works very well as i show you in the following (08:04) example but it fails under the more complicated settings so what does it mean for the learning rules that come out the learning rules that one derives for the somatic validity on the left-hand side of the somatic balance that um learning are basically pairwise heavy in like plasticity with increasing of the weight if the firing is at the same time which basically says a neuron then selects a certain feature it represents the absolute offset here depends on the neurons or proper strength in addition we have some fast adaptation (08:41) what do we find for the dendritic balance in terms of its local learning rules we do find that the learning rule of that feed forward weight depends on the local error the local arrow either makes the learning rule scdp-like with positive terms on the pre to post-synaptic spiking or it makes it anti-sgdp like where um if the if if the arrow becomes negative which basically means that other neurons are already encoding your specific feature then if that if that error is negative this rule is inverted effectively and thereby (09:31) we make sure that all the different features you have in your input are represented in a distributed manner across the neurons i would like to demonstrate here so any natural images have some correlated hidden features also the scenes then have correlations i'm always saying talking about the apples and bananas that might co-occur at least in your supermarket but um let's say that's an absolutely general feature but we because we have a small network and also the calculation of the learning rule is (10:03) a bit complicated we decided to go for a fairly simple task and we also wanted to have a full control over the correlation so what do we do we take um we take the a bar task with with five times five bars and we either this we always show two bars an apple bar the banana bar whatever you want to think about it and this can be completely independent so this correlation or probability of co-occurrence is zero the other set that we we then have is that we have a certain probability the second bar is just a flipped one the (10:40) diagonally flipped one and with probability one minus b it is just a random other one so in this set of stimuli there's only these pairs of bars occurring that also makes obviously the codels lower but with then probability close to 1.0.95 there is in principle the two bars also occurring independently and a good encoding would be able to disentangle the two so this is then the represent and this is then the performance for using somatic balance it's fine as long as there's little correlation but then the more (11:17) correlations they are the better uh the the worse the worse it becomes then if we if we um have instead a a dendritic balance where the error is computed locally at every single compartment then the error becomes in there or the arrow becomes better the decoder loss becomes better this is because the entropy of the stimulus goes down so what we see here is a decrease is the entropy of the overall stimulus being reduced so and not only the entropy being reduced but then also the different neurons learning disentangled (11:59) representation and not as we can see here uh neurons that are representing always these joint pairs of the bars instead of mainly the independent virus this also works if one puts natural images in we pre-process the initial images with the written i like feature and then one can see that no matter how many neurons we have in the systems between 250 neurons so it's fewer neurons the task becomes more difficult decoder loss goes up that's absolutely clear but um what one does clearly see is that no matter what is the number of neurons the (12:38) dendritic balance performs better and also that was about disentangling correlated input the second challenge is the transmission delay why is it imagine one neuron codes for the banana the other one codes for the apple that should inhibit each other but if they're both basically coding at the same time inhibition is too late and therefore um does not reduce the feed forward weights there have been like field forward weights and this is something we do see uh here that if we increase the delay in our simulation then we find this breakdown (13:16) of uh decoder loss for the somatic balance implementation and this image here illustrates what's happening in the neural network so here in um so here in the somatic balance once these both aspects one sees that the representations don't become as crisp and clear as they become in the dendritic balance and you also see how the neurons basically are spiking in a highly synchronized manner instead of an asynchronized manner so that um with the synchronized manner they we have this yeah burstiness of excitation inhibition (13:54) flipping back and forth um do we find evidence for dendritic balance in vivo and um we do think we have some so this is older but classic study from 2004 they measured excitatory and inhibitory currents at at at these spines and they did find that there was a fairly good balance if the spines were at the same dent right compared to a balance of spines at different dendritic compartments the other evidence that we have is that the balance indeed might influence plasticity here are some ltd protocols either with or without so without or (14:42) with gaba and only with gaba which would decrease the local dendritic um or what decrease the local membrane potential only with that we find the decrease so that is at least some indication that the local membrane potential might not only be well balanced but also play a role and shape the neural learning rules um so in summary the dendritic buildings in a was local representation learning and then links provides the local error for representation it enables local learning of feed forward and lateral connection and this links the (15:17) computational theory with concrete biophysical mechanism so putting the arrow and the learning from the soma into the dendrite i think makes overall neurons way more powerful potentially than they have been before and if such a implementation is possible then often that's annual networks will probably have managed to learn or find that in via evolution with this i really want to thank my group especially fabian and lucas and i welcome your questions thank you very much fiora um there are some questions so the first (15:59) one was actually in the chat but uh since um since it came out first i'll just um read that so this was tim who was asking how is actually the local era defined and the second question with any drawbacks having dendritic balance so one drawback i would i should have been more open about that but it often comes is that for the dendritic balance as you can see we we basically bring in the representation of all the other neurons to some local compartment so in principle at least in theory if you don't want to make any (16:31) approximation this is all to all connection to that local compartment and you can see that the number of connections explode what we did numerically but it's not yet in the paper is to just prune away 95-ish percent of these connections and then the network still works very very well so in theory it's necessary in reality it's not necessarily needed how is the local arrow defined that local error is literally the lateral inhale put so it is the encoding that all the other neurons have chosen projected via the lateral weight w to (17:07) that local compartment and the arrow then is the membrane potential the difference between the feet forward excitation and the lateral inhibition good so then there's another question and which is um by dias um who's asking i guess the network is trained in a supervised scheme where labels are used at some point i i guess it's a reconstruction actually in a way but um if so do you think we could use the same learning principles uh with a sort of winner take all network at the upper player to introduce (17:39) competition and hence learn the representations without supervision actually this is unsupervised i should have stressed that this is unsupervised learning why is it unsupervised because you want to optimize the representation how do you optimize representation this basic principle there is that you want to basically balance the feed forward input and the lateral inhibition lateral inhibition is how the other neurons are representing what's out there and if i say that very sloppy let's say to my students i say (18:12) well if another neuron already say it's i code for the banana then it inhibits your apple neuron and the apple neuron should shut up and therefore you have an emergent um unsupervised representation of the hidden features these hidden features are the bananas and apples in your supermarket and ideally you don't represent them by pixels but you represent them by their object categories apple banana and whatever you find in your supermarket and the important part is that it's well distributed and now the (18:42) second step is yes if you would only show one stimulus at a time then it would be easy then your stimuli are perfectly decorated but in your supermarket the apples and the bananas are often coming together so you want to be able to present both so it is not a winner take all it is the same idea as a winner take all ish because you have the lateral inhibition but only a very very soft one in the sense of it's possible to represent as many of the hidden features at the same time and they can even occur in very (19:13) correlated manner and that is the the strength and the strong advancement here in the field i think all of that field is that we can disentangle them even if they occur together i mean there would for other networks that look like an apple banana a joint joint object and this if it's sufficiently often let's say more than at least five percentage of the time occurring independently then we can with these type of networks disentangle them i mean there's not a hard bound or we didn't properly look at (19:42) the bound this is just the estimate from the current data so yes it's unsupervised i would like to stress that i should have been more clear about it yeah he's very excited um so he commented just on his question so unfortunately we can't do two more questions i'll just as one we have like basically 10 seconds but uh so um thank you for the interesting talk did i miss something or does this model also require hydrosynaptic plasticity in a way it does not necessarily heterosynaptic plasticity depends on how (20:16) you specifically define heterosynaptic plasticity it all it needs is it you want to have the plasticity of the feet forward dependent on the local membrane potential on the local membrane potential the membrane potential probably is local we know experimentally that the inhibitory currents tend to fall off within a few tens of micrometers or more but there seems to be locality so in it's indirectly heterosynaptic in the sense of the other synaptic input playing in a role via the dendritic membrane potential that you measure at a (20:52) given time okay great thanks thanks for the short answer so there was one more by araf which i post in the chat so it's not lost and maybe we can get back to it later unfortunately we have to move on now uh thank you very much for this very nice talk viola and thanks for coming um and with that i will move to the next session great thanks,"The video is a talk by Professor Viola Priesemann of the University of Gottingen, discussing her research on dendritic balance in spiking neural networks. The main point of the talk is that by placing the learning from the soma to the dendritic compartment, the error signal can be computed locally and the exact gradient can be used for the update of weights. This improves the ability of neural systems to learn complex statistical relationships in the environment despite facing severe constraints. The talk also mentions that this approach is useful for disentangling complex correlations in inputs, and that it can be used in spiking neural networks to learn image representations.",ChatGPT,,,,,,,,
https://www.youtube.com/watch?v=aLNGcs_zYsY&list=PL09WqqDbQWHEqm1_3a620tKUKnC6FgBrG&index=7,2021,SNUFA Workshop,Nicolas Perez Nieves,Imperial College London,Understanding the role of neural heterogeneity in learning,Learning,(148) 07 Nicolas Perez Nieves - Understanding the role of neural heterogeneity in learning - YouTube https://www.youtube.com/watch?v=aLNGcs_zYsY Transcript: (00:05) right welcome back uh with our next speaker nicolas perez nieves which i probably mispronounced therapy he's from imperial actually works with ben goodman and he will talk about understanding the role of neuroheterogeneity in learning thank you thank you very much and thank you to the organizers so i'm going to talk about the role of neural heterogeneity in learning so to begin with so the question that we try to answer is why is the brain so heterogeneous so here you can see for instance um some data some (00:42) membrane time constants that i took from the nearelectro.org webpage you can see these are all recordings from over 370 publications uh where they they measure experimentally 87 different neuron types and you can see that the membrane time constants vary from 25 milliseconds up to about 200 milliseconds and something that is constant on all these uh um all these experiments is that uh many parameters morphologies etc are heterogeneous and the brain seems in general to be heterogeneous so the question is why is the brain (01:13) heterogeneous and the several hypotheses could be is there some functional role to this unity um it could be is just a byproduct of noisy developmental processes or it could be that it's just the result of some contingent uh evolutionary history um it could also be some sort of combination of all of them um so we try to answer this question and in particularly uh i'm going to now do a brief summary of all that i'm going to to talk about um and basically what we have done in order to try to answer this (01:45) question is is train spiking neural networks on difficult real-world tasks and and where we allow the neurons to learn its time constants and also we tried what happens if we initialize them in a heterogeneous way so the results that we had were the following three the heterogeneity helps in task with complex temporal structure that there is an optimal distribution that is found very consistently of time constants that matches experimental data and that heterogeneity gives robustness to hyper parameters tuning so the (02:15) conclusion of the work would be that hygienity seems to be an efficient way to improve performance at a low computational cost so how have we done this so what we have done in all of our experiments is a simple uh leak integrative fire integral fire recurrent um neural networks in which we have some input spikes some recurrent layer which usually we we have few neurons uh because it's very computationally expensive so around 128 euros and then we were recording the membrane potentials of the output and we (02:46) make a prediction prediction uh with this membrane potentials and we back propagate using surrogate gradient descent so we train in four different regimes and the four regimes are the ones shown here and and throughout the presentation i'm going to follow this color scheme for them so the baseline would be these homogeneous initialization and standard training regime in which all the neurons are the same all the neurons have the same parameters and we only train the weights uh we can also either uh initialize them heterogeneously so the (03:15) neurons have different time constants and then train the weights or train both the weights and the time constants of the neurons and of course we can do both things so initialize them heterogeneously and train both the weights and the time constants so these are the four uh setups in which we have done the training and the dataset that we have used to to investigate this are datasets in which we try to increase the temporal structure the dataset has so on the left here we have datasets with with lower temporal structures that will be (03:44) something like the neuromorphic mnist and the fashion mist in which by adding all the spikes uh across the temporal dimension you can pretty much tell what you're looking at um and this in this case would be a zero so so the temporal information is not so relevant and something similar happens from the fashion mnist where we encoded each of the pixel intensities as as latencies as spike latencies some of the data sets like the dds 128 we have actually some temporal information that we require in order to be able to classify but still (04:14) some of the samples are it's enough to just see a sum of all the spikes in order to tell whether it's one class for the other and finally we have the shd and the ssc data sets uh which are almost purely uh or fundamentally or highly temporal in their nature and these data sets are based on spoken digits and spoken commands which have been converted into spike times using a very detailed model of the cochlear nucleus so the results that we'll take when training this kind of network on these data sets are the following so the (04:47) baseline would be here in blue and and as we go down here we we would be increasing the level of heterogeneity that we allow for so with the neuromorphic amnesty we see that there is basically no improvement at all by adding heterogeneity of any of these kinds as uh however for the more uh temporally uh relevant or temporary complex data sets we see that any heterogeneity that we add seems to be increasing their testing uh accuracy and this can be seen here again the fashion amnesty is a strange case in which it (05:18) seems that only the heterogeneous cases seem to get this uh 88 87 performance and i'll talk a bit about it uh later on why this this is happening so so we we have seen that it seems so far that uh using this heterogeneity seems to improve the performance um but now what we wanted to look at is what happens with the time constants that we have trained so here on the left you can see the distribution of time constants either in orange the heterogeneous initialization and in blue the homogeneous one and these ones where after training in (05:49) each of these data sets converted into these new distributions and we can find a pretty much uh all of them follow this distribution in which most of the weight is concentrated at the lower uh time constants and and some of them particularly the ones that have more temporal information seem to have more uh weight also added into the into the time constants that are really large and interestingly uh we looked at some experimental data so that would be data from the pulmonary data set recordings and from the alien institute (06:21) and we found that this distribution resemble uh actual experimental distributions um and interestingly these distributions didn't have any large uh time constants and we believe that the reason why we see these large time constants is because our networks are small so some of the networks uh some of the neurons are needed to be really large in in memory they need to have a long time constant so that they can remember uh uh information for longer time but if you have a larger network this wouldn't appear (06:49) and this was not only consistent across datasets but also across different initializations so we tried uh initializing it at really large time constants or with a gaussian distribution or with a uniform distribution and in the this is the shd data set we found that the distributions are pretty much identical in all cases so so this seems to be the optimal uh distribution for for training and learning in this task we also try to see what happens if we augment the the data set so the original data set would look like this it would (07:23) take about 0.8 million eight seconds for for the whole sample but what we do is scale it so that either we compress the spike times or we extend the relative spike times and we now have inputs that can have these different scales factors and what we do it now is we train the network on by drawing this scale factor from this uh log normal distribution which is the same distribution as the human syllabic rate so the network will uh see samples that have a probability given by this distribution of being of each of the (08:00) scale factors and then what we will do is test on on never seen samples at all these uh scale factors time scale factors how the network performs and this would be the the result of that and what we see is that um the baseline is is much worse at uh being able to or relatively worse at predicting what the output is going to be for really large time scales that it has never seen and the others simply to perform better and very interestingly the heterogeneous initialization without the heterogeneous training uh manages to (08:36) keep up with the performance of the other two the ones that are actually training the the time constants which would give you some hint of why perhaps a a system would evolve to to have some heterogeneous time constants as it seems that it has a better generalization against time scale factors that in in your lifetime you see uh less often um we did something similar but kind of the the reciprocal of this so we have the hyper parameters uh properly set for a time scale of one and we train the in this case we only train the weights we (09:09) don't train the time constants and we did this so that um we have a homogeneous distribution of the time constants and heterogeneous distribution of time constants and an intermediate distribution and the intermediate one is basically two homogeneous at two different time scales one large and one small so what we find is that this uh um homogeneous distribution actually training the weights at scale factors of four when the hyper parameters uh were were set for for one uh is really bad at generalizing and the heterogeneous (09:44) however is pretty much flat at all the time scales although the hyper parameters were set for one and the intermediate one is in between as you would probably uh expect so i i was going to talk also about the the hyper parameter uh miss tuning that that i i pretty much uh skipped before so basically what we're seeing in the fashion m is fashion mnist was was trained uh with using the hyper parameters for the shd and what we found is that the heterogeneous initializations would prevent you from having these (10:14) issues where some of the some of the seeds would basically get stuck in local minima and it would take much longer for them to to get out of that and and properly train um so so it seems that if your hyper parameters are mis-tuned having some heterogeneous initialization would allow you to train the network in a much more smoother way and this is something that we also tested on a different training method so this would be with force training in force training instead of trying to classify some data what you do (10:46) is you you try for your network to memorize and then you ask it to retrieve uh some high dimensional data in this case it would be this spectrogram so um the the the network will try to memorize what this spectrogram is and then you would ask it can you give me this spectrogram can i reconstruct it and we again we tune it for 1000 neurons the learning of this spectrogram and then we vary the number of neurons that we had with different initializations so again this would be the homogeneous gamma will be the heterogeneous and that (11:19) will be the intermediate as before and what we find is that the pretty much at some point the homogeneous one breaks and it just provides it just gives this this highly bursting uh and unsaturated activity and nothing can be retrieved however for the um homogeneous heterogeneous one the gamma particularly you still have some nice activity and the spectrogram can be perfectly well recovered um so why does this happen so we looked at the the islands or the areas of stability of the network when training uh with these (11:54) distributions as we varied the hyper parameters that we had uh fitted for varying number of neurons uh what we find is that is that the gamma distribution is much better uh and it's much more stable so so blue in this case is good so the error is low it's it's much more stable regardless of what hyper parameters you put neurons as opposed to the um the other and particularly homogeneous one in which case this area is much smaller and you require parameters that are a lot more fine-tuned in order to be (12:28) able to to perform in the same way so um as a summary of the whole thing that i just presented so the conclusion would be that the heterogeneity is computationally efficient um we have seen that it has increased the performance is particularly in the temporally constrained data sets for a very small increase in the in computation um the training uh adding more or learning the time constants only grows uh linearly with the number of neurons that you have uh however learning the more weights uh would grow quadratically with the number of neurons (13:09) that you have heterogeneity also provides robustness to hyperparameter missed tuning so we have shown that the training can be smoother and it also is better prepared to adapt to unseen uh time scales uh and and finally there are some open questions so one of the main questions would be does the brain optimize for this or this is something that uh it's it's uh innate to a certain extent um and the second question would be do other forms of heterogeneity matter as much so we have only trained the the time constants not the (13:42) uh we haven't provided any any input as to whether we have neurons that are excited to pray others are inhibitory different neuron types or anything like that so all the neurons are the same but for their time their time constants and and weights and finally if you to find out more you can look at our recent publication that yeah and thank you very much everyone for listening and to all my co-authors thank you so much for this nice talk so it's a bunch of questions um first one is by tim maskeville which is um did i get it right that you (14:22) use a single pool of recurrently connected neurons no layers in a layered network we observed that learning one times one constant time scale per layer and not by neuron was usually enough if you tried this um we tried so so yes we only had one layer one recurrent layer and we learned the individual time constants for each of the neurons we also tried just learning a single global time constant for the whole layer and that seemed to be much worse in performance actually it would get stuck in local minima we also tried uh (15:00) having several layers and learning all the time constants on those layers and i think we only put like two or something like that and we didn't find pretty much any performance improvement what we didn't try was learning a single time constant per layer which i think that's the what the question was was asking and so yeah certainly it could be that that that would be key and and and much better because then you need to learn one parameter per layer except not one parameter per neuron right good so then there's a question by (15:36) camilo ortiz would you say that a heterogeneous heterogeneous uh snn displaced temporal and time scale in variance similar to how cnn has translational invariance um i guess that to a certain extent you could say that uh but but i don't think it would be as accurate so so in a convolutional neural network you're basically forcing that by making sure that the filter is shared among uh different uh neurons uh on the same uh depth uh on the same channel or filter um but in our case i think pretty much what's happening is (16:13) that you are able to to very better select that some neurons react faster to the input some some others react slower to other inputs so i don't know if that would be invariance i really don't know what that would be called uh actually um i guess that is just variable memory or something like that perhaps right yeah i guess uh recurrent neural network is already invariant in time right insulation and brilliance so you already have that but yeah good um so the next question is um this is my question actually great so i (16:50) get to ask my question it looks like you get different timescale distributions for the shd and the ssc data set but given that they're both generated with the same conversion model and i wondered whether you wondered where this comes from yeah so so we don't know about that so so it was rather surprising that the ssc data set is is a lot harder i'd say to train um it's longer it has more classes longer in the time window and and i was expecting actually that the time constants the longer time constants uh that you need to find are (17:24) are more so so you would expect to be more heavy tailed but we found pretty much the opposite that the shd required more longer time constants and maybe what's happening and is this is just a guess maybe what's happening is that when you train the ssc um it it manages to to distinguish enough classes by just taking information from smaller windows and it doesn't really get into the larger picture because it may be too hard and there is it just gets stuck in a local minima there is definitely a lot more to learn from that (18:00) data set in any case because it's only 60 our best accuracy and some other people have managed to to improve in that but yeah i'd say that there is something like that going on that it doesn't really manage to to to look into the really longer uh time correlations as there may be on the data okay interesting there's also the point that is much noisier so the underlying audio data set is actually much noisy so maybe some idea for something to look into in the future yeah good thank you um so another question by (18:33) kareem um does the distribution depend on the input form like using poisson spike trends instead of latency so i think that it may it it could be the case so so for instance the fashion mnist is just uh using a very small number of spikes so every every input neuron only spikes once um what that means is that everything happens very quickly and very soon uh you don't have any spikes the number of times that you have is very small so the result of that is that most of the distribution is is concentrated at very very small time constants so if (19:10) you were to use a poisson input to encode that uh i would think instead of using the the latency i i i would expect to have some longer time constants in that case because you need to be able to to remember more spikes in order to to be able to tell what's the frequency where the frequency of of that pixel so yes i think it definitely uh affects the that kind of encoding that you have thanks good um so the next question is by gregor orlands uh it's a bit of a technical question um in your paper you say that you're training um x of minus (19:50) one over tau rather than tau itself why did you do that and does this not also skew the learned distribution yeah and um so the reason why we do that is because uh pretty much for numerical uh stability so i think in a previous talk by henning sprickler they they were saying something that the training the time constants were very tricky and i think they were training them directly um which has this uh inversion and then exponentiation which can make things numerically very unstable and i think they tried to do uh the inverse which (20:22) was a bit better but it still was giving some travel um and i know some other people have tried to to uh um train them directly and have succeeded so it's by no means impossible um it could be that that the fact that we are using uh this um exponential is is making it uh um skewed to a certain direction it could be but um it's the only way that we found that it could train um properly and also we we not only did that but we also had to clip at the two ends at the lower and the higher end because otherwise at the (21:00) very beginning um the network would try would get into very really bad local minima so so you would find that it will reach um negative tank constants so that what that would mean is that the network um well and also really really large time constants so so pretty much it would get out of the of the space of solutions that would actually be able to solve the problem so we had to constrain that to to to that space um yeah i think i think maybe that answers the question i think so thank you and so let's do two very quick ones um so one is by (21:37) teamwork uh to what extent could the training of time constants be replaced by random constant time constants with the same statistics as found after training yes so so we actually try that and and maybe we should have included it um but basically what happens is that if you take the train time constant and you initialize a network with those time constants but you randomly initialize the weights and you only train the weights then it manages to get pretty much the same result as it got when it trained the the (22:09) time constants it's not as good um probably because the initialization is far from what it needs to be um but surprisingly if i remember correctly it performs pretty well in any case okay thanks okay now a short answer well oh yeah sorry no no please go ahead yeah so i was saying that perhaps what they were referring uh what he was afraid about was what if i take that distribution and i sample from it uh and then train we haven't tried that uh i i believe um but yeah it would be interesting good things okay so last one very quick (22:47) one do you think the distribution of time constants would change depending on the level of recurrent connectivity in the network yes i think that it could so our models are fully connected um so everything is connected to everything and i think if you were to constrain things make the network larger uh or and remove connections it could happen definitely i believe that what we will see if we make the network larger is that we see less large time constants in the distribution um i'm not sure about what happens if we (23:21) remove connections and we make some sort of sparse connectivity um yeah i couldn't predict exactly what will happen there uh maybe even longer time constants because uh you yeah i i don't know i i i rather not uh speculate too much about what would happen okay good well thanks this was by the way rory byrne who asked this question so thanks a lot thanks a lot for this nice talk thanks to all the speakers from this session again i will now have a 25 minute break and then or basically a 20 minute break by now and and then we'll (23:58) reconvene on zoom this time for um for the for any discussion and also because i invited there to uh [Music] list so um you should have already seen the link uh otherwise uh worldwide newer is gonna post it also in this chat and with this uh thank you again for the talk thanks to all the speakers and thanks for the great audience for all the questions thank you very much,"In this video, the speaker, Nicolas Perez Nieves, discusses the role of neural heterogeneity in learning. He begins by posing the question of why the brain is so heterogeneous, and suggests several possible hypotheses such as functional roles, developmental noise, or evolutionary history. He then goes on to describe experiments where they trained spiking neural networks on difficult real-world tasks and allowed the neurons to learn their own time constants, and also examined the impact of initializing the neurons in a heterogeneous way. The results indicated that heterogeneity helps in tasks with complex temporal structure, that there is an optimal distribution of time constants that matches experimental data, and that heterogeneity gives robustness to hyperparameter tuning. The conclusion of the work is that heterogeneity seems to be an efficient way to improve performance at a low computational cost.",ChatGPT,,,,,,,,
https://www.youtube.com/watch?v=4SOPbEdEmA8&list=PL09WqqDbQWHEqm1_3a620tKUKnC6FgBrG&index=10,2021,SNUFA Workshop,Dylan Muir,Synsense,"Machine Learning with SNNs, for low-power inference on neuromorphic hardware",Mobile and edge applications,"(148) 10 Dylan Muir - Machine Learning with SNNs, for low-power inference on neuromorphic hardware - YouTube https://www.youtube.com/watch?v=4SOPbEdEmA8 Transcript: (00:04) sorted out attack um i have with great pleasure oh i'm here to introduce dylan muir dylan is a true interdisciplinary persona all in himself he has a background in electronics computer science neuroscience uh and and in his postdocs he already combined neuroscience with machine learning technology um right now he's a senior director at syn synsense which used to be ai cortex for those who didn't make the connection yet and he's going to talk today about to us about machine learning with spike neural (00:38) networks for low power inference and neuromorphic hardware dylan thank you very much for being here go ahead thanks thanks very much sander can you hear me perfect great yeah thanks very much for the introduction uh as sander mentioned i have a background originally in uh electronic engineering and computer science in australia i did a little bit of work in artificial neural networks after which i moved to switzerland to do a phd in computational neuroscience i worked in academia for a few years in in a series of experimental neuroscience (01:12) labs and then joined since in 2018 to to co-lead the machine learning algorithms team at since so i'm really looking forward to having a chat with you guys today about what we do at synsense uh we are a uh a hardware company uh a startup based in zurich we have offices also in in chengdu and shanghai now we make low power spiking neural network neuromorphic processes for for real-time sensory processing so uh where we see our processes being incorporated is in smart sensors neuromorphic smart sensors by smart sensors i mean devices that are (01:56) very opinionated about the things that they're interested in very selective for example a microphone that's sensitive only to human voice or selective only for particular sounds so where for example the the input bandwidth to this sensor could be very high continuous audio continuous vision but the output of this sensor would be extremely sparse extremely selective uh very low bandwidth but highly informative so smart condition detection for example um or keyword spotting for audio or or human presence detection (02:33) which ignores pets ignores cars so we see we want to continuously monitor some sensory input and provide a very informative signal we want to do this using spiking neural networks that's obviously why i'm talking with you today so we we place our devices close as close as possible to the sensor we want to operate uh in real time by real time i mean um less than 200 milliseconds so human human responsivity time and we want to make use of the the spike in neural network architectures to do this at low power by which i mean less than a (03:12) milliwatt ideally much less than a milliwatt also we have two main hardware families at synsense the first on the left is a series of general purpose spiking neural network processes we use these for low dimensionality signals such as such as audio processing by signal processing this includes uh some traditional mixed signal neuromorphic processes uh coming out for example of the work of giacomo and diva at university of zurich as well as a newer digital spiking neural network processor which i'll discuss in a bit (03:49) more detail later on the second line of hardware on the right is designed around a spiking convolutional neural network core designed for vision processing we've integrated that with a event-based image sensor array to produce a compact chip that does sensing and processing on the same chip you can see the little prototype module there and we're using this obviously for vision sensing applications for example as i mentioned before smart presence detection or behavior detection so vision-based fall detection by (04:21) monitoring someone inside someone's home or gesture recognition for interaction these sorts of use cases um today i'll i'll focus mostly on mainly on the first case of the general purpose uh spike in neural network processes uh for auditory processing um and uh but we've got a couple of presentations actually later on this week about the vision processing side of things so i'll give you some pointers to that later on as well so in in both cases our focus is really on low power real-time sensory (04:50) processing and interaction but i want to emphasize that for us biological realism is is a non-goal so we're we're not trying to make hardware uh or network architectures that mimic or reflect biology uh in any deep sense we're really trying to engineer efficient artifacts and we're using the the the sparseness of spiking neural networks as a way to get an energy low energy benefit there of course none of this work could possibly happen in a vacuum so i want to start by quickly highlighting the rest (05:26) of our algorithms team at since um i only have a time to talk about a very small fraction of our work today but i've included also at the end of the talk a few pointers to to some additional work that we've been involved with so i want to start then today by showing an example of training a toy spiking neural network using our our development tool chain i'm going to talk about our digital spiking neural network architecture and i'll show an example application running on our hardware um but to begin (06:00) with i'll start with this this toy task so the task is as shown here i'm going to train a spiky neural network that listens to a real-time audio signal and it produces as its output an image of the bird that it's heard so this is a it's kind of a complex sort of toy task it's a multi-class task um it's a mixture between uh recognition and signal generation so the network internally has to uh listen to the audio classify which bird call it's listening to but then it also has to produce a (06:38) an output of a different modality so it has to produce an image encoded output absolutely sort of cross modality mapping flavor to the task you have to produce a complex temporal output signal uh and we need to do this with a spike in neural network but that's operating in strictly streaming mode so we don't we don't provide buffered uh a buffer of input that it can analyze um across time simultaneously but really the dynamics of the network should operate in streaming mode over time to to solve this task (07:11) and we'll do end-to-end training with back propagation through time on the spiking network so i'm going to accomplish this using our open source development platform which is called rockpool this is a python based system using industry standard machine learning pipelines such as pytorch and jacks to enable training back propagation based training of spiking neural networks we also support more computational neuroscience flavored back-ends for example brian and nest for for inference for simulation uh as well as some sort of (07:46) native numpy um modules for spiking neural networks as well uh in this case i'll show back propagation based training example uh rockpool supports deployment as well to our hardware firstly our xylo digital spiking neural network chip and a development kit which which is available now and we'll also soon support deployment to a mixed signal development kit based on on dynaps2 okay so this task obviously spiking neural networks can't process necessarily raw audio intrinsically we need to to convert this (08:29) input signal into an event-based representation that can be processed by the spiking neural network this is what i'm going to show you now is an overview of how we do that we have some hardware that we've prototyped within the company uh as an audio front end so for for doing precisely this encoding of uh real-time analog audio signal into a streams of events for processing uh for for audio processing tasks with spike in neural networks um this is the the an overview of the architecture here again uh it's (09:02) biological realism is a non-goal so this isn't a cochlear model uh in any strict sense but of course it it produces a multi-channel event encoded output so the approach we take is um we have our obviously our raw microphone uh input and we pass this through a low noise amplifier and then we split the signal into a series of bandpass filter banks so we we analyze the audio signal and split it into a set of frequency bands spaced and and tunable to cover the the bands frequency bands of interest in whatever audio input you you're wanting (09:41) to use um and then we perform uh rectification and smoothing uh so that the uh the the that each frequency band is now encoding the uh instantaneous power in that frequency band then we pass this instantaneous power estimate uh through a leaky integrate and fire neuron uh to convert this into a series of events so the result of this front-end encoding system is we have a single channel audio signal that is then converted into a number of event-coded audio channels where the firing rate in each event channel encodes the instantaneous power within (10:23) that particular frequency band so if you have any questions please ask them in the question chat i can't see this right now but i'm sure sander will jump in if there's any burning questions um including during the talk if there's something which is not clear enough uh please stand and jump in and and pull me up on that uh so here's an example of what that audio encoding looks like on top we have the raw audio waveform uh in the middle we have a spectrogram so here we have 12 channels in this (10:54) particular case and you can see that there's the the encoding of energy in these different frequency bands over time but in this case i've chosen the frequency bands between two kilohertz to 24 kilohertz this roughly spans the range of audio for the bird calls and at the bottom is the the actual individual events which are used as input to the spiking network so similarly for the the target output image encoding obviously spiking neural networks can't natively produce an image so we have to encode this image (11:32) as events the way i've chosen to do that is by encoding the the rows each row of the image as uh in the output channels of the of the neural network and the columns of the images are encoded across time so we sort of stretch out the image uh in along one dimension over a period of time the network should produce this encode this image over a period of time so the uh the result is that each output neuron channel encodes a component of uh the pixel rho and has a temporally changing signal across time that encodes the the (12:12) intensity of the pixels along that row uh so if we zoom in to a little bit more detail here you it might be a little clearer what i mean so here i'm showing the encoding of two image rows row zero and row one and the red green and blue components of each pixel are split up into independent uh event channels zero one and two so this is this is then pixel one row one and row two and and then we have the image columns encoded across time so within each little dashed box here is the encoding of one pixel split into red green and blue according (12:47) to the output channels and then encoded across time according to the intensity of each channel so uh the the number of events within this particular time bin encode the red the green or the blue intensity of that pixel at that moment in time so if i show an example of one of those encoded images here at the top we have we have one target image stretched out across time the samples for this particular task are five and a bit seconds in the middle you can see the event raster which is used as the target signal for the for the network during (13:24) training so you can see the uh the individual pixel rows are encoded rgb encoded as individual channels on the y-axis and then the the temporal sequence of pixel intensities is encoded over time along the x-axis and at the bottom is the is the actual plotted events which are used for the target the neuron model is a very simple very standard uh leaky integrated fire neuron model um i don't need to go into any sort of detail with that uh certainly for this audience but for completeness i just lay out the uh the dynamics here uh (14:01) we have independent synaptic and membrane dynamics independent synaptic and membrane time constants we have a bias added on to the membrane potential the input spikes are integrated directly onto the synaptic current the output spikes are produced through the spike production function which is basically a heavy side function i'll show that i'll plot that in just a moment as a function of the membrane potential and then we have a subtractive reset of the membrane potential based on the output spiking so it's a very standard (14:34) leaky integrated fire neuron the obviously uh for the purpose of this workshop is about how difficult it is to train spiking neural networks and of course one of the principal difficulties comes about through finding a way to get gradients through the network the the off-the-shelf solution now is of course surrogate gradient descent um here's the spike generation function for this leak integrating fire neuron of course i don't need to go into detail with this here either but the problem is of course that the (15:05) the derivative the gradient of this heavy side function is zero everywhere except at the threshold where it's undefined so it's not very good for gradient descent and uh of course we are not the ones to um who have come up with the concept of surrogate gradient descent i've got a very incomplete list here of friends and family many of whom are in the audience today who have been investigating this question for for quite some years we use a very simple surrogate gradient function which essentially approximates the (15:35) transfer function of the neuron as a piecewise rectified linear neuron and therefore the the backwards and the backwards pass the surrogate gradient is either zero or a constant value so it's very very cheap to calculate okay the network architecture that we use for this task is shown here uh in in green is this audio encoding front end that i explained previously so the raw audio comes in on the left then we have our 12 event channels which encode this in audio instantaneously we have a set of linear weights which (16:13) are shown in blue with w and then leaky integrate and fire blocks shown in orange here with laf to transform between the 12 input channels to the number of hidden channels uh then we have two residual blocks which i'll explain in more detail in the next slide and then another set of linear weights and spiking neurons to do the final encoding for the 96 output channels this is the rgb pixel rows for the the encoded image uh sorry i also want to say that this is strictly a streaming architecture during inference (16:51) there's no time windowing really these 12 input channels at a single moment in time is the only input this network is receiving during inference during back propagation training we train on an entire sample so uh information from the entire sample is used to compute the gradients and used to compute the parameter parameter updates but then in the forward pass and during inference mode it's purely a streaming architecture this is a residual block uh probably most of you are familiar with what a residual block is in a residual network (17:26) but basically it's a block where you have the same number of input and output channels you can perform some internal processing in the block but you also pass the input data completely around this block by passing any any information processing transformation that's taking place within the layer so within the layer we have a set of linear weights and a set of linear uh sorry leaky integrated fire spiking neurons um but then we have these n event channels coming in which can also bypass the layer entirely and uh for a (17:59) spiking neural network this is potentially very beneficial for low low latency processing um so you can completely bypass any temporal integration which is taking place uh due to the membrane and synapse dynamics within the leak integrate and fire neuron layer so what does this look like in rockpool uh here's some what the code looks like to generate this network um we're we're using so as i said rockpool is our open source tool chain for machine learning spiking neural networks uh provides many standard modules uh many standard blocks (18:36) for building and training spiking neural networks uh in this particular example i'm i'm showing uh an example of using the jacks back end uh jax is a uh an open source library from google for uh automatic differentiation and uh accelerated computation let's use gpus cpus tpus whatever you have available but we have spiking torch modules available equivalently for rockpool and any standard torch module you can use directly in rockpool so here's what the code looks like we import the linear weight layers (19:15) we import an laf layer we import these two combinators sequential just builds a feed forward stack of layers residual implements this residual block and here we very simply define the structure of the network exactly as i showed you on the previous two slides we need to define a lost function for optimization here is a minimal loss function that would use for the for the jax training we here we receive the parameters for this trial and assign them to the network we simulate the network by passing the input data through the network and (19:55) receive the the output spike raster and then we compute and return a loss in this case we're using mean squared error loss but really you it's completely arbitrary you can use any loss that you can pass gradients through so for example cross entropy um ctc loss uh anything else any anything else you can think of you can add additional regularization terms here um in a very straightforward way uh we use this auto differentiation facilities from jax jacks. (20:26) grad for those of you who haven't seen jax before this simply takes your loss function and converts it into a gradient of the loss function so you uh you you for free you get a function uh that gives you the gradients of the loss with respect to all of the parameters in the network and this is what we use then for training uh so we have a very simple training loop here against the minimal sort of training loop um where we're using atom as an optimizer in this case uh provided by jax you can use any of the standard optimizers uh anything that's available (20:58) you can easily write your own optimizer if you choose in this case we use atom we we loop over the data we get the parameters for this particular trial from the optimizer we use our gradient of the loss function which we got on the previous slide uh to get the gradients for this trial and then we use the optimizer to update the parameters for the network and then we do that tens of thousands of times to train our network here's what the the training loss looks like over time um this this example here took about one (21:35) hour to train that's around 120 trials per second i think that that's pretty reasonable performance for for a network of this complexity this is also on a on cpu uh on a fairly old macbook so this is this is certainly not the the fastest performance that one can ever get out of this uh it's a bit difficult to see but they in fact the the loss is still decreasing at the end of this uh uh 400 000 trials but the the performance of the network at this point was satisfactory so i stopped training here uh and then here's the output of the (22:12) network the trained output so on the left is is the spike raster produced by the network in response to the this particular audio call corresponding to the uh it's a prairie warbler if i recall correctly uh and on the right is the is the target raster that it was after um so you can see that it's it's learned the task it hasn't learned i didn't train it long enough to learn precise spike timing i was a bit lazy with my my imaging coding so i didn't encode the pixel intensities there's some sort of (22:42) cross-on rate but i really encoded it as these kind of bunched uh spikes so that's that probably makes things a little bit more difficult but nevertheless it's it's managed to learn the task and if we look at these uh these two particular classes then we can see that it's it's learned the image encoding uh for for the both of these classes so obviously i've tried to make it look and sound as simple as possible in practice there's always more to it than that we know empirically that spiking neural (23:11) networks require a little bit of careful shepherding during training to take care of numerical stability for example to avoid problems of vanishing exploiting gradients to make sure that you you have a network that's deployable uh to hardware um so essentially this means adding some some regularization and and taking care of things during the training process so for example we add some regularization uh to the weights to avoid network instability particularly for recurrent networks uh as those of you who use (23:45) recurrent networks will know that's very important um uh we can regulate activity-based regularization to ensure that we have non-vanishing gradients and we have we don't have silent networks uh that wasn't a problem for this particular use case but we we've seen that this is a very important aspect parameter constraints are also very important especially for example when training time constants um as we heard yesterday you have you you have to make sure your time constants are strictly positive of (24:16) course in fact in practice we need to ensure that there's some minimum time constant to avoid numerical instability uh during the simulating the neuron dynamics so nevertheless we can we can use this tool chain to train all the parameters of the network what i'm showing here is the distribution of the membrane and synaptic time constants after training so the the red dashed line is the pre-training initialization value uh they were all set homogeneously to 200 milliseconds for synaptic time constants and 500 milliseconds for membrane time (24:47) constants uh and then after training they they adopted um a broader distribution this spike around 100 milliseconds is exactly this minimum time constant constraint that i that i mentioned previously so this is what this is our constraint on the time constant um what i found interesting as an outcome here is that the network clearly tries to make some use of very fast or instantaneous information in the signal by having as short time constants as possible but it's also clearly important to have some degree of temporal integration of (25:21) the signal especially over over fairly long durations uh to make use of information across the broader stretches of time okay so our goal at synsense is to build these sorts of models and run them on spiking neural network hardware process hardware for inference so i want to show you an example of an audio application running on on some of our hardware i'm going to start by explaining a little bit what the hardware architecture looks like so this is our xylo digital spiking neural network architecture this what i'm showing you here is the (26:01) essentially the neuron model this is an all digital uh synchronous digital core it's designed to make use of the weight sparsity and activity sparsity of a spiking neural network for efficient computation efficient processing this is what i'm showing here is just a single neuron each neuron has a 16-bit integer membrane state two independent 16-bit integer synapse states so this would allow you to for example have synapses two synapse time constants for a single neuron uh both the membrane and the synapse (26:40) states implement a an integer arithmetic approximation to exponential decay which is just cheap to compute and the processor supports a fan in of up to 16 input weights per synapse when an input arrives input event arrives at the synapse then the weighted input is added to the synaptic state the and the synaptic state is then added to the membrane state both synaptic states are added to the membrane state at each time step when the membrane state is above the 16-bit threshold then an output event is generated by that neuron so all of the (27:18) events are single bit uh spike events there's there's no there's no more uh complex encoding added to the event as there is in in some other neuromorphic recent neuromorphic processes the the processor core has this sort of logical network architecture um up to 16 input channels uh event encoded input channels are supported uh we provide then linear input weights between those 16 input channels and the 1000 neuron spiking neuron population laf neuron population this hidden population supports recurrent connectivity as well as (27:58) providing a set of readout weights between the hidden population and the eight spiking output neurons which then comprise the output channels of the chip so this is the logical architecture of the chip you can of course embed and encode much more complex networks into this architecture for deployment which is which is what we do in practice we have a development kit an hdk available for for this this architecture i have one sitting on my desk here i'm going to show you this running in just a moment we have a direct interface from rockpool (28:38) from python for training building networks for running the simulations of the networks on the device uh rockpool also then has a bit accurate simulation of the hardware architecture in software uh so you can test your deployment in simulation uh before really putting it on the hardware and we uh we support deployment from a trained network to the chip in approximately two lines of python depending on how concise you you want to be okay so i promised to show you a example application running on the chip this example application is going to be (29:17) a keyword spotting task so it's audio processing temporal signal detection task obviously we're looking for a particular spoken keyword and then producing a detection signal at the output of the network when we recognize that spoken keyword the network architecture i'm not going to go into any detail of right now today because it's work done by philip vital and static chic in our team this is hot off the press freshly available as a preprint so all of the details are available there in the preprint but very briefly (29:56) so the network architecture here we use the same audio to event encoding that i showed you pre for the previous example uh and then we have this wave sense architecture uh from from philip and static so this is a feed-forward spiking neural network architecture it's been designed specifically for neuromorphic processes and laf neuron dynamics and it uses the cleverly used as the time constants of the synapse and membrane to implement a temporal convolution um so i'm not going to go into any more detail but please check out this uh (30:32) their preprint for all of the details of that implementation but again the network is running strictly in streaming mode there's no time window in here we have real-time audio input encoded passed through the network and and then we have a a single output event channel for detection when the keyword is detected okay now i'm going to take the great risk of doing a live demo and cross my fingers that everything worked as it did 10 minutes before the presentation uh okay so i'm just going to start the uh the demo architecture here uh so (31:10) what we've done is we we've trained a network in on the pc in simulation and then we've deployed the network uh onto onto the hardware uh so what you'll see in a moment is uh the the uh the real-time audio which is being encoded on the pc and then passed as a stream of events to the hardware the uh the the network is running in inference mode on the device sending events back over usb uh to the pc for visualization on the gui um sander if i assume you can see this uh exactly what i'm saying if you can't (31:48) see a gui with showing an audio uh waveform then please jump in immediately and tell me i'll try and fix that otherwise i assume everything it's really okay great good great excellent so obviously what you can see is the raw audio as it streams through and uh also the behavior that the output of the network which is currently sleeping because it hasn't heard uh its magic keyword which i will attempt to say now hey snips hey snips okay so second time lucky uh the the network woke up when i heard the keyword and it (32:24) selectively ignores everything else uh that it that it's not interested in so this is what i mean about having a a selective uh a selective sensor a smart sensor okay so uh again the uh the all of the details of this network architecture and implementation are available in this preprint from uh from philip and static which i encourage you to go look at but we've we've deployed this onto our hardware and we achieve a good sensitivity low latency so less than 200 millisecond operation with low low false alarm rates (33:08) all right so obviously there are fewer researchers uh in the spiker neural network field than have been available in in the a n deep neural network field in the past years even though of course the first artificial neural networks were spiking it's only been recently that uh this approach this machine learning for spike in neural network approach with supervised training has really been been practical and started to get some focus uh in the in this subfield and so as a consequence there there's uh quite a few points (33:42) about training spike in neural networks that we we know are important or that we suspect might be important but for which we don't yet have uh analytical results for example the question of initialization for spike in neural networks so we know that for deep neural networks the optimal initialization depends on the sizes of each layer uh the transfer functions of the network obviously spiking neural networks have additional parameters time constants thresholds um empirically we know the optimization strategy makes a difference uh but we (34:14) don't really have much in the way of first principles results yet about what is the best initialization strategy but i know that julius is speaking next about exactly this topic i'm very very much looking forward to her clearing up all those issues for us um in terms of optimizers so here we used adam we've also used stochastic gradient descent all of these optimizers are available uh for use but they're all that will come out of the field of training artificial neural networks training deep neural networks and (34:45) they're designed for those purposes obviously the dynamics of a spiking network are more complex the training problem may also have more comp itself more complex and more non-linear dynamics uh as a as a consequence of the other types of parameters uh that we're trying to train with the spiking networks so it's possible that the optimizers we're using are not optimal if you like for training spiking networks and uh it's possible uh certainly that that snn tuned optimizers might reach higher (35:16) performance there for parameter constraints i mentioned briefly previously as well most deep neural networks don't require parameter constraints during optimization to get things working but obviously spiking neural networks do especially for time constants and it's it's not yet completely clear what is the best way to include those constraints during optimization uh as part of a good training strategy that's tuned to spike in your networks so i'm looking forward to uh to to this field um coming up with good answers to (35:48) these questions in the next years uh okay so obviously i i have only had time to touch on a very tiny fraction of the work that we're doing in our team but i want to close out by highlighting a couple of the recent publications and preprints that we have as other other available work so for example we've looked at methods for making networks energy aware during training so that you can optimize specifically for low energy consumption and this is worked on by martino tien massimo and sadiq we've uh in collaboration with giacomo (36:23) and diveries group at the neuromorphic engineering group at university of zurich we've we've looked at work for training spiking neural networks that are robust to device mismatch which is a particular problem for mixed signal processors memristor crossbar arrays as well as spiking neural network uh neuromorphic architectures uh and these issues make single-shot training and then deployment to a large number of chips very difficult so we've come up with a number of methods to try and uh address that problem uh so this (36:53) is work done by by julian dimitry sergio jacomo and myself we've recently looked at performance of spiking convolutional neural networks under adversarial input attacks so for vision processing uh moving the this adversarial input attack um methods from uh standard convolutional neural networks to spiking convolutional neural networks so this is work it's done by julian greger yellen martino and static and then so i've only i haven't touched at all on the vision processing side of things today um so if (37:29) you're interested in vision processing in what we are doing for vision processing we we have two presentations as part of tiny ml asia this friday so implementing optic flow using our neuromorphic hardware so using our little integrated vision sensor as well as talking about the architecture of that vision sensor and neuromorphic vision processing itself so both of these are are on this friday as part of tiny ml asia so i i also spoke about rockpool mostly today but we believe very strongly in trying to contribute our work back to the (38:04) community as much as possible uh so in addition to rockpool we have we have two uh other main um open source platforms uh tonic is one that we've adopted just recently uh we are we're contributing strongly to this now this is uh for those of you who haven't heard of it it's a tool for managing spiking data sets uh and for data transformations and data wrangling specifically for neuromorphic spiking event encoded tasks this is what we're using now as a data front end for all of our applications (38:37) as well as synapse which is another python open source library for training and deployment for our vision processing tasks all right thank you very much once again i appreciate the chance to talk to you all today and i very much look forward to answering any questions you might have yeah dylan thank you very much great talk super lots of questions also so uh we have uh fortunately a couple of minutes left to ask questions uh the last question is whether you were doing the the training on the bpt and and and whether there are plans actually to do (39:16) that off of in terms of online training none of our hardware that we've produced includes on on device training and the reason for that is we struggle to come up with a commercial application that requires on device training um you you have to pay a lot in terms of chip area a lot more in terms of chip complexity obviously that you know especially for bptt the memory constraints to do that are much higher than for inference much much higher and most of the time we expect our hardware to be used for low power (39:50) inference and so we're not willing to to sacrifice that amount of silicon which also burns energy just just sitting there for the most part um so we're focused on uh on-chip inference having said that our chips are reconfigurable so they're not single purpose a6 you can configure a spiking neural network onto the chip that's also true for the vision processing tasks and so it's certainly possible to have that chip in the loop have a little bit of logic in a microprocessor on the outside and to (40:22) fine-tune a network uh fine-tune the output layer this is this is definitely possible wow that's that's an interesting solution yeah other questions um we don't have that much time so so freedman asks for about a residual block so it it's adding spikes he's wondering whether it is um if you add spikes to the input spike train by the residual block does it lead to undesired side effects i'm not sure what those undesired side effects would be so we're essentially merging the the output event (40:58) um event channels so you get more spikes in the same channel so you have in n input channels n output channels you do some processing in between but you also pass the n input channels around and copy them into the n output channels so that the input and output dimensionality are the same but you've merged the unprocessed and processed events together in those output channels okay clear to me i hope also clear to the others as a topic on its own of course the residual links in spiking networks yeah one more question was was a bit more (41:40) general is from tom burns was you talked about how snns are attractive in electronics engineering due to being low powered from that perspective is this mainly courtesy of sparsity um if so why are snns more attractive than sparse dnns or other low-powered engineering strategies i'd be very interesting yeah there's something i was tempted to jump in and talk about last night but i felt like i was talking too much last night anyway so i didn't say it but from the dnn side of course there's a lot of work on on special purpose uh dnn (42:12) accelerators um tpus being being one sort of example that even more specific architectures and when i hear the engineers who are building those talking about it they're talking about weight sparsity they're talking about activation sparsity they're talking about low bit depth uh inference they're talking binarized neural networks and at some point uh they're gonna converge with us um i i'm very confident about that it's happening uh so we have because our community has a bit of a head start on that because we're (42:45) used to thinking in this mode whereas they're used to thinking in the linear algebra with real value numbers mode but i do see a convergence there that's a cool point uh i know some of the binary people here in amsterdam and i'm wondering when they will converge indeed um and maybe one final question uh kareem habashi is asking maybe i missed it but why output a full image instead of an address that called an image from a memory so this is regarding the task why are you going for this this time roll out rather than (43:23) say well this is bird because it's cool look i wanted to come up with a toy task that was also impressive right it's obviously if it's classification only that's a lot easier uh if if you just need to say it's bird a bird b bird c um outputting a complex learning and outputting generating a complex temporal output signal is a much harder task and so i wanted to to try to impress you all by showing you a more difficult uh needlessly more complex task that it looks super impressive so maybe it's art that you (43:58) show to people spike based uh images cool thank you very much dylan good great and very much thanks everyone what were your future developments here so i think we have to move in a few in 30 seconds to the next talk so i think i also moved to that there and um see you all in that session","Dylan Muir is a senior director at SynSense, a startup based in Zurich that creates low power spiking neural network neuromorphic processors for real-time sensory processing. He has a background in electronic engineering, computer science, and neuroscience, and has experience in academia and industry in the field of artificial neural networks. In this video, he discusses using machine learning with spike neural networks for low power inference on neuromorphic hardware, specifically focusing on auditory processing using the company's general-purpose spiking neural network processors.",ChatGPT,,,,,,,,
https://www.youtube.com/watch?v=vC5EHUt7dQs&list=PL09WqqDbQWHEqm1_3a620tKUKnC6FgBrG&index=11,2021,SNUFA Workshop,Julia Gygax,FMI Basel,Optimal initialization strategies for Deep Spiking Neural Networks,Neuromorphic-compatible algorithms,(148) 11 Julia Gygax - Optimal initialization strategies for Deep Spiking Neural Networks - YouTube https://www.youtube.com/watch?v=vC5EHUt7dQs Transcript: (00:05) ah and we're back um so the next talk already and and dylan actually alluded to it already this is a serious problem that julia's tackling so julia is presenting joint work with julian uh mondry and friedman um on optimal initialization initialization strategies for deep snns and and i'm also very interested this is very difficult for julia please go ahead yeah thanks um yeah i'm very excited to talk here today at nouveau um as already mentioned i i want to thank already here to julian manvi and freedman who were working (00:45) together with me on this project the question we want to address is today how we should initialize spike neural networks as it is now possible due to surrogate gradients to do end-to-end optimization um this has become a bigger question um this it is already known for general audience that a good initialization is crucial also for a good performance here in example for from 2015 where with this came here in it in a m it was suddenly possible to train a network that with another initialization wasn't trainable at all (01:28) um and for our case in snns we take some inspiration from biology um here you can see a spike raster plot where time is on the x-axis and here on the y-axis we have the neuron entities so each dot is a spike um we this is here in this case asynchronous irregular firing which happens due to being in this fluctuation-driven regime where we have some excitatory input current which is closely followed by an inhibitory input current so that they nearly cancel each order in time so if you look at the member potential there (02:10) are some random fluctuation with just occasionally emitting a spike and we he put his eyes now that this fluctuation driven regime might be a good initial initial state for future learning um and therefore so let's look at our neural model we're using a leaky integrate and fire model and where we have this poisson distributed input spikes and then should lead to such a fluctuation driven membrane potential um the the equation that describes here with filters the behavior of this membrane potential you can see here on the right (02:50) we are focusing now only in the sub threshold regime so looking how um it looks like when the spike is generated from the input so we have here the the spike trends so this input that are um filtered with this epsilon kernel that just describes the shape of such a spike and then weighted with the synaptic weight so the question is now how should we choose those weights to really end up done in this fluctuation driven regime um and first of all we look how how we can describe this fluctuation driven regime so if we just sum up (03:30) all the values of the membrane potential into a histogram we can see that this leads to this nice gaussian distribution with here the mean around zero and we have the threshold at times the standard deviation so with this psi we can kind of vary the the width of this distribution so that we and can specify how much of this tail of the gaussian gets cut off as above the threshold so those are the values that will induce spiking um here again i put the part of the formula we're using now for the sub threshold regime (04:09) and then we can now um determine the values like the mean and the standard deviation of this distribution and if we now make some assumptions for like for that the map gets simpler we use um n inputs with the same firing rate and we also have identi independently identically distributed weights and just for this talk today we will stay at the mean membrane potential of zero um so that the expressions get a little bit easier so if you now use these assumptions we can simplify the expression for the variance and now you already see that we (04:50) have now um as a variance and mean of the weights in there so we can solve this just for the the variance of the weight um the for the mean now since we assumed a mean membrane potential of zero also the mean of the weights have to be zero therefore we choose mean of the weight zero and the variance dependent on the number of inputs the firing rate of the input neurons and then we have the variance of this epsilon kernel again um threshold and our x i that determines the distance between the mean of the distribution and where (05:27) the threshold is so we can say now we have found this distribution that when we wave sample the weights from here we can finally end up with such a distribution and the membrane potential so the be in the fluctuation driven regime so now let's see how this applies to the experimental results we had two classification tasks um first one is the random manifolds data set also called randman which is a synthetic classification data set with some temporal structure and the idea is simply that we like have this space of all spike times here in (06:11) the example in three dimensions um and there we put some random manifolds from them we can then sample like spike times so each neuron then during the simulation time just spikes once uh just cut them look like this here on the other hand we have some real data so this viking heidelberg dataset we took which is um spoken digits from zero to nine in both german and english and they are already provided as spikes so here you can see how such a sample will look like and then we also have different kind of architectures (06:53) starting here with a one hidden layer networks this is a feed forward network of leaky integrate and fire neurons then to be a little bit more biologically plausible we add dale's law and with now two separated like an excitatory and an inhibitory population and we also added recurrent connections in the hidden layer that they are of course time constraints and due to inhibiting neurons all the inhibit and finally we had a three hidden layer network which is now a spiking cnn so let's start with the um (07:33) simple one um so here you can see a raster plot of or like here you can see in the color the inputs colored corresponding to the label they have then there is in the hidden layer some nice activity and then in the readout you can see the membrane potential of the readout neurons where i just colored the one that corresponds to this label in the same color and the others are gray here um we are using a maximum over time loss so the the one that is the the winner should be reached once a maximum in this simulation time (08:13) and then after we trained this with surrogate gradient um it really is now um the the highest membrane potential um we made some parameter sweep over different standard deviations and means of the weight where you can see here those black lines correspond to this initialization we derived before and as you can see the the maximum value of test accuracies in our runs is really following this um line although the as you can see the um absolute values of the weights should not be too big so this example you can see here on the left side is taken from (08:58) where the star is at a mean of the weight of zero and the corresponding standard deviation after the formula and now let's look also at one that is top here at the bad um bad accuracy so you can see that already at initialization the hidden layer neurons just like spike at every possible time and also training that does not really help so this also might explain the the bad performance of this network here then it um we also um we're moving now to this alien network and now you can see in the hidden layer (09:36) we have a population of inhibitor neurons around 20 and then 80 of excitatory neurons and it turns out that this method also um extends to such daily and recurrent networks what is also interesting in this case is now we can look at the the behavior of the excitatory and inhibitory inputs so if we now see the excitatory input here in blue is quite closely after some delay followed by the inhibitory input and if they they follow each other like at each time step quite closely we can say it's tightly balanced and if we analyze (10:19) this balance over our different ones we can see that the best performing ones um they all are rather balanced although in all the like not best performing ones there are still some quite balanced networks and therefore we can conclude in this case that balance is indeed necessary for a good performance but it's not sufficient it turns out that also for example the um activity could be interesting in case to predict good performance um yeah then let's go to the spiking cnn so you can see here how this looks likes (11:00) before training this this is now on the shd data set um where you see the three different convolutional layer um also trend with surrogate gradient it looks like this after training and as we already know general from a ns that deeper networks usually perform better than shallow ones also this is here the case so a three layer network performs when looking at the test accuracy performs quite a bit better than than the single layer one although when we look now at the parameter sweep over x i um we see that with one single hidden layer (11:40) we have quite a broad regime where the parameter or the the initialization leads to good performance while for the network with uh three hidden layer there is quite some quite a narrow regime that that we need to hit for a good performance so deep networks require quite more precise initialization um this is when we look now at the network like at um this parameter here we can see that the the reason is that the activity does not even propagate to the third hidden layer and so nothing um reaches the readout so (12:20) um there is no gradient at all at the end that we can apply our loss to so we cannot learn anything with this network and if we now look at the firing rate over the different hidden layers here and for this case you can see that um already with quite a lot of this um of those parameter sweeps we can see that the at the third hidden layer we don't have any activity at all um and there is now of course the question how we can um help or to rescue this so there is um this firing rate homeostasis where we could define a regime with (13:00) acceptable firing rate where training works well but if you go below here for example neuron doesn't spike at all we can apply this neural lower bound homeostasis so each neuron is required to at least spike once otherwise this loss term is applied and also we have something like this in the other direction where when the whole population just fires too much we have this loss that is applied and that tries to drive the firing and rate again in this acceptable regime then when we look this in our experimental (13:38) setting so going back to the three layer networks you saw before with this quite narrow parameter regime that leads to good training we can see that with firing atomic stars we suddenly have a quite broad regime where the performance is good so when you look now at the firing rate um rates over the layers without homeostasis you see that it doesn't learn anything so before and after training just looks the same um while when we add some homeostasis we can rescue this firing rate so also the the hidden layers show some activity now (14:16) okay now um to sum up everything we can say that in shallow network uh our method works quite well to provide a good initialization and best is when we also looked at the absolute value of the weights remain small so maybe the mean at zero for deeper network it requires a more precise initialization but the firing rate homeostasis might help there and then we also saw that balance seems to be a good initial state for future learning now there is also some working progress for example in the case of delia networks we were using truncated (14:54) gaussians which were truncated at zero before but one could also look more into distributions that are already calculated at zero like the exponential or log normal distribution and still are able to provide such a fluctuation driven membrane potential and we're also exploring more in different homeostatic initialization um mechanisms like um for example against synchrony or maybe us kind of driving a sub optimal initialization at a good point to start draining there and also we're looking more in the effects of balance in daily networks (15:36) um yeah now i i want to acknowledge again julian manvi and freedman especially but also the other people from the lab and you find our web presence here in the in this box and the the code will be released on our github and also we're working on a preprint great thank you very much julia very inspiring so inspiring that i have to ask for a friend on behalf of dan goodman could you make the math also work for time constants so basically the temporal dynamics how they influence the membrane distribution the the time constants are also included (16:24) maybe i just switched to uh a backup slide i prepared here so um we have this epsilon kernel and if we now um do all the math and everything it will turn out that the epsilon bar is exactly the the synaptic time constant and where the epsilon hat is um this part like it depends on both the synaptic and the membrane constant and you could make this argument also about the distribution if you were to work with distributions of time constants we didn't yet work with distribution we just had a fixed time constant for (17:03) for each population but then you would maybe need to average over these quantities here yes very very cool nice thank you um a couple more questions jamie knight is asking how do you include the dale's law constraints in the network maybe you can add a bit on that um we were like for the initialization we were using just a gaussian with mean at zero where we just took the absolute value so to have only um positive weights and then to initialize the network we just took the negative soft plus function of this and (17:47) in every um run like in every update step we first again apply the soft plus transform that so that there then only all positive weights and um yeah they cannot get negative clear clear um jamie also has more questions so he is wondering so am i actually does better initialization also speed up our training it tends to be slow our current training um yeah we were first like trying to focus more on on performance so trying to um fix like some some number of epochs where we then just look like the accuracy at the end of this um but we we (18:31) didn't really explore more on this topic or maybe julian if you want to add something yeah i can jump in quickly um uh yes i actually looked at this it seems like the optimal initialization also speeds up training substantially um so in order to really compare the especially in the deep networks it it does speed up uh training if you're at this like narrow parameter regime where it actually works really well okay nice good to know uh see if we can use it i think we can ask one more question membing park was really early with a (19:12) question regarding the fluctuation regime he notes that it would be great for instantaneous responses and he asks could you comment on the effect on temporal memory properties of your initialization scheme do you suffer from vanishing gradient type problems um yeah actually we or it's it's um rather more obvious in the deep network so i would say this is a good example for where we had some vanishing gradient problem um this is where when we really are in our good um initialization regime also the spikes will propagate through (19:52) until the end of the readout so we don't then don't have any vanishing gradients but to be really sure that the or the the performance works well there's also this this kind of loss that can be applied to um work against vanishing gradients because in this case every neuron is forced to spike at least once so um if the at the beginning would be any kind of vanishing gradients in in the objective function we also still have this homeostasis that was would rescue this yes i think on the sorry on the point of of temporal memory (20:31) properties is a super interesting thought actually i think that because this fluctuation driven regime initialization doesn't mean that the membrane potentials of individual neurons are some close to threshold already at the start of the simulation right so i'm i'm not sure how this would be great for instantaneous responses for longer samples i guess you would have that but in terms of temporal memory properties i would rather argue that that this would be in the time constants of the neurons and that then that would link back maybe to (21:14) generalizing this to heterogeneous time constants in the network i think we should keep it to this julia thank you once again for a great talk and i'm looking forward very much to the archive papers too so we can also use it and i propose we now switch to the to the next talk which should be in one minute ago so see you in a bit,"The speaker, Julia Gygax, is discussing a research project on optimal initialization strategies for deep Spiking Neural Networks (SNNs). She explains that a good initialization is crucial for good performance when training SNNs, and takes inspiration from biology to suggest that the ""fluctuation-driven regime"" - where excitatory and inhibitory input currents nearly cancel each other out - might be a good initial state for future learning. The speaker goes on to describe a specific neural model using a leaky integrate-and-fire model, and how the choice of initial weights can lead to a ""fluctuation-driven regime"" with a gaussian distribution of membrane potentials. The speaker then simplifies this model by making assumptions about the firing rate and distribution of weights, and shows how this leads to an expression for the variance of the weights.",ChatGPT,,,,,,,,
https://www.youtube.com/watch?v=oM7XEsDVcNg&list=PL09WqqDbQWHEqm1_3a620tKUKnC6FgBrG&index=12,2021,SNUFA Workshop,Christian Pehle,Heidelberg University,Event-based Backpropagation for Exact Gradients in Spiking Neural Networks,Learning,(148) 12 Christian Pehle - Event-based Backpropagation for Exact Gradients in Spiking Neural Networks - YouTube https://www.youtube.com/watch?v=oM7XEsDVcNg Transcript: (00:13) yes welcome back so this is the final talk in uh in this uh morning evening or afternoon session depending on where you are before we have a break with posters um the next speaker is christian paler presenting joint work with timo wunderlich and he's going to explain to us how we can do exact gradients or event based back propagation for exact gradients i'm very much looking forward to this so christian all yours thanks and thank you to the organizers for allowing me to speak so i will be talking about event-based back (00:48) propagation for in spiking neural networks but before i do that let me briefly remind you about back propagation which is i assume everyone is familiar with so back propagation is this algorithm which really fuels the current deep learning revolution so the all these advances in image classification vision processing natural language processing and so on and in essence it's an algorithm that is a message-based algorithm so there's two phases a forward phase during which messages get passed between processing (01:24) elements which are typically thought of as like these layers and so for example you get a green input to one processing element and you produce a red output and you remember the input that you've gotten and then a second processing element might produce a blue output and you remember again the input that you had and then during the second phase the backward phase you again in a message passing way compute errors and gradient updates ultimately for the parameters so again you pass in an error value in the in one of the processing elements then (02:06) you compute um an update to the parameter and so on so this algorithm is nice because it scales really well so you only need a memory proportional to the number of processing elements and really most of the computation can be done locally provided that you get messages which allow you to compute the updates and so on so in continuous time or like in the context of computational neuroscience there's really this question of how to best do um temporal credit assignment and this is a really hard problem because as you've (02:44) seen in the like even if you think something like back propagation might help your guide to to a solution to that there's really these two phases and but more specifically in the case of spiking neural networks there's the additional challenge that you have these discontinuous state transitions so really there's two issues compared to back propagation you have continuous time and there's discontinuous state transitions and for i think most people even thought or think that it's not really possible to solve these (03:20) two problems satisfactory in an analogous way to the back propagation algorithm what i will explain in this talk is essentially that there is such a solution namely applying the adjoint method with partial derivative jumps really gives you an exact answer and more specifically in the case of spiking neural networks it results in an event-based algorithm for grading computation with essentially arbitrary neural models so this is the work that i did with um timo wunderlich in the case of laf neurons we call it event prop there (03:57) and it is really precisely an analogous thing to the back propagation algorithm so again you can consider processing elements these processing elements are now you can think of them as for example spiking neural networks and they receive now events in time and process those to then um produce output spikes and similar to the backward propagation algorithms you need to remember these events and the events that you've produced to then in the second phase you get event-based errors error information and compute (04:34) based on this error information an event-based gradient update and potentially errors for any kind of connected other processing elements so i will explain how this works in more detail now first of all the general theory of how to work out parameter gradients in continuous dynamical systems this was something that was interesting to people even before back propagation was invented namely in the context of analog computers and of optimal control so before digital computers became really powerful um people invented all these special (05:16) devices to to solve particular problems that they had and to do so you one had to have a theory of optimal control of how to essentially in these analog machines how to adjust the dials how to tune them to do the tasks that you want and uh one of the pioneers in this was left pantry again he actually was blind from the age of 14 but he nevertheless managed to contribute greatly to to optimal control and many other things and the what he came up with was this point reagan maximum principle and the special case of that (05:52) is what are called the adjoint equation so the idea is relatively simple you have a constraint optimization problem and you can arrive given a specific dynamics for your dynamical system you can arrive at a second set of dynamical equations which allow you to compute parameter gradients for an essentially arbitrary loss and of course as you all know for example um all neural models are essentially composed of dynamical equations so dynamical system in the case of the lif neuron model which we already have seen today um it's these two simple equations (06:35) for the synaptic input and for the membrane voltage but in addition and that is kind of the main the main thing that is makes it a bit more difficult is that whenever the membrane voltage reaches a threshold value uh jumps happen so in this case we are considering a model where the membrane voltage just gets reset to zero and you get synaptic inputs according to some synaptic weights and this seems problematic because it's not quite clear how to then compute gradients but in fact this was addressed pretty quickly after this theory of (07:22) optimal control was developed by a russian mathematician uh named rosenwasser in 1967 and then later essentially rediscovered by other people by a galan in 99 for example the key idea is why it's possible to actually compute still compute parameter gradients is the following um here i sketch um the membrane time the membrane as a function of both the weight and time for an input spike that arrives at time t equals zero so as you can see as you increase the um as you increase the weight eventually the neuron reaches (08:09) reaches the threshold and the spike would happen so the implicit function that you have is you have a you have this black curve along which a spike would happen and the the task is really to compute a a gradient or a parameter derivative of the time at which the spike happens as of as in terms of other quantities namely the membrane voltage and this is possible because of the implicit function theorem and you can do it exactly furthermore these transition equations allow you to really um relate the membrane the the partial derivative of (08:52) the membrane before and after the jump in a very straightforward manner now i come to the main result that we show in this paper namely we show that for a completely general loss depending both on spike times of and potentially all membrane voltages we can exactly give an expression for the parameter derivative of this loss in terms of the adjoined variables of the of the postsynaptic neuron at the spike times of the presynaptic neuron and moreover these adjoined variables can be computed very simply by an equation by two (09:42) differential equations that look very similar to the original lift neural equations with the additional provision that you have to solve them backwards in time then the kind of thing that that really makes the method interesting from my perspective is that to compute the gradients across at spike times or or rather these atom variables experience jumps at spike times namely the adjoined variable of the neuron that spiked the lambda v receives a jump all the other ones stay the same this expression looks kind of complicated but it's actually kind of (10:24) easy to understand there's one contribution which comes from the if the loss depends on the spike time of that particular spike and then there's another contribution which basically um performs the back propagation in the traditional sense so all the connected neurons um contribute to the jump of this neuron that spiked at that time we can illustrate this in a in a simple example where we only consider two neurons namely one neuron that receives poisson input from a number of poisson sources and is connected by a synaptic (11:01) weight to a second neuron and then we compute a loss which in this case is just the sum of the spike times that the second neuron produces so here you see in figure b you see during the forward pass the first neuron spikes a couple of times and then the second neuron in response to that spikes at these two times and now the question is how to actually compute the gradient and as the the two formulas i showed you in the previous slides give you the answer to that namely you have to solve these adjoint equations backwards in time so this is (11:35) what is happening here and what this what this what these transition equations here tell you is that due to this blue term the first change in the in the atom variable of the second neuron will happen at t plus two and this is exactly what happens here so this starts to jump up and then it decays according to the equations that i've shown you and then then at the second or at the first spike time because you're looking at it in reverse it jumps up again and for the first neuron what you can see is that as soon as (12:14) at all the spike times of the uh at all the spike times of the first neuron it receives itself jumps to the adjoint variable which are due to this red term here and then the kind of amazing thing is that even though the grading computation itself according to this methods happens in like jumps it converges exactly to the value that you can compute by finite differences and here in the upper case you're looking really at the weights of one of these poisson inputs how it's connected and you see there's (12:56) like a lot of tiny jumps that eventually still compute the exact gradient now this was a just an illustration but we also looked at two tasks which illustrate this further one is we use a time to first spike loss and the yin yang data set which is a essentially four dimensional data set where each point in this yin yang figure is encoded as a spike latency and there's an additional bias spike and then we have a simple feed forward network and we use this particular loss which encourages the first spike to occur for the class that you that you (13:41) want to classify that you want to i mean you have three neurons in this case there's three classes red blue and green and you want to um classify the the the points and this loss allows you to do that and you reach comparable accuracy or actually it's slightly better i think than in the original publication by girl said where they introduced this task the the second task we look at is a voltage where we have a voltage dependent loss this max of our time loss which we we've also seen in the previous (14:15) talk and we classify ms with that and with a simple feed forward network again we reach um like competitive performance the kind of performance that you would expect now let me briefly come to some conclusions what i've talked about is basically back propagation and spiking neural networks we've seen that a correct treatment of the spike disc continuities really allows us to compute exact gradients moreover this event-based grading computation allows us to leverage sparseness in time during training and i (14:51) think this is really one of the main advantages of this method and we have achieved competitive results on amnest and um yin yang let me while the time is running out let me come to an outlook i think the the main open things to demonstrate is really to demonstrate this on larger scale and event-based data sets and that is certainly something we are looking into and but on a more like practical level event also has really compelling properties that suggest an implementation on analog hardware and on analog and digital neuromorphic (15:33) hardware and finally the methodology i mean we've i've shown you this for the specific case of laf neurons but this is really general and can apply it in principle to any kind of neural model and there's by now even tools that do that for you automatically so you don't need to give up your all your autograd goodness with that i thank you for your attention and i'm happy to hear your questions yes thank you very much christian wonderful idea i i liked the paper a lot when i read it and i think i've read it (16:06) a couple times now i think i also start to understand the point here it goes way back to physics i think with with the lagrange multipliers and control um there are a bunch of questions i think we have we have a bit of time to to go through them um tim asks a question about non-spiking neurons he says for gradient descent in snns the gradient is often zero um here you use continuous time so providing a neuron fires an infinite decimal change of input weight will cause an infinite decimal change of latency hence the gradient of the loss (16:42) with respect to his weight is probably non-zero but if a neuron does not fire then an infinite decimal change of input weight won't cause a spike and thus will have no effect on the loss the gradient is zero and the input rates will never change is this an issue so i think uh i think there's like even in the a n case there's an issue there right so if you have railroad units and the the railroad is dead and there's never any kind of sample in your data set which produces a non-zero output you have the (17:13) same problem so so i think empirically even like for larger data sets this has not been really an issue because if your data set is like sufficiently large there's a high chance that that your neuron will produce spikes for some of the samples of your distribution so you should really think of since you're not doing like um your sampling right and you're doing stochastic gradient descent you're really integrating your gradients over your sample distribution in some sense and that allows you in most cases to sidestep that of course (17:46) there's like further like stuff that you have to consider you can regularize you can encourage neurons to spike by introducing losses that do that but um yeah so i think i think there was ways around that yeah i agree there i think that's also been our experience usually the smaller the network the more it becomes an issue or at least the less data you have so for big network it's it's indeed less of a thing tim tim thinks um he also mentioned that he thinks this might be where a circuit gradient uh could (18:18) help if you have something that pushes neurons up once in a while i guess that's true but i think the question of how to do regularization well is really still open and i like i brushed over some one thing which is this there's this um there is still like critical values at which you have a problem because v dot diverges and so so there's there's something where you could consider there might be a problem but i think in practice this really doesn't end so much nice there's also a question from jamie (18:58) knight that that i i was also wondering about um he says there there have been some other methods also for uh for doing back propagation of spike times like like what julian golds or julia maria comsa did does the joint method mean that you can use or how does it compare and and does it a joint method mean that you can use neural models without an analytical inverse not quite sure if that's the correct thing yeah yeah that that's a very good question and that's that's kind of uh like i have like one yeah so basically (19:32) like if you think about it right like computing the time at which a neuron spikes this is really a root solving problem if you want to do it numerically so if you have an if you have a numeric if you have a numerical solution you don't need to have an analytical time at which the neuron will spike and both comsa and girls they rely on an analytical expression for when the neuron will spike now the implicit function theorem the implicit function theorem basically allows you to sidestep that completely because the implicit function theorem (20:02) doesn't care about an analytic expression it just cares about being able to somehow determine the spike time and so what you can do is basically and this is what we are doing behind the scenes you can just use a root solver and compute the spike time exactly without having any kind of analytical formula for it so so there's like um i can briefly show you that there's like um immer himmel right so that's a framework that google produces and they're right now they're using this analytical formula but they (20:33) might as well use really the root solver and the implicit function theorem and then so that's the connection ah fascinating cool i think i have two questions that i can put together and then i will stick to that um guinea blohm is asking does this method work with more complicated uh i. (20:57) e uh recurrent spiking neural networks and freedom and is adding to that asking what are what are things that are preventing scaling for this method and i think they're related so i put them together uh yeah so so scale like implementing it for a current neural network is mainly a question of um like computer code so you need to write it in a way that it works for recurrent neural networks the the method itself works for recurrent neural networks and scaling this is something where i i invested some time in in north this library that i'm building with jens um (21:32) to implement a discretized version of this and there we've seen pretty good so i i compared it on fifa for example with like a few million neurons and like a residual network um two surrogate gradients and it appears for like there's like a lot of caveats there because i mean as you all know if you have like uh something like fifa you can there's like we do it for very few time steps so it's not really spiking anymore but in any case so in this case you get like comparable performance so there's really (22:06) no difference um so so i think the scaling up is the recurrent and the scaling up are a bit different because like feed forward architecture you can scale much much better right like it's like especially if you don't have many time steps um yeah okay that's something to look forward to then that's that's great answer thank you very much um i think we'll leave it at this uh even for the sake of time and also so people can still get a cup of tea before going to the poster session uh for the posters dan just posted the (22:38) link in the chat there is a google doc with the zoom links to the posters that people prepared so please have a look and i'll see you guys then in the zoom rooms or at 4 30 again when cat katie schuman is giving the next invited talk christian again thank you very much for your talk very nice and see you in a bit,"The speaker, Christian Pehle, is discussing a method for computing gradients in spiking neural networks called ""event-based backpropagation."" He explains that this method is similar to the traditional backpropagation algorithm used in deep learning, but it takes into account the challenges of working with continuous time and discontinuous state transitions in spiking neural networks. He presents the adjoint method with partial derivative jumps as a solution to these challenges and explains that this results in an event-based algorithm for gradient computation that can be applied to arbitrary neural models. He goes on to provide more detail on how this method works.",ChatGPT,,,,,,,,
https://www.youtube.com/watch?v=iTPi9Y0agcY&list=PL09WqqDbQWHEqm1_3a620tKUKnC6FgBrG&index=13,2021,SNUFA Workshop,Catherine Schuman,University of Tennessee,Evolutionary Optimization for SNNs & Neuromorphic Computing,Neuromorphic-compatible algorithms,(148) 13 Catherine Schuman - Evolutionary Optimization for SNNs & Neuromorphic Computing - YouTube https://www.youtube.com/watch?v=iTPi9Y0agcY Transcript: (00:04) of uh of the of the um of the sniffer workshop and we've got uh a nice a couple of talks we've got katie uh schumann and then a couple of talks on software stuff so let's start off with katie katie's um currently a research scientist at oak ridge national lab but uh moving i think in january to university of tennessee so um congratulations to the the new job and i believe uh from her twitter is recruiting grad students at the moment so do get in touch with her if you are interested in that um and yeah i think i'll just let katie (00:42) speak for her stuff now so yeah go ahead thank you thank you so much for the invitation um so i'm gonna be talking about evolutionary optimization for spiking neural networks and neuromorphic computing today um so just a little bit more background um i actually did my phd at the university of tennessee on evolutionary optimization of specking neural networks so i've been working on this for over a decade now um since i've been at oak ridge i've really focused on neuromorphic systems in particular (01:14) programming neuromorphic systems again using evolutionary optimization primarily um and just have been more broadly looking at neuromorphic computing from hardware software co-design to applications algorithms and software for the last six years at oak ridge i have a us department of energy early career award that's specifically focused on new training and learning approaches for spiking neural networks and as dan said i am beginning as an assistant professor in the department of electrical engineering and computer (01:42) science at ut in 2022 um none of the work that i've done has been in isolation you can see all of the students and faculty who have worked with us over the last six years on this work i will be citing various uh of them over the course of the presentation if you're interested in joining us please reach out to me if any of this resonates with you so i'm going to be talking entirely in this presentation about evolutionary optimization for neuromorphic systems or eons which is a tool that i started developing as a (02:11) graduate student and have been refining over the last decade um so the way that eons works is that it's going to be designing all aspects of the spiking neural network everything from the number of neurons and synapses to how they're connected to all of the parameters associated with them and when i started developing this as i've started to even look at spiking neural networks as a neural network type um i was sort of thinking okay it's not clear to me that the right structure for a spiking neural network should be the (02:45) sort of traditional layered structure that we might see in deep learning what other structures might be good for it to use and i didn't have a good intuition to develop about okay well what's the right structure to use even looking to neuroscience for inspiration for different applications and and for particular neuromorphic hardware implementations so that was sort of the impetus for developing eons with saying okay i want to come up with an algorithm that will just design it for me assuming that i know nothing about what the (03:13) spiking neural network should look like so the way that this works is we start with a collection of randomly initialized specky neural networks for a particular problem that we want to solve and usually a particular neuromorphic hardware implementation or at least a neuron model synapse model a simulation that we would be using for spiking neural network and here i'm showing four networks to start our population typically our populations have a hundred to a thousand individuals you can see that the networks have different numbers of (03:43) neurons different synaptic connectivity the different colors are meant to illustrate different parameters and then what we're going to do with these is evaluate and rank them so typically in the context of a neuromorphic application we're going to take each of these networks loaded onto the neuromorphic hardware or a simulation of the hardware or a spiking neural network simulator whatever and then run it on the application to see how it performs so the hardest part of using eons is defining what that fitness function (04:12) should look like and i'll talk a lot more about that over the course of the the presentation but basically that fitness give function gives us a score for how well the network is performing on that particular task and we take those scores and we rank the networks from best to worst now at the beginning when you start with these random initializations they're all terrible but some are less terrible than others so we can establish this ranking if you happen to know something about what the network should look like you (04:40) can embed that into your initial population but usually we don't we don't make any assumptions about what it should look like and so we start from scratch each time so once we have this ranking we use a selection algorithm to preferentially select better performing networks to serve as parents while still maintaining some diversity we use tournament selection most typically but you can implement a custom selection algorithm we also support other selection algorithms from the genetic algorithm literature (05:06) and how you want to select your parents from the population we then perform reproduction operations this is if you'll forgive me where the magic happens this is where we get our children from the parents the reproduction operations include just cloning a parent into a child random mutations that add neurons synapse synapses change the parameters within the network so it can make structural changes it can also delete neurons and synapses and we also have crossover which takes two parents and produces two children (05:39) which inherit characteristics from both of their parents and we have an operation called merge which takes two parents and creates a child that is the union of both of those parents in terms of structure it has all of the structure of both of its parents and then it inherits the parameters from each of the parents randomly once we have the child population we repeat this process that that completes a single generation we now go back on the child population we evaluate and rank those do selection do reproduction (06:07) and so on and we iterate until we reach a desired performance level now if you know anything about evolutionary algorithms you're already thinking this is slow it's going to take forever to be able to do anything with this there's a reason that the acronym is eons it's not as bad as you might think though um for a lot of the applications in fact all of the applications you're going to see on the the rest of the presentation we train in under 24 hours you can do training on your laptop you can also leverage whatever compute (06:38) resources you happen to have but there's a lot of reasons that we use evolution and in particular eons particularly for spiking neural networks and for neuromorphic hardware more explicitly and so i'm going to highlight those reasons now with some vignettes about some of our research so the first and perhaps most important for our research is that it's applicable to a wide variety of tasks it does not require that you change the underlying algorithm in order to adapt from something like classification (07:09) to control to anomaly detection to whatever task you might want your network to perform maybe even replicating some sort of biological behavior so i'm going to give you some examples of some of the tasks that we we use uh and to evaluate eons this first one is a temporal scientific data classification task um in this case we were looking at data from a neutrino ex scattering experiment called minerva at fermi national accelerator lab this is another department of energy lab in the u.s you can see a picture of the (07:40) detector on the slide cartoon obviously there's a little cartoon person for scale it's about the size of the school bus and what happens in this detector is it's exposed to a neutrino beam and all of the pixels along the detector are looking for certain types of events that are occurring within the detector and the events that we were looking at here were when energy levels were going above a certain threshold um so already it's probably resonating with you that i said events this translates very naturally into spikes (08:09) that might be amenable for a spiking neural network application the particular task that we were looking at was a classification task to look at this data and classify the horizontal region along the detector where the interaction originated so at oak ridge we actually took two different approaches to this task we took a convolutional neural network approach and a spiking neural network approach with the convolutional neural network approach we were using also a genetic algorithm called mendel to do neural architecture search and (08:38) hyperparameter optimization to customize the structure for this task so we were optimizing the network in the convolutional neural network as well as optimizing the spiking neural network structure the differences in accuracies here are negligible they basically get the same performance but what you can see that's interesting about this one you can see that the spiking neural network on the slide here um it looks kind of crazy like a hairball most of the networks that eons evolves looks kind of crazy like a (09:06) hairball you can also see the convolutional neural network structure up across the top you'll notice that it has a couple of fully connected layers at the end here and one of those this second fully connected layer has 98 neurons in it so just that layer has more neurons than our entire spiking neural network um you'll also notice that we are only using 86 synapses it's not even fully connecting all of the neurons we don't get rid of any of the inputs and outputs when we're pruning our network so it's (09:34) not actually using all of the input features to make a decision because we're using the structural evolution that can actually tell us something about the problem space of what's useful and what's not for trying to solve our problem so why is smaller interesting in this case well energy usage is one factor for neuromorphic obviously we estimated that we could we could do this uh classification in about 1. (09:57) 66 micro joules per classification on a memorisative neuromorphic implementation but when you're talking about a school bus sized scientific detector maybe you don't care about energy usage but it's small so it can also be fast so that is very important for these sort of high energy physics experiments so we certainly certainly applied eons to classification tasks like this one but one of the most frequent classes of problems that we apply spiking neural networks and evolutionary optimization to our control problems (10:27) as you saw on the this live with all of our students we work with a tremendous number of students and in fact a lot of undergraduates the first thing that we make all of our undergraduates do is build an application to test with eons and spiking neural networks these are some of the applications that our undergraduates have built let's see if i can get the video to play a lot of them are video games perhaps unsurprisingly um in these cases the fitness function that we're using for most of these if it's a video game (10:54) of some form it's usually the score we also have a couple of robotic navigation tasks where the score has to do with how quickly it can navigate towards the target or cover as much ground in the environment as possible so we we definitely use evolutionary optimization to evolve all sorts of networks and it's worth noting for every single one of these networks that is playing each of these games or controlling the robots or whatever all of these networks are under 100 neurons under 200 synapses so again we're (11:23) talking about very very small networks that are that are solving these applications so these are quite literally toy examples but i have a couple of real world examples that i wanted to show you as well so we've worked with researchers at oak ridge's national transportation research center on applying spiking neural networks on neuromorphic systems for engine control for fuel efficiency and so the idea here is you have an internal combustion engine and at each engine cycle fuel is being injected into that engine (11:58) to keep it running and so what happens is as you decrease the amount of fuel that you're injecting in the engine you're more likely to cause partial burns and misfires which can cause noise vibration and harshness in the operation of the engine which is undesirable and so you can't just keep decreasing the fuel because you're going to get those undesirable behaviors so what we wanted to do in collaboration with these transportation researchers is come up with a spiking neural network that could take sensor data from the (12:25) engine about what's going on inside the engine in particular the amount of fuel the amount of air and the amount of inert gas within the engine at each cycle and make a decision in real time about how much fuel to inject so that we can reduce the amount of fuel used while simultaneously meeting the acceptable performance metrics which in this case was reducing the number of uh partial burns and misfires ideally to zero so we developed a spiking neural networks using eons on the summit supercomputer we only used (12:56) 24 nodes of the 27 000. we used those for two hours to evolve all of these networks and we evolved a set of them that we could then evaluate we trained them with a simulation of the engine and then we deployed them to an fpga-based neuromorphic implementation called microcaspian which we could then run in the loop with the engine at the national transportation research center so in this case the fitness function is adapted so that we're doing the sort of multi-objective optimization where we're simultaneously minimizing the fuel and (13:24) minimizing the number of partial birds and misfires if you're interested in the precise formulation of that function um you can check out the paper on this um this was a pandemic project so i i asked them to take a video of what this looked like this is the the neuromorphic implementation that the spiking neural network is deployed on it is interfacing with a host computer you can tell that this is science because we're duct taping it together um this is the real-time information that we're receiving from the engine (13:53) and it's changing the fuel amount at each cycle so the specking neural network is running on that neuromorphic implementation with the engine in the loop controlling the engine in real time and the it was actually able to translate what it learned in simulation into the physical engine and the network outperformed the fixed control strategies on the physical engine as it did in simulation so we're really excited about this we're actually continuing this work to do real-time evolution with the engine in (14:18) the loop so continuous learning with the engine so that is one example um and another example is yet another one of our pandemic projects i really like to evaluate spiking neural networks on real world problems i like to have platforms that we can test them on um and one of the platforms that we are now testing with is this f-110 platform this is a one-tenth scale formula one vehicle there's a full community surrounding this i encourage you to check it out if you would like to to play with these vehicles they have all of the (14:50) specs for what you need to build them why is this interesting for neuromorphic computing this is a relatively inexpensive real-world demonstration of what neuromorphic computing can provide and it is one step along the path of using neuromurfix systems for autonomous vehicles control and it's one that i can play with at my house which is also attractive for a pandemic so what do we do we did the same thing here that we did with the engine we trained in simulation and actually we trained on just a workstation and not on the (15:18) supercomputer um what we're receiving to the spiking neural network is lidar sensors as input and the output is steering angle and speed for the car and we're taking our best evolved spiking neural network we're deploying it to again uh the the same um fpga based neuromurphy platform micro caspian and we're also simulating it on the cpu on the jetson in lieu of not having the micro caspian um and so what does the the training simulation look like well it looks like this um the car is this little black dot hopefully you can (15:49) see it going around the track we actually trained on 110 scale formula one tracks i know nothing about formula one so this is catalunya we trained on five um five training tracks and we tested in simulation on a variety of other formula one tracks that it had not seen over the course of training but of course it's really nice that we have the physical car uh but we actually want to deploy it and test it in the real world which means that you need a racetrack so we built a racetrack in my basement uh where i'm sitting right now um so (16:19) this is uh the first fitness function that we used in applying eons to this task was just just drive and don't run into things complete as many laps as you possibly can so you'll notice it's not quite acting like a race car yet going pretty slow because it didn't have speed as an objective um so i actually have a couple of high school students uh they're seniors at oak ridge high school here in east tennessee who are working on me with this project so they have been adapting the fitness function for eons to try to make it go (16:53) fast and this was actually a couple weekends ago a new faster network that is now driving the car successfully around these haphazard tracks that we've we've built based on you know cardboard boxes that we've bought um so you'll notice uh still has some undesired behaviors this this sort of weaving salmon-like behavior we're working on the fitness function to adapt that so that it will also remove that behavior as part of the training process and uh it's worth noting that all of these networks trained again in under 24 (17:29) hours on a workstation um so those are a couple of the applications all of those the eons algorithm the way that the reproduction works the selection works all all of that does not change all we're changing is the fitness evaluation and it is tailoring it to the particular application of interest okay so why else do we use evolutionary optimization so as i noted it can learn the topology and the parameters and not just the synaptic weights so this was really attractive for me because again i i sort of had the the intuition whether that's (18:03) correct or not that that these sort of layered structures may not be the best way to do spiking neural networks um and we wanted to be able to evolve the structure to see if it could discover what different structures might be able to solve problems and so what do the networks look like these are some simple classification tasks like iris and and wine and breast cancer the toy data sets that you might see i just wanted to give you an example of those extremely small networks with few hidden neurons eons will evolve to try to use (18:35) the input and output neurons as for computation as well we see a lot of recurrent connections a lot of you know this hairball structure that's going on um as we saw in the fermilab data um it will also evolve you know to say some inputs aren't required some outputs may not be required to solve the problem that you you've selected um and so we didn't i didn't prune this network here but you can see that some of the infant neurons aren't connected at all and some are just connected to themselves where (19:03) it's not actually affecting the functionality of the network so you could prune those out to get even smaller and it tells you something about how to solve your problem so what is the other attractive feature of using very small networks well we can start to drill down into what they're actually doing and how they're making decisions so i am far too impatient to do this but my collaborator at university of tennessee jim plank hates machine learning because he can't explain what's going on so he (19:32) really just wants to understand what's going on when eons involves a network so he will drill down and actually look at what's going on in the network to try to explain what's happening so this is a task front-facing sensor avoid we have this agent it's got the mars coloration here in the middle that's trying to navigate towards this purple column as the target and then it's trying to avoid these meatballs along the way and it has lidar sensors on the front uh 25 as it's its front panel that's at sensor (20:02) information its inputs also include angle to the target two altitude sensors for low and high and a bias which is like a heartbeat that's just giving it um continuous input its outputs are go left right down up forward backward and then they're just three hidden neurons here and so here is a video um let me play the video of it in action navigating throughout the environment you can see the the activity in the network that sort of aggregated across simulation runs to see how it's actually performing (20:38) so jim traced through exactly what was going on and started to identify some things about these networks and so for example one of the things that he saw is that the bias the heartbeat neuron is directly connected to go forward so the default behavior and absence of everything else is just keep going just keep swimming just keep moving forward as perhaps expected we didn't embed this into the network but it makes sense that it would evolve it if the target is to the left it connects to rotate left similarly if the target is uh to the (21:08) right it connects to rotate right but if you have conflicting goals like the goal is to the left but there's also trouble to the left there are obstacles to the left then it the behavior here is to go left and go up but also move back so that you're turning in the correct direction that you're you're actually moving backwards so when you have networks that are this small you can start to trace into what they're doing this is where i'm going to attempt to live demo because i wanted to show you (21:38) um another one of these networks and how we actually do this so this is actually the network that was driving the car in the faster example and so this is one of the the simulators and here it is it's we've slowed down the simulator significantly so that you can see what's going on we're actually currently in the process of tracing through what this network is doing and our visualizer lets us look at the activity see how it's actually driving the car in real time and do things like drag different neurons around (22:10) organize them in different ways the visualization also lets you label the different neurons so that you can try to understand what's going on with these because even though you know there's some complexity in this this layout with lots of synapses connecting lots of different directions it's still small enough that maybe we can wrap our brains around what's going on in it okay so stop those go back into presentation mode hopefully you can see that again um okay so so evolving this the structure the topology is also a big (22:41) feature of this approach obviously in the context of neuromorphic computing having the ability to be applicable to different architectures and devices is really important so eons will attempt to tune directly to the underlying hardware um so just to give you some some quick highlights on how we've applied this to neuromurkic systems we've worked with eons a lot for co-design to help us understand how to design the underlying hardware when we're working with emerging devices and materials and so one of those is a collaboration (23:14) with garrett rose's group at the university of tennessee looking at a memberistive mixed analog digital system neuromorphic systems where the synapses are implemented with hacking oxide members so in this case we used eons for co-design in simulation to understand the effects of this particular architectural layout and the hackney oxide memoristor on the plasticity mechanisms that we should realize for our applications on the neuron and synapse models that we should use and on the connectivity requirements that would (23:41) then influence the actual chip tape out that we're in the process of doing now sorry another architecture that we've worked with is by far the weirdest neuromorphic device i have worked with to date this is a group at oak ridge's center for data phase materials science that decided that they wanted to build a neuromorphic synapse out of allomethysen doped biomembranes these are literally two water droplets encased in lipids that are squished together to form a membrane then you apply a voltage to one side and (24:19) it opens an allomethyn channel ion movement it acts like a chemical synapse they're weird and definitely weirder than every other device that i've worked with in neuromurphic systems so again we came up with a simulator for this device based on the experimental data and we used eons to evolve networks that would solve real problems with these devices trying to figure out how to leverage the inherent plasticity mechanisms of the biomembranes and how to design the corresponding neuron model to operate with those biomembrane synapses and we (24:48) actually designed a it was a six neuron six synapse network of these um that would do eeg classification um so we're continuing to work on on that as well and we've also worked with researchers at nist led by sonia buckley in looking at their single flux quantum based neuromorphic system in this case they really wanted to use eons to come up with small networks that they could actually fabricate with their devices because they couldn't fabricate even a network that would solve in this because it was just (25:18) too many devices for them to do with the scale of fabrication they could accomplish so we they still wanted to solve interesting tasks um so we used our eons approach to design networks that were small enough that they could actually fabricate them we also used eons in this case to help them understand what the features of the neurons and the synapses they actually needed to solve these real world applications and tailored the design of the neuron model in these cases as well so the same application on all three of (25:47) these architectures will not result in the same spiking neural network it will tailor the spiking neural network eons will tailor the specking neural network to the underlying hardware to try to leverage whatever the characteristics of the hardware are to try to solve that problem now at the same time as it's going to try to leverage the characteristics it can also operate within the constraints of the architecture of the device and so we do evolve under hardware constraints depending on what the actual constraints of the hardware (26:17) are so if you happen to have limited weight precision limited delay values structural constraints and the physical network connectivity you can realize uh eons will optimize within those constraints and in in this chart i'm showing different constraints on delays and weight values and the accuracy ranges here just under 90 percent up to about 92 and a half and you can see it was able to able to tailor the network depending on whatever those constraints were to still perform pretty well so pretty much everything that i've showed (26:50) you already we're using eons to evolve the structure of the network as well as the parameters but we can actually combine eons with other training and learning approaches to be able to learn other aspects of the network or have eons only learn for example structure or only learn parameters so we have combined it with liquid state machine or reservoir computing like approaches um where we were asking the question how do you decide what the reservoir should look like we actually had a graduate student who worked on (27:22) this and in this case we were looking at eons designing the reservoir but the readout layer is still trained as normal and we found that perhaps unsurprisingly even when you're trying to encode in your your random reservoir generation the rules that we know about how reservoirs ought to work having eons evolve the network can give you better results by doing this i also had a graduate student who worked on combining eons with scdp and what we found in doing this is combining scdp and evolutionary optimization and in this case we were (27:58) using just an unsupervised stdp learning rule and it resulted in better generalization and smaller networks than the individual algorithms by themselves we actually also wrap our eons and scdp as well as eons by itself and stdp by itself with a bayesian hyperparameter optimization approach which tunes the hyper parameters of everything it tunes the hyper parameters of eons it tunes the input encoding approaches that are used it can tune hardware parameters as well as fcdp parameters and so we're trying to make a sort of (28:30) one workflow that will allow you to play with different algorithm combinations and tune it for you automatically rather than you having to do it manually we've also used eons to evolve ensembles of spiking neural networks and we've shown that our ensemble approaches outperforms the evolution of a single network for classification tasks the the best performing ensemble uh evolution approach was a diversity aware ensemble evolution in this case each of the networks that was evolved in the ensemble knew what the other networks were (29:05) learning and that influenced the evolution of the ensemble collectively so we were trying to improve the performance the diversity of the networks to give us the most accurate performance and if you're interested in learning more about that there's a paper on that as well so i hinted at this earlier in talking about the applications and defining what the fitness function looks like we're often doing some sort of multi-objective optimization in the case of the engine example we were looking at you know minimizing the number of (29:34) partial burns and misfires while simultaneously minimizing the fuel which are trade-offs on each other in the car we want to go fast but also not crash into things so we have these sort of multiple objectives just in the performance on the application but often we also have other characteristics that we want to do multi multi-objective optimization width such as minimizing the energy usage of the network on a numeric hardware implementation minimizing the network size or improving the resilience so you can update the fitness function (30:05) to encourage different properties of the network in the the slide here i'm showing the testing accuracy the number of neurons in the number of synapses with no multi-objective shown in blue and multi-objective optimization to minimize network size shown in orange and you can see that by adding this additional objective we're not impacting the accuracy at all or very little and we're significantly decreasing the size of the networks we've also done multi-objective optimization for resiliency um and in (30:34) particular as you probably know in dealing with neuromorphic systems that have emerging device types those devices often have faults or failures or noise associated with them so we want to be able to continue to operate normally even in the presence of those issues so we can update our fitness function to include not just the score on the original task but also the score in the presence of different types of failures in this case small perturbation to the weight values on the network and when we're doing this we can then (31:04) evolve for resiliency as one of our objectives in this case we're also evolving to decrease the network size so trying to minimize the network size trying to improve the resiliency and optimizing for performance on the task all simultaneously and with that particular optimization approach we were able to show that we could significantly improve the resiliency of the network in the presence of those weight variations and this was on a pole balancing task uh similarly if our failures were even more extreme in this work the the failures were (31:41) complete synapse failures the synapse just stops working altogether um we adapted the fitness function a very similar way where we had a weighting factor for how important the original accuracy is versus the accuracy on networks with imposed failures and we found that as we decrease the importance of the accuracy on the original network we could see improved resiliency and these are the resiliency curves so the testing accuracy in the presence of you know 10 20 30 40 etc of the synapses deleted on a couple of different (32:13) applications so we still achieve comparable performance in terms of accuracy on the original network um but also improve the resiliency of the the system okay so it's slow right they can be slow to can you just briefly interrupt to say we're a little bit over time so if you could try i'm sorry yes i will wrap up very quickly um if you happen to have a supercomputer which we do at oak ridge national lab but if you happen to have a cluster or cloud or access or whatever we can scale up on high performance computing systems we (32:45) use an island model where we run populations individually and they share information via migrants so individuals migrate from one population to another by doing this we can significantly improve uh computation get to better results faster with more resources so again if you happen to have a super computer you can use it if you happen to have neuromorphic hardware you can also use it to get to better performance faster you can either use it as an accelerator or to get lower power performance and in this case we did (33:14) neuromorphic acceleration using a xilinx as zinc system which is an fpga based implementation and we're able to show that we could get comparable timing performance actually a little bit faster than what you would see on a laptop with significantly less power so there's a lot of reasons that we use evolutionary optimization there's a lot of ongoing work that we're doing we're evaluating the performance of different neuron and synapse models as you add biological complexity and plausibility (33:42) into the models what effect does that have on real-world application performance evolving structures of simple neural components to form more complex neural behaviors trying to match again biological behavior we're evolving synaptic plasticity mechanisms we're combining with a variety of different neuromorphic algorithms and we're exploring indirect encoding approaches for scaling the spiking neural network size so even though evolution can be slow to converge it has a lot of attractive qualities for spiking neural networks (34:08) and neuromorphic systems there's a lot of opportunity to combine it with other spiking neural network algorithms and i i think it's exciting that we can use it to probe into the computational capabilities of spiky neural networks and neuromercury computers more broadly and with that i will thank my collaborators at oakridge and at the 10 lab neuromurphy computing research group and i'm happy to take your questions that was brilliant katie thank you so much that was that was really inspiring talk really impressive array of uh array (34:35) of work thank you so much um we've got tons of questions the first one um the top voted one was actually my question which you pretty much answered but um i i'll do a slight variation on it so my question was could you alternate evolution steps with gradient based steps and you definitely answered that you definitely can do that sort of thing 100 yep can it can it speed it up yeah so so by doing that you can definitely speed up the parameter optimization because when you're when you're optimizing all of the parameters (35:05) especially as your network scales up that that gets to be rather large that's why we're exploring these indirect encodings but using the evolution to tailor the structure along the way you can restrict it to be a structure that a gradient based approach can handle eon supports that and then you have that to be able to tailor the parameters along the way so yes it can definitely speed it up cool um so the the next question um it's it's a slightly different sort of style of question um basically the the question as i (35:38) understand it is asking can you use this evolutionary approach to sort of learn what the plasticity mechanism should be basically they're saying we know the ingredients you've got your pre and post traces you've got all of these sorts of things can we use evolution to work out what the plasticity rule should be we're we're doing this right now and actually i would like to reach out to enrique as well after this is um i'm actively working on this and so we're we've done it already in the (36:04) context of um sort of a limited uh you assuming a sort of stdp like structure and we're just optimizing the the parameters for a particular application but we're actually using genetic programming now along with eons to optimize the entire formulation of the the plasticity mechanism taking the spike trains the pre and the post as input to be able to to optimize what the plasticity rule should even look like and we're going to actually interleave the evolution of the structure alongside the plasticity to try to evolve structures (36:38) that learn wealth with that particular plasticity rule okay is that is there a relation there with i know that um tim vogels was looking at uh trying to find what the optimal plastic stereo should be using uh backdrop is there any relation with that i we haven't we haven't done anything with backprop with the optimal plasticity rule but i imagine that there is going to be synergies with that okay yeah um cool okay so the next uh one is is there an argument either mathematical or philosophical saying why it should be (37:12) possible to reach the optimum architecture using this using your sort of genetic approach i guess that would be a more genetic algorithm literature question there is there's a lot of literature in the the genetic algorithm space but i think for me what's interesting about the evolution approach is that we can evolve for the same task each evolution run might result in a completely different structure and so i don't know even for spike in neural networks there isn't one best solution i think that you (37:47) may have for these the sort of pareto optimal depending on what your performance characteristics are like do you care most about accuracy do you care most about energy you care most about runtime defining what the optimal is sort of is already a question but convergence rates and things like that that's that's left to the genetic algorithm literature yes it should be able to eventually evolve just given enough time okay yeah um so i think freedman is asking what's your input encoding in your systems and (38:20) do you also evolve that yes um we evolve that so we uh we support we have a software framework that we use and we support population coding rate encoding temporal coding stochastic rate encoding a variety of input encoding procedures we can optimize it as part of the eons process but we can also do that hyperparameter optimization where we're optimizing the input coding as part of that cool uh i'm just going to quickly inject my own question which i didn't get to ask here so you said that that the the robot (38:53) car thing was inexpensive roughly how much does that cost actually to set up that pla that particular platform is about a thousand dollars but there are cheaper ones um there's a one that's about 250 so we're going to be buying a couple of those too but um yeah cheap lidar input they have lots of simulators lots of software everything you need to get up and running on that i would love for that to be a benchmark for the neuromorphic community um to target for for neuromorphic hardware yeah no i'm just thinking about it (39:20) because i'm going to start a spiking neural network course at my my university and i'm wondering if it's something i can get for the students students love this everybody loves it actually it piques the interest of all the every researcher that comes well the videos were cool um whether or not we find enough space in in london to set something up like that is another question hey i did it in my basement no you do it anywhere um cool all right so the next question um did you consider different types of (39:48) random initializations for the connectivity and and did it change the convergence rates that's something we're working on right now and so we just uh injected a bunch of so so the uh all the results that you saw were just on um uh uniform random initialization there was nothing special about the connectivity we have now implemented different random network initializations uh small world um a variety of others that are now escaping me but um but yes we will then we're evaluating that now that is an (40:20) ongoing study cool um and then the next one is i i think maybe you've already answered it but they're asking have you tried transfer learning i.e using something you've optimized for one task as part of the initial pull and i think that's kind of what you were doing with your sim to reel right so right that that uh but we do we're we really want to establish a library of useful networks that you can draw from to initialize your population in the sort of transfer learning way um that is also something that's ongoing because (40:50) it's not clear it's not clear to me how well things would would translate from for example the engine to the car is there something useful that's going on in the engine application that may be a sub network that would also be useful in the car scenario maybe there is maybe there's not that's something we do want to explore cool so actually that relates to a question someone else uh asked about so carl johnson asked which is do you have a way of preserving and passing down sub modules within a network to children i (41:17) guess that's that's we're working on that that's that's active work it's something we've i've wanted to do from my dissertation days and we are now working with like graph theorists and things like that to help us identify what those sub modules should be okay cool um yeah so the next question is is another one of mine um which was uh did you think about running your evolutionary algorithm not directly on the network but on a sort of network growth rule that's what i mean by the (41:46) indirect encoding and i think somebody said okay yeah so the indirect encoding is basically um you're not representing every individual component neuron synapse weights etcetera connectivity uh it's more like a growth rule um that you're you would the the way that the network grows rather than the every aspect individual aspect of the structure we're working on that right now with some genetic algorithm experts okay so are you thinking about that more in a sort of graph theory way or you're (42:14) thinking about it in terms of like how biological growth rules work you know with like great we're thinking about it more in a graph theory way but that's because we don't have the expertise so if if anybody has that expertise on the biological um growth rules network growth rules i would love to incorporate that into the the way that this could evolve those those sorts of yeah growing and uh yeah growing rules neuron growth neuron deletion over the course of evolution i would love to do that yeah (42:46) there are a couple of recent papers about that that that might be interesting there's this idea of the genomic bottleneck that might be worth looking at um cool uh let's see what's what's next um so carlos asks another question have you considered the evolving evolvability phenomenon learning networked architectures that are most modular and adaptable to new tasks yes i so this is having something a learning a learning rule embedded to learn a structure that is most useful for that particular learning (43:22) methodology or algorithm or whatever that could be applicable across multiple tasks that's something that we're doing when we're evolving the plasticity and structure simultaneously is we want to make sure that it's not just targeting it towards one particular application but something that would be useful across multiple applications [Music] and the last question actually is is a bit related do you have you observed any patterns across different tasks regarding what are the best connectivities oh it's really hard to (43:49) analyze that's why we've got the graph theorists it's not even clear it's the the graph isomorphism problem of like how do you identify that it's the same from network to network um so we're actually um we just proposed a we just did a proposal this morning uh pitch on looking at graph embeddings to to analyze the network structures to see if that will help us analyze the structures more effectively cool okay well excellent brilliant talk i think we've got to move on to the next speaker um but yeah that was brilliant (44:21) very very inspiring indeed i'm sure you'll get lots of uh phd applicants after that please reach out to me i left my email up the whole time for that reason thank you cool all right thank you so much thank you and i think we might need to both close our window to stop the thing because uh yeah let's see if you,"The speaker has developed a tool called EONS, which designs all aspects of a spiking neural network, from the number of neurons and synapses to how they are connected, using evolutionary optimization. The purpose of the tool is to come up with a structure for a spiking neural network without any prior knowledge of what it should look like. She uses a fitness function to score the performance of the networks on a particular task and iterates until a desired performance level is reached.",ChatGPT,,,,,,,,
https://www.youtube.com/watch?v=2FthDOP1uq8&list=PL09WqqDbQWHEqm1_3a620tKUKnC6FgBrG&index=14,2021,SNUFA Workshop,James Knight,University of Sussex,Efficient GPU training of SNNs using approximate RTRL,Neuromorphic-compatible algorithms,(148) 14 James Knight - Efficient GPU training of SNNs using approximate RTRL - YouTube https://www.youtube.com/watch?v=2FthDOP1uq8 Transcript: (00:04) hello everyone um thank you for coming to my session and thank you to the organizers for inviting me um so at the end of uh the end of snoofer last year you guys published a paper and one of the things that stood out to me was that there was a real need for um for new hardware and software to performs well for spiking neural networks to sort of push this field forward especially to larger larger problems both in terms of neural numbers and um and data sets so that's that's kind of what these preliminary results relate to (00:39) i so a lot of a lot of people in this field are currently using some existing machine learning tools for simulating snns and these tools underneath the underneath the hood represent the spiking neural network as a computational graph so in the most naive representation you have your input coming at the bottom you multiply it by a weight matrix and then you perform some sequence of fundamental operations to emulate a lift neuron so for example you add add the add the input to the current state decay it and apply a threshold operation and (01:13) then you get a binary activation vector which you multiply by the next by the next level of weights etc so when you implement this on a gpu each of these operations in the naive approach is is an individual kernel uh and this is bad because each kernel has some kind of fixed latency so it's sort of order of microseconds on linux but still it sort of adds up and also between these fundamental operations you're writing data back to global memory which is definitely unnecessary um so by using just-in-time compilation (01:47) which both tensorflow and pytorch do or by using custom kernels which i believe norse which jens is going to talk about after me does you can get you can merge these kernels together into single kernels which obviously reduces the latency but the latency of this the latency of this these models still scales with the depth of the network which is bad especially when you're thinking about um about deep networks and it also is repeated every time step so every time step you're getting this latency cost um (02:16) and more fundamentally these computational graphs are executed sort of in dependency order which in the case of a feed forward model means sequentially so the model has to be as wide as the gpu so you have to have enough hidden neurons to um you have to have enough neurons in each layer to occupy your gpu which generally means large batches which whereas is generally found in machine learning more generally it's not it's not necessarily great it doesn't scale forever like that um and finally sprite but spike (02:44) propagation is not matrix multiplication um it's more just like summing the rows of where there's spikes so theoretically that's a much cheaper operation if that's true on current hard or not it's a different question but theoretically it's cheaper so as anyone that's seen any of my talks over the last five years it's not to be surprised to see the work i'm presenting here is going to be involving our gen simulator so jen is a cbos plus library for generating snn simulation code it's now got back ends (03:14) that can generate cuda opencl and cbos plus code and it can everything you can do in gen can now be done from python it's the the level of abstraction is still somewhat lower than uh than sort of then tools such as like norse but it's it's all you can do a lot of stuff from python um and part of the reason for this lower abstraction is that previously the focus has been on computational neuroscience and neurobotics and and if you're interested those papers look at the bottom of the slide where our previous results in this this (03:44) area and the link to jan itself here but throughout uh development of gender this maxim has been to maximize the use of control so as a user you can fiddle with a lot more stuff in gen than you can in typical snn simulators and we think this means that it's well suited to sort of have a new life as a as a back end for high performance bike-based machine learning and hopefully convince you in this talk so um snns and jenna represents in a very different way um spike transmission is not instantaneous so you can break (04:15) the dependency between the layers of neurons which means that you can simulate all the neurons simultaneously and all the all the synapses simultaneously and this also means the model doesn't need to be a direct cyclical graph and within these layers you can do various fusing stuff so you can simulate them using a sort of minimal amount of code and we talk more about this we talk about how we the details of this fusing in our in our most recent paper and by doing this you also reduce this latency so the latency is not quite (04:44) comparable because this is sort of pipelined like you have to wait you have to wait a number of times before you get any output but after that like cpu a pipeline cpu you're gonna get you're you're gonna get um a much lower latency output so um what model we can so in this in this in this work we're using this very simple model uh so we're using we're training small recurrent networks so these are these are basically you've had some input neurons project to a densely connected recurrent population (05:13) and these connect to uh these then all the recurrent neurons connect to an output population um and we a lot of people who previous talks have used backprop through time to train very similar networks to this so we're taking a slightly different approach we're using a sort of approximation of real-time recurrent learning specifically this symmetric this eprop rule which uh this awesome paper by bellick cheritel from last year um last year uh presented and this is um this is only one there's lots of lots of learning ones that do (05:47) the same approximation and this uh like for me this paper by uh friedman and emre from this year like really really sort of uh clarified the link between all these learning ones and backwards through time so i thoroughly recommend that anyway in these models um we have a simple lift neuron model with uh adaptations there's a second state variable with a longer time constant and a relative reset so every time you get a spike you subtract something from the membrane rather than setting it back to zero um there's a non-spiking output neuron (06:18) which basically is low-pass filters the um the output of the network and each synapse in the model has has not one but two eligibility traces epsilon and e and um the the weight update is a simple difference as you feedback the difference between your targets which are these pi k t star and uh the soft max of y k so the soft max of output you project this back to your current population in our case we're just using a transpose of w out which is b and you just sum these over time so this is kind of a sum loss function (06:55) and it's applied to all the recurrent weights and we don't actually you could do this online we don't choose to do that we want we want to use optimizers and stuff so we we sum up these weights these delta weights until the end of the batch and then we uh we apply them to the weights all at once but that's but nonetheless this could be an online learning rule so we've added some extensions to gem this new version 4. (07:18) 6 was released yesterday-ish um so you can now do batching which is important for um fully occupying your gpu when you've got small models like these so this means yeah you can instantiate multiple copies of the model and you can share you can choose to share variables between the weight between the instances so you can have weights that shared across all batches in the typical machine learning um sort of configuration and the second main feature is these custom updates so as well as as well as neurons and synapses you know (07:47) have these custom update stages which you can use to implement arbitrary operations so in our case we use this to implement stuff like adam adam optimizes on on the to turn the sum of delta weights into actual weight changes and also this system supports sufficient matrix transpose there's plenty of computational science papers on how to do efficient matrix on a gpu so we've just taken one of these kernels and implemented it so we've kind of we don't need to care about the weight transport problem right now we can just use a (08:19) efficient transpose at the end of each batch and also we we've implemented reduction operations with some more syntax in these custom updates so you can do you can you can reduce across many batches the the weight up the gradients to get a weight from a single weight update it also supports mccl to go across multiple gpus um so like a lot of people we've been looking at the spiking heidelberg digits this is about 10 000 recordings of 12 speakers speaking of digits 0 to 9 in english and german and these are (08:52) converted to 700 spike trains using a realistic model of the ear so we're comparing here against i mean against um some of the results from friedman and tim vogel's paper from last year where they trained small lift neural networks using backup through time um and in short using a feed forwards using a feedforward network they achieved somewhere around 75 percent accuracy on this task and around eighty percent if they use a recurrent network using one of these ls and ends train with eprop and gen i feed forwards models are slightly (09:29) worse but i think the there's and as are our recurrent experience but only very slightly like this is probably within the um within the within the error bars and we can overcome this by just throwing a few more neurons at the problem um because we're not using back property time there's not really any problem to use more neurons and by doing this we can we can exceed the exceed the performance um of the backup through time train network and so how fast is the training so this is the other thing um so (10:01) here we're training we're training the same this is a training times this model we're comparing uh pi torch the pie touch code that comes from spy torch um and and gen using this lsn and we're training both on relatively large batch size so batch size of 512 so we can fill our big gpu um and you can see at the small scale gen is a bit slower but by by around 700 time steps uh jen jen starts to gen starts to win out uh and by 1 370 time steps janna's significantly faster than pie torch so basically the (10:39) just because we're not using backpack through time we we can train we can train we can train longer for faster and if we go into a bigger model i pi torch is clearly faster and this is because pytorch is taking advantage of the um the tensor cores on our gpu and we aren't yet able to do that but um backward through time runs out of memory this is on a 12 gigabyte gpu so it's a massive gpu but you can't train one second of activity on a 512 neuron network whereas in gen you can um and similarly on one of the four neurons (11:12) jen is still slower because we're so we're not um taking advantage of the tensor cores but we can train we can train many more time steps and we i mean jen wouldn't run out of memory for a huge number of time steps but there's not really much point in the bigger network here so that was one data set the other data that we're looking at is a spiking sequential mnist so basically in this data set you take the endless digits and you scan across the you scan across the the pixels in time like this (11:41) and each you have somewhere in this rk 79 neurons and each one represents a threshold crossing so when you hit some threshold crossing you get some neuron activity uh so this was this this data set was used by this this pretty cool paper that came out earlier this year by wolfgang masters group and they used they compared a whole selection of hardware which we're going to get to in a minute but basically they were also training lsn so adaptive neural networks with tensorflow and they got kind of um so they trained at lstms and they (12:14) trained these lsns and both of them got kind of 95 95-ish percent like maybe 96 on the ltm um and then they train some feed forward they train some purely lift networks which perform much worse it's around sixty percent here uh gen doesn't perform quite so well or so right the epoch doesn't perform quite so well so we were getting sort of closer to 90 and this only increased slightly from the number of neurons so this this is clearly a task where um the real like taking you need to consider the gradients flowing through (12:45) the recurrent connections but nonetheless 90 of this task is still pretty good um so in this task we also looked at inference performance which i think is which i think is the most interesting result here uh so on the right hand panel we're comparing the same gpu running tensorflow and an lcm which we saw is performing sort of 95 and our recurrent lsn symphony's using gen and you can see in the top that the latency is lower with gen using all the batch across all batch sizes um the gap reduces as you get larger bat (13:19) sizes because we don't batch quite as efficiently as tensorflow yet um but still this is a really good result i think it's the first time that there's been shown there's sort of any performance advantage of using snns on the same on sort of standard hardware over um over and models so they also in this this paper they also um use this energy delay product so basically multiply the energy taken for your simulation by the by the latency and here again um running running uh using gen and gen and snn you you have a lower you (13:56) have a lower uh you have a lower energy delay product um so these are all batch batch sort of with large batch size data sets but we also looked at batch size one where you can start to compare some other stuff so including low ihi which they used in their paper and um and tensorflow running on a cpu so these ones are stars are numbers we've taken from from uh from the paper and the other ones are ones we've run ourselves so in short tensorflow with batch size one is both slower and uses more energy and tensorflow also because (14:29) i because it's very con simulating lstms is very compute heavy performs very poorly on the cpu um whereas gen even at small batch size is significantly faster and in fact significantly faster than loihi uh also the cp just gen can also generate simple cpu codes and this was even faster than gpu here because with that size one you can't really occupy your model properly and snns are not particularly mass intensive so cpu code can be remarkably good and if it goes to the energy delay products you see a similar story like gen uses less (15:02) the energy label is much lower on gen on cpu or gpu the only thing that beats it is low he which is hardly surprising um so that was that is that's me done um yeah i'd like to thank all the people at sussex who've helped with this work uh my friend is at the epsrc who have agreed to continue to fund us for the next five years which is very exciting um and various other people including um gregor lentz who the author of tonic without which this work could be much more painful okay thank you very much (15:38) great thank you very much jamie um cool all right so uh we have some questions and and also to the audience if you want to ask some more questions we'll probably have time for more questions than we've already got um so actually the first uh question is going to come from tim masquelier so he says how does the memory required for your approximated rtrl scale with the number of neurons um so there's it scales the number of neurons in the same way as any other forwards sort of forward pass in the neural network so you have the (16:13) additional memory per synapse of the eligibility traces but there's no so there's no extra memory with each time step so it's memory doesn't scale with with time that's the key thing okay yeah uh and the next one is for me um which is uh this is like going back to some old-fashioned things so i i was wondering how efficient is this efficient matrix transpose and could you use that to speed up the sort of more classical http uh thing that we all used to do before we were doing this sort of thing (16:45) i mean so it's basically as fast as copying the data around the gpu so um yeah so it's basically as fast as reading the data from global memory and writing it back to a different bit of global memory um but you still wouldn't want to do every time step which is why we're currently we're still using a sort of batch we're using this kind of hybrid batching approach where we only do this copy after after your batch is completed can you can it also work with a sort of uh with a sparse representation or does (17:13) it then stop being so uh this this particular algorithm doesn't um but you could also as you say use the kind of uh uh make online matrix transparent stuff that um many people have done with sddp okay yeah yeah because i guess at some point we're all going to start thinking about how to do all of this stuff more sparsely and indeed yeah this this is still fairly dense in the learning phase yeah yeah um oh there's another question from me sorry um so i i'm wondering if so you're using um this approximately rtrl and not using (17:52) backprop through time does that lead to biases in the sorts of solutions that you find i don't know um in short um i think yeah i don't think anyone has really explored that uh no one's really explored that problem that's that kind of space i mean the as i understand it the the sort of theoretical difference is that we're not the eprop doesn't take take it take into account the gradients that flow through the recurrent connections themselves um but clearly the recurrent connections do improve the performance (18:24) um yeah this is not totally clear i i we need to find a data set where it's more um where it's more apparent perhaps because the as as that 2021 paper shows if you sort of um what's the words um if you uh artificially sort of constrain back property time to ignore those gradients you still get roughly the same performance so it's yeah it's not totally clear yeah yeah well exactly i'm not sure that you could even answer that question like we have we have tried it in some tasks where if you kind of think about (19:01) the solution yourself and try and like just assemble neurons to do it it doesn't come up with that solution even though when that solution seems fairly obvious but um yeah that doesn't really mean anything in the space of uh gradient-based algorithms i don't think no indeed uh all right so last question then is from thomas uh how about scaling for multiple gpus and multiple hosts with multiple gpus well i've actually got a slide to answer that thomas yes so we we did we did some scaling experiments across multiple gpus um (19:35) using both a system with eight v 100 gpus and another system with uh multiple nodes with four a100 gpus and you can see that basically within within a node so kind of from here down to here you get pretty pretty close to perfect scaling it does start to drop off across nodes but but still i i this is using nccl which is uh which is the same library that tends to flow in pi torches so i would expect scaling across gpus and across nodes to be pretty similar cool all right uh well with that i think we'll say uh thank you again to to jamie (20:12) um and do go and check out um jen it's a great piece of software and uh we'll move on to our next talk thank you very much,"The speaker is discussing the need for new hardware and software to effectively train and simulate spiking neural networks (SNNs) on a GPU. They mention that current machine learning tools represent SNNs as a computational graph and that this can lead to high latency and poor performance when simulating deep networks. The speaker introduces their own tool, called ""gen,"" which is a library for generating SNN simulation code. They mention that it can generate CUDA and OpenCL code, and that it has a lower level of abstraction than other tools, but allows for more control over the simulation. They argue that this makes it well-suited for use as a back-end for high-performance SNN simulation.",ChatGPT,,,,,,,,
https://www.youtube.com/watch?v=4nwfaMPW4Ng&list=PL09WqqDbQWHEqm1_3a620tKUKnC6FgBrG&index=15,2021,SNUFA Workshop,Jens Egholm Pedersen,KTH Sweden,Norse: A library for gradient-based learning in Spiking Neural Networks,Software and tools,(148) 15 Jens Egholm Pedersen - Norse: A library for gradient-based learning in Spiking Neural Networks - YouTube https://www.youtube.com/watch?v=4nwfaMPW4Ng Transcript: (00:06) okay all right so this is our last talk of this workshop um and it's my pleasure to introduce egg home pederson did i pronounce it correctly beautifully okay brilliant uh so he's a phd student at kth and looking at spiking neural networks and robotics and i think the author of this really cool and interesting noise software which he's going to tell us about today thank you roy excellent thank you for the introduction then i thank you for the organizers um for for inviting me i'm here to talk a bit about grading (00:36) based learning which i know have been touched upon a few times in this workshop so hopefully that's relevant it's not going to be a science talk um as such unfortunately so i'm not gonna present too much interesting science i'd rather focus a bit on the technical part a bit and what what jamie was was doing before um this is joint work with christian peele who talked a bit earlier and and so so the base theme is basically from from the perspective of a of a spikey neural network scientists working with (01:05) gradient-based learning um and i'm actually not really here to sell norse as a library which is what the framework we've been developing is called i'm i'm more here to try to port some of the success that we must conclude deep learning has been into the domain into the realm of spiking new networks and so um i i don't just think it's a matter of efficiency or of um or or of money so to speak so these deep learning frameworks have been immensely successful also immensely funded well-funded and it's also a matter of (01:37) abstractions and and a matter of of of um ease of working with it as a student in in my case but also as a scientist in the longer term so what i'll try to do is to first motivate while we're doing this what what's the point um i'll try to talk a bit about some applications and limitations what our software is capable of doing and and has trouble with doing and finally summarize and discuss some some perspectives so i should probably first describe what norse is and i'm trying to avoid um relating it to too many other (02:14) pieces of work even though there's been tremendously developed uh drill bit in the field rather i'll try to talk a bit about what what we have tried to do from the realm of deep learning and we're specifically building on the the tool called pi torch and if you don't know what pytorch is it's deep learning accelerator that basically carries this intermediate representation computational graphs that can then port to different hardware accelerators like cpus gpus tpus and so on and so forth what we have done (02:46) is to extend pytorch with a few um differential equations describing spike dynamics so we have basically um exploited the entire pi torch infrastructure 2 to augment the tiny layer of um spiking dynamics so norse is purposefully quite a thin abstraction and the why really pertains to the experience i discussed before so not just being able to run things fast but also to be able to describe it rather efficiently and to to to to discuss and work with the abstractions rather efficiently i'll talk about that specifically in terms of spiking (03:26) dynamics and compositionality is a big term for me i'm a computer scientist by training and of course i'd like to put things together and and i'll explain how that gives us somewhat of a modularity in terms of networks learning is of course a big topic in this particular case gradient-based optimization and finally i'll discuss some performance because it is of course also irrelevant expedience um i think pertains to the way that we can describe our models and not just in in talking and in math but also actually in (04:00) code like the the more correspondence we we have between those two the the better in in my opinion so this is one example of a small activation uh function in a torch in pytorch you have an import statement and describe the activation dynamic so in this case you have a rectified linear unit which is not particularly interesting from a spiking case but um you can subtract it or sorry substitute with different other activations so if you wanted to have a hyperbolic tangent you can do that um but the the i think innovation here is that (04:38) those activation functions could as well exist in time and that's what we've we've we've done with with north so instead of importing torch we now import norse and we simply define uh leak into getting fire cell but notice that the the semantic is saying we have this computational cell that we can exploit just as as well as relu and of course one would probably want to parameterize this so it's very easy to inject parameters here we're setting the voltage threshold to 0. (05:06) 8 instead of one which of course artificial constants but there's also a way to to specify more biologically correct constants if that's uh what we would like so um of course it's possible to exchange this dynamic so we can have etiquette cells and other dynamics plug and play and this is where i'd like to discuss a bit about modularity because in principle um it's not just enough to simulate one activation of a neuron we want to of course build networks of it and what you have here is a fairly simple example of (05:37) a convolution network in torch is very standard it's not very inspiring but what i want to highlight is the distinction between these convolutions and linear layers which are actually ubiquitous compared to anans and essonnens and of course the activation so in this case you can see the rectified linear units and with the um discussion we have before we can simply just replace those activation elements and have the exact same network and one small hook to that is that we've need to describe the statefulness so of (06:10) course the big difference between rectified linear units and spiking networks is that we have state and we are handing this in what we call a sequential state which is still a composition sorry of different spiking dynamics but where the state is being handled so we're taking care of the temporal dynamics to make it as easy as possible to model this so that's still happening under the hood in terms of learning i need to talk a bit about how um pytorch is going about optimization and i hope this is not (06:39) going to be too boring for many of you i'll try to make it brief i basically need to describe how all the differentiation works because a big part of why this is an efficient framework to work with is because we can do auto differentiation what that means is specific is that you can think about a network as this computational graph i mentioned before you have basically some input that's then applied to some operations with some parameters over time and finally you might get an output and some loss yeah (07:08) i'll return to that in a second each of these operations are then differentiable so what torch does is it keeps track of the activation graph so that you can at a later point in time derive the exact um [Music] the exact dynamics with regards to some loss and and parameters later on so there's a it builds up a memory graph where you can you can you can backtrack so to speak and that's what christian palermo mentioned before the second step of the back propagation algorithm you can backtrack this graph to discover the (07:45) exact um effect with respect to these parameters and the obvious question in in the realm of spike in dynamics is of course discontinuities what do you do when you have spikes and i hope i'm not offending uh too many of you when i just mentioned one particular example of the circuit gradient method this is from single friedman and severe ganguly and the super spike method which which or superspike gradient which we've implemented and of course christian peter's talk from before on event-based background with the adjoint (08:17) method so those things can be implemented so that your approximations or in the case of the item method exact gradients for spiking dynamics and with that i think we can claim we have differentiable neurodynamics without going too much in into detail there what we still need to have though are errors estimations and derivatives of the error with respect to the parameters so we need to actually do the calculation and now we have the the graph we have to apply the actual error to to get the derivative of of that (08:49) error and so what i want to do very technically just to show you briefly how this is done it's actually quite simple um dilemma mentioned something similar in his slide so i won't go too much in depth but imagine you have some teaching signal so a input output tuple you define your model as we saw before you then apply your input to the model to gain some prediction you can then calculate the loss in this case you have mean squared error you then create this entire graph and then back propagate through it (09:23) and this is all done under the hood in pi torch so you can then access the gradients what you then choose to do with the gradients is outside the scope of this talk and dylan again mentioned optimizes like atom which is an obvious approach but there are many other interesting things to do and that's that's really i think the power of this approach that you can you can basically apply whatever method you would want to to to work with of course this needs to be performed especially if you train deep network you (09:50) need um you need you need you need fairly efficient um both forward inference and training passes so what i've what we've done here is basically benchmark between three pi torch based libraries so this is bindsnut who was a presenter than previous talk and of course north so we've had together a quick benchmark that shows um the simulation of a variable amount of neuron on the x-axis so between 250 and 5000 neurons we have 32 batches so in effect we are simulating 32 by um uh 5 000 neurons um in in the end on the (10:27) y axis you have the running time in seconds so you can see this is a 10 to the minus one we simulated one thousand time steps so five times for each data point and you can see the shaded area represents the variance and um without going too much into the detail we we get roughly a factor two performance for for noise in this forward pass um gen keeps a very stable performance because they've been brilliant enough to to not use matrix multiplication which becomes prohibitively expensive when you scale the the the matrix (10:59) but i think this is this is this is proof that that we can do fairly well and and of course we've been clever in our application of pi torch but really this is due to pi torch having um invested a lot of effort into just in time compilation and um acceleration hardware acceleration is just specifically around gpus and and cuda so now that i've talked a bit about the theoretical or the idea behind noise i want to talk a bit about some applications i want to bring to you three applications that i have to go (11:29) through a bit fast because we're we have some time constraints i want to talk a bit about sparse computations for event based data memory model um that exists in the literature and then finally how we can integrate this with neuromorphic hardware so this is unpublished work with philip mundor from from kth we work a lot with event-based cameras as you see to the left so you can imagine you you you record some real objects and to the right you can see the difference between the cfar data set where if you want to apply this (11:56) over time you need to find a way to work with these frames as you see in the in in the left right axis of course the the dbs data that we get from the event cameras is radically different and what you see to the to the right there is um it's a part of the ibm gesture data set and and and what we really have to do is to um to exploit this sparsity uh to to really gain the the benefits of snns of course and what we have done in norris is to actually support these bias activations so we can actually support um (12:29) inputs that have very very small fraction of active elements throughout the the simulations and what we've done here very briefly is to simulate some poisson rates you see that on the x-axis we generate some percentages of activation we have roughly a thousand lift neurons with ten thousand weighted inputs and we simulate this over 500 time steps and what you see basically in the beginning if you have below 10 or so activation you get a factor 304 performance thanks again to the power toward sparse activations (13:03) and this is very very simple to implement and work with as a scientist again you just simply apply the data assuming as it's sparse like everything under the hood comes for free so i think that's a very important point if you work with event-based data second we've been trying to replicate results in in the literature i think this paper was mentioned before it's from both grandma's lab of julian delic working with learning to learn and long short term memory and what um one of their tasks they (13:30) mentioned in the paper is basically to learn a bit pattern over time so you have to retain the memory of some bit pattern and reproduce it later and briefly the architecture is um consists of 10 leaky integrated fire neurons and 10 adaptive leak integrated fire neurons so long short-term neural net networks and that's very very simple to explain in in in north it's modern north we simply have this recurrent um network architecture so now we have the currents in between these um these neurons that model the (14:00) the two-bit pattern into uh into the population the hidden layer dynamics so three models were trained to replicate what happened in the paper we have this 10 by 10 model here but we also had a 10 um sorry 20 lift only and a 20 l as an end only to see the the the comparison with with this dual setup and what we can see is that we replicate the results of the paper uh well that's hard to see here but basically we can see that the the dual approach here with these two different uh network uh or neuron types performed pretty well (14:37) and as expected um the the the other neuron types perform quite well because the the dynamics are different i think and what this really illustrates is that we can reproduce the results but also actually that there are some um dynamic dynamics to be explored here uh despite the fact that we are working with this tensor-based approach we have a lot of other deeper models available for you to to explore if you're interested finally i want to mention our integration with spinnaker because of course we can work with spiking (15:06) networking simulation but as the previous talk um [Music] we're explaining there are a lot of interesting games to to to to find when applying this in in the real world this is ongoing work with um garibaldi garcia from sussex and that that team over there um and what we've been trying to do is to take our trained model and put that onto the neomorphic hardware platform spinnaker we do that via pine so the the approach has been to train the model in norse we do that because spinnaker does not um implement this type of gradient based (15:41) optimization which is i think normal for neomorphic platforms so we train it outside the neomorphic platform we then extract these trained parameters into a file we generate the scripts in pine that can then execute this trained model so it's very much what you can call in in computer science a transpilation approach which is not very efficient but it's very easy to use um exactly because pytorch has these very straightforward underpinning representations so what we called redupt the project by thrust to stay in the (16:11) nordic nomenclature and basically what you do is first export this model into a python script that called it snn.pi and that you can then then run so i hope this illustrates the simplicity of the approach and the expedience i discussed before i really want to touch on some limitations in this approach of course we have to suffer these deep learning idiosyncrasies i mentioned tensors before which is the basic building blocks of these reasonably quickly we're running out of timer but yeah of course so another limitation is the lack of (16:45) complex biological models we we have a lot of work to do to catch up with other libraries and finally there's a real-time performance of course you want to do this in in real time i'm actually just getting to the summary side which is to say that we are basically we basing our work a lot on pi torch and what they've done with the added dynamics of spikes we've added quite a lot of dynamics but i think the reason for north specifically is because it's very expedient to use you can combine deep learning and spike network (17:11) research i don't think they're mutually exclusive there's an underlying competition graph you can then use to export and there's a host of community tooling so the final note really here is that there are a lot of future work that's very interesting to do specifically working on biological learning rules and better integration schemes so we can have proper support for continuous learning and continuous neurodynamics finally i just want to say the contributions are welcome we are licensed on the gpl3 so it's very open (17:38) license i have a host of people to thank especially the group in heidelberg and the hpp um with that i want to thank you so much for your time and i'm looking forward to your questions great thank you very much it's uh it's a very cool library that i've had in mind i want to play with for a while now and as soon as i get some time i'll definitely be doing um yeah we've got a number of questions um the first one is from tim mascalia he's asking about what the big differences are with spiking jelly (18:10) that's a very good question so spiking jelly is is implementing the custom cuda cores to get very fast performance on box lift models so they have current jumps in in their models which is of course um very fast to simulate but not so um so realistic um otherwise i think actually it's a very similar approach we have a bit more newer models than than they do and they seem to be focusing more most on the gpu performance than than we are okay yeah and people are also asking about snn torch and about bindsnet and (18:40) various others um i don't know if you want to make a quick comment about that or yeah of course so it's they're very good questions and there are a host of other libraries of course we have to position us i think um snn torch is is it's a very recent library we started north uh the initial thoughts for this related 2017 but the github repo started in 2019 snn torch is newer and so so that that we couldn't have used that um bindsnet is a very interesting approach but they don't support back propagation so it's (19:08) very difficult to do gradient based learning with bindsnet okay that's a brief answer yep that's cool that's perfect i think uh next question was from me um do you have support for defining new neuron models um support for defining the models or new neuron models yeah like to make an adaptive life or yes we do and and something i i didn't so actually we have adaptive life models and we have we have quite a few and by now but of course there's a lot more to be done and we don't expect to to have (19:38) an exhausting competition all the existing models um so what i didn't mention is that everything here is python right so so even the the performance you saw was python with a bit of magic but but all new neural models can be defined in python it it it's very simple to approach so definitely we everything is open on github so it's very easy to extend and we're of course eager to talk with the community if you have some ideas okay um so uh nicholas paris is asking if you can train your own parameters apart from (20:10) weights and biases yes um and that's actually um uh there there are a few notebooks we have online i didn't mention that with that shows this where you can do parameter tuning of basically arbitrary parameters because the only thing you need to do is to expose these parameters to this altered differentiation i've discussed before so as long as you can include this in the loop you can you can basically use back location to optimize it as you wish um i'm happy to share some links later on on exactly this (20:39) cool okay well there's quite a few more questions left but i think we're really out of time at this point um five minutes over so um i think we'll we'll call it a day for for that if you want you can answer some more of the questions in the chat here um happy to ask questions can uh can take a look um with that it's the end of the workshop we're gonna have a quick um five minute session just to say goodbye and thank all the speakers and our stuff and we'll pull you into that in in just (21:07) one minute or so so don't leave yet um it'll be riveting i am sure i assure you and so thank you again uh thank you again jens that was a great talk thank,"The speaker is introducing a library called ""Norse"" for gradient-based learning in spiking neural networks. The library is built on top of PyTorch, a deep learning accelerator, and extends it with differential equations describing spike dynamics. The speaker emphasizes that the library is designed to be a thin abstraction, with the goal of making it easy to work with and discuss the abstractions efficiently, particularly in terms of spiking dynamics and compositionality. The speaker also mentions that the library has some limitations, and that the performance is also relevant. They also state that their goal is to apply the success of deep learning frameworks to the realm of spiking neural networks.",,,,,,,,,
https://www.youtube.com/watch?v=5SrEycIbfRE&list=PL09WqqDbQWHFvM9DFYkM_GfnrVnIdLRhy&index=1&t=1359s,2020,SNUFA Workshop,Sander Bohte,CWI Amsterdam,Effective and Efficient Computation with Multiple-timescale Spiking RNNs,Neuromorphic-compatible algorithms,(148) Sander Bohte (CWI) - Effective and Efficient Computation with Multiple-timescale Spiking RNNs - YouTube https://www.youtube.com/watch?v=5SrEycIbfRE Transcript: (00:09) hello everyone i hope you all made it into this session so it's my great pleasure to introduce our first speaker of the day that's sunday borja sunder comes from the cwi in amsterdam and many of you might know him for having worked on spiking all networks long before before they were fashionable so spike prop for instance that's sander right there so it's a really great pleasure to have him here for talk today and he will talk about effective and efficient computation with adaptive spiking recurrent no networks take it (00:44) away sander yes thank you freedman so it's great to be here thank you very much for the invitation to talk to so many people like uh you say i've been doing this for a while and i don't think i've ever seen 300 people actively interested in this at one place so that's very cool uh and i hope to show you a little bit about cool spiking neural networks that we've been working on over the last year and a half basically and [Music] so starting with this challenge effectively this is jan lacun um i think isscc (01:21) from last year where he's expressing his skepticism about spike neural networks and neuromorphic architectures and not in the least reason for because there are as he put it no spike based neural networks come close to state of the art on practical tasks and then of course the next question is why do you build chips for algorithms that don't work so i take it as challenge and then i'm not saying he's completely wrong or completely right but i think we get a lot closer to this and i can show you at (01:56) the end how close we got so brief outline of the talk i think i have the whole talk is scheduled for 45 minutes freedom correct me if i'm wrong i think i planned it for about 35 minutes for some questions um so i'm gonna talk about uh spiking neural networks i just addressed the main problem that that other people are seeing outside spiking neural networks and i'm going to go through some of these things what is a spiky neuron uh how can you do big things like image classification temporal classification circuit (02:31) gradients and i'm going to show you how how far we got on these these real problems with adaptive spiking recurrent neural networks and surrogate gradients pptt a lot of dog so of course everybody knows this um spiking neurons in the brain most neurons are spiking neurons uh rather than the neurons that we usually talk about in machine learning spiking neurons are a lot more complicated and elaborate than artificial neurons they are comprised of of cell bodies dendrites that receive input axons that transmit (03:09) pulses to the next neuron it doesn't just connect there's a synapse in between the axon and the next dendrite when a spike arrives the axon releases vesicles with neural transmitters that cross a synaptic cleft and then influence the somatic state of the next neuron and so it's all actually quite complicated uh once you go down to it if we abstract it a bit you can say that input spikes affect the membrane potential of the next neuron positive input spikes excitatory inputs increase the membrane potential um if (03:52) nothing if it's not too much the potential starts to decay again i think this is what you see here you see that i can it's a laser so if there's an input spike and it's an excitatory input spike the current flows into the neuron and then current flows out again if you get a couple of spikes into the neuron then it will reach some kind of threshold and the neuron will actually generate the spike now when the spike is being generated spike goes to the next neurons but also the membrane potential of the (04:21) neuron itself is being reset and the whole process goes on again but this is what's what real neurons do at least almost all of the neural neurons in your brain and it's quite different if i abstract the whole thing we have a schedule like this spikes come in something happens to get it into a potential there is some sort of a non-linear function and maybe stochasticity that puts turns it into spikes ever is a spike you have this refractory response and the spike goes to the next neuron and if we go to artificial neurons we (04:53) have a very different picture and artificial neurons you have an analog value that is being generated by a neuron that's weighted by a weight these sums are added up to get your activation and that as activation is taken through the transfer function and you get an analog value that goes to the next neuron um so if you want to come from from the spiking neurons to this you are making a bunch of assumptions about how spike ignorance transmit information and and how that goes about the general idea has always been that (05:31) this analog value that is that's coming into your standard artificial neuron represents something about the firing rate the number of spikes per second in your spiking neuron that's the this classical relationship between the artificial neuron and the spiking neuron then all these rates add up to some sort of a value and the soma of the the neuron adds it up in a non-linear way so then you get a non-linear function to get the output firing rate of your artificial neuron note that in your artificial learn (06:04) there's really no concept of time this is all frame based there are values coming in they're multiplied there's a function being applied and there's a value coming out no sense of timing or whatsoever so if you think about a real spike in urine and you're trying to think about how do you get to these firing rates it's actually a little bit complicated because we do want to have a firing rate or some analog value at any time but the question is how does a neuron actually compute that how can how can what is a neuron a (06:39) spiking urn actually aware of in terms of a firing rate um a simple one is to say well i'm just computing an instantaneous firing rate um by taking the time between the current spike and the previous spike that that is you're receiving you can just do one over one over the time difference and you get a firing rate but that that doesn't add up with the computation that's going on in your spiking neuron as i just showed it the other idea that's often being mentioned is some kind of population (07:08) coding that's where you say well my artificial neuron actually doesn't really represent a single spiking neuron but it represents a whole population and if a hundred if i have 100 spiking neurons then i could say well at any time i can just look at how many spikes i'm getting from those hundred neurons if they're roughly similar and then at any time the input neuron or the neuron can see as input some kind of a rate sometimes with an intensity now that works but it's very wasteful so there is another way that we've been (07:44) looking into for a while which actually fits much better but it's still a rate code and i'm going to show you how that works in a very simple example so any spiking neuron will be receiving spikes the spikes if nothing happens if there is no spiking mechanism the spikes will result in some sort of a trajectory of the membrane potential of the neuron and here i only took in positive inputs now of course there is a threshold in your spiking neuron so when you reach threshold there will actually be a spike that is (08:19) emitted and there is subtracted from the input a refractory response now since there is a spike being emitted by the spike neuron there is a postsynaptic potential that is added at the next neuron so we subtracted the refractive response and our current comes in again it keeps coming in to the neuron so the potential goes up until it reaches threshold again so another spike is emitted another refractory response is re subtracted from the spiky neuron from the potential and another potential is added to the next neuron (08:55) and this will keep going and you'll get your spikes you'll get your sum of refractory responses and in a filtered way those spikes are added to the next neuron as a sum of postsynaptic potentials and you can already see there is some relationship between the positive part of the input into the spiking neuron and the sum of post-synaptic potentials that will arrive at the next neuron this is a very simple and linear way of encoding signals at least only the positive part of a signal it's actually not a bad (09:25) way of doing it so here i'm plotting the in this case the potential that i'm putting into the cur into the neuron on only the positive part so this is my signal that goes into the neuron here i'm plotting the potential of the neuron and i draw on a line where the threshold of the neuron is actually and what you will see is that current goes in and then a spike will be generated a refractory response is subtracted and here we're just keeping track of how much is being added in terms of postsynaptic potentials to (09:57) the next neuron so here it goes and as you can see here in purple is the approximation of the positive part of the input current it's actually not a bad approximation we really are following the signal quite actively with not so many spikes this is a couple hundred milliseconds and we're using maybe a dozen spikes so such kind of a rate coding with some of post-synaptic potentials is pretty effective in general there is a small so you can show that if you have a mechanism like the spiky neuron that we discussed earlier (10:33) and it is doing this whole business of filtering a non-linearity spiking and a subtraction that it is an effective way of encoding an input into a spike train it actually maps exactly to an analog digital digital analog conversion and this is something that's been shown in the past a number of times i'm just putting in some uh recent papers from yoon in 2016 and i hear an individual also showed that in 2019 if you have a mechanism like this for a lyft neuron a leaky integrated fire neuron it maps to a particular kind of (11:07) asynchronous pulsed sigma delta modulation coding scheme so it's a kind of neural of rage coding we know it can can do really well to approximate analog signals using a spike drain and what we can also note is actually works quite well for low firing rates and long enough kernel lengths so long post synaptic time constants now there's one tricky part and that's that electrical engineers this is an electric engineering solution they usually have good control over the bandwidth of the input of their signals and (11:41) neurons don't necessarily have that so this is quite obvious if you try to do the same thing and you use a much smaller threshold so you mismatch deliberately the amount of current that comes into the threshold then you see that there are problems so here you have the same simulation and you see that there is because there is a maximum firing rate the sum of all your postsynaptic potentials actually has a maximum a maximum amount of signal that it can convey to the next neuron and you also get lots and lots of spikes (12:16) that you may or may not want this is much too much for a real neuron and of course also obviously if your threshold is too high compared to the signal then you're not getting any spikes out it's not a very exciting simulation but it also it means that your threshold actually needs to very carefully match the dynamic range of your input signal so one fun thing that we worked on is that of course the brain has this problem it it can encounter very different dynamic ranges of input signals um and it still wants to encode these (12:50) signals in an efficient way now this is where people have brought up spike rate adaptation as a potential mechanism um here the classical example from from harris in 2000 is where you just where they study a blow fly and they actually change the velocity that the blowfly is subjected to because it's on this apparatus we can change the torque that the blowfly is experiencing in a dynamic fashion so we can subject it to this kind of a torque dynamic torque but we can also make the signal exactly twice as large (13:26) and then study how these neurons h1 neurons actually encode this the velocity signal and what you find is unlike what you would expect is that the neuron actually uses about the same number of spikes to encode both the uh the slow slowly evolving signal and a faster evolving signal and it does this through a kind of spike rate adaptation we know the mechanism um what actually what you find is that if you have a fixed stimulus going into the spiking neuron the firing rate will decay over time in a usually with a power law dependence (14:06) and what actually happens if you make a model out of it one way of modeling is to say well every time there is a spike i'm adding something to my threshold which then decays again and this is a kind of adaptation the hypothesis is actually that adaptation allows the neuron to adjust to the signal statistics and with parallel dynamics you could even adjust to the statistics over multiple time scales and and uh the anecdote area is also that the models that we make for this kind of spike rate adaptation seem to be very (14:39) similar to how the brain consolidates memories that's a detail but if we add adaptation to our model we can actually get rid of this problem with the dynamic bandwidth and we can start with really small thresholds and encode a signal in a dynamic way by effectively changing the size changing the threshold and changing the effective size of the spikes so that's a long story to show how you can get from inputs to currents to refractory responses to postsynaptic potentials in the next neuron the main idea is that if there's a fixed (15:18) amount of current coming into a neuron it will respond with a certain at least after adaptation with a certain variability in the next neuron but on average it gives you a fixed signal input current in one neuron results in a certain amount of out input current in the next neuron and that's the transfer function that we typically use in artificial neurons so this is one way of getting rid of our problem with the relationship between inputs and outputs in spiking neurons we're essentially subtract saying that (15:56) we have an activation into the neuron as a sum of weighted post-synaptic potential uh resulting in an output that is meant measured in terms of an unweighted sum of postsynaptic potentials at the target neuron and the nice thing of course is that these values x of t and y of t are always available at any time but defining the gradient d y dt is a bit tricky and a while a long time ago already i did show that if you just assume a very linear gradient so if you change the amount of cur of current or if you change the weight here between (16:35) the neurons then in a linear way approximately the target receives more input so the relationship between the activation the weight and the output is roughly linear and you can learn a lot of simple temporal tasks this way another way of using this transfer curve is that you can also use it to quickly convert a standard deep neural network into a spike in neural network just by taking into the neural network instead of your standard relu function by taking a adaptive spiking neural network function did this half sigmoid essentially if you (17:14) do that you can do all kinds of nice image classification tasks sorry and it works quite well spikes go in you have a fixed firing rate for each active pixel and then you need to somehow decode spikes on the outputs um if it's easy then you can measure it as output neuron you measure that it's exactly a zero and not one of the others if it's a little bit more difficult then you also see that different numbers get different activities over time i'm going to skip the um one trick that we you can use this is (17:52) all fine and other people have done similar conversion tasks but if you have the the transfer function then you can do the trick in the neural network and that's that you can dynamically adjust the precision that with which your encoding signals so you can tune the neuron to use settings where it uses relatively few spikes to encode a fixed stimulus which results in a relatively large variation in the received signal in the next neuron but at the same time we can change the parameters of the neuron so that it uses a lot more spikes to (18:25) encode the same level of signal and if we then reduce the synapse between the two neurons you would get the same average signal at the next neuron but with a lower variability and this could be one way to model arousal for example by saying that if you start out with a bad signal like something which is encoded with relatively few neurons then if there is some confusion between is this a 9 or is this a 4 you can change the context in the neuron in the in the neural network you can change all these weights and arousal curves use more spikes to (19:01) actually figure out that yes this is a four rather than a nine where here you are uncertain when you don't use a lot of spikes so this is one model of arousal as a tension where you dynamically tune the precision in the spiking neural network this is attractive maybe not for images but imagine that you have an edge ai problem then you do want your device to run usually at low energy but only when it's confused about what is seeing it should use more spikes and be more certain about what is going on so arousal could be a dynamic mechanism (19:36) to to tune the number of spikes that is being used in the neural network and this actually works quite well it almost halves the number of spikes that we need for different tasks but at the expense of of reaction time of course of latency because first the neural network is not performing all that well and then it detects so for some images that it's not so good and then it needs to encode a lot of things at a higher position now just to come back to why spiking neural networks in general and of course what we're really after is is (20:10) something which exploits the fact that we are using only one bit per spike and we don't have a lot of spikes in our network then then it makes sense to use spiking neural networks from a machine learning perspective it also helps that if we have these one bits per spike that we can just add the weight to the next neuron rather than having to do a costly multiplication at every time step if you want to exploit this you're not really the these kind of image co image classification tasks are not really the (20:43) most obvious cases you you really do want to go to time continuous cases such as speech or signal analysis and robot control maybe cognition although i've left that out here and and this is uh these are the sort of tasks that we focused on to to work on with compact spiking neural networks and here we looked at two kinds of tasks both temporal tasks both streaming tasks and classification tasks and in a streaming task imagine there's an iot device sitting somewhere it's measuring all the time and it has to have an answer for what (21:21) it's seeing at every time step so at every time step it needs to have an answer for what is the probability of what it's seeing at this particular time given what it knows maybe a bit of the in the past and maybe you can even run with a little bit of buffer so you're already you add information about this data point but you're saying something about this data point and you have to determine the class for every time step in your your task or in your signal so this is an example of an ecg signal (21:53) um the task here is to to detect for every time step what the particular phase of the heart rhythm is in like and there are a couple of different phases that are all called in different colors here so when you are measuring this with people you want to see when there are certain parts of the of the phase in the heart rhythm if there are anomalies in these phases that points to can point to heart disease so this is why people want to do that but of course you cannot record that for a long time and then start analyzing you (22:23) want to to be able to say something reasonably fast when these faces are going the wrong way so that's the streaming task where we try to classify at every time point given only a certain window around the time point and not the entire sequence so in the next time step we get a little bit more information but we need to classify this data point and so on and this is in contrast to to a lot of classification tasks on time series where you're basically given the entire time window and then asked what is the class associated with this (22:58) particular time window so this would be a classification time task in in a temporal domain so what we did is we designed a spiking recurrent neural networks with multiple layers so we took our our input input can be any part of your temporal signal and then we just created a layer with uh fully connected fully locally connected spiking neurons that are then connected to another layer of spiking neurons that are then connected to an output layer and because this is a temporal task we then simply try to minimize the loss (23:37) function that we defined on the output layer and simply means doing arrow back propagation through time we know what the class should be at any time ah here what the class should be at any time and then you can do your classical aerobac propagation through time to optimize all the weights in your network to solve the task as best as possible now that's very easy to say of course but spiking neurons are a little bit annoying because it's not that easy because spikes the relationship between spikes weights (24:09) potential and spikes is a little bit unnon-linear actually it's discontinuous so doing our standard gradient descent doesn't really work especially this case how do you how does your spike change if you change your potential that one's a little bit tricky and discontinuous if you make your potential too low there is not a spike and that's always a problem you cannot quite measure that this is something i ran into of course all the way back in 2001 already with spike prop and what i did then was to say well i (24:42) just going to assume that this is a linear relationship if i change my potential a little bit i assume the spike timing will also change a little bit and in a linear fashion now that that is a very specific case for spike timing but you can do that in a much more general case and emre nefc and friedman zenker had a really really nice way of putting that and freezing it as surrogate gradients in the general case to make an approximation that makes this relationship differentiable in meaning we just put an assumption about what the gradient of (25:18) the membrane potential with respect to the spike is like and here we use it as a normal distribution around it was then we can solve the whole problem defining if we define a loss function on the output we can use pytorch to train the whole network all the weights back to optimize the output i should say a few things about what we did some specifics the first is that we tried a lot of different things on how to encode uh inputs in general with spikey neurons because in these cases you have an analog input signal (25:53) and it somehow has to be turned into spikes for for some of the problems we tried a lot of different things we ended up reporting data for poisson population coding or just personal coding other things like just intensity coding we tried a bunch of different things they all worked about the same roughly the same performance and we didn't find anything that worked much better or much worse so we just went with this because it's the general accepted way of doing it output's a little bit more tricky because we need to define an (26:26) output at every time step and and have to think about what it is um we went for two ways two two things in the classification tasks you can do a spike count kind of way you just count how many spikes you have in a certain time window and then have the highest spike count be the winning neuron if you do a streaming task we found that we can also use spiking neurons that don't spike which might sound a little bit strange but if the neurons don't spike they just accumulate current which then decays again and you can just take the (26:58) highest or the most active neuron the most highly activated spiky neuron as the winning neuron at any time now the real trick is that we use pytorch to train this because with circuit gradients we can define the gradient in spy torch and we can use the whole framework that's been developed so very nicely at frame at facebook to do our hard work for us uh instead of computing everything bit by bit by torch will adapt everything and that means we also it's it's very easy to adapt the spiking urine parameters themselves (27:32) and that turned out to be the trick that we needed to get really good performance so what do i mean we went for two different kinds of spiking neurons first of all the standard lift neuron the standard leaky integrated fire neuron and here you have the equation you have to show a good gradient as we put it together um but we also went for adaptive spike endurance these are these neurons that every time when they spike they increase the membrane the threshold and then the threshold decays again so we put that together this is actually (28:07) the model that we took from a paper from guillain-barre who did some very nice work that i think we will hear later about today um we can make we use these spikey neurons in the network and we train all the parameters including the membrane potential here the membrane potential in the lymph neuron and the membrane potential in the adaptive neuron and the time scale of adaptation that's the decay rate of the adaptation we train both these parameters in the adaptive neuron to improve the to solve the task and i can say this works actually (28:43) remarkably well and it delivered as far as we know uh state of the art on a number of tasks so here you have the sequential mnist this is where you feed in pixels one at a time into the spiking recurrent neural network and so on and you try to classify what the digit is that you're seeing and here is the uh in standard reinforcement learning our standard deep learning the best network is 99. (29:11) 4 and with some effort we get very very close with the um spiking recurrent neural network we've not so many neurons to be honest because this uh dense ind rnn is a very expensive one it's very deep very many neurons and the srn n also outperforms the lstm here and in other most other cases as well what is not being outperformed is actually the relu srnn so it turns out that the the shape of these spiking neural networks with tunable parameters inside the neuron is actually a really good idea because what we did is instead of having (29:48) spikes come into the neuron we have membrane potentials coming into the neuron at every time step from the other neurons so basically instead of spikes there were 32-bit analog values coming in and also what was transmitted to the next neuron was also the potential of the neuron this is how we turn the spiking neural network into a non-spiking spiking neural network so but we are adapting the exact same network with exactly the same parameters and it turned out that that does a little bit better than just the standards we could neural (30:18) network with spikes but if you look at the other numbers then you also see that the the spiking neural network um does a lot better i think with some modifications here we got to 94. um first this spiking heidelberg data set that freedom and and co-workers developed this has spikes as input the adaptive spiking recurrent network also achieved very high performance better than lstms getting close to a very large cnn so the cnn if you did the math has actually a million neurons whereas our adaptive neuron only had an (30:58) adaptive network only had 256 neurons so we get close performance again a little bit worse than the uh the relay version of our network but this is really no comparison with the cnn um same story with the ecg data adaptive spiking recurrent networks best performance that we achieved again the analog one was only slightly better but we really outperformed lstms and vanilla iron and grew lstm by substantial margin so this is in general a good idea there are some other data sets recently we worked on scaling up this this (31:35) problem and this is some unpublished data um so in the same paper um there is a version of the spoken command set from google um in the paper kramer at all reports getting seven some fifty seventy three percent with lscm um about seventy percent seventy seven percent with a cnn and again the adaptive srn does a lot better gets close to cnn performance for the solid data set which is a set of radar gestures so we have 40 frames of a gesture that someone is making in front of a radar yeah a simple radar for that is in front (32:16) of a phone like the google yeah the the google phone uses the solid data solely radar to recognize gestures and faces the a cnn with lstm gets about 87 right of the gestures and the adaptive srnn the latest results were getting close to 92 percent so really outperforming these classical machine learning algorithms and finally we also got timid to work so we have results on timid that were at least exceeding uh the results from guillaume balak with eprop also with fewer neurons compared to veom and i think that state of the art in (32:57) machine learning in deep learning is about 70 with very large cnns so here we are a little bit behind cnn's but we are getting very decent performance out of the the network something that is really getting you to become useful now the question is why does it work what makes this work uh here we did a comparison the comparison is between a relu srnn and an adaptive srnn and you see that having an adaptive neuron gets your performance actually quite close to the analog neuron whereas if we have lift neurons standard (33:34) leaky integrated fire neurons then performance really is a lot less so having the complex adaptive neurons makes the task a lot more feasible and a lot more competitive and what we also find is that if we don't optimize these parameters the the time constants inside the mirror and then performance also drops up drops off substantially so you need to adapt the time constants in the spiking neurons to get good performance out so the spike in urine makes a significant difference uh here also to illustrate we initialize (34:08) all the time constants initially at a fixed value and here are the values after training for a set of neurons in this case for the shd task so the pi torch really does adjust all these time constants to something that apparently makes the task a lot better there's one more result that also for different kinds of neurons we find that if we have larger networks our performance goes up but also our sparsity the number of spikes in the network goes down which is kind of nice behavior because the next thing of course we're interested in (34:43) is what's the energy cost of these tasks uh we did the math and we we just did the math for how much energy this is costing assuming um some numbers for the accumulate uh energy cost in a network and the multiply accumulate in a network usually standard neural networks use multiply accumulates because you are accumulating the activation and then you need to do this multiply with the weights in our spiking neurons we don't need to do the multiplication with weight so we have a much cheaper function but we have some extra (35:21) functions inside because our spiking neurons need to do some some multiplications to get the state right but you can do this for all these different networks you can compute how much of these types of calculations you're doing and then it turns out that the energy cost for the snn is actually really much better about a factor of 100 better than the the best rnn which actually is the analog version of our srnn and compared to lstm there's really no contest because lstm is ridiculously expensive in terms of computations (35:59) yeah i'm almost done the the only thing we did here is that we are assuming that there is no cost for memory usually in a standard machine memory access cost dominate but we will assume that people in the future will use their very clever memristors to avoid this problem and then all the memory is local and we assume that multiplies and accumulates will start dominating the energy cost so just to summarize um we did supervised learning with back propagation through time and circuit gradients and we achieved really high (36:35) performance and theoretically low power srns were a lot of real tasks we also find that the type of spiking neural model matters and adapting spike in your own parameters like pythorg allowed us to make substantial difference and finally the network architecture does matter so i would end with this i think we should get this to yandere kun and it should be a little bit less skeptical i think this will save a lot of energy in the future and there really are now good algorithms the circuit gradients do a magic magic trick (37:12) of course there are also a bunch of open questions to work on in the future so where should we go with spike endurance should they be more real realistic should we have more complicated architectures uh can we do anomaly contextual and and what do you need to do with on-chip learning these are some of the open questions that we are working on and also interested in i also hope to learn more about these things here in the workshop uh the rest of today and tomorrow and that was all i wanted to tell and and i only thank my co-workers beaujon who did (37:45) a lot of the work on the back propagation through time that she saw together with federico karate who's at imac and david zambrano who did a lot of the um the conversion work with the adaptive spike neural networks thank you brilliant thank you very much and there for this uh very inspiring talk thank you and you've got a lot of questions actually which is great thank you very much to the audience um and i think the first one that actually came up is about the attention mechanism i think i think you went over that quite quickly (38:20) and i also had the same question but somebody had typed it up earlier so that was um gabriel banner who asked hello could you describe a bit more the process of arousal as a tension is it a modulation of the number of spikes used in a task depending on the ambiguity of the outcome so i guess the question is how do you decide how many spikes you need i think it's this graph right so this is the process that we used um so we start with a network that is at a setting that is using relatively few spikes in this case (38:58) on average 12 hertz and then after uh i think 250 milliseconds you try to make a decision and if the if there if you cannot make a decision because a number of classes are both active and we use the threshold what we did then is we changed all the parameters like we reduced all the weights and we increased the spike rate in the network and then let it run for another 250 milliseconds and that usually disambiguated the two classes that were unclear here before the at a low firing rate right that's the mechanism (39:39) i hope i hope that answers the question also for gabriel um so the next question that goes got most of the votes also and by the way again to the audience please feel free to vote up questions that you find most relevant so next question is your ssn model includes oh hang on wait i should first check if the person wants to come on stage no dylan says i can ask that's fine thanks don so your ssn model included a stochastic firing mechanism is this required or important for any aspect of the training or computation (40:19) it's not in the in the work i presented uh here we we are we added in in the graph the stochasticity is just added because everybody puts it in there all the work that i showed you is deterministic um i would this also means that if you look from from a computational neuroscience perspective you're not getting your nice inter-spike interval curves because the neurons are not the neurons inside the network are not spiking in a stochastic way i think you could use the stochasticity to compute things like uncertainty that's just my (40:55) assumption so the spike internet mode models that i showed you only use stochasticity in the inputs where they use poisson neurons to encode analog values into spike trains how about improving generalization like dropout or something like that does it improve uh the dropout of course is applied to um applied to the learning stage and we did not try it that's an idea in the the stochastic gradient you're right you could probably in the stochastic the circuit gradient work you could use stochasticity as a way to increase (41:44) regularization i think that would work we didn't try that yeah me neither somebody should try it yeah good idea i think he's on okay he heard it okay great let's see another question what do we have here so um okay rishika mohanta says i should ask for her because she's on her phone so if at this point traditional ends perform better in most tasks why should we even bother why with spiking a ns it seems like all we're trying to do is make spiking and ends and as good as traditional alns is there (42:26) a class of tasks where spiking enemies have a computational advantage this question will also come back to you later during the discussion session but uh we would like to hear your answer already now yeah uh yeah that's a question of course that keeps coming back um there if you take a firing rate approach the way i showed with an analog digital digital analog conversion and i think the circuit gradients do the same thing then the argument really only is that i can make a much much cheaper chip with which with maybe a hundred to a (43:04) thousand times less energy consumption assuming a lot of things about memory and io etc but if you want to build a really big ai chip in the end it's very nice if you don't need to spend a thousand times more energy actually it's it's prohibitive to use that much energy so there's an energy argument if you're gonna run anything on a battery you want to be very efficient and that's a huge problem and i think here the snns are now demonstrating that they are almost as good or as good as our (43:36) standard a ns but much much more efficient in theory and then of course the other thing is what we would love to have is cases where the spike in neural networks really do something different and maybe somebody else has a good idea on that and yeah again this i think is something we really need to get back to at the during the discussion session because it's it's obviously the question that always comes as you said thank you i think we can do one more question um i guess that's the one that i asked but i think (44:20) you answered it so i'll take the second one um so that's again i can ask material ask this question are those spiking neural networks for image image classification recurrent either within the layer or interlayers if so what's the connectivity actually architecture how does this influence the performance of the model and is it important complicated question um for the image classification task like this those are for feed forward networks they're they're fairly deep uh i think they were vtg (44:57) 16 networks that we converted from an artificial network into a spiking network so there's no recurrency although you could say that the membrane potential and the adaptation are recurrent but they're not used explicitly so this is a vgg network okay i think others did something very similar uh timothee and uh and uh yeah that's right and the end also the image classification networks are usually free for work right indonesia all right awesome so i think i'm gonna i'm sorry about the remaining questions (45:38) we'll we'll answer all these questions hopefully during the discussion session but um in the interest of time i'd like to move on to the next session but let's thank uh sandra uh again i see many people send you club club emojis in the chat so thank you very much for coming thank you very much for the talk and i'm looking forward to our discussions later thank you again for having me it's great to see so many people all right so then we should move on to the next session which means we're going to close this (46:12) one because then it closes the recording and then we will move on to the next speaker and you'll all get pulled into the next room basically in a second you might see a blank screen for a bit but then things will move on thank you very much again for listening and thank you again sander for this wonderful talk thank you,,,,,,,,,,
https://www.youtube.com/watch?v=rk9AJ0w1mrw&list=PL09WqqDbQWHFvM9DFYkM_GfnrVnIdLRhy&index=2,2020,SNUFA Workshop,Iulia M. Comsa,Google,On temporal coding in SNNs with alpha synaptic function,Neuromorphic-compatible algorithms,(148) Iulia M. Comsa (Google Research) - On temporal coding in SNNs with alpha synaptic function - YouTube https://www.youtube.com/watch?v=rk9AJ0w1mrw Transcript: (00:06) okay everyone um welcome to the second talk of our of our workshop uh i am very much delighted to welcome yulia okamcha who is at google now she did her phd at cambridge and and then moved straight into google and there she is one of the few people working on spiking neural networks so um without further ado julia do you want to take it away yes um so first of all thank you very much for the invitation it's really great to be at this workshop and uh it's great to to hear also the other speakers who have been doing some (00:43) really great work in the field uh so i work at global research in zurich and over there we have a pretty small team working on biologically inspired ai so this project i was liking the networks is part of that research exploration uh and the sizes i'm going to present are about the paper that we've published and you can find it on archive if you're interested it has the same title as the slides all right uh so in this talk i'm going to first give some biological inspiration and motivation for our work so i'm going to (01:22) talk about spike timing in the human brain and some interesting studies that uh talk about this then i'm going to present our model the model that we described in the paper which is a biologically inspired model that performs temporal coding and i'm going to to give a universal approximation group since the title of this workshop is liking networks as universal approximators i'm just going to give it an simple so not a lot of complicated math just so anybody can understand how to go about that and i'm going to show how this model can (01:56) learn with bad propagation and exact derivatives and then i'm going to show some results and experiments on some first on some simple boolean logic problems and then on image recognition on eminence and trying to also reconstruct the images that that it's learned okay so i'm not going to do justice on for this topic and uh just one or two slides but basically everyone knows that conventional artificial neural networks are inspired by the biological brain and benchmarks for them are on tasks that are solved by humans (02:31) so by the biological brain but they compute in a fundamentally different way compared to biological brains so one thing is that they do synchronous processing so you you have to activate all the neurons and you wait for each of them to to to compute something in order to go further and there's no true temporal dimension not your temporal coding even if there are lstms or recurrent networks and you can train them by unfolding them over time it still has fixed time steps so there's there's no true temporal encoding in there (03:04) whereas in biological spiking neural networks um as we all know neurons communicate through action potentials which are all or non signals so i think everybody everybody knows i know what this looks like so this is the the membrane potential uh if a stimulus comes in if it's not strong enough then nothing happens basically uh whereas if it's strong enough then the membrane is depolarized and an action potential is produced then the membrane is repolarized there's a refractory period in which the neuron (03:38) doesn't cannot spike and then it goes back to its resting state so the action potential is sent along the axon and it further sends signals to other neurons so this type of computing is asynchronous and crucially with this kind of computing you can encode information in the temporal patterns of activity and another feature of biological networks is that they have states so the brain is not just taking in inputs and processing them and giving outputs all the time but it's rather something that has a state so the inputs just (04:13) influence and are processed according to the state that the brain is in there's this theory for example called predictive coding which says that the brain is trying to make model of reality and with every input basically it uses every input in order to adjust its model of of the world um and of course with this kind of of computing uh you have energy efficiency which i'm not going to talk about in detail i think there will be other talks where this will go into more detail uh so now if you think about uh (04:49) biological neurons you can ask okay how is information encoded so the most widely held view is that of rate coding so early in physiology when people were trying to do experiments and seeing what cells respond to they noticed that their cells that respond preferentially to certain input features like lines with certain orientations for example and they also noticed that those particular cells fired more when they were shown a stimulus that was that that was close to to their preferred input so the closer it got the more that (05:26) cell fired so this led to this model of rate coding where neurons fire with some probability that's proportional to the strength of the stimulus and this is a widely held view and this sort of encoding can be very reliable but it can also be very slow since you have to wait for accumulation over our spikes and an alternative view that some people have been interested in recently is that of temporal coding so this is the idea that information is encoded in the relative timing of spikes not in the rate so uh relative timing to what in that it can (06:06) be relative to other neurons around one neuron or relative to brain rhythms now there's some debate about brain rhythms and some people say that they're an epi phenomenon but anyway this is this is just one possibility and temporal coding means that um the spikes are fired with very high temporal precision and also this allows very fast information processing because you don't need to accumulate you might if you if you need to you might act just on the basis of the timing of a single spike so i want to present some evidence from (06:45) some biological studies that show that temporal coding is used in biological brains and can be uh quite interesting to think about so there's a series of studies by thorpe and invert in their lab so they wanted to see uh how short does can a stimulus be so that we still recognize it so a visual stimulus so for example if you present images of objects uh if you present them for only 100 milliseconds you you can still recognize the object and by doing experiments uh showing images to people very fast they estimated that there's repertoire (07:22) of at least 100 000 objects that can be recognized by presenting them for only 100 milliseconds um so this is quite interesting and then you can ask okay so how does this work how many neurons uh need to spike in order for this to happen so here what you can do is uh for example in the macaque monkey you can record uh neuron spikes at um for example in the temporal lobe you can see when neurons in the temporal lobe fire spikes that are informative about the presented image and so you know that an image is presented (08:04) and it has to go through a certain pathway through the visual cortex um so basically you know how many synaptic stages there are between the presentation and the neurons that you recorded in the temporal lobe and then you measure when when are those spikes being fired after 10 synaptic stages and then you can say okay so how long does it take for an action potential to be fired how what is the signal the speed of the signal propagation through through through the axons and through through the whole pathway and then basically (08:38) you can compute that um that that the response can be made with with around one spike per per stage so this is just the first response so basically single spikes seem to be informative and seem to carry some information then of course this is not to say it's just temporal encoding and it only works like this so then of course there's room for waiting for more evidence to accumulate and for feedback connections to also influence the the information or the signal that's being propagated but it seems that the first response can (09:16) indeed be made or there's some information for the first response on the basis of the single spikes just based on measuring uh the speed of firing uh then another kind of experiment that has been done was looking at spikes in the retina uh usually it's the i've seen studies with redness of salamanders um so there is studies showing that retinal spikes are highly reproducible and they convey more information through their timing rather than their spike count than the fact that retinal cells can encode the spatial so it can (09:54) discriminate between the images through their the relative timing of their first spikes then in the human fingertips um there's information about the fingertip force and the shape of the surface also in the relative timing of the first spikes and then there's there's another argument that you can make if you think about sddp learning so uh stdp means that basically if if if there's a spike um and if there are inputs that are very close to that spike then the connection is reinforced between them but if you think about it (10:34) if you keep giving the same input that causes an output neuron to fire then if the connection keeps being reinforced then you don't need as many spikes in order for the neuron to spike and if you keep presenting it then eventually the output neuron is going to spike on the basis of a single input neuron if you've presented it enough times and if you reinforce the connection uh enough so from this this suggests that it can be that in some cases you can act on the basis of single spikes because of this kind of (11:07) learning uh and another interesting topic is that of the face procession in the hippocampus so the nobel prize in 1993 was awarded for the discovery of this uh in the red brain and probably also in the human brain there is an ongoing tethering in the hippocampus and it's been discovered that in the hippocampus there are place cells and grid cells so place cells fire when the animal is at specific locations in in the room whereas grid cells fire also at specific locations but in a grid like pattern so for example in this image you can (11:49) show you can see so this is a 2d space where the animal is and the red blobs are the places where a certain cell fired fires uh this is a model but in recordings it looks sort of similar uh so this is pretty remarkable this shows that there is some um um the code for for for encoding the map of a location in the red and the interesting thing is that the spikes of blase cells and grid cells are timed with respect to the theta rhythm this is called phase precision um so basically the closer the animal gets to the preferred (12:33) activation location of that cell the earlier with respect to the theta rhythm that cell fires so this is pretty interesting again and this is again not to say that this is only about rate coding or time coding it can be that in different parts of the brain or different types of stimuli are processed differently or there's different kind of computation arising on the basis of different codes so there are ways to also turn rate according to time encoding and time encoding to rate encoding which you can find for example (13:07) in these references uh so this is this is basically to say that information can be encoded in the relative timing of single spikes so this is just an interesting model to think about how the brain computes so we wondered how can i translate this to artificial neural network so i want to to acknowledge some previous work so spike prep and some some authors of this work are in this workshop and have given our will give talks so spiker was probably the first model with temporal coding with single spikes and approximate derivatives (13:44) and there were extensions to to to a spike prop um then there's a nice paper by mustafa from 2017 that showed how you can do temporal coding with single spikes and back propagation unfortunately with non-leaking neurons and i've also seen papers that do sdp and reinforcement learning that also do temporal coding but they don't learn this about propagation okay so how to encode a problem if you want to uh to do temporal coding so the idea is that earlier spikes encode more salient information so for example if you have a on a (14:32) digital eminence digit then you have an input size of 28 times 28 and where there's no information or so every neuron corresponds to to to an input pixel so there are 20 times 28 neurons each corresponding to an input pixel and in the places where there's no information the neurons just don't spike whereas in the places where there is information the darker color represents earlier spike times so in the center of the shape there's more salient information so neural spike faster whereas at the edges uh they (15:14) spike later because the information is not as important or it might be noise so if you consider a classification problem with any inputs and any possible classes you can encode them from the problem in an input neurons that spike at a time proportional to the maybe strength of the stimulus or some other characteristic of of the input and in order to decode this in the case of digits you can have 10 output neurons and we can classify the input as class 5 if and only if the fifth neuron spikes are least okay so in our work we were inspired by (15:57) post-synaptic potentials recorded in real cells that look like this so this is an example of an excitatory potential and this is inhibitory and it has this shape that has a fast rise and slow decay so we decided to use in the model uh the alpha function which is k times e to the power t and is parameterized by decay rate so this function looks like this so it has a fast rise in slow decay and this is the equation that describes a membrane potential with weighted inputs and in this example you can see how the membrane potential changes (16:38) as it receives a number of inputs most of them excitatory so with positive weights and one input with negative weight so inhibitory okay so to to sum up the model we have the alpha synaptic function which is parameterized by a custom decay and by a weight so in this graph you can see this is the the orange line is the baseline and you can see how the decay rate and the weight change the shape of this so the decay rate basically scales the function both horizontally and vertically whereas the weight scales it vertically (17:15) and we have a fixed firing threshold and biological networks it can be adaptive but in this case we we make it uh fixed and so this is this has the advantage of being both a biologically inspired model and it allows rich temporal dynamics uh it's maybe a bit more computationally intensive than other models but we wanted to show that it's possible to do to do it with this and um so it's important that that the neuron is is leaky because this allows forgetting input so this allows more interesting uh interplay of temporal dynamics (17:55) as the inputs are forgotten okay so the how do we compute the spike time of neuron basically this is the this is our equation that the membrane potential for a given set of inputs equals the firing threshold and then we if you do the math you get this equation for computing the output spike time this is the lumbar w function uh and a and b here are depends on the weights and on the input spike times so what is a bit tricky here is to to find the correct set of inputs uh that determines the neuron to spy because you might (18:33) predict the spike and then another spike might come in between so you have to be a bit careful um but basically we sort and add the spikes one by one and we get the output spectrum and anemia may not spike and in the model that we present here uh every non spikes at most ones so another thing that we introduce are synchronization pulses uh which are sets of neurons that are connected to each known input layer they can be shared between layers or they can be individually connected to two different layers so these pulses (19:08) they act like temporal biases so they sort of give a time reference for the network and they're also important in ensuring that eventually there are spikes across the whole network and this would turn out to be very important during the learning process as you will see and so the process have learned about spike times and weights uh in the same way that i will show a bit later um that the regular neurons and weights are are being learned okay so now i'm going to give a sketch of the universal approximation proof for (19:42) for this model uh just in in very easy terms so the problem is given a well-behaved function f with n inputs and when output find the spiking network that approximates f within epsilon so an attract that spikes at the time f of of the given input plus minus epsilon um so the firing threshold and the decay rate are fixed so basically we are looking for an architecture that can solve this problem so i'm going to show three steps first we express smaller than and greater than then we express intervals or hypercubes and then we split the (20:15) function domain into intervals or hypercubes in order to make the approximation okay so in step one we show that we can build metrics that can express the input is smaller than a constant t by producing a spike at approximately a time t out that we decide so the key thing to to see here is that if you have two input spikes with opposite weights so exactly the same weight but with opposite sign then when they are summed the potential is zero but if you move one spike earlier than the other then the sign of the potential will be (20:53) the sign of the spike that came later so um we set the input rate to to something negative to minus the w and then we add a pulse at time t which is the t that that we're making the comparison to um and we set the the weight of p1 to to a w so if the input comes before b1 then eventually the sound potential is going to be positive and if t1 comes after e1 then the potential is going to be negative it might be just slightly negative but we're just interested in the sign okay uh so this means that eventually (21:33) this potential is going to be positive if and only if this condition is fulfilled so if the input came before t and then what we do is very very close to t out since we're approximating so it's just very very close not exactly um we add two pulses one pulse p2 with a very very large wig that almost instantly raises the potential to the fairing threshold and then another pulse p3 with very large negative weight that comes exactly at the time when p2 would hit the the firing threshold if the potential were zero (22:08) so basically this means that the neuron is going to fire due to p2 if and only if the potential uh is going to be positive the sign of the potential is positive which only happens if ti came before p1 okay if the potential is even slightly negative then p3 is going to stop the neuron from firing all right and we can do the the same kind of reasoning also for the other condition that a spike is larger than than some given uh constant t so you can see here how how the sign of the potential changes so this is the sum between (22:49) p1 and ti and you can see that there's a spike if and only the eye is in the blue area okay so now in step two we combine the networks that we obtained in step one using an end and we express this kind of conditions uh so basically in the previous step we solve the problem that is the input before or after t1 is the input before after t2 so we can combine this condition so we can say um t1 uh so we can make the same number that we did before to express that um t1 is greater than t capital one and smaller than t2 (23:34) um and then for the second input you can do the same so basically you obtain these um squares if you want or hypercubes if you're going to into multiple dimensions um and in all the all the cases you can reuse p2 and p3 because you want everything to spike at approximately the same time so now you have this kind of network and basically all you have to do now to do the end is to assign the weight in such a way that the neuron is going to spike if and only off all the input spike at the same time approximately at the same time (24:10) okay and now finally in step three uh we split the function domain into equally sized hypercubes and then we approximate the function in each hypercube using what we had at step two and as we find the subdivision the approximate becomes more and more accurate and you can see here an example this is approximating the target function with a little bit of noise that i think you cannot see here but um basically the the more you split it the the more hypercubes you have the better the approximation is um so just a technical deal that if the (24:45) function is lip sheets which means there's a bound to how much the functional value changes basically then we can bound the number of subdivisions so that is the number of numbers required for approximating the function to epsilon to this number where k is constant uh if you want more mathematical distress then you can look at our paper all right so now that we have this model um we can use backward regression to teach it so the usual problem with spiking networks is that the spike events are not differentiable (25:21) um but temporal coding overcomes this problem um so basically here the learning goal is to adjust the timing of the outputs but the timing of the outputs depends on the timing of the inputs so recall that this was the solution to the equation that we had before so basically t out depends on on the weights wi and on ti which are hidden in a and b here so basically you can take the derivatives of this and they don't look so pretty but they're computable so um this is what what we get in the end and so once we have this setup we can (26:01) just do what we do for conventional networks we can use an optimizer and minimize the cross entropy loss in our case we use the atom optimizer and the difference is that in the output layer we want to minimize as opposed to maximize the spike time so for this we do soft max on the negative spike times just to add a minus that is going to propagate and make everything um and minimize things instead of maximize them okay so some training challenges challenges that we had were uh the following first of all initialization is very important with (26:36) spiking networks so enough neurons to spike in the beginning that um there's some gradient that starts flowing in enough neurons basically and for this we use the modified blur addition initialization um so we have the standard deviation depending on the number of inputs and outputs but also a custom mean for for the distribution from which the weights are drawn um and this also actually this this allows some neurons to specialize into or to to be encouraged to be uh inhibitory or excitatory if you put a negative or a (27:10) positive mean um then the other problem is that as a member as the membrane potential a process approaches the threshold so the neuron barely spikes or barely doesn't spike then the derivatives approach infinity and to avoid this problem we have hyper parameters that clips the derivative um some things that helped with training were quite surprisingly updating the network only when the classification was wrong so if we had some inputs that were classified correctly we if we didn't touch the network so if we didn't (27:46) encourage it to learn even more the distinction then um we got better results and also very small batch sizes worked better and we're not sure why actually maybe this is something we might discuss during the the discussion if the other speakers might have similar experiences so uh some other ideas that we explored but that didn't lift improvements were regularization in the form of weight decay or adding random noise to inputs or to to hidden neurons or to poses we also tried something brain inspired um or retina inspired to add bipolar (28:26) neurons that respond to um so so for the same pixel one yarn that responds to brightness and one neuron that responds to darkness basically but this didn't seem to help and we also tried uh to ease the computation by forgetting inputs when they indicate below threshold but this also didn't seem to help okay so now i'm going to show some results that we got so first of all we tried very simple networks on very simple problems so we had the n or and xor and concentric circles encoded in time with spike times between (29:01) zero and one and we had very small networks so with just two hidden uh neurons and once in transition pose connected to all the non-input layers and this is what the classification boundaries look like so for each problem for example for and we have the first input spike time and the second second input spike time so this basically represents the values of the two inputs and this is the classification boundary that we got for each problem and uh yeah just an example of of how it works um here i'm plotting the timing (29:39) um in the hidden layer and in the output layer so the orange line represents the pulse which was connected to the whole network then these are the hidden neurons so as the inputs come at two times they cause a different increase in the membrane potential then it goes to spikes over here and then the in the output neuron you you have the spikes of the hidden neurons um and actually in this picture it looks as if the network spikes the two to output neurons spike at the same time it looks like they're the same (30:12) but actually basically the network learned how to barely discriminate between the two so the classification is constantly um correct it's just that the timing is is very very close and in this case um for this problem is because we didn't encourage the network so we didn't train the network if an output was classified correctly only if if it was incorrect so this leads to this kind of behavior okay so then we did an experiment on mnist did it so this is handwritten digit recognition and uh we did a hyperparameter search so (30:47) these are the parameters that we had the decay constant the fire threshold number of hidden layers number of pulses per layer a multiplier for for the initialization of the weights of the pulses and regular neurons a different learning rate for the network weights and the pulse timings then the batch size for the optimization the clipping value for derivatives so they don't reach infinity and the penalty added to present the quits if anyone didn't fire so basically boosting weights if the neuron didn't (31:21) fire so some things that i want to draw attention to here are the fact that uh for the weight initialization the chosen value was negative for non-pulses for the regular neurons in the network and positive for the pulses so this means that basically the pulses were encouraged to be excitatory whereas the long pulses were encouraged to be inhibitory slightly and the other thing is that the batch size that was chosen was very small so as i said larger bachelors doesn't help okay so in in this experiment based on (32:00) the hybrid parameter search we had the reasonably small network with one hidden layer with 340 neurons and 10 synchronization pulses the digits were encoded at spike times between zero and one and the pulses were connected to each layer and were initialized to spike at evenly distributed times between 0 and 1. (32:22) and the results were that so we got almost 98 percent accuracy on mnist and for comparison we turned a non-convolutional to refer a non-convolutional radio network that had basically a similar accuracy and one thing that was pretty interesting that we did not expect and that we discovered during training is that the same network spontaneously switched between a slow but accurate operating regime and a very fast but slightly less accurate operating regime so you can see here the difference in accuracies in the slower gym is 97.96 and in the (32:58) fast regime is a maximum 97.4 and it's not a big difference but it's consistently lower so we looked we made a plot uh across epochs for the same network basically and we looked at spike times in the various layers so in the first part in this part the slow classification part we had the inputs coming and then the hidden they're activating and then there's the first output spike and then then the mean output spike um and afterwards at some point at this point there's there's a change where the where (33:37) accuracy just goes down to three percent and then the whole network starts operating differently and you can see here that the first spike time the purple line now happens before even the main um spike has the mean spike of the of the hidden layer so this is very fast classification um so uh in this picture you can see this the specific spike times um of of the neurons in each layer when classifying a specific digit so this is the same digit that's being classified in the slow regiment in the fast regime the orange lines are pulses here you can (34:14) see the input spikes then hidden spikes and then you can see that the slow network makes the classification after everything else has spiked um whereas in the first regime you can see that the classification is made even before all all the input neurons have finished spiking so this is really really fast and you can also see here that the second guess of the network's network was a three so it's quite interesting that you can see what the second guess of the network is or what it was more confident about and so on um (34:44) so we wondered why this happened because we didn't hardcode this change from slow to fast regime and we noticed that this change was likely produced by fluctuations in pulse timings caused by a relatively high learning rate as chosen by the hyper parameter search so basically at some point all the pulses synchronized at the sort of uh at the very early stage and then that somehow just flips the operation of the network um okay i think i should try to wrap up um so uh this this finding was interesting because (35:23) uh in human decision making as well you have the same speed accuracy tradeoff where you either wait for more information and you make a more um accurate decision or you make a decision very fast but often it will be less accurate because you have this information uh so one other thing that we looked at was um at how how the output neurons where we're behaving and what the inputs look like and we noticed that there was a lot of uh in inhibitions or negative weights uh in most of the non-post neurons whereas the pulses were actually (35:57) excitatory um and finally one other thing we tried was uh to reconstruct the data so this is something you can do with any network not the spiking networks um so what you can do is you set the input to blank or just noise then you set the target in the output layer so you want to generate a three and then you gradually adjust using the same kind of derivatives as as for web propagation learning you can really just gradually adjust the input to minimize the target output spike time and you have to adjust the parameters a (36:36) little bit and be careful and not adjust too much at once but basically you can do something like stop when the correct class is produced for some number of consecutive epochs and these are some examples of they just like zero one three seven that the network uh generated okay so to conclude um the timing of single spikes can efficiently encode information in the brain which we saw from um multiple um studies um in biology um we've shown a model of a spiking network with a biologically inspired neuron model (37:12) and that does temporal coding which can be trained with back propagation and can perform digit recognition at competitive accuracies and uh we think this this is interesting from a multidisciplinary perspective so uh one thing is that it can shed light on the representational capabilities of biological light matters and and this is what i think is so for me personally this is the the more interesting part but uh it's also interesting from the perspective of of neuromorphic computing and advancing this field in general (37:42) and we have some operations open source code if you're interested in playing with this and i want to thank my colleagues from google who helped with this project and i think i'm ready for questions great thank you very much julia um i think you're you're only going to hear me clapping unfortunately but i'm sure that everyone in the audience was it was similarly appreciative there's lots of questions on the on the router um okay all right so i will start off with the first one so the first question is um saying you (38:15) are using alpha-shaped uh post-synaptic potentials uh have you considered conductance-based synapses um because that's more like how real neurons work oh and also now we're seeing uh as as as the chat catches up you can see that the the audience is all clapping you can see the little emoji scrolling past [Music] thank you um so i didn't uh sorry i am the question can i see it so i'm looking at the the question it's the top voted question um so it's so that is that they're asking about (38:52) alpha shaped um post-synaptic potentials and conductance-based synapses uh yeah that's an interesting question so no we didn't try other models but uh yeah i think indeed it's great to move in a more biologically uh inspired the direction and it would be great to see more work in this field but we haven't tried a good question okay good um all right so the next voted one was actually my one um so i was wondering if so you use the synchronous sync pulses basically to generate activity could noise work just as well by just (39:35) adding a bit of noise so that you just get some random firing or um not really so we actually tried this and we didn't really see that noise helped so we tried multiple ways of adding noise so we tried adding noise to the inputs adding noise to uh non-input neurons we tried adding noise to the pulses we tried with less pulses so it didn't seem like noise really helps so the point is that with synchronization pulses they are learned so their timing is learned and their weight is also learned so this thing you could not have with (40:09) noise so there's some extra information that goes into the process that's important okay so it's not just a case of it generates activity it's actually doing some function yeah okay great um all right so uh the next one is um so um gentine asks in the input is the importance of in the importance of timing for salient information uh wouldn't you think the edges are more important than the middle shape of the s i'm not sure i quite understand but maybe you get it i think i understand this question so (40:46) maybe the point is that that it's important whether i don't know the edges might might change them so when you have a four or nine for example then the edges might be important and distinguish distinguishing between the two i guess now uh i don't know so this is a question of interpretation this is just a way to to encode things with the spiking network and temporal coding but in in the brain so we're not saying this is what the brain does it's just i mean i think it's just a matter of interpretation and (41:19) you you could you could encode things differently um on the other hand we tried um adding as i mentioned we tried adding sort of bipolar neurons so two neurons with the same receptive field that responded to opposite brightness so one responded to brightness and one responded to darkness um so that didn't seem to help in this case but it might be that um also in other data sets you can include things differently for better accuracy yeah it's a totally valid idea okay um all right so i think that you answered the next question but i'll just (41:56) quickly answer it since it's which is um how can you decode the spikes into analog values to use the snn for regression i guess you used it for classification so far and they're asking about regression yeah and um i think you can i mean you can just change just i think you can do it just like in a regular network so if you if you put things like this in with temporal coding and you do the sort of optimization you can just use the same um training setup that you would use for a conventional network to do regression (42:37) okay um yeah and i think we'll see lots of different schemes from from different speakers in this workshop so that should give some ideas for that um all right so daniel asked the next question which is uh it's about oscillations so it says theta is a very important oscillator in the hippocampus but there's also slow gamma at 30 hertz which is enriched during exploratory behavior in mice do you think multiple phase codes could exist in parallel at the same time and if so what kind of functions might that (43:05) support yeah that's a very interesting question so indeed so for example one piece of research that i saw about this was um something like uh um using finita and gamma oscillations for short-term memory to encode objects so basically the the gamma waves um being used to to encode objects within the theta cycles um yeah so i don't know a lot about this but yes i think there is a bit of research in this area and i think there are lots of things that that we don't um really know and there are also many things that arise maybe they're (43:52) maybe phenomenal so some people think that brain rhythms are just epiphenomenal that they don't necessarily play a role um so yeah it's it's a very interesting question and i think there are many things that that we don't know about how it works there's some research and for example with short term memory i'm sure there's more about it okay um all right so the next uh question is from tim musgelier who i guess is the person who's done the work that's most similar to this he's also (44:23) done some work on training the output spike times with with a single spike sort of assumption and he's asking if you train only the weights or do you also train the time scales of the alpha functions and and freedom throws in an extra question as well which is um did you change those time scales individually or are they all tied so we've got a bunch of questions there we'll just stream the synaptic weights and the timing of the pulses that's all other parameters we said during the hyper parameter site (44:56) so there's some a bit of um tinkering there but during train ones we set the parameters of the network we only train the synaptic waste okay and also so in this model all the neurons have the same parameters basically you could have a model with different parameters for different neurons and adjust them but then you would have a lot of parameters and we found that it's not really necessary it could be useful for other more complex data sets maybe okay um so for the next question i'm hoping that someone (45:33) is going to come on screen um lauren lauren perrine has said that he could come on screen but uh i might just wait to wait for a few seconds see if he answers um tim in the chat says okay thanks to that one okay well while we wait for lauren to answer that i'll ask the next one um so um colin is asking i'm not quite understanding how temporal encoding overcomes none differentiability of spikes i know this is the point of the work but could you recap this part um yeah okay okay so the idea is that in order to do back (46:14) propagation so in back propagation and gradient learning you want to adjust some parameters of the network based on the output so you know in this in which direction you want to change the output and based on that direction you adjust the parameters in the network to make that direction more likely um so with temporal coding you want to adjust the timing of spikes but you know that the time spikes depends on the timing of the input spikes of the spikes and so on so you can propagate this and it also depends on the weights so you can also have (46:49) derivative with respect to the weights okay actually i had to follow up on that which is what i think you said it but i missed it which was what do you do when there shouldn't be an output spike um we don't have anything because yeah so we always want there to be an announcement basically um so we find that in this model because we're minimizing that is their spike time and maximizing the spikes that we don't want we end up with the important things spiking quite fast and then there are also spikes in the neurons (47:28) that don't uh reflect the current class but they fire later so technically we could then just remove um the pulses that cause them to spike because it's mostly pulses that eventually make them spike so we find that there's a there's a so we could just change the network in order to have only uh only the important spikes occurring but there's no case in in this model where we don't want something to spike explicitly okay yeah uh right so i think we have um laura on the screen now to ask the next (47:59) one hello can you hear me yes yes oh good it's great to have a 400 people uh looking at this uh workshop thanks dan and clement for this my question is just that um it looks very impressive to have this network working it seems to work on discrete time and i can imagine that you can implement a neuron that will be a second order linear equation that will implement these alpha functions and but from from your computation of the output strikes could you uh uh implement which will be even better but you will not need to have the (48:43) computation at every discrete time but that you will have only the computation of the spike times and lose the computation at all only these times which would be very important for neuromorphic chips um yes you could do it basically so we just have this because we have a single spike per neuron and we just have the model set up in such a way that you can just do everything feed forward but yes in this model just nothing stops you from accumulating spikes at every neuron as they come and just having an event-based implementation yes it's possible (49:18) okay great thanks okay great okay i think we're actually already running over quite a few minutes so i think let's just make it one last question um so we have someone asking they say basically uh you mentioned relative time of first spikes and they say relative to what and i i guess the question is so in in your formulation it makes sense because everything only spikes once there's only one spike window so it actually isn't really relative it's relative to the start of the thing but i guess they're asking (49:45) what would the more general setting here be yeah so you can have two things here so either neurons the spike relative to each other so maybe that encode computing information so if something encodes red and something it goes blue then if red spikes then the blue doesn't spike and is inhibited for example so you can have this sort of local competition but also um in the human brain um as in the example of the hippocampus with the phase precession the spikes can be relative to the brain rhythms that occur in that area so um actually (50:22) maybe maybe i can show the slide where i answered this question um yeah so with this slide i haven't shown a picture of this but basically the spikes of blace cells and grid cells are timed with respect to the platoon so they fire earlier with respect to the tethering phase when the animal is closer to the preferred receptive field of that cell okay yeah okay great um i think we probably have to leave it there i've run uh eight minutes over over what we said um what i'll do is i'll leave this session open i'll i'll end the broadcast (51:08) i'll leave the session open and and julia if you feel up to it you could hang around and maybe ask to answer the remaining questions in the chat um and also i don't know do you have a twitter account people could maybe follow up with for some of the other questions or whatever you're like really yeah so i have a twitter account it's not very active but my google it maybe i can just write it somewhere um sure yeah if you just write that in the chat okay so i'm happy to receive any questions and (51:44) we also have so i had the link to the open source code and i think if you if you google this then you will find our work online and thank you so much someone shared the the link to the to your code earlier already so we've had that in the chat brilliant all right well thank you very much again and uh thank you from everyone yeah thank you very much it's been great thanks that's great all right and to everyone else uh we will be back i think in about 20 minutes time okay all right enjoy the break bye for (52:14) now bye,,,,,,,,,,
https://www.youtube.com/watch?v=8ivYxlLQvcU&list=PL09WqqDbQWHFvM9DFYkM_GfnrVnIdLRhy&index=3,2020,SNUFA Workshop,Franz Scherr,TU Graz,E-prop: A biologically inspired paradigm for learning in RSNNs,Learning,(148) Franz Scherr (TUG) - E-prop: A biologically inspired paradigm for learning in RSNNs - YouTube https://www.youtube.com/watch?v=8ivYxlLQvcU Transcript: (00:06) okay hello everyone and welcome to the uh the third session of the uh the third talk of the day um we have uh franz scheer from doing a phd in the group of wolfgang mass and uh and he's going to be talking about more biologically inspired learning for us great friends can you take it away yeah so thanks for the introduction and also thanks for the invitation of course i'm happy to be here and to have the opportunity to discuss this with such a great uh crowd yeah and uh like said so in the next half an hour i will uh (00:45) talk about the biologically inspired learning algorithm for recurrent networks of spiky neurons which we call epro and so uh the work that i present here is actually collaborative effort of the people that you see here listed below and so this research was led by wolfgang mars alright so i have divided this talk into some parts where i will first start out with some background information afterwards we will quickly dive into the algorithm itself then i will discuss also an extension grid and eventually i will try to conclude (01:25) the talk with a short summary all right so why would they actually want to study recurrent networks of spiky neurons because they're sometimes referred to as being notoriously hard to train and so one motivation of course is the brain employs some spike ignorance as its computational substrate so to say and these networks are actually highly recurrent also and so if we understand better uh the learning our procedures in in spike ignorance and recurrent ones uh we actually gain also a better understanding uh how of how the brain works and so the (02:08) obvious question is why did actually nature decide to use such recurrent networks and of course it must have some reason for this decision and there are some obvious advantages to this kind of architecture so first of all recurrent networks are really good in tasks that have like strong temporal component so for example humans are experience experience a lot of uh sensor sensory uh sensations uh through time and they have like to have to piece together all these different kinds of evidence in order to come up with a more accurate (02:54) description or belief of the environment that they act in and so what is also the case is that humans are very good at making decision very fast if they're required very fast so imagine an emergency scenario a human can quickly decide what should be done right but as more compute time is allocated to this kind of decision problem humans can also refine the decision and think of it in many different kind of aspects and so such an iterative kind of scheme fits very naturally with uh recruit neural networks all right and so also if you consider (03:41) machine learning perspective uh in order to get more performance in some some kind of tasks one often kind of increases the model size stacking more and more layers and so uh with recurrent networks you can consider like each computational time step as one section layer and so therefore it has already been shown that you can achieve a similar accuracy with a recurrent network despite having a much smaller network actually and so for all of these reasons recurrent networks are actually also a very attractive choice for future implementations of (04:22) of uh kind of uh neural networks in hardware so neuromorphic hardware is the field in which this is interesting all right and so some of these kind of advantages were also picked up by by machine learning and have led over there to kind of very impressive results and so the one of the famous architectures that are recurrent there are so-called lstm networks which have like an additional memory uh cell content which enables these networks to further accumulate evidence from past from past tenses and so of course uh an architecture is (05:06) just half the brand someone also needs a like a training or optimization kind of algorithm a learning algorithm which actually uh can install and make use make use of this recurrent architecture and install some function and so in machine learning this is quite every time a gradient-based learning method in particular back propagation for time and so these kind of items some kind of recurrent architecture plus the training method back propagation for time have resulted in many impressive results but you can still say that brains are (05:53) quite superior still to all what we have seen because they're really learning machines in fact and they do employ recurrent networks of spiking neurons and also it's quite impossible that the back propagation for time is actually used as a learning algorithm uh in these networks or in the brain more specifically and so therefore we consider biological glossier replacements for these two items so instead of lstm networks uh in all of the results that i'm going to show you we will be using uh lsn ends (06:30) which on which i will elaborate later and instead of back propagation for time we will use e-prop all right so uh let me shortly clarify what ls and n's actually are so ls and ends are simply recurrent networks of spiking neurons where some of the neurons have exhibit spike frequency adaptation so sander had already uh talked about this earlier and so the basic principle of the spike frequency adaptation is that the neuron adapts its spike output in response to a constant stimulus and so this amounts to a slower internal (07:12) processes like an adaptive threshold and it has been shown by one by guan banik that this helps gradient based learning methods to achieve a performance that is similar to lstm networks in really difficult tasks all right and so a few words to back propagation for time also so it is widely known that the back propagation can be used to minimize a loss function with respect to the parameters of a neural network by gradient descent because gradients are what is what is being computed with background and so back propagation for time is (07:55) simply the extension to recurrent matrix and so let me shortly tell you how this works so back propagation for time simply uh uh makes uh this kind of virtual unrolling of the computation in such a recurrent network where you kind of uh consider that each computation timestamp is represented by a virtual copy of of this recurrent network and the outputs that are produced by this uh by this network at one time step are being sent to the virtual copy of the network at the next time step and so after some time of uh computation (08:38) uh you're actually then able to evaluate the loss function e which you would like to improve and so for that you simply then apply back rob to this virtually unrolled neural network and so here comes the problem with this kind of algorithm it requires that all the intermediate states that correspond to the different times within the computation have to be stored because then when the loss function is evaluated you need to propagate the gradients starting from the last computation time step backwards through time and so this makes (09:18) it highly impossible that the brain could actually implement such an algorithm for learning and so we considered this problem and tried to uh overcome this somehow and so what came out of these efforts is eprom which was recently uh published in nature communications and so uh the basic idea of e-probe is to use some biological inspiration or more particularly observations that have that one has seen in the brain so the first uh key element is that sinuses uh obviously maintain like a fading memory of recent activity (10:01) that is local to the science which are often called also eligibility choices and so then the second kind of observation is that there exists a lot of so-called top-down learning signals in the brain which can take on various different forms very popular of course neuromodulators and this can cause a large synaptic plasticity or large changes in the synaptic weights if they were for example preceded by by synaptic activity which further implies the existence of such eligibility traces all right and so we take these two (10:43) ingredients and our goal is like before to minimize a loss function uh by applying synthetic plasticity but uh instead of this cumbersome offline processing that is required with back propagation for time we want to have like an online rule that would be plus will also would also be possible to be implemented by the brain and so uh we can write this down in that we adapt the weights in the direction of this product where one component should represent the eligibility trace and so this should be specific for each (11:24) synapse and also independent of the loss function because it just should trace like recent activity local to the science and then on the other hand we have a top-down learning signal which should uh transmit the like the task rather than the information whatever that may be we will see it later right and so this is uh specific to the postsynaptic neuron so it's much more fine-grained than like a scalar reward signal let's see and so uh we want to connect this of course to gradient based learning and so this means if we actually apply (12:06) this line with a smaller small enough learning rate that would correspond effectively to gradient descent uh if the gradient of the loss with respect to the dyslexic weights are given just by the sum of these products in time and so now i'm going to show you um if we uh carry out the math what meaning actually uh comes to be for the learning signals and the achievability traces so what is the form the mathematical form that they assume and for that we start with the computational graph where we have represented each (12:48) computational time step and then we say the hidden state there exists a hidden state of neuron which summarizes the current state of the membrane voltage maybe also the current state of spike frequency adaptation and all kinds of other internal processes that describe the behavior of the neuron and so we've said we denote the output of such neuron which in a spike neuron is just a spike all right and so uh if we apply back propagation for time uh we would um start of course at the end of the computation and propagate the backwards in time uh (13:30) these gradients which is uh the derivative of the loss with respect to the hidden state at every time step and so our strategy will be to kind of separate out the internal processes of the neuron which we can achieve if we apply the chain rule uh at the nodes of the hidden states in each time instead so if we do this here for example we end up with this slightly expanded expression which here includes the derivative of the loss with respect to the hidden state in the next time step and so we can perform this iteratively (14:13) and after some manipulation of the expanded expression that we get there we basically end up with this at first complicated um looking expression but here already we can read off what meaning we can attribute to the learning signal and to the eligibility choices so here of course it makes sense to say okay the learning signal should now be this derivative which actually just tells us how the loss function would change if we change the output of the neuron at that time step which kind of makes is sensible for for (14:55) the term of a learning signal and then on the other hand we have the eligibility trace and this should now be represented uh by the rest of this expression and so as you can see what the eligibility trace does is it tracks how the synapse affects the hidden states of that postsynaptic neuron and this kind of attack is propagated forward in time according to the dynamics of the post-synaptic neuron so we can write down like a recursive expression for the computation of this eligibility traits and we can compute this alongside (15:36) network computation independent of how long how many computational time steps there are all right and so far now we have just uh reformulated the gradients of a recurrent neural network right so this representation still yields the same gradient that would also obtain with back propagation for time but we have separated out the neuron specific dynamics and summarize them as section eligibility trace okay and so now let me remind you uh our initial goal was to have a learning algorithm that can work just alongside the network computation (16:22) and so obviously this learning signal that i mentioned before is actually not available at the time step at which it is required because the output of neuron can also affect like future hidden states of other neurons and therefore we cannot know this at the time step t and so at this point uh we say all right but we have like uh accumulated a lot of information already in the eligibility traces and at this point we kind of afford to have an approximation so we say we just work with what is available at the current time step (17:03) and so this would amount to a broadcast of instantaneously arising losses so how does the neural output immediately affect this loss function and that means also that we by taking this approximation we deviate from like the true gradients that we would also obtain with black propagation for time but now we can perform online learning okay and so now let me demonstrate to you that we can we are still able to perform a monthly bill credit assignment non-trivial temporal credit assignment and i show this to you on the basis of (17:43) the following diagnostic tasks so here in this task the network receives a queue inputs in the left and at the right side and after a delay the network has to uh report on which side there were more cues and so because of this a non-zero learning signal meaning a broadcast of an instantaneous loss is only defined during such during this decision period and therefore also synaptic plasticity can only happen during this decision period but the difficult thing is uh the plasticity that is applied at this point in time (18:26) has to affect the computation that happened long before in particular the integration of these queues and so the way how this works is uh the input can of course activity in the spiking network and this activity in turn causes eligibility traces and so as you can see uh uh i mean we have to apply to uh we have used here uh uh normal lyft neurons and for such leaf neurons with integrated fire neurons the eligibility traces decay very quickly but we also employed the english ls and ends uh neurons with slower antenna processes (19:09) such as spike frequency adaptation which then result in much longer lasting eligibility traces that actually extend into this decision period and therefore combined with the learning signals can cause synaptic plasticity which eventually enabled the network to learn this task and so we also applied the this learning rule to non-trivial tasks or non-point tasks maybe but also to tasks that are considered in machine learning as well so for example the recognition of spoken phonemes in the timid data set and so over there (19:52) we use the same recurrent network architecture being lsn's and we trained a number of networks either with back propagation or with eprom and so what we obtained here is that the performance of the networks be trained with apra was actually pretty close to the networks uh that were trained with black propagation for time and so this uh is really uh cool in this in in this following sense because uh epro of course uh can be performed online just alongside network computation which fact propagation for time cannot (20:33) and so one remark that i would like to point out here is um the recurrent connections do really matter a lot in this task because you also trained fifa networks on this task that were much larger but performance wise they were no match for the recurrent networks all right and so these kind of gradient based learning methods they have this great flexibility in specifying what the last function should be right so we cannot only consider supervised learning but we can also use loss functions that are used or employed (21:12) in deep reinforcement learning so policy gradient with active critic let's say and so uh this actually resulted in a learning algorithm that we call reverb-based eprom and that allows networks to learn trust from rewards and so we tested this on the benchmark of atari games here in particular the game of pong where spiking network received the current frame of the game screen as an input so very high dimensional observation and then has to decide on which action to take in order to beat the opponent so in this case here the network (21:54) controls the green panel the green pedal and then it successfully outplays the opponent despite only receiving uh reward signals without any further teacher which rather demonstrates how versatile these approaches are all right so now i come already to a to an extension to eprom which uh specifically tries to address the learning speed of improv as you might recall uh i've said um now this ideal learning signal which would um actually make the gradients uh equivalent to those that were that would be obtained with fact propagation of (22:40) time they are not available at the current time step and so therefore we had to use some approximation of it like an instantaneous broadcast but in the view of biology i did that seems to be rather talk right because uh it is actually the case that learning signals are generated within the brain itself and so one could argue that the generation of the distribution of such learning signals was quite a bit optimized through evolutionary processes let's say in order to support fast learning of survival relevant tasks (23:22) and so one region which you could identify as distributing uh specialized landing signals is the area of eta because it was recently shown that it not only uh kind of uh transmits a scalar reward prediction error rather there is a much task rather than information also contained in this signal and this arrives at different populations of neurons as well and so uh we kind of further take this inspiration and we model this kind of with our own artificial vta let's say and so uh now what is promising about this approach is (24:09) since uh this learning signal generator as we call it has its own computational facilities it could possibly come up with much better learning signals that are really tailor-made for the kind of problems that are likely to be encountered and so uh we still use eprop in for the connections that are shown here in grant with the eligibility traces just as before but now the learning signals are not the random broadcasts rather they are being sent from this learning signal generator okay and so now uh we wanted to (24:48) evaluate um this uh learning architecture on how fast it can actually learn uh learn something and so for this purpose we use the omniglial dataset which actually consists of uh many different handwritten characters from many different alphabets and so each character represents a different category we can see uh some samples of different categories here and in addition uh there is also significant variation within each category because you can draw each character differently so it's a standard data set of meta learning (25:29) actually and so now let me tell you uh how we constructed the task uh in order to uh to evaluate this learning approach so we were particularly interested in one shot learning meaning that the network should be able to learn uh to classify uh and or to learn what is a category right just by seeing one sample of such a category and so for this purpose we came up with the following task fraction where in a phase one the network is shown a sample from the target category and then it proceeds into a second phase where it is shown a sequence (26:14) of uh different samples from different categories and then it has to report uh at which point a sample from the from the target category was present so in this case uh it was the third sample in the second phase and the network has to report at this point in time that this is the this is like the sample from the from the target category so if it reports uh at a different point in time that uh uh it's it's it's a sample from the target category it would be counted as as an error and so let me uh also lose a few words (26:56) about the concrete architecture that we used for this task so like said we had we have two networks we have this learning signal generator and we also have this learning network which applies synaptic plasticity and then for this task because we're working with uh image kind of input we also use a cnn but it consists of rather simple mcculloch pits neurons which are just threshold gates and so concretely when a network learns um a new category uh uh it actually applies uh this learning rule with a natural eprom (27:43) in this first phase so it applies eeprom but the learning signals come from the learning signal generator and then we've now changed weights the network goes into phase two has to perform the task but in this phase two we inhibit the learning signal generator such that no plasticity takes place anymore and so at this point you might kind of wonder who does actually optimize the weights in this learning signal generator or how does actually the learning signal generator know what is a good learning scenario right (28:22) that supports fast learning and so to address this we introduce another kind of learning process that acts on a much slower time scale across many different such one-shot learning tasks which could correspond to evolutionary processes and so we use here a back propagation for time to optimize the weights of the learning signal generator and also the initial weights of the learning network but for if we then evaluate the learning performance we turn off this slow learning process such that there are such that no effects (29:05) can such that no learning performance is actually uh implemented by bank propagation for time afterwards all right and so we carried out our tests and we found the uh the human performance is likely around 85 percent based on the informal testing uh just in our group and the results that we achieved with this learning setup was actually pretty close to this performance and so like said we did evaluate this without back propagation for time happening in a silver time scale anymore and we evaluated the learning performance (29:48) on categories that the network has never seen before and so as a comparison we also trained uh like a normal network uh to do the same kind of one-shot learning just by uh remembering uh kind of features in its intel state and it resulted in inferior performance and so here's an example of the natural color learning in a new task where we have in the first phase learning signals being generated by the learning by the learnings in the generator which are then transmitted to the learning network and then cause synaptic (30:28) plasticity and this results then in the network to correctly report when a sample of the same category is shown in phase two all right and so there are also additional kind of uh fast learning tasks that we uh could achieve with with this kind of concept of natural hebrew for example we showed that it is possible to do one shot learning a few arm movements and also fast learning of posterior probabilities but i won't go into detail for these kind of tasks rather i want to conclude the presentation and summarize quickly what we have been (31:12) talking about so far so first of all we have seen that we can modify kind of the gradient representation or the way how back propagation for time computes gradients and factor out the internal processes within the neuron such that we obtain such eligibility traces and then we have seen that even if we approximate kind of the learning signals within this uh learning algorithm such that it becomes an online algorithm we can still match very closely the performance to back propagation for time in many different tasks that are also of (31:57) interest in machine learning uh for example uh reinforcement then um right and uh we argue that um he probe with kind of online learning scenes is really powerful indeed if the if the neurons that are being used uh exhibit some slow kind of internal dynamics such as like frequency adaptation because they result in long lasting eligibility traces and so then we also have seen some extension to eprob where we use some kind of refined learning signals which are computed also by recurrent network of spiking neurons and this gives rise to a very fast (32:42) learning capabilities so in fact one shot learning on some tasks which we call natural apron all right and so this brings me already to the end of the presentation uh where i would like to thank you for attention and i'm happy to answer your questions now great thank you very much friends um you'll only hear the clapping from me but you'll you'll probably get some some clap emoji coming through on the uh on the chat in a minute which i don't know if you can see or not because i think you're on a one screen (33:15) setup um cool okay so there's been lots of uh there's been lots of interesting discussions um lots of interesting questions posed and we could probably spend hours speaking about them more um i think we can we can kick off with one that i asked right near the beginning which was when you were talking about recurrent neural networks it reminded me that there was a twitter discussion the other day and simon cornberg said that recurrent neural networks were just equivalent to feed forward networks with weight (33:43) sharing um do you think that perspective is fair or not yeah i mean it depends on how you think of it right when you consider recurrent neural network right that uh performs computation for some time right uh it would uh with each computation times that add another layer to this uh feedback network right so if if you want to represent the computation of the recurrent neural network uh with a feed for an effect that has weight sharing maybe for a month of time so let's say a few seconds that would lead to like thousands of layers within this uh (34:27) cool okay so i think for the next question uh we have freedman on the screen to ask hi hi friends thanks for the nice talk so i was wondering also when reading the papers like that you often have these two neuron types the one with uh the slow adaptation time scale and the ones without and uh and i was wondering why i i always felt probably the ones with adaptation just maybe with a different time scale or more of them would be fine so i wondered where they comment on that right i think this is a very good question (34:58) so in principle of course you could say um we now use just um uh neurons which like actual adaptation uh and like um doing this with great and decent and how much the impact of this is right but so we actually uh did not do this right so we just said um okay there is a number of neurons that exhibit this by frequency adaptation according to values uh of uh of like the brain so there is like 40 which have significance by crash adaptation and so we just use this but there is no reason uh to uh do it exactly this way and so i (35:37) think um uh already sander considered to optimize uh you have the time constants and everything uh for such adapting neurons i hope this answers the question oh sorry i admitted three months sorry i need to do did you want to follow up on that for them uh no i'm fine i'm fine thanks for muting me no sorry i just was quickly enough for my headphones tonight a reverb i guess um no thank that answers the question thank you very much cool um all right so uh the next question i'm gonna ask is um so this is a it's a bit of a it's a (36:26) two-part a long two-part question so um it's from a user yigit i don't know if that's uh what that is exactly uh so hi friends fantastic work with eprop i have two related questions first lif requires e-trace per neuron whereas alif requires a trace per synapse what kind of tasks do require e-prop to have e-trace per synapse to perform well um yeah that's uh i think this is a good question and so uh uh we kind of started out of course with with the idea that every sign obsessed it's on lgbt trends (37:04) and so it's it's just a mathematical result that uh in the neurons you can represent this per neuron on a parallel basis right and so it turns out if this postsynaptic dynamics i mean the dynamics of this phosphatic neuron include terms that depend on the positive postsynaptic neuron then the eligibility traces really have to become uh sign up specific right because in the div kind of uh case uh the positive dynamics is just this dk right uh according to the membrane time constant and so therefore this is a more special (37:50) case that you can use uh eligibility traces um for your creasing of the kinema i mean it's a little bit more difficult uh because you also have they are the skating right uh this uh voltage dependent turn on the post synthetic side and so therefore uh the e trace itself is always themselves specific but the part that you propagate forward in time that can be uh specific only on the per neuron basis so i think it's more like the special case just in the lift case but as the neuron model becomes more complicated (38:31) uh your you will end up with uh specifically phrases okay there was a there was a follow-up as well the second part of the question was uh can you use uh an lif with a long e trace time constant uh b computationally equivalent to an alf neuron um so i assume uh if you have the time constant of the membrane voltage decay very long kind of long is this true or is this uh that's that's the that was the question as i so i think uh there may be a few answers to this question uh and so the first thing is um uh the time constant that with with (39:24) which they each raise the case depends uh just on the dynamics of the postsynaptic neural line so if you want to have long lasting uh eligibility tracers the neurons have to have a long uh long scale um like a really uh dynamics that happens on a slower time scheme and so for just lift case that would mean um it would have to have a membrane time constant that is very large and so i'm not sure if that would like uh lead to an equivalent to these adapting neurons because it kind of kind of hurts the performance so if if (40:08) no neuron actually can't forget any evidence right so this is i think it's very useful if there are also components in the network that um don't have like this long long memory right yeah i think maybe this is already the answer to this question yeah yeah i think so okay so we have um material on screen now to ask his question uh yeah can you hear me yeah okay so uh thank you very very thank you for the nice talk and uh yeah my question is more related to uh the mathematical part of the e-prop so has the eligibility trace is actually (40:46) the uh convolution with the kernel of the member potential in the ala and the leaf case the leaky integrated fire case so is at the end of the day the gradient part of the propagation through time then i'm wondering is e prop then simply somehow the stochastic approximation of vertical back propagation through time as we people does in general with the stochastic gradient descent in the normal fit forward neural networks as every time step you receive uh approximated error signal that is from the approximated gradient (41:22) given the fact that you receive one only one data point every time step and then you accumulate this information um yeah so uh the thing is uh so i'm i'm trying to answer the the first part of the question one uh where he was talking about the convolution with this uh yeah with the postsynaptic exponential i mean so this uh simply arises because um we have factored out the dynamics of the postsynaptic neuron and the dynamics of the postsynaptic theorem is simply this dk right uh expansion okay and so therefore the uh (42:05) this part uh is just uh like the convolution with this uh postsynaptic count that is true right but in the case that the neurons become more and more complicated and have more components in its instant there is also interaction between the components that represent the membrane voltage and other parts well and so the other part of the question uh so i'm not sure if uh understood correctly uh that um yeah maybe you can repeat it there so no they're actually related so they're somehow the same so my question is um we know from (42:49) normal propagation that you can apply stochastic with datasets this is a concept that comes from stochastic optimization you instead of applying and updating the the weight at every time step with the whole gradient you apply one you get one data point at a time and then you approximate the gradient so my question is is that in this perspective e probe the uh stochastic approximation of prep propagation of time because mathematically to me as far as my understanding they look pretty like exactly the same so he's applying (43:24) stochastic greater descent but on replication through time uh no i i wouldn't uh say so because um uh that being a stochastic great reason that you point out is when you have like a complete data set and uh you will just apply updates with respect to some examples right and uh so this is also the case with back propagation for time when you consider just the computation of uh of like some sequences right and so uh so we start there so in the case that we just represent this differently and use this ideal learning signal (44:04) we have the same gradients as back propagation pretend and so therefore we also do need uh this kind of um [Music] uh stochastic uh optimization also here if we um like with a small learning rate we process uh examples at a time and therefore it will end up with uh so has created using but there is this additional part right where we uh approximate the learning signal because the ideal one is not available but we send just the instantaneous broadcasts right and so there uh we kind of uh deviate from the true gradients (44:44) and so therefore we cannot speak anymore from statistic gradient descent maybe because it's like an approximation right and it's for sure bias so it's it's like not an unbiased estimator of the gradient that you would have back for the ratio of the time okay i see i thought that the the approximation they do it every time step is actually somehow as approximate in the gradient but yeah i see the point yes let's say it's uh simply points you know okay cool thank you very much okay yeah unfortunately i think we're going to (45:18) have to wrap it up there there's still 12 questions left uh unanswered uh but uh unfortunately we've got to start the next session um maybe people can either email you or tweet to you or something like that is there any preferred way you'd like people to get in touch if they want to answer ask more questions i think email is probably the best yep okay i mentioned your email is hopefully easy enough to find us by googling you sorry all right that casey um thank you again my friends and uh i think we're about to start the the next (45:50) section next session so i will end the broadcast there thank you very much thanks,,,,,,,,,,
https://www.youtube.com/watch?v=if2Q4BN6htA&list=PL09WqqDbQWHFvM9DFYkM_GfnrVnIdLRhy&index=4,2020,SNUFA Workshop,Emre Neftci,UC Irvine,Synthesizing Machine Intel. in Neuromorphic Computers with Diff. Programming,Theory,(148) Emre Neftci (UCI) - Synthesizing Machine Intel. in Neuromorphic Computers with Diff. Programming - YouTube https://www.youtube.com/watch?v=if2Q4BN6htA Transcript: (00:09) all right welcome back to the last talk of the day before the discussion session and i'm really happy that i can introduce edward nfc our next speaker emery is a professor at uca uh irvine in california so he is on a couple of hours behind swiss and uk time we are really glad that you could make it uh and we are up to that early and i'm very much looking forward to your time all right thank you very much uh later on so let me close this other window here it's echoing all right okay so uh thanks all for (00:46) being here and a huge audience uh so that's uh you know great job uh to the organizers and um i think this might actually be the largest audience i ever spoke to live so uh yeah great so i will be talking today about uh very related topics of what we've seen today with uh sanders and francis talk and also julia's giving i'm giving a lit a twist into neuromorphic computing and neuromorphic hardware because that's mainly what i'm concerned with and what i'm going to tell you is a story about how we can use (01:20) all these nice theories about gradient based learning for you know configuring and using neuromorphic hardware for for practical purposes and even though this talk is really on neuromorphic hardware you'll see actually it's also interesting from a biological uh perspective as well so my uh goal i'd say right now is really to solve this task i think you know this work by josh tenenbaum he had this nice figure showing that so if i give you uh information that these uh objects in the red boxes are called tufas and i tell (01:57) you to find the other tufas in this uh in this figure you'll have no problem in doing this and this is quite remarkable because from these three shots you can actually learn an object that you've presumably never seen before if you haven't seen this paper yet and you know we can do this well we and obviously we've just you've just learned what these uh tufas are and wouldn't it be cool if you can do a build hardware system that would have the same capabilities in learning just on-site at the edge okay (02:27) so neuromorphic engineering is is basically the process of trying to capture the dynamics of neurons and neural networks in an equivalent physical process and this basically occurs starting from the very low level so we use transistors as uh ion channels so essentially you can show that the dynamics that govern ionic currents are the same that govern the electronic currents of substantial transistors or more recently these uh resistive switching rams and you can basically that builds from the bottom up you know synapses neurons and and (03:09) full systems so going up here is really the idea of synthesizing brain or this neuromorphic hardware and the the interest the original interest in in this field was really that after you've built these systems you can break it down and analyze what you've built to understand it better and this is the the process of analysis by synthesis that's put forward by um my faith here carver mead was actually the main uh uh the the central figure behind neuromorphic engineering and the the central point here was that (03:40) the our technology at the time which was analog silicon systems and still today are are similar to our brains basically in that the wire is limited uh power is precious and robustness is essential so it's really um if you can build systems that respect these three conditions and you maybe learned something about the brain so there's this idea of um a hardware uh and uh and uh biology uh a comparison through uh by building uh basically hardware okay so neuromorphic engineering has uh as a computer architecture is quite (04:21) interesting because i mean as you all know neurons have their own dynamics it has its so spikes that are uh output from each neuron basically encoded into this address eventbus that's basically a digital um uh a communication that transmits the address of the neuron that spiked which then gets decoded at the at the receiving side so the the key idea here is that there are very rich local dynamics happening within the neuron but only that uh all or none spike is routed to the other neurons in the network from (05:02) a computer engineering perspective this is fabulous right because it's very scalable we only have these signals these binary signals that are communicated but it's challenging right because a neuron cannot arbitrarily sense the state of another neuron the network it has to do so through these uh spike events to a large extent so what we need here is basically are basically algorithms that are robust to this local uh communication this local computation and from a technology perspective this is not so different from what we see (05:39) in um you know computing and memory you may have heard these uh these uh new hardware architectures were basically computing on the memory and so this is a really real problem now in the technology industry how can you do all these computations with that local information and every every bit that you send actually is costing you uh energy and and space and time okay so that's basically the problem that we're trying to solve so you know we can i'll start here with just the overall view of you know us we have software and uh and hardware (06:14) and machine learning together related through basically the existence of these software machine learning frameworks which can get compiled onto hardware such as gpus and these other new many core processors that are out there so this is basically the ecosystem of machine learning but i'm going to add here the block of neuroscience which basically you know says we have software that can simulate neuroscience for example the nest interest initiative nango or the brian simulator we also have um the basic neuroscience can be directly (06:51) implemented in hardware so to say through this different types of neuromorphic hardware you know developed in zurich heidelberg and or at intel so what i'm going to be interested in is basically creating this uh uh and using this third direction here which is that we can try we can understand neuroscience from a machine learning perspective and we've seen a number of different talks today that uh contribute to that to that connection as well as you know other work in the field some several researchers are now trying to (07:21) use machine learning as uh a metaphor or even as a model of what uh brains might be doing or at least parts of this of the brain so in order to build this uh kind of neuromorphic hardware system and and to um to configure our systems where i'm going to leverage all these different tools that are related uh to machine learning kind of a middle out approach and i like to make a disclaimer here is that i really mean machine learning in this general sense not necessarily a deep learning sense in fact most of the networks that (07:57) we use are not that very deep for machine learning from deep learning terms so how can we do this so how can we relate neuroscience models to software and basically compile them onto neuromorphic hardware there's been some work on this in the past so i know i'd still like to you know acknowledge that so you know pine which is you know this python neural network toolbox for uh you know using different simulation hardware back-ends on the same configuration scheme so you can build populations and connections just map (08:30) them onto hardware we had something similar in the past and ibm built this really nice framework of correlate so there's some work there in the configuration but nothing that really relates to the machine learning to the functional building blocks per se on the other hand you know in deep learning we have nice tools like tensorflow and and pi torch and even some of these are now starting to be implemented in neuromorphic hardware but what we really need is uh you know to to push forward this idea of we need some high level functioning (09:00) ecosystem that can really exploits the unique features of the hardware mainly that it's a dynamical system it's a physical it's a physical process and so that's really what i'm going to be talking about today okay so let's start from the basics here so we've seen these uh integrated and leaky and fire neurons a number of times here um so i'm just going to this is going to be a repeater or if you haven't come to the previous talks well here's uh here it is for the first time so we (09:33) have some membrane potential at time t plus one i'm writing it here in discrete time because that's how i'm going to use it late using it later but there's no specific limitation in using discrete time dynamics so that that membrane potential at that time step is given by the previous time set a membrane potential times some leak term here plus some synaptic inputs from the inputs maybe and minus this term here which acts as a reset potential so i want to be clear here that this is the uh the simplest model that i can use just (10:07) to present the the dynamics here uh but you know we're not limited to these dynamics uh you know all and i suppose how int leak integrated fire neuron works we get these inputs generate these post-synaptic potentials which eventually elicit an uh postsynaptic spike and then the reset okay okay so now what i'm going to do is to cast these dynamics in the form of a computational graph a little bit like we saw in france's talk just earlier and just building it one by one so because we have temporal dynamics (10:39) this also means that we're going to have different states at different time steps so and we need to keep those states in memory in order to build this computational graph so we have this membrane potential u i should have mentioned earlier so we also have the spiking state which is basically equal to in this case a step function of the membrane potential if the membrane potential basically that is larger than zero and then there are the neuron spikes so this means that we basically have an edge that goes from u to s (11:07) which really captures uh this uh computation here okay so i'm now going to add these terms one by one so now we we basically relate the time uh steps to each other through uh the the leak term here which basically feeds u t minus one to uh ut or t to t plus one uh through a leaked term beta we can have these synaptic connections going from the input spikes to the membrane potential like this and we assume here that this is the subsequent layer or the loss function we have some recurrent connections that basically feed that state s back (11:43) into u and may we can also subsume here this uh um this reset term uh as well so what we have here is i mean the particular form of this graph doesn't really matter but it's the idea that this is the same graph as an unfolded artificial recurrent neural network and so through this equivalence what the equivalence being that we started with a spiking neural network and we end up with something that's at least formally looks like a recurrent neural network through that equivalence well we can use then all the wonderful tools of pi torch (12:14) and tensorflow in order to simulate and even train uh our neural network and this is we we've seen this a number of times this back prop through time discussion uh as we saw in the in the previous talks so so here's that framework here uh really the machine learning framework here applied to the spiking neural networks so the idea here is that we can just repeat the same workflow as in machine learning which is that you create some objective function that captures your the performance on some tasks recognition navigation or (12:49) whatever you're interested in which itself is a function of the neuro neural network uh which has neurons of the type that we've just seen before and because we're going to be applying the same tools as machine learning well why not just use gradient descents and that gradient descent on that loss function basically ends up in this three factor learning rule that you may already be familiar with and the three factors being that you know the derivative of the loss is basically something that relates to uh error we have the (13:21) derivative of the activation function uh the theta prime i'll just call it and some synaptic eligibility quite a lot like we've seen in the in the previous talk so the cool thing here is that well this gives us basically a mathematical framework for um uh basically deriving a learning role or even a synaptic plasticity rule that we can implement um on the hardware or or or in your biologic biological model to train uh that neural network so that's it's it's a mathematical framework that relates plasticity to neuron dynamics (13:58) and that means that basically it gives us strategies for hardware design right so if i if i build hardware that has this type of neuron and i want to do gradient descent i'd rather build a plasticity processor or some plasticity dynamics that can support this class of functions okay and obviously as you've seen before this this whole framework basically gives us a bridge between biological neural networks and and machine learning and understand the whole learning process in at least one fundamental way okay (14:31) this is by the way so this is quite different in some ways to spike timing dependent plasticity but also related it's related by the fact that if you look at the updates that you obtain at the end of learning and and you plot them on the graph similarly to scp you see that something that looks like this double exponential uh this is actually a slightly different dynamic by jean pascal pister but um but the results also hold for these uh three factor rules uh it's different however in that uh the the actual learning rule is doing (15:00) something uh very uh a very different it depends on these external errors and so on so in some ways it's it's supportive of stdp as an observation but it also says that well if you want to use stdp for solving practical tasks maybe that's not the best option okay so better use some of these three factor rules okay so i talked that the the top the title of the talk was about differentiable programming and i'd like to talk to you about basic one uh solution to differentiable uh one part of differentiable programming which is (15:30) called auto differentiation it turns out that at least personally i think auto differentiation is really the hidden figure of deep learning success um which is you know hardware basically gpus um and auto differentiation auto differentiation is really that tool that does the magic that you've uh seen in this little piece of uh you've seen this little piece of pi torch you've done this multiple times basically you can calculate your output and you calculate your loss very complicated function but then just (15:58) some magic happens when you just say law stop backward just calculates all those gradients at least in the beginning when i was using theano this was like wow how is this even possible it turns out that actually auto differentiation is a field in itself that exists uh since a very very long time um well very long being uh in the uh 20 30 years which has been applied to scientific computing a lot in the past but the basic idea here is that we can reuse this auto differentiation um on neural networks by by by building these differentiable (16:30) programs composed of these building blocks of of neural networks which i feed forward convolutional and recurrent elements so if this can be done for um artificial neural networks it can also be done actually for you know spiking neural networks as well as this neuromorphic hardware instead of programming our gpu we just program our neuromorphic hardware what we need to need to do this is basically to build the primitives the differentiable primitives in our software so the neuromorphic tensorflow doesn't exist yet but that's (17:01) basically what we're working on okay so now let's take a step back and just go back to this three factor rule that i was discussing earlier so the three factors here is that uh what we want to do is calculate of course the update on this synaptic weights it has these three terms here and there are a couple of challenges in computing these terms and the ones that i've highlighted in blue the first one is that this activation function is non-differentiable um sunderbota actually gave a really nice talk about uh (17:33) about this non-differentiability and how uh uh his approach actually led to the uh uh this idea of surrogate gradients which is basically that we're replacing that uh non-differentiable or this um uh not non-differentiable term by a smooth one for the purposes of optimization only and and freedom on puts this in a really nice way it's basically like you're you're creating a surrogate network in which you're calculating the gradients and applying those gradients onto your original spiking network which (18:04) is a little bit like you know going down this approximate uh smooth valley here so that's an easy problem um and it's largely solved at least for not too deep networks this the second hard problem here actually the is the deep spatial credit assignment problem as you know so if you want to calculate the loss the global loss with respect to your local spike well you need to know how that output spec is going to affect the loss and maybe and depends on all the computations that happen from that neuron to the output so (18:41) this is a hard problem i mean obviously create assignments something that we've heard a lot and that's really the goal so neural networks really uh training solves this problem through back propagation by back propagating the errors through the network this is not very biologically plausible as we've seen before um so one way to as we've seen in the other talks i'm sorry um so one way to overcome this problem is to back propagate the the the errors randomly so that you don't have to have the symmetric (19:12) transpose here or you can broadcast those error signals uh francia was talking about this just in the previous talk and this uh other method that we've been very fond of is this idea of local errors basically you can define a specific loss function for every every layer and train that layer only with that loss function i like to see this whole credit assignment problem as a game of chinese whispers i think it's a nice way of explaining it um so if you have some input coming here at the left and the output is here basically that in (19:46) the beginning that um and your net this table is your neural network so that information gets uh corrupted and then the output is very different from the input but then back part what propagation would do is that just come to that output and say okay the correct answer was this and then he would basically pass that message back into the input and then we have this forward and backward phases so you see that forward and backward phase basically introduces this delay that you really need to do this two-phased learning feedback alignment (20:18) or direct feedback alignments that instead of waiting for instead of giving the uh correct answer to the output you just broadcast it to the entire table and local errors is basically like every person has a partner who tells him what the correct answer is for for that layer so to say okay so that's just one way to see um the these different approaches of back propagation so there are some solutions and they work reasonably well the heart the things become really hard when you have to do the temporal credit assignment so remember i (20:53) mean we're working with a spiking neuron which has its own dynamics and eventually the hardware because it's you know uh is also physical process also has its own dynamics so how do you solve the terrible credit assignment problem back propagation through time is one way but i'd like to give you take one step back and talk to you about auto differentiation which is really you know the fundamental solution to um uh temple cr has the fundamental solution to the credit summit problem so the um so this is just general just (21:24) uh you know forget about spiking neurons uh for for this line so the gradient of some function composition let's say we have some function f of g of x with parameters theta the gradient is going to be a product of jacobian matrices right so and these every term here like we had in three factor rules basically a jacobian matrix well what you can do in order to calculate this gradient is that is that you can just multiply these multiply these matrices basically do this product of matrix you can start from the left and you go to the right (21:58) and if you do this this is like doing back propagation because you start from the loss function you go down maybe to for example the the layer where you have these particular weights assuming this were a neural network so in back propagation through time not tie in is basically the application of back propagation into this unrolled network but that's that's reverse mode uh automatic differentiation that's basically what uh tensorflow and pytorch all these machine learning frameworks natively implement this (22:27) reverse mode but there's also a forward mode because you see i did this product of jacobians here from left to right but i could also do it from right to left right so i can start with this jacobian here then multiply this one here so it's basically as if i'm just putting parentheses in different places um in this product of jacobians so that's one way to see the forward mode automatic differentiation which in uh in recurring neural networks is basically called real-time recurrent learning i'm sorry i (22:58) should have actually written down the uh the actual uh the acronym here so um turns and the reason why we don't use forward mode automatic differentiation is just because it's computationally expensive you can imagine that you know you if you if you you know this jacobian here is basically a much larger jacobian than this one here this is actually a vector on the left and the right we have a matrix here so if you go from right to left here basically you're going to be doing matrix matrix multiplications (23:31) if you go from left to right you're going to be doing vector matrix multiplications okay so that's that's i'm just giving here a very hand wavy uh description of the problem here and in fact this is not how auto differentiation is implemented you can be implemented much more efficient way but it gives you this uh the uh i think the intuitive idea of what does reverse mode what this uh forward mode and what later i'll be talking about mixing forward and and reverse mode um okay so let's come back to this (24:02) temporal credit assignment problem so what we have here is let me just quickly check the time okay so we can apply these two modes so reverse automatic differentiation and forward automatic differentiation to our graph so if we do it then this is the same graph as we had earlier with the integrated fire neurons so if what you do here is that basically you start at time step t and you propagate forward as you propagate forward you you hit this loss function then from that point on you can you take the gradient and then you back (24:36) propagate right so this is the back propagation through time we've seen it many times what you see here is that you only get an update after uh t plus seven steps right that's basically all the steps you need to do in order to go to the loss and then back okay so that means that basically your updates are delayed right so and plus this neuron would need to keep a history of everything that happened in order to calculate those um those gradients in forward uh automatic differentiation basically you just you carry forward all the information (25:07) that you need for calculating the gradients and this really comes by the fact that as you're calculating this product of jacobians from right to left you're basically going with the flow of time so to say and the cool thing when you do this is that you see as soon as you hit that loss function you have your update so this is a an online learning rule okay if you look at the complexity of this problem i'm not going to detail why you end up with these complexities but um it turns out that forward automatic differentiation has a (25:38) terrible time complexity it's it's according on the number of neurons in cubic in space whereas a back proper time is squared and n but it has this dependence on time which is very annoying and partly the reason why we were not able to apply back propagation through time and these very large spike in neural networks it's because it's because of this time term here we need to unroll a lot of steps and that just blows up memory another nice thing actually about forward automatic differentiations that (26:10) you don't really need transposes right because you're you're propagating everything forward and so you don't never actually um need to uh re uh reverse the the direction of these arrows so to say um and automatic differentiation is online but it turns out that you still need some non-local information so forward ad doesn't really solve the problem of local computations local learning as as i've started with today so what can we do so what i'm going to talk to you about is basically an (26:47) approach it's it's a type of mixed automatic differentiation with some approximation on the forward automatic differentiation part and what will result with is an algorithm which has a time complexity that's that's squared space complexity that's uh that's linear um and so we don't need uh transposes it's online and it's local so it really hits all the points here uh that you know it's uh uh this basically an efficient uh learning rule that we can implement in hardware i can't go into the very details of what (27:24) were all the details that were going to go there but i want to give you some just a bit in the following slides so here's that graph again so this in this case is the forward uh the forward a d graph what we want to calculate uh very similarly actually to francis talk is basically this loss term here with respect to the parameters theta actually in this case they're going to be the w's we can decompose this in two parts so the loss with respect to u and the loss with respect to ut of ut with respect to those parameters (27:56) so this is really the part that pulls in the temporal component here if i expand this across the unfolded graph i end up with this equation here right so we have d theta at time t is equal to some term that captures the dynamics you see basically we have ut uh derivative of u2 with respect to ut minus one and you can show that basically you also end up with this other term ut minus one t theta which is the same as this one here okay so basically we have what we have here is a recursive relationship of gt um with itself that pulls in these (28:39) dynamics it's the same it's it's almost a mirror recursive relationship with respect to what's happening in the neural network we also have another term here which is the d of ut and d theta t so using this more compact notation i have in those other braces basically i end up with this recursive relationship here so this is the the the main recursive relationship we need to uh retain in order to uh in order to compute in order to compute these updates and forward uh ad and all this story about synaptic uh (29:12) or neuron eligibilities they actually come from this relationship here which can be shown from basically automatic differentiation okay so this another step that we can do here is that well you see actually these dynamics they actually capture these arrows that go from t plus one to t plus two right but they come from two different places right so i have two arrows here and so i can decompose those two uh components one that is i'll call explicit uh or uh basically explicit recurrences that may come from other neurons (29:46) the implicit recurrences that come from this may come from the same neuron so i'll call this h i and h e okay i'll going to give you more detail on that i'm just going to give you i'll talk to you about one trick here is that these f of t's which is basically the derivative of u with respect to that to their weights at that time step well why calculate them in forward mode right i mean i can we can everything is happening at the same time step so i can just back propagate those uh those signals um uh across that (30:15) time step and this is a little bit like you know the the uh the action potential back propagation within the same neuron you can think of it in that way and so this is where we mix basically forward automatic differentiation and and reverse automatic differentiation but i want to come back to this uh to the separation on these terms because this is really where we gain this huge uh we you know we go from this quartic time complexity to the quadratic one and it's the following here so when you have implicit dynamics (30:48) so the implicit dynamics here is inherently diagonal meaning that it only affects the neuron in itself this is how we defined it as a result so if you multiply diagonal matrices in this case this is kind of a special diagonal matrix well you end up with something that's also diagonal so that this part that diagonal property is preserved across the recurrence uh forward ad for explicit recurrences this is not the case right so if you propagate that this diagonal basically becomes this dense matrix here the immediate jacobians themselves are (31:22) diagonal by design of neural networks so what we can do here is basically just say okay we can't do this right because this just this is quadratic we're never going to solve this problem so we just ignore this red part and a lot of these you know the surrogate gradient learning and also the work that we've done in decal um and and possibly also eproprop i'm not sure i understand all the details there but they you know they rely on some form of sparsification sparsity and approximation as we have (31:49) here in fact the same picture also applies to the case where you have more complex dynamics for example san diego talked about these adaptive neurons that you know guillain-barre and the wolfgang mass team have developed and that the same story applies there where instead of having diagonal matrices just have block diagonal matrices the block diagonal property is preserved across across time so basically what we do is we're just taking this yellow part uh here and because these are sparse matrices we're just computing those sparse (32:22) the elements that are non-zero and this greatly reduces the complexity in our case from you know quadratic from quartic to quadratic in time and from cubic to linear in space uh a quadratic if you have non-linear dynamics um by the way this has also been applied to standard machine learning where in a team in deepmind show that basically sparse approximations to these explicit dynamics outperforms in learning speed about propagation through time using lstms so this is something that's also known from the standard machine learning community okay (33:02) so we apply these ideas to um you know learning again so i'm interested in neuromorphic hardware so we actually use these neuromorphic sensors in this case designed by uh by any labs which you know capture dynamics in the uh basically the spike events that basically you know just in the end produces cloud of points and we we these cloud of points is basically a large spike train um a large dimensional spike train and we process it using the spiking convolutional neural network we use here these uh local loss functions these are very (33:40) similar in in spirit to these uh this kind of natural uh eat prop idea that france was talking about and we get pretty good results um you know this four percent on this gesture recognition data datasets from ibm there's some better results that we have i'm showing here now this after we published but basically i think this is the best results on online training this training was fully online so really for every time step after every time we make an update okay so um i think just go i'd like to go very (34:14) quickly over some of the problems that are solved and some of them that are open basically we can learn in multi layers for example on local learning that's what i showed you we can map parameters to artificial neural networks to spike neural networks on that body talked about this one we can learn these with sparse approximations and implicit recurrences and that's you know several people have worked on this but you know partly also deep mine we can also learn with low precision weights and learn the structure of the spiking (34:46) neural networks some of the open problems basically learning with you know without catastrophic forgetting and learning with local losses very deep networks we can't really do that but do we really need them and some synaptic plasticity with the explicit recurrence that was red blocks that i was talking about so i'd like to finish up with basically what i started with which was this you know learning of the tufas in this case we want to do it in hardware because yeah we can this is was the the the intel luigi chip (35:21) is a neuromorphic chip which has uh programmable learning capabilities basically the chip has somewhat 128 000 uh neurons each you can compose in your own compartments in any uh in some restricted but you know programmable ways and what we what we did is that um uh i'm actually going to skip this one here just an interest of time but what we did is that we basically pre-trained the functional simulator of that neuromorphic hardware using back propagation through time and because it's a functional simulator (35:53) it's compatible with that intel intel hardware we map it onto that hardware and we basically learn those new gestures in this case online using the plasticity processor here so really i mean this is taking us from the full way starting from you know spiking neurons and understanding um what how can we do learning in these spiking neural networks we end up with this reverse mode and this forward mode and learning and here what we're basically doing is that you know we we can train these networks on the gpu (36:28) so why not we just pre-train them on the back popular time and then do this on one-shot learning on the device using these tools of uh forward uh automatic differentiation so it's really basically few shot learning of something similar to this toofus so there's a lot we can do this a lot better the um the accuracies are not top notch yet but this was our first step and was very convincing at least to us okay so i'd just like to summarize a couple of points here uh that well coming back also to loken's (37:02) uh comments that sander was talking about so i think spiking neural networks in some cases can be as good as artificial neural networks so i think indeed there is you know something there it makes sense to build hardware for this we can build efficient implementations and and basically use this machine learning as a guiding principle and we can use sparks approximations of real-time recurrent learning um and then this mixed mode automatic differentiation we can reuse the tools of machine learning for for training and configuring (37:35) hardware um and so that's uh that's it so i'd like to thank the people here now i want to say that actually a lot of the work that i presented here was also done in collaboration with friedman and all my students and various collaborators here thanks amber i guess i have a bunch of questions about that work then uh so actually dan already dropped the bomb in terms of questions um and i'm glad i don't have to answer but you have i'm just going to read the question so then i would like to know is there a (38:08) mathematical reason why the circuit trick work should work it feels kind of magical well i don't think it's very magical and that's um because i mean uh i think so sandra gave a a good talk earlier uh uh a good reason earlier that basically just making this linear assumption which is as if a little bit like a straight through estimator if you're familiar with that that already gives you some some learning signal so basically what you're doing here is that you are just i'm just going to be paraphrasing the (38:46) the fact that you know we don't have a mathematical foundation of why this is working but it's just in practice it works very well and the uh yeah i think there's the the ball is out there as why mathematically this works but in practice we're happy that you know it works well i just put it that way yeah yeah so basically we don't fully know mathematically why it works intuitively it seems fine but yeah it would be nice to have a full mathematical understanding eventually i guess okay so [Music] (39:27) yes the next question is from syed who asks um input and output spikes are very advanced but the circuit breaking learning computes area gradients at all the time steps can we can we can we just do it at firing times can we do it event paste yeah uh we we have a paper on this um it's uh there's a it's an ai cast and the other one is actually on review but you know we can post it on archive so basically what you can do there is that you can instead of just like an sctp you know you trigger learning on pre and post events (40:03) so those are the two factors we had remember our factors are error and pre and in post hand-wavy way well why not do the triggering on the error events and it turns out that this works very well and it makes a lot of sense right so you should only make an update if you've made a downstream error uh so yeah that's a that's a side you can do exactly that cool so here's another question by dylan um is there a reason why you need a local loss per layer why are circuit gradients alone not enough to build deep (40:42) spiking on networks they are actually if you're using back propagation through time there is no problem in using surrogate gradients across multiple layers the issue is which i kind of sweep this under the rug it's true but basically if you have see this orange part here basically this directly goes from the loss function down to the membrane potential if this went through several steps then things become more complicated um and it's difficult to solve this problem uh using this online learning algorithm (41:18) okay so if you're using back propagation through time you can do it but if you're using these online methods that rely on this that basically get rid of that explicit dynamics you know the red block that i was talking about then you can't do this anymore okay and that's the same reason i think that also for example eprop also has these learning signals that are sent directly to the neurons because you just can't learn uh credit temp spatial temporal credit assignment across multiple neurons in a tractable (41:50) way but i think that's material for discussion later absolutely yes yes um okay here's another question by who says i should ask so how would local errors work in deep networks that is how would you define targets for hidden layers right so so there are many ways of doing this we went for simplicity because i'm i'm really interested in building the software for this and i'm letting the community actually build cool applications what we did here was sorry there you go so basically we use the approach (42:29) of um mustafa who that basically has these local classifiers with the target labels provided for each layer and that's the target label here so this works well in practice and it works well for classification if you don't have those local layers but you can use you know contrastive losses and you know similarity measures that has also been used by the knockland has a paper uh interesting paper on that so yes you have to build these things by hand or uh as we've seen in the previous thought you can also train them using (43:06) evolutionary methods or you know metal back propagation metal learning you can also train these local loss functions so i think there's a lot of interesting things to explore there very well um by the way sorry manvi is she not he i mix this up i'm very very sorry so um next question um is and i think you probably have a slide for this is there a good reference for these spatial and temporal scaling rules uh forward and backward learning i've stared at them a few times and can't figure it out uh what do you mean by scaling a rule (43:45) maybe that's a phone typo i imagine propagation rules i guess special yeah yeah so okay so let's assuming that this is spatial temporal learning rule um then i would recommend this really nice article by christina seven and her lab that really explains this forward and backward in the same article and tries to make comparisons between them um our paper is not out yet so i can't refer to that one um so and that that is completely independent of spike in neurons so it's only an artificial neural networks if you want the spiking (44:25) version of it then you know you can also refer to our previous surrogate gradient work but if you have trouble in understanding the backward learning or the reverse automatic differentiation it's completely normal it's quite um unintuitive it turns out i would also say that the um there's this really nice article on automatic differentiation by baiden here that is also a fantastic description of the field and with working examples of forward and backward id cool thanks so here's another question by the same (45:08) person so in electronic hardware is there really a significant cost associated with non-local credit assignment and what is this cost oh yeah so that's the same it's the cost of communication so it turns out that in hardware um the one of the biggest prices you pay um is obviously the clock but also sending signals from one place to another so if your memory is for example situated in a ram which is in the today still a different chip than where your computation is happening you have to wait a lot of uh cycles so that's a long time and all (45:44) that communication basically takes a lot of a lot of power so if you get if you can put the memory where the computation is as it's done for example this in-memory processing systems then you don't have to communicate and that makes a huge difference and the credit assignment the non-local aspect of the credit assignment is directly related to this community cost so um yeah so significant okay cool um right so there's one more question i'm going to try to invite the user on screen um and see what (46:25) he or she says because i'm not entirely sure what ifa is but maybe you know it so the question is um or is he is the person coming hello no looks like no so the question is is there relation in your opinion between the concept of combining forward plus backward auditive and ah here we go yes [Music] do you want to ask your question yeah i was uh okay i can ask that like um seeing the the whole concept that you presented about the forward and reverse uh autodesk um i could not say helping not think that there might be a (47:11) connection to the indirect feedback alignment um and the theorems the theorem practically that norwich introduced so i mean i'm not an expert in feedback alignment but i was just i would just uh welcome comments on that like to understand your perspective i do actually so i mean you're entirely correct right so if in this slide here i was talking about this feedback alignment and direct feedback alignment and that's basically if you're if you're in reverse actually this can also be applied to (47:49) forward mode but basically if you're uh in this reverse mode case i mean you can back propagate those errors directly from those layers thereby obviating the need for doing this spatial credit assignment problem uh across layers things become a little bit more complicated if you have the time as well because then you have to broadcast the events in space and in time as well and turns out that broadcasting in time is very problematic right because you'll be learning something the outputs based on some previous inputs and there's a (48:26) mismatch between uh in the timing of these two uh events basically events when the error comes and the input you'll be calculating updates based on new inputs but the errors are calculated based on old inputs so that doesn't work okay so what you need to do is really solve this problem with the taking in the temporal dynamics into account and i think it'll be interesting to see if are there ways that we can do um you know feedback alignments also in time without having this problem of mismatch time as much (48:59) if i may ask like i mean from my kind of understanding at least from a probabilistic approach unfolding in time is yet another way of saying a graphical uh model right so you don't care if it's special or if it's temporal at the end of the day right that's absolutely true yeah the the difference here is that oh sorry what i was thinking is that in the indirect feedback alignment you go back to a certain layer from the loss function and then you go again forward so you have a part of it that goes backwards from the (49:33) loss and part of it that goes forward to some intermediate layers so the way i was imagining it is that a certain point you have a signal coming from the loss directly which is kind of your global signal and then you have a feed forward part and you could have backward part and you know the temporal one would come from one direction the squeeze yeah i think that's kind of the uh the gist behind what we're trying to do with that mixed mode automatic differentiation uh that you can basically what you can do is you can forward propagate some of (50:10) the gradients and you can back propagate some of the gradients that come from the feature which you can approximate uh as well and then you can the place where this joins basically make an update yeah uh i i think that's possible and you can in that back propagation can be done at least spatially it can also be done with um with you know direct feedback alignment i think that's a you know that's a perfectly valid point i think you're you're right on okay great thanks a lot for the question and thanks (50:44) for all the questions actually um and i'm just gonna ask dan whether he wants to quickly come back up on stage and i'd like to thank you again emre for uh a great day of talks here with a great talk yourself it was fun listening and uh yeah so as you all know next step is that we are going to rejoin in like 20 minutes or so for the discussion session and i hope many of you can make it and we've seen now that roughly two to 250 people are usually online at the moment and so we think we can do it on zoom (51:22) and okay and dan is coming in casey has some extra um instructions for us but i've seen that the link for the zoom chat has already gone out and um so the idea is that whenever you've uh finished your pee or coffee break that you can hang out in this zoom room and then about 20 minutes you will join um and there will be basically a moderated panel discussion going on with the speakers and with the audience and all the questions that you haven't had time to ask or that took some time to percolate through they (51:59) should be asked there and today the topic will be as with the talks more mostly centered around first technical issues and technical constraints how do you actually train spiking on that works but then we also want to start a little bit the discussion about okay we can train spiking or networks now but what next so what what do we do with this now how do we apply this both in an applied sense and in the computational neuroscience sense to understand how the brain works and i'm very much looking forward to this discussion with (52:29) you and i hope to see all of you then did i forget something no i think we're good um yep all right then um yeah thanks again all to all the speakers and to the audience it's been grand and see you in 20 minutes okay i i i should say i'll i'll post the link to the um to the zoom meeting in the chat here actually as well because it's probably going to be useful thanks all right i guess i can close now right here so see you in a bit thanks a lot,,,,,,,,,,
https://www.youtube.com/watch?v=F9O3f-gjPa0&list=PL09WqqDbQWHFvM9DFYkM_GfnrVnIdLRhy&index=6,2020,SNUFA Workshop,Timothee Masquelier,CNRS,Back-propagation in spiking neural networks,Learning,(148) Timothee Masquelier (CNRS Toulouse) - Back-propagation in spiking neural networks - YouTube https://www.youtube.com/watch?v=F9O3f-gjPa0 Transcript: (00:06) right okay hello everyone we are live with uh the first talk of the day uh which is tim mascalio i've known tim for years as he was one of the early users of brian and uh and very enthusiastic about it so i have very like positive warm feelings towards him for that if nothing else um so yes so tim is going to talk to us about uh some of his cool stuff in uh impact propagation and spiking your networks so um yeah please take it away tim all right so everyone see this is my slide i guess so yeah i'm a cnrs researcher i work in (00:50) toulouse at the uh the rochelle servo recognition which would be something like brain and cognition research center and today i'm going to talk about bug propagation inspecting neural networks but before i get started i want i really want to thank the organizers because i think this workshop is great and and here i want to insist a bit because you know usually people say that and they don't really mean it and uh i've said that in in the past without really meaning it but this time i really mean it okay um (01:24) you know i i many times i all the time when i go to workshops or conferences i have the feeling that i am only interested in a minority of the talks there and this time i have the feeling that i'm interested in all the talks it's the first time it happens to me so this is great so i have the feeling that i i have finally found my community uh first good piece of news and second one good piece of news this community is huge right it's much much larger than what i thought so i'm not alone so it feels it feels (01:54) very good so thanks to the organizer dan and frederman and we should do that more regularly and i can i can help definitely yeah just as the size of the community we have 195 people watching live right now one this is by far the biggest audience i have ever had so [Music] at least one of the talks so far so it's it's a big community yeah bigger than me exactly so great so as i said my talk is about back propagation in sparking neural networks so what what is back propagation well it's an algorithm for supervised learning and (02:33) feed forward artificial neural networks so what i mean by supervised learning is it's a fitting algorithm basically you want your network to produce a certain output for certain input so basically you you do you define a cost function which is a distance between the desired output and the actual input that that you get for given input so this this loss function technically it's only defined in the last layer in the output layer of the network and for the distance you can use the mean square error for instance or the (03:08) cross entropy and then you want to find the optimal weights for your network or other parameters and you want to find them using gradient descent so basically you move the weights in the opposite direction of the gradient okay and the total force of backprop if you like is that because the loss is only defined at the output layer and um just to interrupt you for one second yes uh should you should your sl should we be seeing uh the um like the powerpoint window or should we be seeing your slides full screen because we're seeing the window at the (03:42) moment on the first on the title slide no you should see my slides okay in that case we are not saying the right thing all right so maybe i should i i try to share the as only the powerpoint but maybe i should share the whole thing uh yeah maybe because yeah um okay so i'll close this one and then and then you can reshare again all right all right let's see if it works better okay yeah we said we're showing your whole screen now okay okay fantastic so um yeah basically you want you want to move your weights in the opposite direction (04:36) of the gradient um and the oops all right and the the total force of backflop because as i said the loss is only defined in the output layer but in fact the total force of backdrop is to be able to compute the gradients in all the layers recursively and this could be done not manually but using automatic differentiation and in fact backprop is a short for backward propagation of errors okay and why is backprop so cool because it solves the credit assignment problem uh which which could be rephrased in uh what should the hidden layers do (05:21) because as i said back prop is a fitting algorithm so basically the input is specified the output that you want is specified but the activations in the hidden layers are not specified so backprop basically tells the hidden layers what to do in order to help another way to say the same things is that backprop optimizes the feature extraction and the classifier jointly i'm saying that because before before using backup i've done a lot of work using for instance stdp and some people have also designed feature extractors manually like swift (05:59) or org or stuff like that and and then i would we would feed those features to a classifier and we would optimize this classifier but the total source of backup is to optimize both steps jointly it's joint optimization so basically it optimizes it finds the best features for the classification task you want to do so this is really cool another cool feature the number of layer the number of layers is arbitrary at least in theory in practice you can have some problems like the vanishing gradient or stuff like that but (06:33) in theory it can the number of layers is arbitrary so it opens the door for very deep nets and it has fueled the deep learning revolution so this motivated us and others of course to adapt back up to spiking neural networks so i'm going to talk about a couple of projects in adapting a backdrop to sparking neural networks the first project is about when you want to deal with static stimuli and we are going to assume a latency-based coding there and we are going to derive a new backprop learning rule for this sort of (07:06) coding and the second series of projects is uh when we want to deal with a dynamic stimuli and then it's a it's uh it's it's you you need more than one spike on your own and we for this particular case we use a surrogate gradient learning okay so let's get started with the first project it's called s4nn s4n is so short for single spike supervised spiking neural network so this project is done in collaboration with said reza kerat piche so said used to do his phd with me a couple of years ago he came to toulouse (07:42) and now he's back to iran he has a his assistant professor at chaid bayshetti university in tehran and basically as i said in this work we use latency coding so what is let me explain the concept the concept is you have to imagine a spiking neural network which is at rest before being presented with a stimulus and in that case the stronger the stimulus the earlier the first spike so if you have a weak stimulus for instance you may not reach the threshold at all so you have no spike at all if you use a medium stimulus then (08:18) you have a spike at a certain time point and if you use an even stronger stimulus you have an earlier spike okay so it's a simple concept but it's different from what most people assume um when they deal with packing our networks assume that the intensity of the activation is converted into a rate here it's converted into a latency there is no rate here because there is only only one spike per neuron so you cannot define a rate but you can define a latency it's an analog value and it can be used to encode information (08:52) so it's a simple concept but you see that it can encode a special stimulus into a special temporal spike wave so this particular stimulus will would generate this particular spike wave and the spike wave is the signature of the stimulus because if you change the stimulus for instance this stimulus would cause another spike wave okay um it's also known as time to spy coding as i said it's suitable for static stimuli because if 0 stimuli evolves through time you need more spikes to encode it but if it's static (09:28) then one spike i think one spike is is enough there is some biological plausibility for this sort of coding for instance in the visual system that is for instance this paper by galician meister it's very fast because basically you can you need just one spike to encode the information so you don't need to wait for subsequent spikes in order to know the activation of the neuron when spike is enough for the same reason it's very energy efficient because usually in the brain and also on neuromorphic hardware (10:03) the energy consumption is mostly related to spike emission so if you don't if you have very few spikes you save energy and if you do it smartly the latency coding if you implement it smartly using driven computation then the the time represents itself you never store the time you use the time for computation but you never store the timestamps for instance or you don't have to so there is no memory footprint so this is really a really cool feature because time is an analog the latency is an analog variable it could be (10:37) arbitrarily precise and you don't store it so you there is no memory footprint so this motivated us and others of course to adapt back to this sort of coding scheme so others for instance there was this seminal work by thunder [Music] spike prop nearly 20 years ago now yesterday we also heard about the work by julia and this this project is in the similar line yet we use a much simpler neuron model in fact we use um so yeah i forgot to say that this paper has been published this year in international journal of neural system (11:21) and the code is available on github and as i said we use a very simple neuron model it's an integrate and fire neuron non-leaky there is no leak and it uses instantaneous synapses so it couldn't be simpler here you see an example of the potential as a function of time so when a spike is received it increases instantaneously then it's flat because there is no leak and at some point it may reach the threshold and produce an output spike which defines the latency of the given neuron and then we stop the computation (11:54) because we are not interested in subsequent spikes so we don't need to do a reset we don't need to integrate again we are done basically and um so what we do is we we define uh okay the desired activation in the last layer are defined in terms in terms of desired firing times desired latencies in the output layer basically we want the neuron for for the good category to be the first one to fire and we can define the error of latencies based on the difference between the desired latencies and the actual latencies and we are going to (12:32) back propagate those errors through the network let me explain how this is done so here this is an example basically i have i'm interested in computing the gradient of the loss with respect to this wji which is a weight of the synapse between neuron i and neuron j first we're going to apply the chain rule so the derivative of the loss with respect to this w is just a product of derivative here here we have the derivative of the loss with respect to the latency of j times the derivative of the latency of j with respect to (13:10) the potential of j at the at the time of threshold crossing and here we have the derivative of of the potential with respect to wji okay so this is just a notation the first one we are going to call it delta j uh for the second one um yeah i forgot to mention that if a neon doesn't spike during the whole simulation we we somehow invent a fake spike at time t max which is a maximum number of time steps and so if the threshold was not reached at time t max we invented a false spike but in that case moving the potential (13:53) has no effect on the latency because the latency will remain at tmax anyway so in that case this derivative would be zero but in the other cases which are more standard when you have a real spike then if you increase the potential you are going to decrease the latency okay because if you increase the potential the threshold will be reached earlier so i'm not i'm not able to compute this term exactly but i know that it's negative because again if you increase the potential that will cause a spike before (14:26) in time so we're only going to keep the sign of this relationship minus one okay we don't we don't we don't know the exact value we keep on either sign it's a good approximation i know but in practice it works quite well and then the last term the derivative of the potential with respect to the wji well if i i helped in reaching the threshold which is if i was t i was before tj then this derivative is is 1 because increasing the w would increase the potential but if t i is after tj it means i sent the spike to j after j reached (15:09) its threshold so this spike was unuseful and then the derivative is if zero is zero okay so this is the first equation and the second equation like in classic backdrop is to use a total derivative because we want to compute the delta j as a function of the deltas in the subsequent layer so for this we use a total derivative we iterate over k where k are all the neurons that j touches so we have the sum of derivative of the loss with respect to the latency of k times the derivative of t k with respect to t j so this first term (15:50) is just delta k this is just the notation and this second term here again we need an approximation so just to give you an intuition of the approximation we use uh you you you would notice that if tj is after tk again it means uh the changing the latency of j has no influence on the latency of k because because j was too late anyway so in this particular case the derivative is zero but in the other case where tj is b for tk while changing the latency of j clearly has an impact on the latency of k and this impact you feel that it depends (16:33) on the synaptic weight for instance if the synaptic weight is zero then this impact would be zero but if the synaptic weight is strong then changing the latency of j will have a strong impact on the latency of k so we just assumed a linear relationship again it's a good approximation but we we know that this derivative depends on wkj we just assumed it was proportional to wkj so this leads to the following equation and of course for the output neuron the deltas are defined because we can compute the mean square (17:09) error given the desired latencies and then we can back propagate the errors using this recursive equation like in classic backdrop so using this approach we used a very simple network a fully connected network and so there was no convolution it's only a one single layer fully connected when single hidden layers are fully connected and we got pretty good performances on the nist data set comparable to others or i would say in the similar to to comparable networks but i would argue that our neural model is much simpler (17:54) and more hardware friendly uh another cool aspect of this work is that uh the processing can stop as soon as the neuron fires in the readout layer so as soon as you have one spec in the readout layer you can stop the the computation you don't need because you decide based on the on the first spike and you don't need to to to continue with the computation and at that time only a few percent of the neurons have fired more recently we are working on a binarized version of this network so basically we constrain the weights to be (18:32) either minus one or one so we could encode them with just one bit the motivation of course is to decrease the memory and computation footprints at least at inference time so basically we have the real valued weights w as before and we define their binary version which is just their sign b equals sign of w in the forward pass of back propagation we use the binary weights and in the backward pass we use the real valued weights to back propagate the gradients and we use a straight throw estimator introduced by core barrier (19:09) basically we it's like we pretend that we use the real valued weight in the forward pass when we do the backward pass so it's again a good approximation and it has a small cost on accuracy you see here on nissan fashion mnist as foreign which is 97.4 and 1988 and there is a little drop of accuracy if you switch to binary ways but i would argue that it can be acceptable given the decrease of memory and computation footprint so just to conclude this first project i think it's interesting from a neuroscience point of view and from an (19:53) ai point of view from a neuroscience point of view the trend model is compatible with the speed of processing in the primary visual system we know that we recognize objects with at most one spike per neuron and the current model can explain this sort of rapid processing even if the way we trained it i would not pretend it's biologically plausible but the resulting model can be and for for ai it's interesting i think because influence can be done very efficiently on low power neuromorphic chips all right so with that i'm done with the (20:30) first project now i'm going to to talk about a second line of projects uh which deal with dynamic stimuli uh and for this we are going to use surrogate gradient learning and we will see two applications one is for speech recognition and one is for internet traffic classification okay so what is a surrogate gradient learning approach well i think it's especially suitable to process dynamic stimuli for those stimuli uh we have to release the at most one spike per neuron constraint that we had so far in s4n (21:08) why because the stimulus evolved evolves through time so it changes through time so we we need to encode those changes we can not uh keep only one spike for that because the stimulus then will change and we need to encode those changes with additional spikes and uh similarly we have to release the knowledge constraint that we had in s4n because now a leak is crucial i think because the leak will help you to forget all the events all the input events and you need that because you don't want the current output to be influenced forever by (21:45) by by an input so we release those constraints what we do is uh we train a specular network with backdrop full time for this we need to discretize the time and the firing threshold causes an optimization issues this will become clearer with the next slides and for this problem we use a surrogate gradient in practice it means we can train a speck in our network using frameworks that leverage automatic differentiation like by torture tensorflow so we don't have to compute the gradients manually uh all right so that was an introduction (22:29) of on surrogate gradient learning let's get let me give you some more details uh for the neural model we use a leaky integrate and fire neuron but we could use other neurons but for simplicity is the one we use so far and we use a very simple the simplest version of it where the synapses are instantaneous so basically the input current is a weighted sum of direct delta functions and so this is a formulation with the differential equation but you equiva there is an equivalent formulation which is that for every input spike you will have an (23:09) instantaneous increase of potential and this increase will correspond to the weight of the synapse through which the spike arrived so each input spike causes an instantaneous jump of potential and then the potential decays back to the resting value which is zero in this in this particular example we could use more complex synapse models like with non-instantaneous synapse with the time scale this introduces another differential equation but for simplicity here we use just instantaneous synapses and of course if the threshold is (23:44) reached then you have to fire an output spike and you have to reset the potential to zero well this those are the formulations in continuous time but as i said we want to apply backup through time so we need to to work in discrete time now so what are the discrete versions of those equations well here here they are so basically we are only interested in the potential on um on the time steps on multiple times the time steps not on on every time points and then we the equivalent of the differential equation is the following (24:24) recursive equation we have the potential at time step n plus 1 equals the potential at time step n multiplied by beta where beta is a leak coefficient so this reduces the effect of the leak between t and t plus delta t actually this part of the equation is actually exact there is no approximate approximation there if you integrate the differential equation between t and t plus delta t this will give you this exact multiplicative coefficient there is no approximation there but here we make some approximations those are the (25:02) jumps in potential caused by the input spikes in the particular time being so sj in here is a is a tensor it's a binary tensor containing the input spikes so basically it's one if you have a spike arriving through synapse j in the corresponding time being in time being n and otherwise it's zero and here why i say it's an approximation because basically we ignore the difference in arrival times between all the specs that arrived in the particular time step we consider we do as if they were synchronous we ignore the (25:38) so for this reason we cannot use a too big too large time step we have to use a small time step for this approximation to be to be reasonable and then we have this reset term which i will detail later when we have output spikes we need to reset the the potential to subtract the threshold at each time step we check if the threshold is reached so this is done by applying the heavy side step function to v the potential minus the threshold if it's more than the potential is more than the threshold we generate an output (26:18) spec s out equal one otherwise we don't sound equal zero and if we generate an output spec then we have to reset the potential so we have to subtract the threshold to the potential this is a soft reset um and um so this is a recurrent equation so it should make you think of recurrent neural network and indeed we can unfold this recurrent equation through time and so on this slide i'm going to try not to spend too much time because emre had a very similar slide yesterday so basically the idea is to enroll the (26:58) network through time to get a feed forward network that you can train with backprop so you see the time on the x-axis here so you see the different time step time step zero one two and you see all the influences between the different variables on this graph so for instance a spike that enters here will impact the potential of layer 1 in the next time step through the weight matrix w this beta is a leak that reduces the leakage from time step 0 to time step 1 for the potential here at each time steps you check if the potential is more (27:37) than the threshold and if yes you generate an output spike so this is a heavy side function and if you have an output space you reset the potential this is this link and so once you have unrolled the network you can in theory train it with backprop but there is still a problem here which is this heavy side function because the derivative of the heavyside function is zero everywhere and infinite at the threshold let me explain that better here you see in blue the step function and here you see its derivative so its (28:10) derivative is zero everywhere and it's infinite at the threshold so you cannot use it for back propagation because the gradient would be either there zero or infinite which means you cannot use it numerically so to overcome this problem there is a really cool idea what that was proposed not by me but by my colleagues emery friedman and um in in this review paper that was published last year surrogate gradient learning and spiking neural networks actually this is a review paper so the idea the idea first appeared in other papers (28:50) in 2018 maybe papers by them and others but to me it was really by reading this review that i really understood the concept and that i really understood that it was a game game changer um because it would it would it would allow somehow to the snns to to compete uh with a n in a more balanced way it would make the competition between those two more balanced because we could use the same weapon the same optimization algorithms and the same frameworks and it will make the competition more fair if you like so the trick i still didn't (29:31) explain fully so the trick is to um so when you do the forward pass of back propagation you apply the true function the heavy side function which is what you should do but when you do the backward pass you just pretend that you used a sigmoid in the forward pass you didn't but you just pretend you did so you use the derivative of the sigmoid instead so it feels a little bit like a hack and it is a hack but in practice it works very well um all right another thing that uh another ingredient that i wanted to (30:04) put in our networks is is uh is the heterogeneous conduction delays because i think that delays matter a lot in specking neural networks first if you if you add some delays it it increases the richness of the dynamics of your dynamical system and uh in terms of expressive power of spanking neural network it increases a lot the expressive power of your specular network the reason is because the neurons can detect complex special temporal patterns and not just synchrony patterns so this was at this point was made by (30:42) izkavic in 2006 for instance if you have three neurons b c and d and two output neurons a and e if b c and d fire at the same time then a will receive three asynchronous spikes and so will e and neither of them will will reach thresh threshold but if you hit first d then c then b the conduction delays might compensate the initial offsets and then a would receive three synchronous spikes and would fire a spike and conversely if you fire b c and d in this order then you would elicit the spike in your own e so it's it's a simple mechanism but (31:23) really it can enrich the expressive power and the and the dynamics so uh i wanted to add the telegenerous delays the way we did it is uh by introducing temporal convolutions um so the concept is um is the following let's say that between two layers you have three connections on this example and each connection is defined with a weight and a delay the delay should be a multiple of the of the time step we still use discrete time so and between two neurons you can have multiple connections with different weights and different delays (32:01) well the way we are going to represent those connections is using a temporal kernel so for instance this connection here with the weight 3 and delay 4 is represented here because here you have the time steps so one two three four the first time step and this is for new one for our favorite one those two connections are represented here and basically to compute the input for this layer we are going to convolve the output of this layer with the temporal kernel which will simulate the conduction delays and the another trick that we use is we (32:41) want to explore broad delays we want to explore to have a big range between the shortest and the longest delays but we don't want to use a too big kernel because it would overfit so for this we use the concept of deletion which is we force some coefficients to be zero in order not to overfit and yet to have a broad range of delays so the first application that i'm going to talk about is an application for speech command classification this is work done in collaboration with roman zimmer who was a master student last year he (33:18) did his research project under my supervision at circo and also under the supervision of thomas pelegrini who is a professor at the university of toulouse is a specialist of deep learning for audio so we used the google speech command data set so this data set has a 60k files of 1 seconds of one second of recordings containing different commands there are 12 classes to discriminate 10 commands like yes no up and so on one unknown class and one silence class and so for this the first step we used was to compute a spectrogram of (34:07) the sounds so a spectrogram is the energy represents the energy that is contained in the sound at every time state and in every frequency band um so then so that was the input of the network and then we used three convolutional layers so convolutional convolutions were done in time to implement conduction delays and in frequency um so we had three uh of such layers in a row and then we had a fully connected uh the radar player was a fully connected layer it was the only non-spiking layer of the network basically we took the mean those were (34:52) leaf neurons with no threshold so basically they have a potential that is computed with a leaky integration but they never reach the threshold and we took the mean of their potential over time to decide we decided the class of the stimulus based on the neuron with the maximum mean potential so this is an example of a certain word of which is pronounced and you see the spectrogram of the word earth and here you see the spikes for one channel of the first convolutional layer so the kernel is slided over the frequencies (35:30) this is where you have different frequencies and here you see the time and here you see the spikes that are emitted as a function of time it's a binary tensor here you see the potential in the readout layer so the only non-spiking layer before and after learning this is before learning and after learning you see that usually one neuron corresponding to the category of the stimulus has a much stronger response than the other neurons and we decide as i said based on the mean potential of this neuron on the on the (36:07) on the total duration of the simulation with this approach we reached a test accuracy of 94 so this is really good because if you compare to standard deep learning it's only slightly above 96 97 so we get really close to state of the art using non-spiking networks and despite the fact that we imposed we managed to keep the firing rate quite low five earths on average so the spikes are quite rare in this network which is good for energy so we published those results in a tech report it's an archive and we also (36:46) published the code it's on github now i'm going to talk about a second application which is maybe more original for most of you it was for me what we want to do now is to classify encrypted internet traffic so this is a work that is done in collaboration with alia raster a phd student at sheriff university who might co-supervise remotely again roman zimmer's a master student florian del pesh was a a student at superior last year and he did a research project under my supervision and also the supervision of carlos aguilar (37:27) who is a professor of computer science at superior and who knows more than me about traffic classification about internet traffic um okay so what do we want yes we're running over a little bit on time so if you could try and go through this bit quickly that would be great all right all right uh see this is the last project so it should be okay um okay so basically uh we want we want to be able to recognize the category of the traffic for instance voiceover ip video file transfer chat and browsing despite the fact that the the traffic is (38:05) encrypted for instance using a vpn or using tor why we want to do that because we want to prioritize the traffic to enhance user experience for instance this is the voiceover ip you should you should give higher priorities and it is if it is file transfer for instance so we took inspiration for from a paper published at infocomm by shapira and chevit what they did is they they first represented so we cannot look what is inside the packet because it's encrypted but the information we have is the packet arrival time (38:36) and the packet sizes so they represented those information in a point cloud and you see that they already look very different this is vpn voiceover ip this is vpn chat here you see the time the x axis and the and the packet size on the y axis they already look very different and from those cloud cloud points they created histograms and they classify those histograms using a cnn the net five as if as if they were images so basically they treated the time as a special dimension and what we do here what our approach is (39:13) to use a snn instead why because this sort of internet traffic classification should normally be run on a satellite so there are strong energy constraints and we also think that the temporal patterns are presumably alien diagnostic here but we wanted to treat time as time not as space not as they did so because we wanted to to build a causal system that was that could be suitable for real time in france so basically uh we don't want to to to build a system that sees the future the network can only see one time step (39:47) at a time and it cannot see the future it's a very simple network it has just one hidden layer of fully connected network a fully connected layer and one readout layer so there's no convolution no delays and we just we're just going to to to to swipe this simple network through the time steps and our preliminary results okay it's a work in progress but uh our preliminary results are are quite encouraging we reach a test accuracy of nearly 94. (40:18) it's similar or even slightly better than chaperone chavit yet our architecture is much simpler so this is a conclusion the advantages of the approach i think it solves the special and temporal credit assignment problem it can handle a very deep networks at least in theory dense and convolutional layers it can uh it can handle delays and trainable runtime constraints this is really cool because those parameters you don't have them in artificial neural networks it's agnostic about red versus temporal (40:56) coding so this is really cool because you let backprop decide which coding scheme is the best in s4nm for instance we imposed latency coding if you convert some people convert an inn into snn for in france and then then you impose rate coding here we do not impose anything uh the coding scheme will be chosen we can use a regularization term to encourage sparse activity fast processing and so on and so on this is really cool and in practice it means uh a sentence can be trained using classical frameworks like by torture (41:32) tensorflow which has whichever very large community so this is cool and of course there are also drawbacks it's memory hungry linear with a number of time steps we do not take advantage that is not yet of highly sparse stencils it's not hardware friendly at least not the way we are doing it but you should see emre's work for attempts to make it more hardware friendly it's not biologically plausible but you should see eprop that we heard about yesterday to for more biologically plausible versions (42:09) and that's it i want to thank you for your attention and i'm ready to answer your questions great thank you very much tim uh very interesting talk and and a surprising application at the end there that i hadn't considered before i had to go quite fast for this one um yeah so we've got plenty of questions actually but we're running over a little bit on time so i'm gonna i'm gonna not ask anyone on the screen but rather um combine some of the questions into one should i can i close yours (42:41) your shed screen or yes okay um cool okay so um a number of people asked about the the latency coding um so i'll sort of try and combine a few of these questions i think a number of people wanted to sort of ask what what the biologically plausible interpretation of this was um and that one of the first people is asking could you just consider it as an inverse of rate for example have as an inversive rate of rate so it's like yeah yeah i mean i mean if you usually you know if you if you look at the neuroscience (43:26) literature uh the latency and the rate will be highly uh correlated right because usually the neon with highest higher fine rates are also the one who which fired earlier um so so i would argue that both quantities somehow represent the same information but the interest of latency is you can access this information earlier and would you say that there was a sort of um yeah so someone asked specifically what was the case that this is biologically plausible actually okay so yeah i did not review the the experimental literature but for instance (44:04) the paper i i i i mentioned by galician maester what they did is they flashed static images to salamander retina and they showed that some information were encoded in the relative latencies of the first spike times in the retina so this is evidence in the retina but there is also evidence in in v1 um or even even in its as this paper by um pojo that you can do with the first pack you can already have a lot of information i mean i i i cannot review all the literature yeah sure yeah yeah um okay yeah all right so let's (44:49) let's leave that one there for the moment um yeah so another question along similar lines is so how is latency coding defined when we have a continuous stimulus in time when there's no initial time to use yes yes um okay this is where this is where the the limit of latency is for continuous stimuli stimuli that evolve through time i agree that this is not the best coding scheme and this is the second part of my talk right you you need more than one spock on your own i i i fully agree latency coding is more (45:24) suitable for static stimuli cool um all right so we're going to wrap up fairly soon because we've got the next talk starting in a moment but uh let's just let's just have a little a little bit more so uh so actually i had a question which was uh and it relates to someone else's which is are your delays learnable or fixed i didn't quite get that all right yeah maybe it's learnable in an indirect way because because because we have this temple kernel where basically we have multiple connections between each pair (45:59) of neurons and those connections have fixed delays and we let backpop put some weights on those connections so so so in many cases backprop chooses to to discard some delays and to to focus on on more specific delays but the delays at least in this work are fixed now now we are working on a version where the delays would be completely learnable they still have to be a number multiple number of the time steps but but this is too soon to yeah enough to to this time and i think i think sander asked a similar question actually he (46:37) says while i like delays i've wrecked my brain on how to do it efficiently what's the cost of including delays at inference time yeah um yeah this really depends on on what you use to do your influence right it is true it is it is definitely true that delays have a cost at influence time especially on digital hardware um it is it so it's always an additional difficulty to have heterogeneous delays yet i mean uh it's always a balance between the benefit and the cost now and uh on on on analog hardware you can you (47:20) can have you can have delays uh at no no no additional cost of processing because the delay the delay is implemented physically um okay so that's all i can answer so far okay uh i think actually there's actually a ton of questions left but i think we're going to have to leave it there because we're we're already five minutes over yeah sorry no no worries at all um would you would you like people to get in touch with you to ask them their other questions yes yes please do so email is the best for me (47:54) yet okay fair enough great all right uh in that case we're going to start the next session in just a moment um thank you again to tim great love all talk stuff it feels like this is such an exciting area at the moment with so many like different approaches being tried that's really cool okay bye everyone thanks for watching thanks again bye,,,,,,,,,,
https://www.youtube.com/watch?v=RaNuIZ_xqKs&list=PL09WqqDbQWHFvM9DFYkM_GfnrVnIdLRhy&index=7,2020,SNUFA Workshop,Richard Naud,University of Ottawa,Burst-dep. syn. plasticity can coordinate learning in hierarchical circuits,Learning,(148) Richard Naud (Ottawa) - Burst-dep. syn. plasticity can coordinate learning in hierarchical circuits - YouTube https://www.youtube.com/watch?v=RaNuIZ_xqKs Transcript: (00:05) hello again hello everybody i hope you can see us and back from the break i hope everybody has gotten some refreshments and your brains are now fit and rearrived for the next talk i'm very happy to introduce to you dr noah or actually it's professor noe um richard no from the university of ottawa and he will talk about burst dependence synaptic plasticity can coordinate learning in hierarchical circuits and i'm very much looking for your forward to your talk and yeah without any further ado please dr noah (00:46) all right thank you frieza man for uh the invitation for what is turning out as a really nice workshop i'm really enjoying it so far so uh i'm not really gonna talk about this i'm gonna talk about bob dylan uh because uh yeah why not um i i recently looked at the google for the lyrics of blowing in the wind and it striked me that this is what i got the blowing the wind by joan fate so i guess this is just a silly introduction to to say that credit assignment is hard even for google um and i don't think i need to to (01:31) go and long in a long way to explain why credit assignment in spiking neural network is is an important problem um but i i'd like to share my view here that basically the idea of draining neural networks with the algorithm or the backpropagation of error is is really a solution to the problem in in in um in a coarse-grained way um but there's been kind of a schizophrenic approach to this uh in in history um and and i find that a little bit sad because in a way there's one really important lesson that we could take from this (02:23) and it's that if neurons real neurons are able to represent some type of error about the representation of of what they're doing an error about what they're doing then it could really help them a great deal particularly if they could communicate that sort of representation and i'm not sure if that's really a far-fetched idea and that's kind of what i'd like to talk about today um and in fact part of the the setup of that talk is we want to okay ask how can we have a top-down control on the plasticity of (03:02) synapses down the hierarchy and a lot of the constraints of the biology to do a real biologically realistic version of this um are seen as constraints as i just said but my talk today i'd like to see them not as constraints but really that's element of the of the solution and in fact i see that a lot of the details of the biology are lining up in a way that supports a view that nouns are representing uh the the error of the representations and the talk is structured uh this way where i basically address (03:46) different problems of that big special credit assignment problem um i'll talk about the very popular weight transport problem at the end but before i'll talk about the other problem which is the problem of having phases in an algorithm and the problem of of matching with synaptic plasticity rules as observed in slice experiments so that's going to be the starting point and from this i'm going to add details in the bio in my realistic um biological neural network and show you that these adding those details in are able to (04:27) allow neurons to do sophisticated type of credit design so before i really begin um this is this work was done with the alexandreal a phd student in blake's lab and blake and peterman as a big team it was a very exciting project um and this idea comes from or it was published before by conrad kuding in a visionary paper in 2001 and has been followed up by gokev and richards recently and we take these ideas a bit further as you will see so to start with we have to start with the phenomenology of synaptic plasticity as seen in slices (05:20) so slice work has shown that the connection between a presynaptic and a polar synaptic neurons will change as a function of the relative timing between a spike in presynaptic and say a burst and postsynaptic such that if you have an a causal relationship post before pre you'd get ltd depression and if you have the other way around is ltp the other one is neural modulation um neural modulation as you change the cocktail of neuromodulator acetylcholine serotonin um you will change no matter what type of timing you'll have (06:05) the the connection from ltp to ltd um and so you can go from ltt ltbt sorry ltp to ltd by changing the cocktail of neuromodulators but there's another element another parameter to the plasticity that is not so often discussed and is really the firing pattern of the postsynaptic neuron so if you pair a presynaptic spike with a postsynaptic spike you get lt d and if you pair it with a burst you get ltp so you can switch from one to the other by changing how bursty the odds are and i'm going to come back to (06:49) that idea and this is really central to everything i'm going to show you today so first to talk about this i need to come up with a vocabulary so i set up that vocabulary talk about the firing patterns i'll set up that vocabulary where i say that an isolated spike is going to be a single and a burst of action potential say uh one two or more action potential coming within 15 millisecond of one another is called a burst and both of these are events so an event can be either a singlet or a burst okay so that's my vocabulary you'll see (07:27) why i chose that particular vocabulary later um so if you we create a model of the synaptic plasticity um we would have something like when we pair an event with a singlet we'd get ltd as shown in this let's just experiment here in 2006 but it's been reproduced in many systems um and if we bear an event whether a single spike or a burst with a burst postsynaptically we get ltp uh a little jumping lt in in the weights uh that will accumulate over multiple such pairings now in order to try to understand what (08:13) this sort of synaptic plasticity rule does at the more coarse grain level of rates we need to talk about rates and firing rates are a really bad way to to treat this because they completely ignore the principle of changing the firing patterns of the postsynaptic cell for instance here this if i have one up for the firing rate this is four hertz say uh there's four spikes here but there are four isolated spikes the four singlets and here there's a burst and an isolated spike so dramatically different firing patterns but the same firing rate (08:52) so i really need something with two knobs uh so my knobs are gonna be the event rate so the relative number of events uh so these uh come back to uh i'll explain how i generate those later and the burst probability such that here you have uh two events and half birth probability and here i have four events at zero burst probability the reason why i choose this first probability is that as you'll see later it's independent of the ventricle uh now i can study the effect of that rule on that great view i put my my synaptic learning (09:35) rule um in uh in between two neurons where the two neurons are basically emitting events randomly their poisson event whose event rate i will control and the pulse or the or the postsynaptic side will in determine whether an event is a burst or a singlet according to a predefined burst probability that i control and if i do long simulation of this plasticity rule then i plot the the change in weights as a function of the burst probability that i control for a given set of event rate pre and post you see that oops sorry you see that (10:26) when there's just a few bursts we're dominated by ltd which is were dominated by this sort of situation whereas there's a lot of bursts were dominated ltp which is this sort of hair and there's a sweet spot when there's just as much of these two pairings such that they cancel out on average and there's no net change in plasticity this is really nice because we have a parameter that's independent of the event rate that i can use to steer plasticity from ltp to ltd and its relative magnitude (11:05) changing the event rate as you see in the gray one here does not change the point where this the the switching point from ltd to ltp it only changes the magnitude such that the learning rule looks a bit like this we have a pre and post event rates that is like a heavy factor that gener that that tells you how much potentiation there will be but not the sign of the potentiation and the burst probability will is allowing you to switch from ltp to ltd so really control the direction of that plasticity uh now before going further there's an (11:47) additional and fairly important element that we add to this learning rule and it's that of the kind of saturation in the system uh so when there were a lot of births in the past the weight change for a pairing between an event and a burst is going to be a bit smaller there's tons of processes in in the biology that are giving rise to this but it's not a very well studied phenomena um but this this uh sort of memory uh allows us to to to do the credit assignment later on so the learning rule actually looks more (12:26) like this where if i start at a certain burst probability and i increase the probability and i go to say 30 in my postsynaptic cell then i will generate the net positive change in synaptic weights but as time goes my this uh change in weight will go down which effectively is we do exchanging the the set point where the balance between burst and single spikes is happening such that this set point ends up going down here and this is our new set point that there's no more changes in the weight so weights are not keep (13:13) being increasing forever uh they will they'll balance out because what is driving the plasticity is the difference between the instantaneous burst probability and a moving average of the first probability of the pass in our simulation we typically use anything between 2 and 20 seconds really nothing of what i will say will will be affected by whether you choose 2 seconds or 20 seconds or even half a second for that matter so to illustrate that rule uh here's a simulation where i have a pre synaptic ensemble whose event rate is constant in (13:56) time and first probability is constant in time i won't talk about this very much this is it's net uh synaptic weights and this is the burst probability that i control and i increase it here and decrease it there and what you see is that following an increase the weight is is going up until the moving threshold of the pass activity notice the time scale here is such that the the set point is catching up and there's no more plasticity as you see here and as you release you can go down and as you bring the burst probability down (14:33) again you can control the weight here so really this burst probability acts like a controller of the synaptic plasticity here this is super convenient it would match really well with a representation of error uh within certain an ensemble of cells but what's controlling the birth capability well one example that i like to think of it's not the only one but it's very convenient very well placed in the in the biology um is that of dendrite dependent bursting so there's this famous experiment by natural arkham (15:16) where he forced a single spike in the soil so this here i would call that as an i call that an event it's a single spike uh but depending on what he injects in the dendrite you can turn the single spike into a burst it remains an event but the whether it's a single spike or a burst depends on what happens at the end right here the dendritic input is mismatched in time and the singles the single spike remains a single spike but if he moves the dendritic input the back propagating action potential is coinciding in a nice way with the (15:52) dendritic input and that generates a big calcium spike which fords propagate and generates disperse so what we have is something where um depending on the dendritic input i can control the burstiness of the neuron no matter what the event rate really is so it's a picture like this that i've alluded to before i really have two knobs one is inputs into the proximal dendrites it's going to control the net number of events that are happening and another input to the apical dendrites up in layer one which will control the burst probability (16:31) determining whether an event is a burst or a single spike um on average in this ensemble so in fact in the simulation i had shown you with my plasticity rule here the way i was controlling the burst probability was not artificial i had two compartment neurons here where what i was injecting is at this point a certain increase in the frequency of inputs onto the distal dendrites which increase the burst probability and led to an increase in weight of the synapses down here in the proximal dendrites same here when i suddenly decrease the (17:12) rate of the distal inputs this decreases the burst probability of this pink ensemble or this pink cell here this is actually just a single cell decreases the weight here in the proximal dendrite uh and all this is independent of whether these guys are are having a change in burst probability as you can see here here i've suddenly increased the input to the distal dendrite that increased the burst probability pre-synaptic clean but there was no associated change in the weights of those synapses and another element of the biology that (17:51) fits really well with this uh is in this recent paper on bio archive by guy doron and matthew and jill machine in the group of machu larkum for which i was actually also involved in um in that paper they show that despite the fact that feedback's been involved in many things there's a clear role of feedback particularly onto distal dendrites in regulating learning uh in that experiment they trained mice and rats to detect a micro stimulation stimulation within s1 so it's an electrical shock that's sent in s1 (18:32) and they asked the rats to to detect this and the rats learned this very quickly it's one or two days they become really good he is on train he hears control meaning that the particular manipulation has been done and the rats are within one they're able to and that learning score improve very well so they look in response to a microstimulation now what they've done here is they've blocked the feedback from peril cortex onto the layer one of s one here and period rhino cortex is situated really at the top of the sensory (19:14) hierarchy close to the apple formation in the hippocampal formation i think uh where multiple sensory modalities are are are converging so that would be a nice place from which to start to do sort of supervised learning from other modalities onto say s1 um and when they block that specific pathway so it's just one pathway within the whole cortex they affect learning dramatically so this here is a dread experiment and and really the animals are not able to learn to detect that that task and it's not about the perception because they wait (19:56) for the animals to be expert at detecting this micro stimulation and then they block the pathway there's no change in the performance of the animal so all this goes to say that it's pretty strong evidence that feedback particularly into layer one and the ethical dendrites of neurons is involved in uh regulating learning and in that paper they also show that bursting of those cells is associated with this female so that is that means that it can put a controlling of these synapses away from these neurons to whatever (20:34) is controlling the inputs onto the equal deadlines uh cool right but there's a problem with this if we're to do real credit assignment we'd need to have different sort of information going in different uh direction within the network particularly the sensory information going up the hierarchy from a given neuron within the heart and it this neuron also receives a credit as a signal saying how good its representation of the sensory information is then at the same time if this neuron received information from somewhere else (21:16) it should send back with a feedback signal another type of information that is another inherited credit for this neuron so and this credit that this neuron should receive should be proportional to the sensory information it's coding and the inherited credit it's got so some type of multiplication between the sensory code and the inherited credit we received but the main thing is that these two things are fundamentally different types of information so our neurons able to do that that's another very important problem (21:54) in doing credit assignment and it's solved in machine learning by having phases um but the the neurons i think are doing something different so this is the second part of the talk where i talk about uh getting rid of those phases because it's not it doesn't really make sense for neurons to have phases it would require neurons to suddenly be completely um closed from any type of sensory information for what could be quite a long time um if we were to follow the type of phase learning that is done in machine (22:33) learning so there's multiple types of multiplexing and although in machine learning you do that so the time division multiplexing where you go from phase one phase to phase one phase two in order to do these different types of uh message passing and there's also the frequency division of multiplexing that's done in in radios and where amplitude modulation of different frequencies are combined and then demultiplexed neurons seem to be able to do a yet another type of multiplexing that is specific to spiking neurons i find it fascinating (23:13) and to me is to be one reason why you have spikes still in the cortex um so to explain this this is a summary of our pnes paper in 2018 with henning sprechter you consider an ensemble firing rate called this sort of fast representation of a time dependent signal that is uh here you have an ensemble of cells with responses in time the ensemble rate means that you calculate the number of spikes within each time bit sorry about that and such that the ensemble rate evolution and time represent the input evolution in time (23:59) another way to look at this is to separate multiple types of spike time patterns in order to represent multiple streams of information so we can imagine that an ensemble of cells receives multiple streams of inputs and that we want to recover those streams of input by looking at different spike time patterns here events are denoted in blue and bursts are orange dots here there's one event even though there's tree spike there's one event in one verse here in that time bin there's two events in one burst (24:35) here in that time then there's three events in one verse so the event rate the ensemble advance rate is increasing in time but the burst probability is decreasing in time so these can be completely independent signals and you can represent them fast in the limit of large and samples you can double the amount of information being represented in neurons um and the nice thing is that neurons can communicate these two channels of information by properties of synapses short-term elasticity allows you to communicate those two (25:11) streams of information here's an experimental representation of short-term facilitation in cortical neurons while birth of presynaptic spikes is leading to a gradual increase of the postsynaptic potential i see this as filtering for burst if you have a singlet you have almost no response postsynaptically if you have a burst you get you do get a response the same axon can also into a different target give rise to short-term depression use a potent short-term depression shown in in an in a cortical neuron again and here (25:48) burst has a strong first psp but the later epsp are almost negligibly small so i see this as filtering for events so no matter where you have a singlet or a burst you roughly um communicate the same thing and that's really where my vocabulary comes from so this can be used for multiplexing here i i put all this information a quick question there yeah yeah a couple of your audience have had a question actually because the connection was a bit bad so somebody asked whether um whether it's important that the (26:27) pre-synaptic spikes are actually just spikes or like the prison events are singlets whether pre-synaptic events are seamless or just so it it as it doesn't have to be split it can in in the network in the whole network you'll see that i i move away from that to ensemble picture now we'll let the presynaptic ensemble have events that are either singlets or bursts i think that answer the question yeah if that answer said thanks thanks that's it okay yep that's it just uh keep it slow because i think the connection is a bit (27:17) spotty um okay we're doing um okay i'll i'll slow down then sorry about that so here's a simulation of two ensembles uh and i inject a time dependent input in this lower ensemble it's communicating here with short-term depression to a higher enzyme this lower ensemble event input is shown here the event rate matches at time dependent input and if i look at the event rate and the input are both matching for the spin consumption that's normal you you'd have exactly the same thing with firing rate the difference here is that (28:08) these simulations were not done exactly like this this is not the whole picture i didn't tell you that in these same simulations i had a time dependent input injected in the apical dendrites of those neurons that was modulating in time the burst probability of that ensemble you don't see any effect of this modulation of burst probability on the inventory although you would see a huge modulation on the firing rate and now i've used this short-term facilitation onto synapses here which means that it should (28:44) filters for first multiplication between those two so the first straight of that pink ensemble is flooded here in dash orange and if i'm um doing things right i should be able to represent that burst rate in the burst probability of that green ensemble and this is what i show here the red line is the burst probability of that green ensemble and it's not affecting the event rate representation so i have in this green ensemble a representation of both this feed forward signal and the feedback signal when scaled here with the feed forward (29:30) signal so let me say that again what happened here is that i have input onto the lower ensemble that gives a lower a change in lower ensemble feed forward rate which communicated with short-term depression gives rise to a change in the higher ensemble feed four feet forward rate um and this is then combined by the signal that's inherited from above that could be the credit that multiplies this and gives a burst rate of the higher ensemble the multiplication between what could be sensory representation and inherited (30:20) credit that gives rise to something that could be unit specific credit that is then allowed to specific to back propagate to that lower ensemble and modulate the burst probability and therefore possibly its own synaptic inputs so you see that we kind of have all the elements to do what the back replication of error is doing is it's all lining up really well if we allow this sort of short term depression to the to the feed forward connection and short-term facilitation to the feedback connection which by the way would be (30:59) the one central prediction of our work this has not been observed it hasn't been looked at whether the feedback connection received are sending mostly short-term facilitation on two typical dendrites so we've tested this in an in a in a larger network to see whether we can do so the credit assignment so we're just here did xor where we have a hidden layer input units and an output layer the input units receive low high low high or low low high high activity and time and we'll want to train the network (31:44) to respond only for when either of the two input ensemble is firing high so in the middle here um and we'll do this not by change controlling those weights directly but only by changing the inputs onto those apical dendrites at the output that's all we're going to do we're going to look at what's the response of this cell if so before learning here we have this dashed line um so before learning we see that it's not high response at any point so we'll want to have a high response one in the middle here so whenever i have (32:26) this i give a dendritic input that's positive which will increase the burst probability and then back propagating with short facilitate short term faster facilitating synapses onto the hidden unit ensemble and control those synapses that are multiple synapses away from our controller really and if we do this time and time again we get the after learning curve here this is the event rate of the pink ensemble you see that it learn to fire strongly only when either of the two inputs are are high at the same time and this is done only (33:11) through the sort of dendritic input inverse probability of the peak sound you can test that this is really dependent on the plasticity of those synapses by locking the plasticity of those synapses onto hidden units as seen in the orange line here this is the cost function as a function of training epoch and you see that we surely do not follow the the sort of learning curves that are seen normally in the figure i've just shown you in blue and here is the response event rate for uh uh orange here the the when we lock (33:51) those spikes we've chosen here each hidden ensemble has was uh 500 neurons but we could reduce the number of neurons it's just slowing down the learning as you can see here in green is when we go from 500 to 400 neurons it's it learns but more slowly and we can this is this learning is robust to randomly make a randomization of of the ordering of the examples and it's also robust whether we make some type of predefined pattern of connection in the feedback or we just let one hidden ensemble have random feedback (34:32) so all this together i'd say that the this burst dependent learning rule when paired with the apical dendrite dependent bursting and the sort of short-term facilitating connectivity uh allows you to do credit assignments uh in spiking your own network in a biologically realistic way now to scale up things and the last thing i want to say is to is the idea of alignment and linearization linearity of the feedback so we course grain or or approach we go from spiking to rate models we have a great model equivalent of my (35:15) learning rule that looks like this event rate pre and post and the non-linear readout of the feedback onto the apical dendrites and this is why is the matrix on the feedback so this is a tree neuroscience we call this a three factor learning rule there's a hebbian factor there's a sign third factor but it corresponds to machine learning where you have an unit specific credit that's the three factors and the inherited credit that is uh controlling the sign of the plasticity here and he would have a derivative of the activation function (35:55) which would match with say which with units that would have say here an exponential activation function although we could clearly replace this by relu or other type of activation function which would change the form of a plasticity rule but would not introduce anything that's not biologically realistic so the two differences with real back propagation of error one is linearity here in the in our first prop learning rule is a nonlinear propagation of error we can mend this by taking into account the fact that these neurons (36:34) are integrated in a nunivery micro circuit that can linearize the relationship between dendritic input and burst probability such that here for instance changing the weights of the dendrite targeting interneurons will change the linear how linear is this relationship you can do the same for different features such as vip cell activity or other ways or other parts of other elements of the circuit search test detritic excitability so in our rate-based network we have a mechanism that preserves that the network in the linear regime here (37:16) and with this we're able to learn pretty well now the other element is reciprocity the feedback this weight transport problem it's very famous uh and a typical solution to this is feedback alignment where we just fix the feedback weight and let the feet forward weights aligned to this well we tested this in cfar and imagenet and here is backdrop performance here is node perturbation which is what you would get for reward based control of the of the synapses and here is when you do feedback alignment in our in our network (37:56) um using the birch prop learning rule uh it it just doesn't learn as much and this is something we know already from fruit at all uh 2019 but recruiters also can't come up with a way to solve this which is to learn the introduce learning onto the feedback connections and they do that by using an explicit representation of the gradient but since we also have an explicit representation of the grading we can copy that rule in our network into and it becomes a rule as a function of event rate and burst probability um that's slightly (38:36) different i can go into the details but it's slightly different it's not exactly the same which matches with what has been seen in real neurons that the learning rule onto the apical dendrite doesn't seem to be the same as a learning rule on two proximal dendrites and when we do this we were able to learn this is the red curve here is our burst prop learning for far which matches really burst prop and here is the learning rule for burst up which is short of the back propagation of error but we should (39:11) know that we were not able to linearize our feedback in the convolutional layer for um technical reasons so all this together and the take home for from this talk is that we're at the sort of relative timing of synaptic plasticity might be involved in head and unsupervised learning and the neural modulation might be involved in reward modulated reinforced type of learning i'd like to argue that the dependency on post-synaptic firing patterns allows you to do an unsupervised style of learning and really allows you to see neurons as (39:52) being able to represent an error of the represent of their own representation um and so with this i welcome any question and first and also thank uh all the members that are have participated to this work so thank you great thank you very much [Applause] um yeah sorry about the the connection problems sometimes it happens but i think in the end probably people understood you well at least there are some questions here um um so i'm going to try to get some people on stage actually and we'll see whether they accept (40:39) um [Music] i'm just gonna get multiple people and then we go in there in the order so i don't i don't know do you see the chat window because you're getting a lot of applause here at the moment um yeah yeah and i'm sorry about the connection problem too that's why like with talking slower i think was not a problem okay so so i'm gonna i'm just gonna start asking um for more so bursty neurons are often attributed to layer 5 which have the dendrites in layer 1. (41:23) how would this burst dependent plasticity map to other cortical layers how would it affect the plasticity in other layers as they are recurrently indirectly or directly connected yeah this is an excellent question um and it is probably the most important limitation of the work i've presented today because all of this is really in terms of the details targeted to the layer five b branded cells um and although there's i mean these are really important cells uh they're numerous in the brain we would we would have to do proper (42:06) credit assignment we shouldn't leave like all the other neurons to do whatever um so i don't know how other neurons would be able to do this but i don't think that it's impossible for them to do some version of this for instance like layer two tree parable cells do not do not have full-fledged calcium uh spikes in the dendrites but there's something there so is this little something enough to change the firing pattern in a more subtle way it doesn't lead to those really starkly bursting phenotype but can still (42:47) be used to do the same idea in fact with a master student in my bag zeke we asked the question how how much do you need those birds to be really like uh obviously burst can you have just a smooth transition transition with a firing rate as high in a firing rate that's slightly lower and make a category like this and still multiplex this conclusion is that yes so you don't need like bimodal into spike interval really give rise to the sort of multiplexing i've been talking about the system is able to work with although (43:24) it's making a bit a few mistakes in in its communications it's able to work really well with that sort of uh more fuzzy uh setup so it's it would be a very interesting um area of further research for the question okay very well um so then here's another question so in the in the paper single ensembles uh require 2 000 pyramidal neurons and you require five ensembles to solve x or why do you think this much of neurons are this many neurons are required to solve a simple task yeah so the whole thing would work with (44:07) like one neuron for ensemble [Music] it would just be extremely slow so here in a concern of being realistic my view neurons do not wait like two seconds to have an accurate estimate of their firing rate every layer so in order to communicate a message quickly they do ensemble coding so that allows them to to represent an ensemble rate within 10 5 milliseconds instead of like a few seconds um so here the number is just there as a trade-off for speed of communication um and in the simulation i've showed today we i showed i used 500 neurons per (44:57) ensemble we could go down and still have a fairly good speed in terms of propagation uh and another aspect is that we are just using a very simplified population code here there's no distribution of the coding such as such as is known to be happening in cortex so all these together i think will allow neurons to represent information fast uh and fairly efficiently with with spiking neurons cool thanks nas has a question for you now thanks dr now that was uh really exciting stuff um the question that i have is about the (45:38) fact that in the introduction you created this split between bursting behavior and singlet behavior and of course how we draw that boundary what we do classify as a burst is kind of up to the modeler um but it strikes me that this is maybe you agree maybe you want but maybe this seems to be just a separation into a high frequency and a low frequency kind of filtered version of the neural activity and kind of collecting rates on these to do stuff um and then i guess the question is if we can do this in this kind of in this bimodal way do (46:11) you think there's a place for multiple modes of communication so essentially what we're saying is neurons can then transfer two types of information within their activity and can we split up the space into more frequency bands say do you think there's any role there possibility absolutely and in fact when i first thought of first ensemble multiplexing i didn't i didn't see this as being restricted to the idea of burst and communicating only two signals you could communicate many signals in principle uh you could like (46:42) theoretically you could think of patterns such as like bursts uh silence and silence bursts you know that's another pattern whose ensemble rate could communicate get something else right so the you could in principle communicate a lot of information this way however i'm i in my concern of understanding the brain here i'm not sure if the there exists a way of of doing that demultiplexing with synapses there's there's quite a lot of fancy thing being done by synapses in short-term plasticity uh if you look (47:21) particularly onto the the massive fiber synapse you can fancy things happening there so there's place for a third signal for sure um but more than that i doubt so okay that's really cool because it also speaks to the fact that maybe you know you talked about patterns of spikes and timing of spikes would be a really cool way to leverage again spiking property of neurons so thanks thanks a lot for the question um okay so i i had another question so is it actually perhaps the only putative credit assignment scheme (47:59) with a biological plausible mechanism that uses the same neurons to communicate two different messages well i i yeah i mean how of course one we might have a discussion of what biological plausibility is um there's of course the the work of um of uh sacramento which i haven't uh cited in that paper but it's highly relevant here and it's fairly similar uh they don't have the same type of uh connection with the synaptic plasticity rule uh but there's certainly an online approach there um that would work (48:44) uh other than that in my view it's mostly phase phase which we could argue but i don't think it's financially relevant okay okay so next question was by paul who just apparently disappeared again although we heard him for a moment also connection troubles well then uh maybe we can do it quickly on um how does short-term facilitation and short-term depression compared to recurrent inhibitory dynamics and feed forward inhibition and excitation observed in the neocortex there's a bit too many hands for me to (49:31) completely parse that sentence there's a lot of ants i think the question is the question is basically could you get a similar effect with detecting the bursts uh with excitation inhibition that's what i'm parsing i'm not sure that's what the question is but that's an interesting question at least yeah i i don't know [Music] um well yeah i i then what i would say to this is that um i have ignored here any type of recurrence uh whether it's within within layer or from a layer to another (50:14) lower um and real real cortex has recurrent connections and in fact you can even find some short-term facilitation although i think it's mostly short-term depressing within uh a column uh you can find short-term facilitation and you can even find connections that are within the circuit local circuit going up to the apical dendrites so the biology is much more messy than we think uh and and also obviously there's there's a relationship with the feed forward and feedback inhibition in my view this is this is sticking the the (50:54) the picture i've shown here where when you have a pyramidal cell going to pv positive cells it will send depressing or non shortened plasticity connections and the feedback is also without short-term plasticity uh or just depressing so that that will keep like event rate within that pv system being event rate then when you consent to some other standard positive cell then you connect to the to then then right so that fits with that uh credit system um but uh all together that clearly the biology is more complex and there are (51:32) multiple things happening at the same time and it's not just this sort of supervised credit assignment and what i haven't treated here is unsupervised learning i mean i hope that unsupervised learning is is is using that sort of representation of error but i don't know how uh so it would be really interesting to know you can map an unsupervised learning algorithm onto that sort of cortical blueprint yeah that'd be cool all right thank you this last question is please only a very short answer with (52:03) yes or no ideally and that's paul's question can you do credit assignment through more than one hidden layer oh um i haven't done that uh but i'm sure i can so that's it yes okay thank you very much i'm sorry we're a little bit over time so i'll cut the questions here and i would like to thank nisha again for this uh beautiful talk thanks for the good questions from the audience and yeah we're going to move on to the next and you can ask me on twitter if you do want further questions i'm glad to (52:43) answer perfect so i hope everybody um has a chance twitter otherwise you could write it in the chat here and then everybody knows how to speak perfect okay great thank you so much thanks for the questions thanks for sha again thank you for them thank you everyone,,,,,,,,,,
https://www.youtube.com/watch?v=ygLTW_6g0Bg&list=PL09WqqDbQWHFvM9DFYkM_GfnrVnIdLRhy&index=8,2020,SNUFA Workshop,Julian Goeltz,University of Bern,Fast and deep neuromorphic learning with time-to-first-spike coding,Learning,(148) Julian Goeltz (Uni Bern) - Fast and deep neuromorphic learning with time-to-first-spike coding - YouTube https://www.youtube.com/watch?v=ygLTW_6g0Bg Transcript: (00:06) okay all right welcome everyone to the final session uh final talk i should say of the of the workshop we still have the discussion later tonight uh and just to remind everyone before we get into the talk that will be on zoom and you should have the email for that um sent to you but i will post it in the chat here in any case um and uh right okay so let's get into this session so we have julian uh girls from um heidelberg and uh bern and he's gonna talk to us about some uh really cool neuromorphic hardware stuff (00:41) i think brilliant um julian you're right thanks everyone i can hear again again this is weird i just sorry you sound fine here okay can you mute yourself maybe okay yes okay thanks okay sorry um thanks everyone for this very cool workshop i'm sorry this is so this why is this happening now again okay do you have another window open by any chance i tried not to oh sorry i'm so nervousness um thanks for this cool workshop it's been a pleasure to participate and i really welcome uh the chance to present my results here (01:31) um adding to all the technical problems now i'm also really nervous that i apologize in advance for this uh but now let's get right into this at this workshop we've heard a few talks already about how to use spikey neural networks as universal function approximators and the approach i'm going to present fits right into this we propose efficient and exact aerobat propagation basin based learning on spike times of leaky integrated fire neurons our approach for training needs only spike times as observables and is (02:02) also really robust with regards to irregularities in the substrate this together with only needing spike times makes it very suitable for neomorphic hardware and i will show one highly energy efficient implementation on your morphe hardware i will skim only over the introduction because most of the things have already been said we've already heard yesterday by santa and julie and also emre how different spikey neural networks behave from basically from everyone how different spiking your networks behave compared to classical computers (02:36) and a ns and that still there's a huge run for using spyclear networks to employ their speed and energy efficiency and that we want to take up ideas from nature to make use of how nature processes the speed with speed and energy efficiency we've also heard about the biological possibility of different coatings and that there's especially in particular some time to first spy coding in different uh areas for example in the fingertips uh emre yesterday also talked about different neomorphic hardware systems (03:12) and how we want to use uh them with spiking networks i want to highlight two more points one was a bit pointed out today by claudia about studying perturbations also in the discussion yesterday i unfortunately forget you forgot your name but someone uh told about her use of spinnaker and the difference to the neural simulator and how the neural simulators few simulations uh produced more accurate results than the neomorphic digital neomorphic hardware spinnaker and this difference in accuracy is a detail that we should not brush onto the carpet (03:52) this is a very fundamental thing we should try to find algorithms that are not disturbed by having well some disturbances and any algorithm that aims for neomorphic hardware comparability or even biological plausibility i mean biology is not a perfect substrate as well should prove robustness towards inaccuracies and also yesterday to the answer of a question to sunder about why we bother the with the difficulties of spiking neural networks he answered that we want to do it uh in because we want to uh use the speed and the energy (04:32) efficiency of neuromorphic hardwares and the combination to spike in your networks in theory and i hope that my talk could prove uh one one fundamental point for him to in in the future not used in theory we will provide an actual implementation actual results from an implementation and show the energy efficiency of this i will start by describing the system on which we did this this is the brain skills two system neomorphic hardware system developed in heidelberg then described the approach we're using uh shows some simulation results and (05:04) then the hardware implementation so uh let's start with the neomorphic hardware brainskills2 is a mixed signal neomorphic hardware this means that it uses digital spikes for communication to make full use of the sparseness of digital communication but the analog at neurons are analog this means that biological observables like for example the membrane voltage are represented by actual physical quantities and on the right you see an image of an oscillograph that records one such voltage of one neuron on this chip this (05:40) physical emulation has a few follow-ups one is that all the neurons are independently and asynchronously emulated this means that no matter how many neurons you use on a chip at runtime on this chip stays the same so using twice the neurons will not produce longer experiments another thing is that to emulate those physical quantities on the chip we use tiny resistors and tiny capacitances and those two things are what determines the time scales on which the neurons operate on and on the chip we're using uh these are typically (06:21) in the range of microseconds comparing this with uh typical time scales in biology which are on the range of microseconds a millisecond sorry um we get a speedup of 10 to three to ten to the four this means that we can emulate that one second of biological dynamics in just uh below one milliseconds unfortunately uh the analog nature while having many advantages there's also some disadvantages and the major one is that the neurons do not behave as exactly in simulation there are some variations in between between neurons and (07:01) yes here you see a schematic of the chip um the large shiny surfaces in the in the image on the left are the synapse arrays those are where spikes are routed to the neurons and you can also the neurons on this chip are located in between those large sines of shiny surfaces this chip has a total of 512 neurons and synapses of 256 times 512 well synthesis uh our setup that we use on this chip is for uh layered network you can emulate arbitrary networks in theory but the setup we are using is uh 256 uh inputs uh up to to up to 128 hidden neurons to up (07:45) to 128 label neurons with uh fully connection and this determines uh the experiment sizes we're using um there's also different units on this chip for example the ppu which means plasticity processing unit which is a general processor a general purpose processor which can be used for other experiments and to change a synopsis connection at runtime and all those units um and the configurability of this ship makes it a very versatile research tool and i'll try to highlight this versatility now um by showing some (08:23) experiments this is an experiment schreiber where well in the spirit of doing uh neural research he put a whole network on this chip and the network he put in the chip was a network that is part of an insect brain the ones that has the uh goal of navigating an insect this insect is cruising its surroundings and then has to return in a mostly direct way to its hive and this experiment can be run fully on this chip then another experiment is uh one is by sebastien bilodell and uh benjamin kramer we're all talking about synthetic (09:04) plasticity so changing weights of synthesis what they are doing in this experiment goes further they are not only changing weights of existing synapses but they are using this ppu this plasticity processing unit to adapt to create and destroy synthesis on this chip at runtime so this experiment is again fully on chap chip on chip and uh this structural plasticity so creating and destroying synthesis based on the network's needs allows learning of receptor fields this allows uh experimenters to overcome the (09:38) limitations for connections on the hardware then there's also classification tasks uh one very recent uh work by benjamin carmen's business again together with freedom and senke to put surrogate gradient methods on this chip this is some in some way uh similar to what we are doing well it's classification but it's also in some aspects very different so um they're using in surrogate gradient voltages um yes and on the right you see some plot of our result and this will be shown later again and the voltages here are (10:15) just for um to to illustrate uh what the network is doing we're not using we're not using uh voltages um we're just spike based we only need spikes to learn and we have an exact model as opposed to the survey creating mode so um what is our method we want to learn with leaky integrate and fire spike times it's like terms of leaky decorative finers and it turns out it's really hard and i'll illustrate why we've heard already uh sometime um on on this these difficulties uh on the left you see the post-synaptic (10:51) potentials of um leaky integrating fire neurons uh for different uh membrane time con combinations with some combinations the gray one is a non-leaky integrated fire neuron where the membrane time constant is infinity and you need it for all the other ones the actual leaky integrated fire neurons and the psp is non-monotonic and this monotonicity of the psp is what creates the basic problems i'll highlight two of these problems in the center column you see uh this contin discontinuity introduced by this by these psps (11:27) you see the membrane voltage of a neuron that receives input by input spikes those are the upward errors below and uh if there's an output spike you see it on on the top as in downward error and you see that in the top panel the psp overlap is not significant enough and there is no spike elicited but if the spikes are moved closer together suddenly the membrane is enough uh to reach the threshold and a spike is elicited so the spike just appears this is the discontinuity introduced by a non-monotonicity of them (12:01) for synaptic potentials on the right you see non-monotonicity of the spike timing as well and this is shown again in the setup where we have two input spikes uh one the second input spike the uh black arrow uh stays at the same time uh every all the time and then we show uh in the first and beginning just one second first input spike this is the blue one and the z again there's an overlap of the psps and we produce an output spike at some time this is the blue arrow on top now if we move the blue error input (12:34) error to later times like this then we see that the spike time that comes out of this is earlier than before so moving the spike time the input spike time uh to a later time produce an earlier resulting spike time now if you go even further and press and then move the spike even further back then the spike time the output spectrum decreases again so one action of moving the input spike time to later times produce different results on what the current scenario was and this is well non-monotonicity in in spite times we can also formulate (13:13) this um problem in uh equations and unlike claudia we'll have two slides uh with equations but there's just one so this doesn't count um so mathematically we want to describe the spike time and this is the time where the membrane reaches the threshold this is essentially this equation and you see that the output spike time the capital t occurs in two places in two exponents with different coefficients and this makes it very hard to solve this problem in general one possibility where it's solvable is (13:49) when we have an non-league integration fire spiked him so when the membrane time constant approaches infinity then the first term just becomes one and we can solve this um for the output spike time this was done by mustafa in 2017 but there's also possibilities where you can solve this these are two equations those on the left that are found during my master thesis which i started two years ago and finished last year the first equation that we can solve is if the spike time uh the time constants are exactly equal (14:21) then we don't have a piece p shape of different of difference of exponentials but an alpha shape and this can be solved the resulting equation with the lumbar w function there's another possibility if there's a factor of two between the two time constants and this includes uh the other way around because the psp is symmetric and the two time constants then this equation becomes essentially a quadratic equation which you can again solve and those two equations that you see here are differentiable with respect to t i and double i wi (14:53) um i'll focus now on the first case so with the ratio of the two time constants being exactly one and i wrote down the derivatives so that you believe that they're differentiable and those two equations are remarkable because the first one we remember we haven't done any approximations now and the first one this uh derivative for of the output spectrum with respect to wi and this is synaptic plasticity this is what we want when we want to optimize input weights to optimize the spike time to do something and the second equation so the (15:30) derivative with respect to the incoming spike times this allows us to do uh error back propagation with these two equations we can exactly solve the credit assignment problem and optimize functions and spike times uh however we like in particular this allows us to do error back propagation in networks of leaky integrate and fire neurons and i'll join the setup that we're using so we're using hierarchical networks of leaky integrated fire neurons on the left you see a schematical overview so the inputs (16:04) have the squares then we have a hidden label a hidden layer in circles and the output layer as triangles and for input encoding we use uh time different spy coding this means that stronger features represented as darker pixels here um uh are translated to earlier spike types and you see this in the right there's a schematic raster plot um that features the symbols on the of the left side uh to see that the dark squares are earlier spikes and for example gray or white ones and for decoding we also use an time difference by coding this means (16:41) that the neuron that spikes first determines the class of the pattern that the network is looking at and this allows us to do a um an loss function uh to describe a loss function that is not uh based on any uh onset that is just based on the time differences of the uh output spike times of the label spike times and what our goal in training is to increase the difference between the wrong spikes and the correct spike how does this turn out in practice uh here is the the training mechanism illustrated by voltages and (17:18) you see before training and after training let's just focus on the uh it's free samples that will focus on the bottom row here see that after training which is we initialize uh randomly the spike times are basically indistinguishable but after training uh the spike time of the blue neuron each which you can see as uh where the reset happens uh happens uh very early in the spike and it's uh way before the where the blue the green and the red uh neurons spike and as you can also see that uh during training (17:52) uh this network was trained to inhibit those second neurons the wrong neurons to spike only later how do we cut from left to right from before training to after training here i showed this process uh so on the x-axis you now have epochs and on this uh y-axis you can see the spy time again the lowest panel the blue class we can see that the blues by times of the correct spike time is decreased at early in the training and the others are pushed back this means that the network learns to classify this sample correctly (18:26) and to have this large input separation of the label spike times um this is just for free samples but how does this turn out for all the training samples well here is a histogram plot over all training samples and the spike time of the correct label neurons this is shown in orange is at the beginning so before training uh basically again indistinguishable from the spike times of the wrong label neurons but after training so the right plot you see that there's a big difference introduced um now i can show you the actual (19:02) simulation results uh usually people uh when showing though how their algorithms work will show their shower mnus as an example and i will do this in a second but i want to start with a different data set and this is because in m this difference of what a linear classifier can achieve is actually not that far from what a deep network can achieve and we've designed a special data set at the ying yang data set that you can find on my collaborator's clause github account the link is down there where this gap between linear classifier (19:33) and dig network is a lot larger this is also so this data set is called the young data set and it consists of samples that are defined as an x and a y coordinate so you see those points there and the associated class so whether they lie in the in the young or the dot part of the symbol and yes this is a lower dimensional data set which is still rather hard to train because the points in this dataset can lie arbitrarily close to each other and the network has to have hard decision boundaries sorry on what class it associates (20:14) the um patterns to and actually where the dot r uh dots there are many many points close to the borders so this is a real uh hard task for this data set uh and now i show uh how we come from this special representation to the temporal representation that we give to the networks for this i grab grab three patterns free samples red green and blue and you see that for example for the right one you see the small x coordinate is translated to an early x spike so on the right is the schematic raster plot as well again and the large y coordinate is (20:55) translated to a later white bike now red green and blue you might be catching on funnily enough you've seen what the network does with this before this training mechanism i showed was from exactly these samples and we saw that the network is training those correctly um the classification happens based on the spike time so we're looking at the spike times of the three different neurons again let's look at the left one the neuron so after training this is uh what the neuron uh what the output spike times of (21:25) the skin neuron are yeah yes for the different samples in again the spatial representation and uh to make it clear when a spike has been the first spike we subtract the first spike time in the label layer for this to all so that all classifying spikes are shown as a bright yellow color and you can see that for the scenery uh the the area of the bright yellow so the first classification aligns very well with the area of this class and you can see also that on the border or close to the border the spike times changes (21:57) appropriately so here start non-linearity is introduced by the network to be able to distinguish between the different samples these spike times determine the classification and here on the right we see the classification directly so the dots have the color of the uh what class the network thinks the pattern has and if it uh the network decided wrongly there's a black cross on this uh dot and you can see that the bulk of those points are classified correctly and the network only has trouble very close to the border so only (22:32) uh some edge cases are classified incorrectly and this is um shown again in the accuracy so we achieve nearly 96 percent accuracy which is uh far above what a linear classifier would achieve so it's 60 65 percent um this shows that uh backflow is working in our setup with our algorithm exact algorithm now i promise you amnest results here endless results we can see again that the network trains uh well over time over the epochs and that we redu produce a result above 97 uh which is comparable to what we what other spiking bankrupt field uh (23:15) networks of the same size can achieve um now i talked in the introduction that was one of the points i was making that studying robustness is important this is especially the case when we are looking at heart neuromorphic hardware applicability um but it's also the case when we're describing biology um this is because no uh substrate is perfect and our algorithms should not be failing because um the the substrate is not as perfect as for example the neural nest simulator here we studied uh the robustness of our (23:52) algorithm with with respect to different um distortions of substrate and for example this is for finite way to find the maximum weight or finite weight resolution but there's also noise in the bottom row studied noise on the on neuron parameters and those things they have analogies for both biology and neuromorphic hardware in the bottom row you can see uh results so these are uh simulations that incorporate the specific hardware uh distortion um and the testing uh test accuracy after training in the bottom row you see a noise on the (24:35) time constants and if you recall in my introduction i or in the derivation i said that we need for this for this derivation that this time constants have exactly a ratio of one so it's very interesting how this network copes or the algorithm copes with networks where this is not exactly the case this is why we studied uh cases where the time constants have um noise on them so there's a the ratio of these individual neurons is not one and on the left you see that if we just introduce noise and keep the ratio fixed (25:06) the network copes perfectly with this and on the right you see if we additionally introduce a shift between the two ratio attitude time constants so the um ratio of the mean time constants for the individual neurons is not one anymore and you can still see uh that attendator copes quite well with this now these disturbances that are shown here are relatively high compared to what we see in actual neomorphic hardware and uh to make this point more clear i will know uh now show uh the actual experiment results on brain scales too (25:41) um you see here the again simulation emulation results on this uh brain scales to chip uh we used an in the loop training setup uh so we calculate the um we use the hardware to produce spike trains and use only those spike trains to compute on a host computer um the updates for the weights and then write those on the network again and so on and so forth and um i earlier stated the limitations of the hardware in terms of neurons that we can use and uh not so much here but especially for the amnesty simulation shortly (26:19) uh emulation totally this is what limited our network sizes you can see on the right again that the classification happens very uh correctly for most points and only in the borders there's that the network has problems on the top right you see the simulation result again and you see that they are very comparable so the bulk of the points is classified correctly and only some points on the border are misclassified for anyone who has been working with analog neomorphic hardware and he keeps in mind the input encoding that (26:53) we used these are remarkable results because the precision with which this network and this algorithm classifies those results well is remarkable um so the accuracy here just drops by a few points so uh in software we had about 96 and here it's 94. um this are again the spike times of this of the neurons from hardware and this was uh these four plots that you saw on the title slide yes and you see again the classification time minus the minimum of the label time uh label neurons uh is zero for uh most of the correct areas so the network (27:36) classifies correctly most neurons and close to the borders the spike time of the individual neurons uh jumps properly uh now to the endless classification on the chip because of the network size uh we had to down sample the uh mnist input images to 16x16 pixels we still use classified full lambdas so we effectively just made the task harder for ourselves to make it possible to put it on the hardware and you see in the right these are just for illustration the voltages that were recorded and you see that those are for some samples (28:17) for repeated runs to show the variations and you see that the membrane traces are different uh for each run these are effects of the analog nature of this hardware you can see that the membrane traces have variability but also in the lowest example this this eight pattern um also the spike times they are the despite time vary between the different runs nonetheless all those examples are classified correctly and this is also reflected in the test accuracy we achieve nearly 96 percent on this full understand set i claimed in the beginning that (28:56) neomorphic hardware is fast but is that so well now we run we actually measure the time and for this in this case we start at the time of the measurement before sending images to the chip and then stop the time after having the classification results available in on the host pc and with this measurement we saw or in this national resort that all 10 000 mnist test samples can be classified in less than one second this means each sample is classified in less than 100 microseconds all the while the chip only requires 270 (29:30) milliwatt and this results in an average nat energy consumption of about 25 microtool per classification to put this into perspective a banana has about uh 90 kilocalories this means we can achieve 18 billion classifications per banana another perspective is that current state-of-the-art tpus require about uh power have a power consumption that is higher by a factor of about one thousand um and uh i just want to re-state brain skills too is not a dedicated chip that is well dedicated to for this research it's a (30:12) general research ship and i wanted to highlight try to highlight this with the versatile experiments i showed earlier and also that the scaling is behaves very nice on this chip so having more employing more neurons on this chip uh will not uh make the networks the experiments run um longer and what is more on the current chip uh the neuron dynamics are not the majority of cause for the power consumption so even the energy will scale benevolently and yes the chips speed up and low energy consumption redoubles the (30:48) efforts of this specifically designed algorithm to conclude my talk i showed the framework that allows exact optimization of spike times and accurate credit assignment [Music] i showed an extremely energy efficient and fast endless classification on the brain skills to chip well yes not dedicated hardware and on this hardware it's the effects the characteristics of this hardware so fast speed and low energy consumption redoubling redouble the effort of the coding and the algorithm and i provided robustness arguments of the algorithm that allow (31:31) for implementation of the wide range of neuromorphic substrates and applications [Music] i want to thank the heidelberg lab electronic christians and both burn labs compneur and euro team a in in bern and especially my collaborators my co-first author laura kina my fellow mindful modelers andreas baumbach dominic gold um and the hardware theme is sebastian billudel for the immense software support oliver brightvisa and my supervisors channel khan hensmeyer especially walter zen and even more especially amihabetovici thank you for your (32:05) attention great thank you very much julian that was brilliant i i i particularly love the banana analogy um and and i asked a question and unfortunately quite a few people sorry i've avoided it so you know you now you have to actually answer it which is um how many classifications a banana do you get for a gpu of a gpu well it depends um on on how much time you need for the classification so uh the the the power consumption does not uh directly it's the energy consumption that is important and you can read it up somehow in the (32:44) the paper for the different setups but there's also um like dedicated a n hardware for example i don't know if you you've heard of iris this chip and they classify much larger data sets but if you assume scaling then our results are in the same ballpark of energy efficiency and also speed yeah great um okay all right so we've got quite a few questions um so let's start with this first one uh so someone asks moritz asks how does your model deal with jitter in input spike timing and as an example when you're using a (33:21) neuromorphic camera a dvs um so for for amnest we actually uh trained with noise on the input images uh to to reach those high class suited to uh well oppose generalization problems uh we use spike uh noise on the input spike time so uh in this case it works brilliantly on the yin yang data set uh we very shortly tried this uh but um if you remember the problem of this data where the complexity of this data set comes from is that the points can be arbitrarily close together so if you introduce noise you um without (33:57) switching the class you make it come to another area of a different class and this obviously destroys how the network can classify this so there this is a problem uh in for general for a general answer this depends on the problem cool okay and uh we have friedman here to ask his question yes yeah so i was wondering how easy it is for you to scale your algorithm to multiple layers to make it deep basically it says wait i'm only i not hearing him uh oh hello you don't hear you don't hear friedman i hear him i (34:33) i hear myself i can't hear you though i can actually not hear him sorry well okay can you relay my question please yeah i'll i'll relay your question and and kick you off for some reason that's not coming through to julian hey don't kick me off that's so cool all right you can you can just sit there while i quietly quietly while i ask you a question yeah so freedom asks can you use this approach also in deep convolutional networks um so deep networks we try so more than one hidden label (35:03) layer uh hidden layer we tried and this works well we didn't optimize any hyper parameters on this but this works and seems to work for the convolutional layers this is actually very interesting and uh one remarkable can make to freedom and because he yesterday made this uh well it's night remark towards he feels like bitcoin mining um when he he's training his uh circuit trading algorithms we can actually have event based and not representing spikes as zero and as a large along areas of series with some (35:38) ones in between we can actually make this event-based forward policies passes and for this it's more efficient if the number of presynaptic neurons is fewer so having conversion layers with small filter sizes so filter sizes that are not on the area of uh order of 100 this would actually maybe speed up the training but we haven't tried it this is one of our big possible to do that we can do with this okay so for our next question we have um thomas noetney who i wanted to get up on screen hey thomas hey good to see you um yeah so my (36:19) original question there was uh what was the exact architecture in your example sometimes you had written down something and it was it seemed to be three layers but related to it also i wanted to ask um which of the sign-ups are actually learning and what's the desired time on the middle layer so to speak if you have middle layers so yes we always in those examples i showed you use uh free layers um and it's always for the hardware uh we feed input spikes to the uh hidden neurons those the hidden urine stills are located on the (36:53) chip but the input urines are they just will send their spikes because that's what the input encoding does um and there is no uh designated uh time when the input when the hidden urines should spike this is something aerobatic propagation does so uh we just we tell well we should we put spikes in uh we see when what spike comes come out and say well this is wrong make it better and then our backdrop does the rest for us i hope this answers the question yeah thank you great all right so the next one is from emory (37:31) and he's asking about what the um hidden your own activity about how the hidden urine activity behaves do they also spike only once as in the output layer um so in the simulation um the the remark between a bit for the event-based thing uh this assumes that the neurons spike only once this makes the coding very much easier i think this is not a general problem if we employ for example what emery yesterday said with the reset thing then we can also look at multiple spike setups we haven't done this though (38:02) um and so in the simulations this is assumed and on hardware we can set refractory times which are in the order of the synaptic or membrane time constants well those are the same order um and then this is not a problem for us so effectively they only spike once cool okay and uh and we have tim here to ask his question hello hmm can you hear me sorry yes all right my question again oh jillian okay um all right so um tim says in on slide 14 you had the output latency being different differentiable with respect to the (38:52) weights and the input latencies as long as the output latency is actually defined so the threshold is reached but what if it's not reached yes very good question um so exactly yeah that's that's a major point so if we have a spike we can have um the exact and uh well optimization without any approximations but if we don't have spikes then we have to resolve uh assault to um ad hoc measures and this for us is just uh we we define as a hyper parameter a percentage of neuron that should fire for a pattern and if this is not reached (39:29) then the weights of the neurons that are not active those are increased so it's a very well um well a talk measure and it yeah just bumps those weights all right and in practice how many uh millionaires need in in practice sufficient to have to to to well solve those cases and make uh sufficient activity okay so so actually i think tim was starting to ask about in practice i don't know if julian heard it but he started to answer it so was that was that your was that did that answer your question tim no i mean (40:06) just i'm just curious in practice what percentage of of the neurons do fire endurance they are threshold so so tim is asking in practice what percentage of the neurons do actually fire and reach their threshold um i i i can't pull in a number i i so that the the point with that the percentage we set uh those are published in the paper uh these these are online tonight um and this this is the minimum amount and the maximum uh i should i can look this up i can get back to him okay cool okay all right um so uh all right so (40:53) um so laurel is asking for the same snn how does the brain scales wafer compared to other hardware like louis um well just depends on what so we the exact so answering this in general without actually modeling this is already tricky always tricky because um you can in general put those things there but if they work this this can be a lot of work it was a lot of work for us um so we for example another uh system is the brainscalp one system where i did my master thesis on and uh in a very simple set data set this worked as well for by the way that (41:36) those were um coba or conductance-based synopsis that i used an approximation for and then this the network still learned but i think uh with regards to energy or speed i i can't say unfortunately sorry okay um all right so i think let's just have one last question here um so we've got another one from moritz so how big is the variability of the mismatch you're simulating and is mismatched just something we need to deal with or can it be actually computationally advantageous for what specifically so which uh (42:13) um i think this came in earlier in the talks so i'm trying to remember when i saw the question first pop up probably yes um so here um as uh in our time constants here in simulation are just uh one so um and on the bottom you see that this is noise in in measures of the average um time constant i'm sorry i i just uh had the legend over there so um this is uh for twenty percent uh for a variation um that is 20 um we still see well basically no trouble or even like 40 on the right you see that if the mismatch is uh yeah well (42:53) uh 10 there's no problem even uh 20 is okay but for larger at least we see a drop in accuracy okay all right i think we're pretty much done for time so i'm going to end the questions there um but thank you very much for that uh julian it was a great talk and really really fascinating and the the uh the the power usage is potentially uh extraordinary right yeah it's uh very interesting stuff from that point of view okay great so that was the last talk of of this workshop i hope everyone's enjoyed it um (43:30) please do come along to the discussion i put the zoom link in the chat i'll put that in again in a second we're having a very interesting discussion i hope on uh why spiking um so hopefully that will generate some interest in some controversy and uh and i'll see you all there at that uh later today and if not thank you very much for coming along and thank you again to julia thanks thanks so much for having me thank you,,,,,,,,,,
https://www.youtube.com/watch?v=RyTpWFVE5hk&list=PL09WqqDbQWHGkpZ5RzNPWkvZBf4ZJKQaA&index=1,2022,SNUFA Seminars,Reza Shadmehr,Johns Hopkins University,Population coding in the cerebellum: a machine learning perspective,Theory,Transcript: (00:00) much for coming and thank you for uh inviting me and inaugurating this wonderful series um good for you good for you for uh trying to get perspectives from different directions regarding how uh the artificial and biological neural networks learn i i certainly am very much interested in this topic as well so um i want this to be something where you guys not just listen but but um have the opportunity to think about what i'm saying and so i'm gonna stop along the way and i'm gonna give you an opportunity to ask questions because i (00:37) think by asking questions you make it so that i i learn more about what i'm talking about and also other people can understand a little bit better so i'm sure your questions are not just yours but also many other people are going to be confused along the way so i'm going to talk about the cerebellum and i'm going to first tell you about the people who i'm really lucky to work with so this is from a couple days ago we had a um a birthday of one of my students and let me just introduce to people in the lab so this (01:06) is paul hage simon orozco amin fakharian it was birthday of jay pai was sitting in the front here this is a alden shoop in kyu jiang and that's me and a person that i've highlighted here who just graduated is essen all of these guys are phd students except thank you who's finishing his master's so just a small lab of young scholars who are working on completing their doctorate and that's what makes our little lab and so i'm going to describe to you the work of these individuals i'm going to begin (01:49) with a a simple idea which is the following um i i i think that learning in biological systems is generally fairly easy but what's surprising is that unlearning is pretty hard um to illustrate this i'm gonna focus on this little beautiful animal the the honeybee so um the honeybee but what it can do is that it can do of course many things but it can learn to associate odors with nectar so when it does this order nectar association what it does is that if you give it an order say a carnation well it extends as (02:26) proboscis and so you can train it so that every time it gets this uh carnation oil fragrance it will extend its little little tongue and so here it is here's this training of this little animal and you see that after three sessions of training it when you give it the odor it extends its little tongue and and this results in a long-term memory in that if you come back an hour later or two days two days later you still see that the animal has that ability now typically what is done in to cause unlearning is what's called extinction (03:03) and so what you do is you take another group of animals and train them as well like before but then now you present the odor but you don't provide the nectar anymore so what happens is that trial after trial the animal learns not to extend its little tongue so this is called extinction training what's really remarkable is what happens in the time that follows so if you come back an hour later two hours later four hours later and so forth what you see is that that that extinction didn't really erase anything because you see this this (03:34) pattern of spontaneous recovery of memory it's really interesting how learning produces something and then when errors change direction when you try to unlearn you don't necessarily cause this destructive thing but you you temporarily seem to cause some pressure but then with passage of time there's this recovery toward the initial initial training so extinction training didn't really erase this previously acquired memory this is really a fundamental thing in in behavior it's been observed since pavlov (04:04) how learning and unlearning take place it's not just in invertebrates that you see this of course you see this in mammals you see it in humans so let me show you an example of this idea in humans we're going to look at movements to produce adaptation and then learning from air so suppose i ask you to look at this spot here while you're looking here i give you a target here what happens is that you move your eyes from here to here it's called the sakai so you move your eyes like that now suppose as you were doing (04:34) that i'd move this little target up here so your eye ends here but the target is here so that's the air that you get at the end of your movement what happens is that slowly if you just repeat this trial after trial the eyes become curved in their trajectory they learn from this error and so that their movement that used to be straight becomes this little curved movement and if you keep on doing this the curvature increases now suppose at the end here we look at this this training so here here's the error that i gave and here's (05:04) the eye and what it did and so initially there was no vertical component to it and then as this error was presented this error this caused this little vertical component that we keep on doing it and you see that there is this increase in it all right so now we reversed here we want to cause extinction so you you make this movement i give you this target you make this movement but i jump the target downwards so now you have this error so the error has reverse direction here it is here's this pattern of unlearning that takes place (05:35) so here's the arrow in reverse direction and here's the vertical component of the eye comes back to what it was before and now what you do is that you present that target again but but you don't present any errors it's called error clamp trials so basically you present the stimulus precisely where the eye ends so if the target is presented we're going to error clamp to zero so we're going to presumably cause the circuit to stop learning and just present to me what it knows what you see (06:04) is that slowly there's a spontaneous recovery of that initial behavior so when the errors are clamped to zero the behavior goes back up toward where it was before so we see this spontaneous recovery in a simple task like a sakad in humans it's really ubiquitous across many learning systems so for example memory of fearful events it's true in mammals it's true in invertebrates that you see when you associate a stimulus with an event that is fear that causes fear and then you take it away it causes (06:35) extinction with passage of time it comes back motion adaptation shows a similar thing prism adaptation you put prism goggles on the eyes and you train and then untrained see the spontaneous um adaptation shows something similar i just showed you contrast that is perceptual stuff so similarly moving at the arm that shows something similar as well so there's really something fundamental going on here and many people have thought about this and i'm just going to present one simple idea along this for you and then we're (07:06) going to link it to a particular neural network in this case the cerebellum and we're going to use it to try to understand can can that help us make sense of um what this cis circuit is computing and how it's organized by this error so um here's a very simple model now like all models of course this idea is going to turn out to be wrong i'm going to show it to you that's going to be wrong but i just want to give you the basic intuition a couple of simple equations that describes why in principle (07:37) learning might show this concept of extinction and spontaneous recovery so the basic idea is this you make a prediction and the world provides you with the actual consequences that's your hair you gotta learn from this error now um suppose there are multiple systems that are gonna learn from this error this area is not just gonna produce something in one place maybe in multiple regions and that that makes it so that maybe some part is going to learn a lot from this error and some other parts are going to learn a little (08:05) from this era so maybe that's just the nature of this the circuit let's put together this in a simple set of equations suppose what you're predicting is a combination of two things instead of many things let's just make two things one of them is going to learn fast the other one is going to learn slow suppose that's the predictions that are being made by these two subsystems and that's the sum total of your prediction now your prediction error is difference between what you observed and what you (08:32) predict is here's what you predicted is what you observe now suppose we're going to have this learning in these two systems the fast and the slows the fast is going to have this property that's going to learn a lot from the air so this is going to be large but it's going to forget quickly so this is going to be small whereas this slow system is going to learn a little from this error so this is going to be small whereas this is going to be lower it's going to retain from error so but imagine that that error is going to (08:57) cause learning in two systems one that learns a lot but forgets quickly the other that learns a little but retains well so let's just simulate this system see what happens if you have this fast system high sensitivity to air but has limited ability to remember a slow system that learns a little bit from the air but what it learns it tends to retain so you adapt you're learning something you get this typical learning curve that goes up rapidly and then goes up slowly it has a double exponential that's so typical in (09:30) learning okay so as that's taking place underneath this system are these two systems that are producing your output there's that fast system learns a lot from air but it doesn't retain well whereas you have a slow system that learns slowly from air and retains well so the sum of these two some of the fast and slow is this red this is behavior now we cause extinction so we reverse the errors here when we reverse the errors what happens is the behavior now comes back rapidly down to baseline but these two systems don't return to this (10:02) the slow system slowly unlearns the fast system rapidly unlearned some of these two systems now becomes where you are now what you do is that you allow time to pass and now these two systems forget so the fast system rapidly forgets the slow system slowly forgets the sum of these two is the spontaneous recovery that we see in behavior so it's a very simple model to describe why unlearned extinction didn't cause full erasure it just produced competition between these systems but more interestingly with passage of time (10:35) one system decayed slowly the other one decayed rapidly and you got this spontaneous recovery all right so let's go back to our sakats now we want to we have the simple model that says maybe the underlying circuitry that's something like this going on right how do we how do we how do we test this idea how do we look to see what's going on in the brain so we think about cicadas and we think okay what what is responsible for learning and the behavioral data looking at patients suggests that the cerebellum has a lot (11:08) to do with it so this is a just to do your typical paradigm you make a saccode you get this error and if you're a healthy person what you see is that there's slowly this adaptation that takes place and that you're just the cat's curve and now you cause extinction so you cut your cut comes down back to normal and then you allow time to pass and you see the spontaneous this is what a healthy persistence you take people with cerebellar damage what you see is that well they just don't adapt very well (11:36) they don't learn very well from the air and of course if they don't learn very well there's not much for their spontaneous recovery to take place so the cerebellum has something to do with learning this task but there's more to the cerebellum than just learning it's also controlling your movement so let me show you an example so here's a here's a patient with cerebellar damage i want to show you their movements that they're so you get a sense of what the problem so here's their sakatsu (12:11) so what you're seeing is that the patient is trying to make these movements that they generally can make the movement but then there's this problem at the end of the they can't quite stabilize the eye at the target so here's what the actual trajectories would look like so this is the the blue is what a healthy person would do the red is what the patient is doing the dotted line is the target so the target jumps up to here the healthy person makes a cicada has a tiny error that corrects for it the patient overshoots a (12:40) target tries to correct overshoots overshoots and then stabilizes overshoots overshoots and finally stabilizes so in the cerebellar patient you of course yes you have a learning problem but you have a control problem underneath it so it's it's it's really the problem that in order to understand learning from error we need to first understand what what is the cerebellum predicting because without the healthy cerebellum these movements just aren't very well produced so i need to step back and tell you a (13:11) little bit about the anatomy of the circuit how a movement is generated and what might be the role of the cerebellum control that basic idea is that the cerebellum is really a side loop there is this controller that exists in your brain that can make movements but for whatever reasons those movements aren't very well made you need the cerebellum to make those movements well now the structure looks something like this so for you to move your eyes to make a saccode which you rely on are direct projections from your retina to a region (13:45) in the midbrain called the superior colliculus superior colliculus can makes the cuts in fact in animals like frogs that's all they have in order to move their gaze their orient their body toward the stimulus so the way it works is that you can think about the superior collectiveness as like an optimal controller that's provided with information from the gold here's where the stimulus is and through interaction with other brainstem pathways the burst generators and motor neurons it is certainly capable of (14:16) making the eye move however in you and me in mammals in general and many other animals it's not trusted with that action what happens is that that visual information also of course goes to your cortex and the cortex evaluates what is on the screen what am i what are my options it provides you with a utility map that describes where is it that i want to go and then through its removal of inhibition of the superior colliculus and production of excitation the vasoganglia the parental cortex the feral life field decide where to go and (14:53) get the colliculus to actually produce that movement now a copy of the commands that the colliculus is presenting goes to the cerebellum and the cerebellum does some magic with this with the commands that are being computed and makes some kind of prediction that appears to be central in uh organizing the the output to make it correct to make it well well made so um this circuit has been studied in in the past 50 years by real giants of neuroscience so the colliculus and the brainstem pathway has been studied by david robinson bob works david sparks (15:30) we've really mapped out how the circuitry is generating the saka then in the cortex we have giants as well okay paul glimpses mickey goldberg richard anderson who have described that evaluation of the stimulus by the cortex and the basal ganglia deciding where i should move my eyes and in the cerebellum we have giants as well that have thought about how the cerebellum is getting the sensory this motor output of the colliculus and and then potentially producing these corrections so you might ask me reza where the heck do you fit in (16:02) why are you telling us something new about the cerebellum when there were these people who have obviously studied the circuits for decades what what's what's the problem that you that they still exist well here's the basic problem when we measure neural activity in the cerebellum during cicadas in fact we have a really hard time understanding its language what is it that is predicting and i will show you it's not a simple problem even after these 50 years we still don't really know how to go from the spikes the cerebellum (16:31) is generating to understanding what is it that it's predicting with this output and so i started with the problem of learning but really the foundation of this problem we can't really understand learning from error until we understand what is being predicted which is the basis of describing what is the prediction error okay so fortunately the cerebellum is a three-layer network so in a sense it's not that difficult to think about what is this being computed so the cerebellum looks something like this it gets input (17:00) copy of those commands via mossy fibers it's called efference company that goes to this first layer called granule cells then the hidden layer the purkinje cells and then the output layer the nucleus that's presumably the output that makes predictions those predictions are sent via inhibition to a region of the brainstem called inferior olive that gets the combination of observation and that inhibition and the difference between those two is a prediction error that is getting set back to the cerebellum in (17:31) particular the prediction error is sent back with incredible accuracy with very high strength to the purkinje cell so that every time there is a there's a spike in the inferior olive neuron there will be a spike in the purkinje cell but it would be a very special spike called complex let me show it to you so we're going to show you activity from purkinje cells and i want to show you the two kinds of spikes that are generated here so the purkinje cells are going to make your normal spikes send their prediction (18:03) down here these are called these simple spikes here and then they're going to be these errors are going to be sent back to the to the purkinje cells and we're going to be able to differentiate these two kinds of spikes here's here's what it looks like okay so the neuron is making its predictions the frequency cell is sending its output this is the simple spikes here these are the things presumably that affects your behavior and the error information that is coming back is also dissociable here it is (18:37) complex so all right this is really great because we can we can actually see in a single neuron it's output that it's producing and the error that is being sent back to it so the prediction errors are conveyed via these complex spikes but our job is to understand those simple spikes because those simple spikes are what's producing the modification of your behavior and presumably affecting affecting your movements all right so what's the problem the problem is as follows the activity of those purkinje cells those simple (19:08) spikes that are being produced are really difficult to interpret so here's our our subject this is a this is a marmoset and we study marmosets because they allow us to do something really fundamental they allow us to to look at the cerebellum using these modern probes that were developed for rodents so marmosets are small they're small primates highly social that move their eyes just like you and me but because they're small we can use these modern probes to record simultaneously from many neurons as i (19:41) would show you that's going to be the key one of the keys in understanding this neural computation which is going to be how spikes among neurons aligns themselves in time and the prediction is both in terms of the firing rates and in terms of the timing of the spikes all right so here's our marmoset making sakatsu so here's the eye the eye is moving in this case to the left or to the right this is the velocity of the eye and here's the activity of one percussion cell so it's the simple spikes that are (20:11) being produced so in this case this parking gear cell has a baseline activity of about 40 hertz it pauses and then it goes back up again so one of the things you notice is that in the patient that i was showing you that trouble stopping the eye so you would think that the cerebellum would have a lot to do with precise prediction of when to stop the eye when to produce the activity that you need to stop the eye but if you look at activity at least this one cell that i'm showing you see that it pauses before the saccode starts and it (20:40) keeps on pausing long after the cicada is over now some pause here's some here's another cell a third cell there's a fourth cell who doesn't pause it seems to burst but it bursts after the movement is over this one bursts and pauses this one just bursts and this one does something else so this is the typical problem in neurophysiology you have behavior and you look at the activity of individual neurons and they're all over the place what's really puzzling is that the activity seems to last much longer (21:10) than the movement even though we saw that when there was damage to cerebellum the problem came was was coming up at that end of the movement which we would have thought the cerebellum is doing something to predict this end of the movement but we certainly don't see it in the simple spikes of the individual cells all right so that's our problem how do we understand this encoding all right so here's the basic idea that's this idea is really about a planner do you think about like an urban planner (21:40) the urban planner is the error the error is going to go and organize the cells so that there will be some groups of cells that prefer error say to the left and there will be another group of cells that prefers errors say upward the third group of cells that would prefer errors to the right here's what we're thinking about the anatomy of the system that the purkinje cells form groups and the membership of that group is defined by the error that they receive so there will be a group of purkinje cells we know anatomically there are about 50 (22:14) of them that project onto a single nucleus neuron but we think that the what makes this membership is that you have to receive the same error from the inferior olin and so that that that purkinje cells that belong to what we call a population to have something in common they all care about the same error and i'm going to describe to you what that means so all right what is this error that you're talking about how does it come about so let's go back to our basic idea about the input to the structure so suppose you are looking at (22:51) a target on the screen like this cartoon shows and i show you a target here so if if you're looking at this target on the screen there's activity in part of your colliculus called the rostral pole so there's a bunch of neurons here that are active while you're holding your eyes still i show you a target here that produces activity in another part of the visual system and this is going to produce activity in this part of the colliculus to the to down here so suppose now i you you decide to make a (23:20) cicada this activity rises the one falls and moves your eyes to this location so you're looking over here now now what your brain would predict is that if your target is on the fovea there should be activity here at the this part of the superior colliculus but i've jumped the target over here so the activity is over here so this is the expected sensory consequence you moved your eye the target should be on the phobia but actually it's over here so there's a different group of neurons than expected (23:48) for them to be active so error produces unexpected activity among neurons in a specific region of the superior collectors because the visual map is mapped on to the space you expected it to be here but it's actually here so there's different groups of neurons active than what you expected that's the actual sensory consequence it activates the inferior olive now this error is going to some group of purkinje cells so suppose there are some groups of purging cells that care about this error whereas another group of cells that care about (24:19) some other air suppose that's the anatomy by which this this structure is organized so then the question is how do we then look at this this population the first step is not to measure the simple spikes but to measure the error which is the complex spike so measure how each p each prokaryotic cells responds to an error this is our subject they ask to fixate a target is shown they make a account we jump the target to some random direction and we record those complex fights suppose we jump the target to the left (24:53) these red things that you see here are the complex flanks so in this case what you see is that there are some complex spikes that are generated when the air is to the left when the air is to the right there are fewer complex spikes that are generated so you compute the number of complex spikes that you get for this kind of an error versus this kind of an error and what you see is a tuning so this p cell cares about leftward errors why is it because it's getting input from a specific part of the superior colliculus (25:22) it cares about things that were unexpected in that part of the space all right so you can plot it as a function of time and you see that you know cells that have preference to a particular direction we call that csr the direction of air that produces a complex spike versus when it's in the opposite direction called a cs 180. (25:42) so now you begin to see we're going to define cells based on their preference for error so we're going to define a new coordinate system and that's going to be aerospace and we're going to ask which part of the aerospace do you care about and that's going to be the membership of your neuron and then we're going to put together the cells that care about the same error and then we're going to ask if we do that does the simple spikes the simple spices that produce do they make sense now if we define the space this (26:09) way so here's the basic idea use the preference for error to define this new coordinate system all right so suppose we record for a bunch of percentage so in this case it's the right part of the cerebellar firmness and this is the distribution of the error that they care about some care about upward air leftward air downward air mostly contralateral side thick here in this case this part of the cerebellum now what you do is the following for each purkinje cell use its cs on vector the vector of error that it prefers to (26:43) define this new coordinate system that you're talking about so suppose for a particular neuron it prefers these errors over to the 200 at 135 degrees so suppose this is the error that it prefers now you make a cicada like this that's 45 you would say this is a 45 degree but instead of calling it a 45 degree circle let's rotate our coordinate system and put zero based on preference for error this sakai now becomes cs plus 250. (27:12) so all we did is define a coordinate system based on error and now define movements with respect to the preferred error of that circuit all right so when you do that something i think really just remarkable happens so this is our sakai animal made this sakai and some cells burst some cells pause some cells do much more complicated things in all cases their activity lasts much longer now what we can do is we can just arbitrarily say some of these pausers and some of these bursters and just look at those those cells activities and what (27:41) you would see is that well you know these bursters are obviously increasing their activity these pausers are decreasing their activity but now instead of talking about movements in the direction of cartesian coordinates let's talk about it in terms of direction of error so in this case the movement is in direction cs plus 180. (28:00) what you see is that if you now simply sum the activities of neurons that all cared about that same error you see something remarkable you see there is a burst of activity in their simple spikes followed by a pause and then the modulation goes away so individual cells didn't show anything like this they showed bursting pausing and all over the place but if you organize the cells based on the error that they prefer and look at the population activity among those neurons now you see something that's sensible (28:31) and it becomes direction dependent so in a particular direction in direction cs plus 180 you see this burst pause and you know you see something a little bit less modulated in other directions so organizing the cells based on preference for error gave us something interesting in terms of their spiking and you see something further now if the velocity of the movement becomes higher higher higher what you see is that the activity in this burst increases but then this pause that i showed you seems to be time locked to (29:06) the when the movement is supposed to stop the deceleration so the burst grows with the velocity but then the pause seems to be time locked to the onset of deceleration which suggests that organizing the p-cells in this way is predicting when the movement should be stopped so this is a burst followed by a pause these are inhibitory neurons purkinje cells are inhibitory neurons so they are inhib they're increasing their inhibition then they're releasing their inhibition right around the time when you're supposed to stop the movement so (29:38) let me briefly summarize what i showed you so far we had a hard time understanding activity of individual cells we wanted to know how do we organize them into populations what we did in the cerebellum is that we organize the cells into groups based on preference for air when we did this the simple spikes the things that they were being predicted predicted some features of the ongoing sakat particularly timing of the deceleration onset so let me stop for a second here see if you have any questions hi sorry i have a quick question of (30:22) course yeah so so presumably these complex spikes are actually you know changing some something about the plasticity of the purkinje cells from the granule cells right yeah yeah so they're so the representation of the of the purkinje cells is going to shift in in some direction that that the teaching signal is telling them so if you pick let's say we pick out all the purkinje cells that have contact spikes in you know similar similar complex spikes are they going gonna starting from start from a different position and then you know (30:53) those purkinje cells are gonna shift in the same direction basically as they they're both getting the same teaching signal and change their plasticity in the same direction yeah exactly i'm gonna show you that so you know i started with the learning problem but then i said i can't attack the learning problem until i understand the control problem and so we've made some progress on the control but then we're going to switch to learning in the later part of my lecture so far all i've said is that (31:18) i think the organization is based on error we'll see how that error causes plasticity great thanks i guess my question is pretty much no a great question thank you for asking thank you any other questions all right don't be shy please stop me if if things don't make sense okay so um so far what i've shown you is that um that the there's modulation of these purkinje cells firing based on the movement that was taking place and there was a which is basically describing how average firing rates change and you know (31:59) we started with this idea that there's this group of purkinje cells that project onto the nucleus and what they share is this aerosol now they're inhibitory neurons so these neurons are inhibiting this nucleus cell so through their activity they're going to manipulate how the nuclear cell is going to fire and and one way they're going to manipulate that activity is through the firing race i just showed you that when the circuit takes place in a group of purkinje cells the activity is a burst so there's (32:27) inhibition then there's disinhibition removing that inhibition so this is one way by which you can get the nucleus cell to fire by removing your inhibition but there's something even more interesting which has to do with spike timing so if these neurons that are projecting here um increase their activity but then decrease their activity but then maybe during this period when they were removing their inhibition maybe the few spikes that remained if they would align it in time so that there was synchrony,,,,,,,,,,
https://www.youtube.com/watch?v=HT3mhgB0Gbc&list=PL09WqqDbQWHGkpZ5RzNPWkvZBf4ZJKQaA&index=2,2022,SNUFA Seminars,Matteo Saponati,Ernst Strüngmann Institute,Optimization at the single neuron level and how STDP can emerge from predictions,Theory,(148) Matteo Saponati and Manu Halvagal SNUFA seminar - YouTube https://www.youtube.com/watch?v=HT3mhgB0Gbc Transcript: (00:00) yeah so hi everyone and welcome to the second sniffer seminar uh today we've got two speakers um matteo and manny um each of them is going to give about a 20-minute talk um there'll be time for questions after each talk and then time for like open discussion afterwards um please keep yourselves muted during the talks but feel free to post questions in the chat and uh yeah i also have to let you know we're recording the session and uh it'll be available to you on youtube afterwards uh yeah so with that i'll (00:32) hand you over to matteo for our first talk sure okay so thank you everyone for being here and especially you thank you marcus for the invitation it's very very cool to have a give a talk for the some people of this newfa community so today yeah i'm gonna talk about our recent work that i've done here in the lab that is based on optimization at the single neural level and how sdp can emerge from predictions and i will try to give you my uh yeah to show you what do we mean with that basically so before that i will just (01:08) give a yeah like a why kind of thing question that yeah if we look at data what we see that there are after the discovery of spectrum independent basicity in the end of the 90s like you can see here in this picture there have been several sdp rules that have been found that depend on many different type of the cell type the what the the the region of the brain and there is not only stdp so sdp is just one part of actual huge is a part of a set of different learning rules that you can see in the brain that there is not only (01:43) the homosynaptic plasticity as i was saying that std belongs to this group you also have heterosynaptic plasticity so changes you can see changes in synapses that they're actually not activated by any synaptic input itself you can see homostasis that is more like a control feedback kind of thing there is long but also shorter plasticity and there are others so there is a there are many different rules and one could ask well like what are those algorithms for if they're algorithms like so you can think about (02:14) it more in a debit mark kind of way of thinking that you can ask which is the computational level of these of those algorithms and all those those algorithms especially cbp they depend on spike timing so indeed if we think about temporal code where you have precise spike times are what actually matters it's not the rate then we should expect to see the data some structural patterns of spikes not only rates for example sequences and this is indeed what we see it's being i mean this i think most of you that could be familiar (02:47) with the sequence that you we can see the hippocampus or also there is this very nice work from hamburger italian 2019 where they have a uh in vitro uh cortex of the turtle and by just eliciting one spike in one neuron they can have reliable sequence that they just come just because they start with one pin so in some neurons so you do see spikes these are sorry sequences you do see the structural patterns and then this also how do we match these two things like all those algorithms what are they useful for if you see all (03:24) those sequences and one idea is that that is basically the idea that we based on our model on is based on predictive coding which is of course a very broad topic i'm not going to get into detail what this means but basically the idea is that predictions of your of the future of your input is what matters for the brain very broadly saying and the the point here is that if you have a tunable readout of those interspects in the type then you could be able given those sequences to learn the temporal and also predictive (03:55) relationships between input for example to react faster or any other behavioral tasks the idea is that you can see who comes first who can predict the occurrence of the other if you are able to read out the interspike in the world and that's our basic idea we start with this hypothesis the prediction that i'm gonna try to explain what we mean with prediction later guide synaptic plasticity locally and we base our model on free observation or assumption if you want it depends so the encoding is local so the level of single neurons you you (04:28) have this biological plausible possibility problem that you can only compute with the information that you have at the level itself encoding is limited in this i'm not going to show you what do we mean with limited encoding is costly so there is a concept here of you want to optimize something to be better because otherwise you're just wasting energy basically so let's start from the first two so our model is one single neural model with very similar if not equivalent to an integrated file leaking the environment (05:00) so here just in discrete time a description so where you have yeah the leak and then you have some threshold uh some strong reset given by the fact that you can spike and spike here just a heavyset function with some threshold of the memory potential and then you have your input so if you if you put it in a computational graph kind of thing you can imagine the membrane voltage you can interpret it has a temporal filter with some memory of what happened up to this time so you have some depolarization here now (05:30) this is the result of everything that happened in the past and here you can see it as at every time step you get the input now then you can you are scaling with your weights and then you have the member point voltage of the test and eventually some spikes that happen and here encoding is local in the sense that we are focusing on the member potential as the relevant variable for our computation in the sense that i would just i just told you this temporal filtering with some memory of the test and encoding is limited in this sense (06:02) that you cannot get depolarized forever up to infinite voltage but you have some threshold so you have to find the best way to encode what you need given the range of member of the polarization that you can have and then the last part the code is constantly so that's where we ended we insert the optimization problem that we can go back and more in the detail later but the idea is that the loss the the objective of that one nero is to reconstruct or predict if you like the input that is receiving at time step t (06:36) given the memory that it has of everything that happened before in the member potential of t minus one and the the weights that he has learned up to that one point and here that's how we and we add this term in the computation graph so uh if we do this then we can do just some gradient center try to find out some learning rule and here i'm already giving you the without the derivation that's the learning we get in your line approximation that means that we can actually now that also the weights get a (07:10) subscript of time you we can adjust the synaptic weights recurrently recursively in time together with the dynamics of the member potential and the learning rule is given by two terms that are where the major component is the prediction which is indeed the difference between the input now and what i can say about the input given what i saw up to the previous time step and after this now i'm going to try to show you what if the neuron follows this learning rule what can happen when we train neurons to receive sequences of spikes and i'm (07:42) going to show you and hopefully it will be an understandable way that the um what happens is that the nero learns to give credit to the input that they have some predictive power on the inputs or the other inputs that are gonna come because if there is a previous input here as some predictive power so exp i'm going to expect that the next input of the sequence if the sequence is very reliable structure is going to come so this gives me uh predictive power for the future and these i'm gonna enhance this input and suppress the other (08:16) but let's see it with our simulations and let's imagine one simple case in which we have a sequence of in this case that we have 100 inputs that they're sending one spike per neuron in a time window of 150 milliseconds and this is the sequence that the newton says and then we trade the neuron on this sequence repeatedly and now i'm going to show you what happens to the synaptic weights and to the output so the spiking activity of the neuron across learning and what you see is that at the beginning there's a bit (08:48) of a massive thing but then the more this is the the the sequence the more it learns to give credit to input earlier and earlier along the sequence because an input here is predictive of the future inputs but then the neuron learns that there are previous inputs then they can be predictive of those and the convergent point is that it gives credit to the first input of the sequence which are which is the unpredictable part of the sequence itself the unpredictable part is the starting you don't know what it (09:16) starts but when it starts you know that the sequence is going to be this longer is going to be those inputs and this is the spike time of the neuron as you can see while the neuron is learning also the is going it's changing where it fires so is that is learning to represent input earlier in the sequence and that's the convergence point then we can move a little bit more on and say okay but that was a bit simple like each one here and spikes one new uh each one this electric has one spike only blah so let's imagine that we have a pattern (09:49) so now i'm just computing here i just it's a random pattern homogeneous poisson for 500 inputs in a time width of 100 milliseconds this is in the not order case if you then could take this pattern and you try to order as a sequence that's what you see so you will have something like that and we trade the neuron on this but still it's not that it doesn't depend on the how many inputs each one neuron is it's firing it just depends really on spike timing and the buttons that the sequence contains and (10:21) you see the same behavior you see a decrease like uh it's gonna learn to give great to the first input and it's gonna represent only the beginning of the sequence and uh this doesn't depend on initial condition and it does not depend on the amount of vehicles that you see so here i'm showing you the loss across learning how it changes for both these spike valleys here means the sequence that's one to one spike per neuron that goes and the spike pattern is what it would be before and you can (10:52) see independently of how many inputs there are or the dependency of the initial conditions here you can just go and put your learns to do that because it's a convergent point of the dynamics that one solution and what i want to say here that the mirror learns to represent the unpredictable part of the sequence what we're also trying to see here is that what happens if this sequence is not a continuous sequence but you have parts of sequence every now and then the input and what you can see here is that the weights that the mirror is going to (11:24) learn to represent input first the components of the input for each subsequence that you have in the sequence and here what i'm showing you this is just the fighting rate computed in the in a time window of the membrane constant of the neuron that that is the relevant variable for these of course because that's what defines the memory of the neuron and here what what does it mean is that there is an input here and then you compute from from each time step you compute time window time scales member time (11:57) constant in the future and then you compute how many inputs you have in this time window and then you keep on going like that so you are at the top where you are at the very first input of the sequence and these lines they represent where the neuron fires at the end of training so as you can see he learns to represent the beginning of each sequence and of course is driven by learning and now we are trying to compute i'm not showing here this because it's a work in progress somehow try to estimate the capacity of (12:28) the neuron based on the parameters that we're using so how many subsequent the neuron can learn if if the the sequence they have overlapping synapses this is working progress so i'm not gonna show you because i don't have it yet so uh but yeah that's basically the idea so the important part here is that neurons learn to represent your predictable part of sequences it doesn't depend on initial condition doesn't depend on the input it just depends on the if you want the spike density so where there is a (12:58) part of a sequence that has some spike so it's dense then the neuron can learn to to recognize the temporal relationships between that subsequence and represent the unpredictable part now i'm gonna try to show you like yeah cool but like which which is the mechanism that niron can do that and here let's imagine in order to do so let's imagine a very simple proof of principle cut thing when you have two inputs only so you have a neuron and the actual inputs with uh here is that two milliseconds and four (13:32) milliseconds and there is so uh delta t a time window in between sorry of four milliseconds and let's imagine that the neural starts by having the first simply sub-threshold then the second input drives the delta file across epochs the neural starts to d to decrease so suppress this input and increase those in the first input such that eventually he will learn to fire not for the second because the second is predicted by the first but it's gonna fire for only for the first and here i'm showing just in this very simple case (14:09) starting from different initial conditions what i want to show you here is that the importance of the output spike let's imagine we take this case in this case you have w1 and w2 are the synaptic weights for the first and second input you see that if the neuron does not fire yet the both inputs are but then as long as soon sorry as soon as the nail starts firing then you have this broke this break of the symmetry and that is where the first input gets kicked in and gets maximized and the second input gets minimized and you can (14:43) see it here for the output five times and of course even in true input case here i'm averaging over many different initial conditions it doesn't matter whatever you start you will end up with the first one maximally potentiated in the second one uh i mean suppressed and these you can also see it if you want in a parameter space analysis so this is a convergent point wherever you start you're gonna end up there and here i'm gonna go to the last part that is the relation with http and i'm trying to i hope i'm gonna make my point (15:20) clear enough so let's imagine that we are here in this parameter space if we start from this initial condition you will have both potentiation and then at some point the neuron will start firing and then you have this break of symmetry but let's imagine that we are here or somewhere there you can see that the dynamics in the parameter space so the way that the the synaptic weights change depends from where you are and depends on the uh yeah if you're spiking or not but let's imagine that we are here here it means that there is the (15:53) second input that is firing then sorry the second input is the one that triggers a spike and the first simple doesn't this reminds us of http protocols where you have a pre-post pairing where you have a pre and then a post and if the pre comes before the post they have potentiation and the other way around differentiation so we wonder what happens if we just use the same input protocol the simple one true inputs one uh two milliseconds and one four and then six in that case but we just see how the now how the (16:26) learning changes if we increase or decrease the density between the inputs has the people dozing icd to compute the learning group this is important because if you think about it stdp somehow is a specific component of the gradient so it is a temporal filter of derivatives if you think about it that your model your system is a recursive system a recursive system that indeed has some hidden activity that gets into the plug into the next time step it will have a recursive gradient and if the system is stable it would this recursive gradient will (17:08) depend on the uh jacobian or whatever the the way that the the activity of the of the system itself gets recursively updated and if the system is stable you gain component of the grid and this is basically somehow if you want stdp you can see some preferences and the point is that though if this is the case then why the effective delta w has to be always anti-symmetrical and and if the if we are using this comparison with the optimization if the output is a discrete spike or not spike what how can the input be penalized (17:51) if the gradient has been already propagated through the fact that the spike happened so how can you have the post pre deposit the potentiation and also we can see that as we saw before sdp depends on many other different things and especially it can also you can also have plasticity even without output spikes so all of these questions and this way of trying to address sdp in a more gradient descent kind of idea led us to indeed has a token see how the the our weights will change if we use a true input sequence and then we just (18:30) change the delta t between the inputs and what we did we did exactly that and we see something like a cdp so basically if you have two inputs that they come this of course we are constraining the input in a way that in this case is the cycle dipole that is triggered in the spike and in this case is the first improvement of the spike but if you constrain that you can see that it's just a matter of the parameters that you're using and the initial condition where you are you can get something like a cdp with this dependency (19:03) delay but also depending on where you are in the parameter space you can have some different http rules so you don't only have this necessarily this one it really depends from where you are so in this case uh these are not so cool examples but you can have the completely healthy ltp based uh smdp or you can have a complete ltd i'm not showing here right now but we also have some cases which you can have the opposite of that so you can have the anti-opinion it really depends from where you are and on top of that what we try to show (19:40) is that we can also reproduce not the classical not only the classical sdp free post pairing but some more nonlinear sdp as they call it so the dependence of http on other factors that is not only the print post in this case here you can see how http how plasticity in general depends on the when you instead of having a pre post you have a pre and free posts and you just change the the frequency of these post-synaptic bursts and what they see in the data is that if you increase the frequency of the burst you can increase ltp but you don't (20:15) change activity and we can reproduce this we can also reproduce the crazy shift that you have there are several papers this is very interesting how sdp depends on the frequency of pairing that of course it makes sense that when you increase the frequency of pairing so you are decreasing the time window between one peoples and the other one if you if you decrease it enough then the second one of one repetition can become the first for the for the next repetition so you're just gonna merge two repetitions together so you what you (20:52) can see is that you can turn ltd into ltp for high enough frequency pairing and that's what we can see what's in our model and for instance we can see that a post pre that would lead to ltd can tur can be turned into a ldp if you then add enough spikes later on so it's supposed to be post post post the more you increase the spikes the more you can turn ltd to ltp so basically the main argument here is that you don't need necessarily to hardcore http in your rules in your model it could actually be that (21:30) sdp is just a is a cross-section of a more complicated learning rule and you see sdp for specific cases and you see another type of sdp for other specific cases but they're not necessarily different mechanisms they can belong to the same underlying rule that in our case we would propose that is based on predictions and yeah for with this i'm done so i want to thank you everybody for listening to me we have a pre-printout many things changed but you can see some some stuff that i talked about here as well and yeah then i'm just open to (22:07) progressing everything thanks a lot man really cool thanks a lot for the talk matteo um if anyone has a quick question maybe we could do that and then uh we'll get on to manny yeah just quickly so you you mentioned um like this the learning rule came about from you know you you started with a loss function that you assumed okay let's assume that the neuron is trying to predict kind of the future and then and then you get you got a weight update that came out of the the derivation of that right but so then (22:39) so the the different shapes of the stdp they come about only by based on your initial weights not they're not based on anything to do with the loss function itself like that you know you showed us the symmetrical the the asymmetrical stdp the symmetrical the ltd different all these variants right these are purely function of your initial weights yeah and eventually of the parameters that you use in the model that they're basically true in our in our model given that is basically a leak integrating fire we have only two parameters that is the (23:13) member time constant and the threshold so depending on where you put your member your threshold and your member time constant and depending from where you start in the permit space that's why you can get yes but it doesn't do it's always the same loss that was a question yeah right yeah yeah exactly cool well lots of stuff to discuss afterwards um with that i'd like to introduce on that speaker oh man do you have a quick question no no go for it please uh so yeah uh i might have missed this but (23:48) this does this uh neuron after learning does it respond more to unpredictable stimuli or stimuli that were not expected if there's like a prediction predicted coding or is the idea that like unpredictable stimuli uh evoke more higher responses right does that actually come out of this so yeah thank you for the question of course this is very interesting because you know indeed predictive coding sort of as expects is this a prediction of predictable it's a bit of a problem whatever uh but um but it really depends on the actual (24:34) context that you have so this is a very general idea that makes sense and i could tell you yes why in our case it works because if the environment of the neuron is the low sequence then the inputs that are later are the predictable inputs and the first input of the sequence is the unpredictable input so he just fired for the first and he doesn't represent the other ones because they're already predicted so if you imagine it that way that's the environment of the neuron it just receives pings from all over (25:08) and that yeah that means that we have we we actually have what predictive problems would have but of course this has to be you know contextualizing what you're having and the specific yeah type of inputs that you have but yeah cool um with that if manu would you like to share your thoughts so yes but for anyone who's interested i'll put a link to matteo's preprint in the chat great so yeah on to our second speaker which is money yes um can you rebalance your screen and hear me okay yep thank you so much (26:01) thanks for joining everybody and uh thanks marcus for the chance to present here uh this is a quick introduction i'm a phd student with uh freedom anthony at the friedrich nature institute in basil and my phd work is about biologically plausible unsupervised learning objectives and plasticity roles and i'm looking forward to discuss some of this work with all of you today so at a high level the motivation for my project is just this simple observation that natural visual input is a stream of images like this little dog running (26:39) around here and represented as vectors in the activities of sensory input neurons the sequence of stimuli would define some high dimensional non-linear mineral and after some time suppose we see a cat running around and then this would define another manifold and so on so in raw sensory input space this defines these manifolds are usually highly entangled in a non-linear way but we know that in the cortex specifically the infra-temporal cortex neural activities are actually disentangled and object categories can actually be (27:21) linearly recognized but how does the brain learn such disentangle representation in the first place right so when you zoom into the brain the ventral visual stream that extracts object representations is consisting of hierarchically connected populations of neurons and we can approximate them to some extent by structure of deep con confidence but the reason why we look at this is that they've been empirically very successful at this problem of representation learning and the process by which they learn can start to shed some light on how the (27:59) brain might be doing this in the first place but the usual way of training deep maths is with explicit and detailed supervision like supervised learning it's not likely to be present in biology so the question is more about how these representations could be learned in an unsupervised way just by exposure to data from them so in our work we look at whether learning by prediction could be a viable strategy for the brain to do this kind of unsupported learning of disintegrated representations and this strategy is based on the (28:34) observation in that inputs that occur close together with time are likely to be corresponding to the same underlying object even if living conditions are changing or if the if the object is moving around and so on so intuitively then what we could do is to pull together represent in neural space the representations of those stimuli that are happening close together so this pulling together is happening in the space of network outputs in terms of an n or in the cortex in terms of strains so basically we are asking (29:09) neuronal activities to be good predictors of future activities so that they become invariant to small changes like human conditions or motion and only sensitive to features of the input that remain invariant or constant over time like object identity of course this idea is closely related to predictive processing models of the brain such as the brain is constantly making these sorts of predictions of its own future activity and we're here trying to look at the idea that errors in these predictions could be (29:41) useful for learning it turns out that this idea this principle has actually been successfully applied by the machine learning community in in terms of these models called self-surprise learning models and these are basically based on the same strategy but they also use something called contrasting objectives but i'll touch upon it towards the end so we can now formalize with this idea of predictive learning as optimizing the objective of minimizing prediction errors in the space of neuron outputs this is a bit different from the (30:16) objective that mateo just talked about which is optimizing prediction errors of its inputs so we are here optimizing the prediction errors in terms of the output of the neuron the problem with this is that such predictive learning by itself has a degenerate solution where the network could just cheat and have constant output and if it has a constant output it obviously has a zero prediction error perfectly minimized and the constant output is perfectly predictable but it's also perfect to use this as a representation (30:54) so we need a mechanism to prevent such a representational collapse and what this mechanism would need to do is to push representations of stimuli that are far separated and not allowed to be the same sort of various maximization constraints the cool thing is one of the most well-known computational models of synaptic plasticity that we probably already all know about is well suited to achieve this kind of variance maximizing effect and i'm talking here about heavier plasticity and to see why here's a sketch of (31:35) uh which is one a stable heavy and learning rule and here the idea is that there's a mean dependent learning threshold and all the inputs that all the inputs that he works to represent evoke outputs that are higher than the learning threshold gets pushed further up and all inputs that are lower than the threshold get pushed further down undergoing lcd and so by definition the output of the neuron is not allowed is driven far and far away from the center of the outward activity space and by definition collapse is avoided (32:12) so with all this in mind we came up with simple plasticity rule uh lpl rule for latent creative learning and uh as usual there's learning great eta and this term the second term here is almost exactly the dcm rule except we use the mean output c bar directly without a nonlinearity of the learning threshold and there's also this weighting by the variance of the output activity which basically turns off have been learning when there's enough values basically when the output activities are separated enough that it's no longer necessary to (33:02) have this push effect and the predictive the predictive term for example here is the term that actually says the activities that are close together in time should be similar enough so that the activity doesn't change very fast so this is what really implements the full effect this plasticity rule is an extension of pcm theory with the realistic neuronal transfer function like we plotted here the learning rule looks exactly like pcm with the threshold that moves around depending on the mean activity of the neuron (33:44) uh z-bar and but now the predictive term the rate of change gives an additional independent mechanism to move the learning threshold around and also this variance dependence which shuts off every learning when there's enough variance by changing the shape of the plasticity let's see now what this neuron what this learning rule does in practice for this we looked at a very simple setting with the rate neuron that just has two inputs and the input stimuli come from two clusters that are separated in the x direction (34:22) and the sequence of inputs is such that if a given input comes from one cluster then the input at the next time star is very likely to come from the same cluster occasionally there are jumps but these are very relaxed so and the y direction is just defined as a noise direction with consecutive samples that just drawn from a gaussian distribution with different amounts of standard deviation sigma y and uh overall this means that the sorry overall this means that the x input is the slow or predictable feature because consecutive stimuli have high (34:57) probability of it having the same value of x whereas the y input is completely unpredictable noise so what does this neuron learn under different learning rules here we started the selectivity of the neuron to the x direction which is the predictable stimulus as a function of different noise levels so what would have been learning rule like oyasuru for example learn uh so at low over the years learning room typically picks up is known to pick up the highest variance principal component and it's low values of sigma y low values of (35:35) noise that's just the x direction but this switches over to the y direction to the noise direction at high values of sigma y that's exactly what we as long does it's selected to x at low noise levels and selected to y at high noise levels and uh the same thing is true of our learning rule when we just have the heavy term order and the predict without the predictive term but when we actually have the predictive term in the learning the neuron always becomes selective to x regardless of how much noise it is (36:10) of course the heavy learning rule we included this in the first place because it was necessary to avoid collapse and we see exactly that's what happens when we exclude the heavy term now when the heavy insurance is not there activity quickly goes to zero which obviously we would want to avoid so both terms of this running rule are important so we just saw that for receivable run but it does there's no features of its inputs but before we move on to apply this to a network let's t,,,,,,,,,,
https://www.youtube.com/watch?v=un07rVjfK3M&list=PL09WqqDbQWHGkpZ5RzNPWkvZBf4ZJKQaA&index=3,2022,SNUFA Seminars,Alessandro Galloni,Rutgers University,Neural circuit mechanisms of pattern seperation in the dentate gyrus,Neuromorphic-compatible algorithms,(148) Alessandro Galloni SNUFA seminar - YouTube https://www.youtube.com/watch?v=un07rVjfK3M Transcript: (00:00) welcome everyone and thanks for joining what is the third of our seminar series um sort of loosely on spiking neural networks um our first speaker today is alessandro alessandro and i actually first crossed paths in the first year of my phd when he was a master student in the lab and we were both doing experimental work um which is pretty different from what we're both doing now and yeah i saw he had this paper out and i think it'll be really interesting for the audience here um so yeah alessandro can tell you the (00:33) rest okay yeah yeah so hi everyone uh yeah thanks for joining and yeah thanks marcus for organizing all this um so yeah i'm gonna talk about some recent work that we've been doing in the lab uh kind of building some simple models of the dentate gyrus and trying to see how different cell types interact and how they can help for doing pattern separation um and okay so one situation you might be familiar with is trying to find your car in a parking garage so this is something that you know really puts our spatial memory to (01:07) the test and hopefully you can find it in less than six months but you know in order to do this our brains really need to figure out how to tell apart very different or very similar environments and try to kind of disentangle their neural representation so that even though every everywhere kind of looks the same we're still able to tell that if our car is here or if it's you know in the next slot or on the floor above or below um so so how does the brain do this well there's one region that's uh you know (01:38) particularly associated with this function and in brain slices it really stands out because uh it has a very high density of cells there and and they're packed very closely together and so when we stain for a nuclear stain we can see it uh it's you know in very high contrast um and so so what exactly this region is called the dentate gyrus uh so what exactly does the dentate gyrus do and and why are there so many cells packed in there um so let me start by just showing you a bit of data about what we know about the (02:09) vantage iris so first of all uh the activity of the the principal cells in the dentate gyrus is incredibly sparse so so these are called granule cells and you know generally only about two percent of the dented granule cells are active in any given environment uh and when there are active they're very selective they're only you know active in one environment generally with only one place field um and and they have kind of fairly low average firing rates uh outside of their field they're completely silent (02:41) um and so so they're kind of very sparse and very selective in in their firing um and the other kind of key uh feature of the dente representation is the fact that very similar environments tend to have decorated population representation and so this is what people refer to when they talk about pattern separation so i'm going in the data i'm about to show you uh is kind of a very well-known experiment in which they take an environment and then they make you know many small changes until eventually the (03:13) environment looks completely different than the first environment they started with and what we gonna what we see in general is that the dentate gyrus the representation is very sensitive to small changes in the environment so so what we're seeing here the points on the right are represent two kind of very different environments and so there we would expect that yeah the population representation is going to be also very different on the other hand when we have two very very similar environments now the dentate gyrus can do can still maintain (03:45) some level of discrimination between these two environments and still kind of somewhat decorate the neural representation much better than for example neurons in other parts of the hippocampus like the ca3 okay and kind of one indication that this this ability to separate similar environments is kind of behaviorally relevant is uh you know here's one example that in old mice that might have memory impairments it seems to correlate with a loss of pattern separation and like a collapse of the representation so (04:17) that the same cell will fire even in very different environments uh you know like we see here whereas on normal circumstances both in dentite and in ca3 we would expect that if the environment is clearly different then the representation would also be different and generally you don't have this the same pattern of firing okay so how does the dentate gyrus do this how does it uh separate similar patterns and kind of disentangle their neural representations and so to get a better understanding of this why don't we take a closer look at (04:53) the local microstructure within the dentate gyrus so as i mentioned the main excitatory cells are called granule cells so they receive feed forward input from enter rhino cortex integrated and then send their axons forward to ca3 and then and then that kind of propagates forward throughout throughout the hippocampus um then uh they're all they locally interact also with a variety of interneurons so some interneurons provide feed-forward inhibition inhibition there are other neurons that function as feedback and here (05:28) the architecture is actually slightly unusual in that the feedback operates mainly through a set of excitatory local interneurons they're called massive cells they're recurrently connected and they provide kind of simultaneously feedback excitation to the granule cells but they're also driving these feedback inhibitory interneurons which are specifically dendrite targeting interneurons [Music] okay so to kind of get a better understanding of how all these cells are interacting what are what are their different (06:01) contributions to the overall pattern separation uh we we're going to abstract a little bit away from the biology and consider a more simplified rate neuron model of the dentate gyrus and sorry to disappoint the the the fans of spiking networks here this is this is a conductance-based model so we have kind of synaptic conductances cell conductances but it's not actually a spiking model but and what we're going to do is we're going to see how does the representation change as we add in different cell types (06:33) so we're going to start very simple we're going with the kind of the simplest possible network just the the input from internal cortex and the granule cells here represented by these output cells um and kind of and we have this characteristic of the fact that there are very many granule cells you have this expansion of the representation um and and one characteristic of the input is that it tends to be relatively dense with overlapping activity patterns you know you can think of like granule cells grid cells that are have many place (07:06) fields in an environment and they're often active across many different environments so they have this kind of very dense representation on the other hand in in the granule cells we would expect to see a very sparse activity pattern and preferably something that's relatively orthogonal so something that has very different activity pattern across different inputs different environments and so on so okay so now what we're going to do is we're going to add different cell types and what i'm going to show you uh what (07:40) happens as we kind of progressively take a kind of building blocks approach like lego blocks we add you know what happens when we add feed forward inhibitory component a feedback component some combination of these or these excitatory mossy cell recurrent excitatory neurons um and and one thing i should add is that we're we're really focusing here on like the architecture itself like it's kind of in isolation uh what kind of prior does the architecture provide to the system that can maybe help it to (08:15) to to try to it doesn't tangle the representations but kind of independent from any specific learning rule and so to try to kind of reduce as much as possible then the all the different free parameters uh rather than actually learning the weights through back prop or headband learning rules we're just going to sample the weights randomly and maybe do a little bit of optimization just trying to tune the overall strength of each projection but but without actually doing any any fine scale learning okay and so as for the inputs what we're (08:49) going to do is we're just going to try kind of all the possible combinations of these seven input patterns so each uh each input unit has their seven input units in this in this little simple little model and each one is going to be active for exactly half half of the time and so if we do all the possible combinations of these this is kind of this is what it looks like and what we're then going to see is what happens in the output representation which we're going to kind of quantify in terms of these three metrics so we're (09:19) going to look at the sparsity of the of the granule cells so in other words how many units are active in a given in response to a given pattern we'll look at the selectivity so for any given output unit how how active is it is how selective is it for one particular pattern and then the discriminability kind of cross patterns how orthogonal are they how how easy are they to separate to distinguish so even though they're technically different we might have some patterns that are very similar but ideally we (09:48) would like them all to be as as separate from each other as they can be and so we might imagine that some sort of ideal intersection of all of these these metrics might look something like this so where we have uh forever here every row is a different output unit and so we might have every unit is specifically selected for one pattern uh there's only one unit active for that pattern and and they're all kind of trying to be different from each other's to be perfectly orthogonal okay this is the kind of the ideal scenario (10:18) um so so let's kind of see what happens as we as we play around with the with the architecture and so starting with this kind of very simple input output network which is kind of going to be our baseline here and so we're just have like a random expansion of the representation and so we we're not really expecting uh anything uh any huge change in in the in the ability to represent these patterns here um and so as we can see the activity is kind of very distributed and selective and actually we see one other challenge (10:51) with this particular uh set of input patterns that we've constructed is that you might have some combinations where you know by chance you might have multiple units that are active at the same time and multiple of the inputs that are active at the same time others where there are fewer inputs active at the same time and so one of the challenges is also how do you avoid uh having all the neurons become selective for the for the strongest input patterns um so here we see kind of a summary of these these three metrics the red line (11:20) indicates like uh what the in what the representation among these seven internal inputs neurons looks like and then the black line is the representation in the output cells and so we see that you know there isn't there isn't a huge difference in any of the metrics uh and for selectivity it looks a little strange that's just because for the input every unit is active exactly half of the time so there's kind of exactly half selectivity whereas in the output units you have some that are just firing completely and selectively all (11:50) the time or and then others that are maybe have by by chance they got slightly weaker weights they're they are only selective for a much smaller number of of the patterns okay so what happens as we begin to add inhibition into this network well uh with feed forward inhibition we now have at least a separate independent readout of this input so so at the very least that kind of can help us to try to normalize this level of excitation across all the different patterns uh it's the and so i'm just going to show (12:22) you as we kind of turn up the knob of the of the inhibition inhibitory strength um we can we can see this kind of slight flattening out of the of the representation across the different patterns but it's this is still a very coarse control you know we as we start to really crank up the inhibition we we start to lose a bunch of the output units they become completely silenced on the other hand we're not really getting any gains in in selectivity of the it's the same strong units that are just active all the time (12:51) and so we're not really spreading it out among the among the output units and if we try to just pick some optimal value for this for this inhibition you know we get some improvement over just the baseline of uh without any interneurons but not huge um so and then let's look at what happens with feedback inhibition well we actually have a similar problem so if we if um if we had maybe a classic like winner take all system you might think that oh you would expect that this would work quite well uh but one requirement for (13:27) that to work well is that there has to be some structure in in the input weights so if a different unit receives the most amount of excitation for every given pattern then the winner take all kind of lateral inhibition might help to clean out to clean up the noise and really sharpen that representation but in the absence of that what you just what you have is that if some units happen to get slightly stronger waste than others then those units are going to win all the time uh and so now you know if we crank up the (13:54) inhibition we we get something kind of similar where again we lose out a bunch of the units and the others haven't really increased their activity all that much and so so we see still you know a little bit of improvement over the baseline but not huge okay um so something interesting happens if we reroute the feedback inhibition to go through these recurrent mossy cell like excitatory neurons um and the main thing is that now we have things mostly to these recurrent connections we have this non-linear amplification mechanism and so uh and so (14:36) even if you have very very weak activity in the in the output cells you can you have this mechanism that can really sort of exponentially ramp up the the amount of inhibition and give you a much more dynamic range for it um and so so what we have now is that we can really uh have different regimes of inhibition that can that can actually really help to really make the population not just sparse but actually selected without without completely silencing any units and without just having the same units active all the time (15:09) um and so we really get kind of quite a quite a substantial kind of improvement over these these uh three metrics that we've chosen um of course we're still not you know still not uh the perfect orthogonal pattern but you know we're still doing quite well with with completely random random connection connectivity uh and just to show you kind of that actually these these recurrent connections really are the crucial element here for getting this to work and and the reason uh is because you know if we remove them then we don't (15:44) have this this sort of amplification mechanism and so now we really have not really any benefit over what we had earlier with just the into the inhibitory interneurons um and so so it's really like this ability to have have this sort of amplification in the system that that can that can really benefit uh and give you a much more flexibility in how you control innovation um and yeah and then obviously this is what how what we can do with purely random connections uh i'm sure you know learning of course is very important and (16:19) so that uh let's see so yeah of course that's kind of one of the future directions that i'm uh working on is to try to see well of course what we would expect learning now to be able to refine these connections especially if learning can help us get a slightly more structured input weight matrix now we now that gives the feedback inhibitory neurons a lot more material to work with so you can it's much easier to get a winner take all system and so so maybe with if you have the right architectural prior now with just (16:51) a little bit of inhibition of learning you might be able to do quite well uh with without without putting too much effort into having something very complex um and so that's kind of the direction i'm i'm pushing on especially trying to see how it's actually known that there is some feedback connections from ca3 that go back to the dentate gyrus so uh uh trying to see if that that might have a hell a role in guiding learning and advantage iris so anyway that's that's me um i'd just like to thank everyone uh (17:24) everyone in the lab here for their help and all our funders and and yeah thank you all for listening and if you want to check out the play around with the model yourself you're welcome to uh or you're welcome to get in touch [Applause] cool thanks very much for the talk alessandra it's really clear um yeah i mean does anyone have any questions which they'd like to give ask so i just want to clarify something if i may thanks a really nice talk really nice figures also it's really clear what's happening (17:56) so at the end you say that you still have to implement learning but it's not so clear to me how do you set up the connections right now is it just kind of global inhibition and global excitation loops or is there some pattern that you the random connectivity or uh yeah so like yeah we just chew we have um random distributions for so um for each of these there you go so for each of these projections we'll have a random distribution that we're sampling weights from that's it and and we we chose for the excitatory connections (18:31) we chose log normal distributions because they they seem to be somewhat ubiqui ubiquitous in a lot of these systems um and and for the inhibitory connections we just uh chose uniform distributions correct yeah you know yeah and um and then and then all we're doing is we do we did some optimization we did a sort of pseudo evolutionary algorithm that optimizes for just like the the parameters of this distribution that we're selecting from because we try to give it the best chance it can with with sort of one hyper parameter (19:04) per projection basically nice thank you right i was thinking just the longer term um you could imagine like a really big space of these models the sort of possible networks of the task right have you had to think about ways in which you could explore like a much bigger space of models um you mean like uh like try to kind of expand the number of different like interacting populations for example or yeah that sort of thing i mean i guess with additional layers or um yeah i mean you could imagine adding like feedback recurrent connections to (19:45) like you know all the populations you've shown here as well right right yeah i mean i think yeah exactly like the the number of possible connections you know really start and especially if you start adding additional populations it really starts to explode uh like all the number of possible combinations um and then it does become a little tricky to try to to try to really optimize all of the connections at once and in fact there are some models that i didn't show but that really have even more connections uh (20:14) in some it it uh at least for our case it like for example when we add this feedback excitatory connection it didn't make didn't make a huge difference in this particular little toy system um although um yeah so so i think it it kind of yeah it depends on what your what your objectives are like yeah we could we could easily easily scale it to have many more populations uh it'd be yeah it'd be harder maybe a little harder to interpret what's what's happening um and so yeah so we try we try to at (20:43) least stay a little bit grounded in in whatever circuitry exists in the biology and then uh yeah and then hopefully see and yeah and i think the more interesting question really is is to now see how this interacts with with the learning rule with learning rules and and i think in fact we suspect that this feedback connection might actually have have something to do because uh because there's a kind of a specific dendritic targeting to this to the to these feedback connections we suspect that that might actually have uh have (21:13) something to do with with helping you know helping the mossy cells potentially drive drive learning at the feed forward synapses a follow-up question if there's time for that yeah yeah uh so you know if you just consider the only free forward rule uh weights and i know you know that uh you know there's a couple of learning rules like the bcm rule that's explicitly really good at separating out patterns yeah and create competition between different input patterns and things like that do you think that uh you could get like (21:44) better performance in your metric of performance if you use if you train the forward weights in such a way instead of the especially selectivity and sparsity for example instead of using um the random connectivity using now uh yeah i i think yeah i would i would hope that that you could definitely do a lot better with uh um with training the weights i think one of the one of the challenges and i mean maybe this might be slightly artificial by by by the way we set up the problem but that if you that you need to be have a (22:18) way to to select um for for it to embarrass the problem is that the patterns are so overlapping that you have some patterns where maybe all of all seven of your input units are active at once um right and so you need to have a way to be able to select for like the one hot pattern without without having that without also selecting for the for the uh seven hot pattern and so that they so it's almost like you have to do uh a some sort of like non-linear separation of the or something a little bit akin to an xor type of (22:52) problem uh right because another sarcomere inputs basically if we're talking about the input space yeah like in in the input space so the output nodes have to be so if we only had like this input output with a vcm rule for example here then that might be a little bit of a challenge trying to say i want to select for the one hot pattern but not the all hot pattern uh right and so there i think i think having that a little structure in the inputs can help and then having and so maybe the bcm can help try to (23:22) create that but then and then the feedback inhibition can clean it up and suppress the it's to suppress the unwanted patterns um so yeah but i think yeah i think that's something that i'm kind of looking to explore to see like if if we compare a few different of these like pcm or other or other heavy learning rules uh or even three factor learning rules then what uh you know what can we get how and how do they what what representations do they converge onto is there time for one more yeah i'm so (23:54) yeah go ahead yeah uh i have uh sort of a similar question to marcus's um in terms of sort of like the combinatorial sort of all explosion of the different uh variations of cell types you have so here you've been sort of like adding one salt type at a time right you started with a feed forward inhibition then you added um the next one then you added the next one to what extent do you need like the the previous like you're adding cell types until you got to the discriminability um yeah to what extent do you need the (24:27) previous cell types that you added like do you can you just get away with like the excitatory feedback um and without any of the um like inhibitory feedback and the feed forward inhibition uh i think the the feed forward inhibition you might be able to get away with it with removing the in this case the the pro the way this the network is is set up is that actually you need the like you need some form of inhibition and and and it just happens that in this case the inhibition is kind of taking the long way around by (24:59) uh via these excitatory neurons but you can't if you only had the excitatory neurons now you have no source of innovation so you so for sure you need like the excitatory neurons on their own can't do anything without the inhibitory neurons they're not going to really help um if you but yeah we did we did try variations with only only one or only the other um of like yeah the feed forward or the feedback uh or so on so so i think the the you know this uh this structure seems to be like the most the most useful one for the for (25:28) this particular problem um yeah um yeah and like i thought that i started i was having on on this in terms of like how do you explore this this large space of combinatorial different populations i wonder if you can sort of like fix some sort of random random weights and then optimize for um for discriminability but only optimize how much each population can participate um and put in some some regularization dependency on that um some sort of sparsely penalty so like what is the fewest number of populations that need to get to the (26:06) discriminability results and then you can explore like uh on whatever absurd number of architectures you want right i see like what like if you if you optimize across all of all of the different projections and all of the and all and including the number existence of one or the other population what's the and yeah so we did something in a sense we did something not too dissimilar for that so when i didn't really go into the optimization that we used um but in a sec but what we're using is like a multi-objective optimization algorithm (26:39) that tries to kind of balance these three these three different metrics and get the get some sort of optimal performance across all three and there is a little bit of a trade-off because if you if you have really high inhibition you might lose out on discriminability uh you might have you might lose out on selectivity because you have like some neurons that are just not selective for anything and then some neurons that are that or some neurons that are firing all the time and some that are never firing but of course you're going to do really (27:04) well on sparsity so so we try to kind of have this have something that is a little bit similar to an evolutionary algorithm that just kind of tries a whole space with not not a full grid search but a whole space of possible like strains for each of these projections and for these hyper parameters and then try to find some sort of balance of optimality for these three uh three parameters and then and then because here we don't have all we don't have so many different like we only have three different or four (27:34) different populations uh so we could basically try every every combination um and and kind of settle on the fact that you know the the one that seems to perform best is is when we have the system with with these excitatory muscle cells or or this one with or without the feedback connection but but certainly with the recurrence uh and so we could just so we didn't really have to include that as as a separate parameter in the optimization we could just run several different optimizations and in each case just say for this particular (28:03) configuration we'll just write we'll optimize all the possible every possible combination of parameters and do kind of a pretty large search um and then and then see what is the best we can do for this configuration um but uh but yeah i think you could you could include uh like in you could include as a parameter of the optimization itself whether or not you have this or that a population of course that's gonna you you know you're gonna need a lot of compute to do that because now you're really exploding the the like (28:35) the number of simulations you have to run and so yeah it's gonna be very compute intensive well a lot less less less human intensive yeah yeah right yeah yeah that's cool talk again okay cool well thanks very much alessandro um i really like the building blocks approach and it's also nice you tried to yeah draw from the biology rather than all right a little bit around it and try to try to keep things as simple as we can and try to see if we can get some understanding so anyway i really liked it and uh all (29:08) right,,,,,,,,,,
https://www.youtube.com/watch?v=tj-Csa410Zg&list=PL09WqqDbQWHGkpZ5RzNPWkvZBf4ZJKQaA&index=4,2022,SNUFA Seminars,Yigit Demirag,INI Zurich,Online training of spiking recurrent neural networks with phase-change memory synapses,Learning,(148) Yigit Demirag and Kayson Fakhar SNUFA seminar - YouTube https://www.youtube.com/watch?v=tj-Csa410Zg Transcript: (00:00) so yeah with that i'd like to introduce our first speaker who's yigit he's a phd student at the institute of neuroinformatics in zurich at the minute but um from his website i saw he'd done some really cool things beforehand as well and today he's gonna be talking about online training of spiking recurrent neural networks with phase change memory synapses so over to you yeah thanks marcus for the introduction so today i'm going to talk about our neuromorphic approach to do online training of spike and return (00:32) on networks using exchange memory synapses phase change memory synapses phase change memory is a type of uh memory device uh it's a specific kind of memory device that i will be explaining so whatever i'm going to present here is done on simulation but uh when we submitted this work after a couple of months we also collaborated with ibm research injury and tested everything on the hardware and but um what i'm going to say here is has already been tested on the hardware and the real devices is the exact same (01:08) settings so you can you can expect these things to transfer from the simulation to the hardware further okay so the goal in aromatic computing is to create efficient computing substrates for neural network type of computation and we differentiate ourselves from the conventional accelerators usually a conventional computing in three different ways one is that we are fighting with von neumann botanic so if you are looking if you look for the energy consumption in the type of uh neural network computation the majority (01:52) of energy consumption goes to the data movements and data storage it's not the computation itself computation is almost for free but whenever you get your data from sram or dram you then when you catch it it's uh it's extremely costly actually the the person which is usually like 95 percent energy goes to better uh movement and five percent computation and the best way the currently we know to attack this problem is using in-memory computing so we localize the the storage and also also computation very close to each other and (02:29) do the computation using uh the physics of the the substrate and we are using non-multi-memory stick devices these are uh small non-volatile electrical devices uh that requires almost no static power consumption so the circuit we usually use looks like this on the right so each a black shape here is a neuron and it has like in this case five synapses uh inputs are coming from here from the other other neurons and whenever a skype the voltage comes here uh due to the ohm's law uh because of the conductance here and the synapse (03:09) it automatically transfers the current and the current cluster here so the same thing happens for the every sign-ups and the current sums up due to the kick of current law and you can have uh the vector matrix multiplication mech operation or synaptic propagation in almost instantaneously so you apply electric for pulses and everything is basically the multiplied with the conductance of there is conductance of the this is the synapse and current sums up so everything is happening on the substrate one cool thing about this (03:43) circuitry is that if you apply uh the voltage pulses the inputs from here and sum it from here you do multiplex vector multiplication but if you apply the voltage from here in this direction and sum it from here what you get is the the the weight transpose basically uh w t time x and this is useful for the n applications we also utilize the spiking communication so then the the sparse events data system comes we do asynchronous processing in our hardware in an events driven manner so when there is no spike coming from (04:22) sensory devices we do not do any burn power we do not burn any power everything gets at but of course uh creating for this type of neural architectures we are also looking for inspiration from neuroscience uh in what architecture level also in the learning level so instead of using like bptt or directly back propagation we are looking for the local uh and online learning goals uh that depends on sometimes purpose the third factor or cycabian uh type of learning rules um and also information encoding is inspired from neuroscience so the goal (05:02) in this in this work is to train a spiking return on network to do a motor task but we would like to use in memory computing fabric so our hardware will be doing in memory computation but in order to also the training you have to do we would like to have basically have a powerful online and local learning group and the problem is that the analog hardware has limitations right it has it has the bit preposition problem it has the noise problem and there are some non-linear effects due to the non-idealities of the hardware (05:39) and for training the problem is really unsolved currently because the credit assignment solution for spiking recurrent network is an unsolved challenge the idea here is that if we can so if you can have an algorithm that does that this uh this training with hardware non-idealities maybe the training procedure itself will overcome this hardware limitations and maybe we can have a the system that does training and also cops with the hardware limitations so i will going to talk about three building blocks that we think is really (06:18) important for creating such a system and i will start with uh the in-memory computing part with pcm synapses in this part uh i will be describing the hardware okay so our the the substrate consists of the this memory storage consists of the test change materials pcm synapses so this phase change material is a basically two terminal non-volatile resistive material that holds a state it means that so this is a very small small usually around 10 nanometer uh size devices with very small footprints when we apply an electric pulse from one (06:57) of one of these directions the blue directions uh we change the temperature distribution inside this active regime which is called the the storage layer or german element when the tellurium really depends uh depends on depends on the the type of device you're using and the way it work is actually very fantastic so when you apply electric pulse you change temperature distribution it's like this device a very localized manner like in this case like here the red region temperature increases and when it increases it (07:31) changes its face from crystalline to amorphous and when it changes this its uh phase it stays like that it's uh it's permanently a dead state and by doing it uh you can change the the electrical conductance of the device because there are four orders of magnitude difference between amorphous and crystalline regimes the electrical distance is different um so if you apply a high pulse you increase the amorphous region and device conductance increases and if you apply uh smaller but longer pulses you can reverse the effects and go back to here (08:10) so this is irreversibly you can store information in these devices um but device these devices are not ideal uh so by look if you can look at these three plots you can see that the real measurements from uh 10 000 pcm devices this is a actual statistical model from 10 000 pcm devices so when we apply a single pulse to this device to increase this conductance just like long-term potentiation right you're going to increase the conductance the device conductance increase but in a stochastic manner this is called right (08:44) noise because of the stochasticity in atomic configuration you won't get the reliable increase but overall on average it increases but it's also there is some non-linearity in the device conductance increase there's also rate mode there's also root noise uh in this devices so the real device conductance can be read by applying very small voltage pulses and looking at the current but there's a small noise around the real conductance devices so whenever you reach the same device you will end up (09:17) getting slightly different conductances although the real device conductance stays same there's also additional problem with these devices specifically phase change memory devices which is called the drips problem so when you program your device to some certain uh conductance level this g here uh the conductance decreases its time so this is called this problem so if this is our substrate and if you would like to see how the spiking recurrent network will act on this substrate we are using these devices as a weights (09:52) here uh we'd like to have a the very good model of this device and here this is the model that we are using it captures the right reads and the temporal conductance strips of this membership devices and this statistical model is built from getting measurements from 10 000 pcm devices so what we are going to do is we are going to create a circuitry where the each synapse consists of two of these devices so you have two membership devices whenever i want to increase the conductance of this synapse i will send the single pulse (10:32) to this device so this conductance will increase but this is just a positive number right it's uh it can be only positive so but i want to be able to represent the negative plates so i'm violating many neurosciences here and in this case i will apply the pulses for other device which is the negative device and i will take the the current difference between these two devices so it can be positive for negative so for every synapse there are two pcm devices okay okay the second building block is the credit assignment solution for spiking (11:06) representative networks what you want to do is you would like to solve the credit assignment problem using the script assignment problem for spiking recurrent method and this is the our architecture so the architecture is very basic um spiking uh recordable network architecture we have uh we have incoming spikes uh incoming input sticks multiplied with the weight matrix and this is the input layer and there's also the recurrent layer which consists of the spike and this recurrent layer is uh basically the the diagonal is not connected (11:47) and it decays it has some constant ipad is the membrane voltage of the recurrent uh the layer neurons and it has a reset mechanism as well so whenever it spikes and the spiking is determined with this heavy side uh threshold function um the the membrane voltage of the current layer decreases for the output we have just a little integrator output layer which projects the spiking of the current network to an output layer with the output weight matrix and it just accumulates in case it does not spike so think of it as a (12:28) like motor unit it just created patterns that might be useful for regression tasks and here the task is really a 1d pattern generation tasks for one second so it's consist of some of uh four random sinusoids it's random amplitudes around the face and this type of regression task is relevant for motor control and also reinforcement learning so you can think of this system as a value prediction system so every every state you predict the value and value is changing constantly okay so this is the architecture and (13:04) this is the task for the learning room uh what we need is we would like to have a local biologically possible and strong learning and online learning goal so strong learning rule here means that there are many biologically plausible local learning goals based on just purpose coincidences uh um some basic http like approaches uh but here we want to have a learning rule that can do credit assignments so well that it performs very well on the complicated tasks and here we choose the eprop learning learning role from (13:41) guillain-barre so uh in improv learning rule um you have this architecture and every time step you calculated the error uh based on the mean squared error based on your predictions and the targets and you project it back to the to the neurons and each synapse has its own eligibility traces local eligibility traces so basically bptt is now factorized between local eligibility traces per sign-ups and external learning signal coming from uh from the output layer so you can do online learning uh with using using the local local information (14:27) okay so building block three so this is currently how the system looks like we have the input neurons you have input weights metrics you have recurrent neurons that does this recurrent uh the processing with the recurrent uh white matrix and you have the the output output matrix and output units output units are not spiking so it the system generates the pattern and we have a target pattern that we can calculate the loss and e probe gives us an estimation uh on the gradient it does not calculate the the the bp integration it approximates (15:02) it um and it gives us a delta w the weight change that we would like to do in order to to perform uh the gradient gradient step and from this we can just update the weights in input recurrent and output layer this is how we usually do simulations in a 32-bit floating point system this is how things work in in normal normal uh the logic logic based systems but here the problem is that if you are using member state devices e probe still can calculate us the delta w the amount of weight change we should get but representing it in the conductance is (15:47) problematic because these devices as i've shown has non-idealities it has their it has this right noise it has this resolution um so we have to find a way to implement the algo the the gradient gradient step uh on this non-ideal hardware so although we have very powerful learning rule we have to still do this transformation okay so yes i just i just mentioned this uh due to these non-idealities in right right model and the drift this this data w calculated by eprop is not uh it's not directly implementable on the (16:31) hardware and here i will go through four different approaches we tried to do solve this this transformation so if you have a gradient information calculated by a very strong learning rule but you have an ideal substrate what you can do is you can very simply uh look at the the sign of the gradient and depending on the sign you can send a single up or down pulses to one of these two devices so if you remember uh for every synapse we have two memory still devices right and depending on the sign of the gradient we will send a (17:14) single pulse which is a with fixed uh learning rule if you want so this sign up just to increase their conductances so it will the synaptic conductance will either increase with a fixed step or decrease it but you don't want to do it for every time step because it's super costly what you can do you also set a stop learning regime so if this uh the magnitude of the the gradient uh is smaller than some some some ticks threshold you don't do the update you basically skip it so if you really need the signups needs an (17:49) update you send a single pulse so it's very efficient to do it on hardware right it's a really it's very simple you just send a single password device the second approach is stochastic update so in this case you can map the gradient's magnitude to an update probability so instead of doing uh the sine base or thresh thresholding based uh programming what you do is you just calculate the gradient with the prop and depending on the magnitude of the gradient for rate you update it you you you assign it to the updates (18:29) update probability the other thing you can do although this is not efficient in terms of uh the scalability for every synapse you can have multiple memes two devices so instead of two you can have n positive and n negative devices and whenever you have you calculate the gradients you can you can increase or decrease one of the end devices in a sequential order so it will give you a wider uh wider range for doing updates so your effective bit resolution will increase and also the noise due to the upgrades you will be will be scaled uh scaled down (19:15) because you are now summing the current over and different devices the other approach is the mixed position update so this is also a recent uh the methods that people developed so what you do is you calculate the the gradient information using ipro on your circuit but you don't do the update you accumulate the gradients on a digital co-processor so you have a digital core processor next to your ideal neuromorphic substrate that accumulates the gradient information until it matches uh the the right resolution of (19:56) this mermaid devices so it means that you accumulate so your learning rate is actually now is much you can implement very small learning grades um because you accumulate the gradients a lot and you you you you can reflect this this change on on this this devices logic resolution devices okay so this is the performance comparison so this is the pattern generation task on its different uh different targets uh then the different recurrent method outputs so if you look at the sign gradient which is the the first one here (20:36) uh it's a messy loss is 0.2 so the msc loss whenever it's smaller than 0.1 in the paper we are showing it's uh more precisely y 0.1 uh you can think that this this task is solved so if you apply sign gradient or stochastic update or multi-members to the device if it's n equals four n equals eight uh you cannot solve the problem you cannot the the problem still it's still too complex and you cannot solve the non-idealities coming with the pcm cross priority the only method that worked is accumulating (21:10) gradient this mixed precision approach so really if your substrate is membrane steel devices currently uh the only way to do training is to accumulate the gradient in some core processor and doing uh the update whenever you can really reflect this change uh on the device so we also wanted to compare this with um [Music] with a digital low bid precision hardware so we run another set of simulations using the same same approaches but this time we don't have read noise we don't have right noise we don't have drifts we only (21:49) have four bit resolution uh the weights that are perfect as like slam baits you have four bits resolution weights in this case sign gradient sending single passes almost worked um sarcastic updates work very well uh multi-member devices and equals eight this corresponds to if i remember like seven bits of uh the [Music] different seven bits of the base it it worked and mixed precision also performed the best okay and when we look at the close when we have a closer look in the gradient accumulation we show that so one pro (22:34) one one criticism usually you can get when you use member state devices that the programming of mems devices is constant so it burns a bit power when you want to program it because you change the atomic structure of the device although it's not uh much power still you would like to decrease the amount of programming pulses that you want that one but if you can accumulate the gradient and co-processor we showed that a very small number of devices actually are programmed during the training so it's only like 0.07 percent (23:03) of the devices are programmed during the training of course this is the problem statement and one of the problem that usually you can get with this kind of differential configuration so if you have two conduct two devices that represent the synapse once positive one is negative conductance kind of if you increase one conductance and decrease the other increase the other conductance because this corresponds with decreasing this corresponds to the increase in the synaptic conductance uh at some point you will your weights (23:35) give us such rates so you have to check regularly whether your device conductance are saturated then read it calculate the effective conductance and reprogram the device but in this case in this scenario it's not needed we checked it and basically nothing has to be uh checked because the number of pulses that were playing already very small and at the end we achieved very supportive inference activity around four points okay to conclude uh we demonstrated on online training spiking recurrent network with phase change memory (24:07) synapses uh we compared multiple weight update methods and we showed that the best solution is those accumulating the gradients until it is transferable to the bit resolution of this memory still devices but if you have a quantized ideal memory just stochastic update or 8-bit resolution also performs very well the future work is comparing with this rtrl and ostl which are two different [Music] learning rules for spiking recurrent neural networks and we are also now working on implementing eligibility traces per synapses so if i (24:46) can briefly explain the last last last work that we are doing is that i've shown you the the the biggest problem which is the drift problem of facing materials so when you program my conductance the conductance field decreases with time this is the biggest problem of base change memory devices in the industry and the reason is that when you apply a pulse any pulse it creates some stress state on the device and there are some experiments that shows this device then goes through a structural relaxation which increases activation energy and (25:25) inter-trap distance these are not important details you don't have to know this but it's just um whenever you program the this device either set or reset you create a stress and this stress caused the resistivity increase with time so this is a bug of the the material and here we are taking this material back and implement it as a use it to implement eligibility traces for synonyms so what we've done is we fabricated german iman's monetary materials that that the materials that i've shown you (26:00) um and do some measurements this is the the preliminary uh the measurements we've done we basically increase the device conductance by applying set muscles then watch it to watch it decreasing so with this mechanism actually you can have eligibility traces you can implement eligibility traces for synonyms in a scalable manner and we show in this paper that our approach to implement eligibility trace because implementing edubits this is a hard problem it has to scale with the number of synapses it's uh and if you want you (26:33) cannot use the capacitors because capacitors are really big and this is was one of two the biggest the bottlenecks uh to implement specific learning algorithms for spiking non-network hardware that requires eligibility traces um so depending on on your learning role you can just apply set pulses for this device increase uh the conductance and uh itself decay so the next step will be using this eligibility trace with implemen,,,,,,,,,,
https://www.youtube.com/watch?v=eIUb3dgOHUQ&list=PL09WqqDbQWHGkpZ5RzNPWkvZBf4ZJKQaA&index=5,2022,SNUFA Seminars,Sander Keemink,Radboud University,Trading Off Performance and Energy in Spiking Networks,Generic introduction,(148) Sander Keemink - Trading Off Performance and Energy in Spiking Networks - YouTube https://www.youtube.com/watch?v=eIUb3dgOHUQ Transcript: (00:00) uh yeah but with that we'll move on to our second speaker for today um which is who's Sandra cubic uh sander did his PhD in Edinburgh he then did some postdoc work uh in Edinburgh and also in Lisbon with Christine mashins and now uh as of last year he's an assistant professor uh at The dondas Institute in the Netherlands um we met a co-signed this year and I really liked hearing about his work and I think everyone will enjoy it today as well so Santa thanks sorry Santa you're you're muted sir I can't interact with zoom when I'm (00:43) sharing screen apparently so hello it's okay there we go yeah thanks a lot for the kind introduction and also for the invitation so I'm uh presenting uh very much work in progress project today that has its root in computational neuroscience and recently we're trying to push it more into a machine learning uh context and so it's super nice to be able to talk to the snoofer audience and get the snoofa perspective on this I hope they'll get some discussion and and uh and questions afterwards that are (01:11) relevant that's what I'm talking about today is how we can trade of performance and energy in spica neural networks and why is it interesting is because we know that at least we as humans we can adjust how much energy we're using and adjust how much performance we want out of tasks so for example I wrote here in Black uh the best letter in the alphabet the S and then as a kind of test of myself I want to see how well can I trace this black version of the letter with another red letter and I can use (01:42) kind of low Focus or high focus and as you see when I had low Focus I just kind of did a shortage up of it and when I use high focus I had a very high performance I was able to trace very precisely okay so this shows that we're able to trade our file with Focus or energy we use and how much performance we get out uh just a very simple example but this is a general case and so this is kind of a general feature that you want out of any system biological or artificial so if there's some system that has some input that has (02:10) some energy allowance and that system it has to have an output that is matched to some kind of Behavioral targets like tracing the letter maybe playing tennis in a certain way Etc then what is desirable is that if you use more energy that then obviously that they that you want them what you don't want is that the error goes down so that you have higher energy lower error but conversely it's also very good that if you're in a situation which you might not need that much performance maybe I don't need to have a very good phrase I (02:38) just have to have the general s shape then it's also nice that you can use less energy before to and trade it up for a higher error so this is kind of a general uh need for uh for any system and today I'm going to consider how we can think about this trade-off of energy and performance or energy and error and spicular neural networks and specifically I want to talk about today if you have a spike in your network so it's a network it's recurrent it's emitting spikes like you know they can be integrating fire neurons Etc and (03:08) the spikes are being emitted camera understands if it's doing some tasks how these ascendants trade of energy and performance and most importantly like a kind of semi-demonstrated in the psychophysics of drawing the S kind of straight have also be adjusted online snap to think about performance and spica networks we must first think about how do we read out on speaker networks and the kind of networks I'm going to be talking about today are spiking networks with linear readouts and generally what you do is you take your network you (03:38) generate the spikes you filter the spikes with an exponential kernel so that you get kind of a more smooth signal or like think of what Downstream voltages are it will happen to the downstream voltages and then you decode the decoder Matrix D which gives you the the output y another well-trained Network or a well-designed network there will be some Target output here shown on the dotted lines that the output of this network is very closely tracking so now what does it mean to have different performances if that becomes very important to think (04:07) about what is the magnitude of the decoded weights d and so the first thing that we can think about is like what if the hang on I'm just moving away the video there we go uh yeah um what happens if we have very large decoding ways and so what I'm showing here is a network with a Target to Target outputs in the dotted lines and the solid lines showing the current readout of this network and I'm showing the spikes at the bottom when D is very large when the defaulting weights are very large it means that whenever a (04:35) spike happens you get a big change in the outputs and so you get these very large jumps whenever a spike happens ndk because you're doing an exponential filter um and so what happens with the federal ID is that if this network is well trained with a large D then you can track the signal but only coarsely because the jumps with each spikes are very large conversely if we use a much smaller D now we can now every spike is going to cause a much smaller jump in the readout and now we can track these signals very (05:04) precisely so you have a higher performance you have a lower error but it comes with a cost because the fact that HD can only contribute a little bit to the readouts it's it's probably can only contribute a little bit to the readout we also need more spikes to track the signal so we are now a much better tracking of the signal but it comes with the cost at much more spikes as you can see here the spikes has now so many that it just becomes kind of a single line okay so that's kind of this already establishes that when you have any and (05:32) this is true for any Spiker Network in which you have a linear readout and that these snns that heavily readouts and here they already have a certain trade-off of performance and energy needs okay so but what do we now mean by performance and energy use it's going to be very specific for the rest of the talk so when I talk about error but when I talk about performance I just mean what is the difference between the target signal and the output signal and in this case the total squared loss I'm going to (05:57) talk about energy use I mean the total activity of the of the network and there's a lot of ongoing discussion if this is a good measure of of energy but at least this gives you a bit of a ballpark for how an energy is being used uh fire now and so this is going to sum across our neurons and this is a turtle activity there once you have Quantified like this you can kind of start measuring what is now the trade-off between the energy or activity and the performance already error and you can get something like this so (06:28) I'm showing you a little just a little example of arbitrary networks in arbitrary input weights arbitrary the current on Fifth arbitrary readout weights but you can do this in different ways and so what I'm showing here well the x-axis the effort firing rate per neuron and on the y-axis if we have a well-trained network for a given level of activity that you want the network to be at what is the error that you get and what you get in these FICA networks if you build them well is that you get these really nice trade-offs where if (06:54) you use more energy if you use more spikes you get better and better error as we just saw in these two pictures so you go from low error to to high error from high activity to directivity that means you move down this curve and so the three colors here are the three types of Curves here are just a reference kind of network that is a for some Network somebody doing anything it's just a forward Network that has poisson spikes and gives you kind of a kind of a an upper limit the lower limits on the on the error you can have (07:22) in these and then we have terrain Network and we're trying to do this with different activity tasks and then you get the summer traded like this and then there's a coordinated Network that we designed to be as good as possible at matching a Target signal I'll go a bit into how these work in a bit and then you get this trade-off and so this really shows you that there is a very inherent trade-off to using spiking networks in doing uh if you want to trade off between energy use and performance um yeah and so the the problem now (07:52) though is that we want to be able to to do this in an online manner whereas the way we generated this plot and the way you would generally try to adjust the activity used by a network is by retraining or redesigning the network so each of these dots here on these curves is actually a completely separate Network that we completely re-optimized or redesigned and so has completely different ways for each of these and so this does not give us a Network that has its online kind of trade-off of the energy use and the performance (08:21) uh so yeah different Traders require re-optimized Networks we wanted to see can we not just build networks that do have this in an online manner but do we also are we also able to build them in a way that we understand what is happening in a lot of detail and you know like any good machine learner what you start with is Define a new loss function like any new loss function will solve all your problems right and so in this loss function we're explicitly trading after the activity and the error in a single loss function (08:48) so on the left here on the last we have the target readout X and we have the current readout the activities of the of the neurons projected to the decoding Matrix d and on the right here we have the activity loss in which there is some Target activity that we would like the network to be at compared to the sum of the activity in the network itself this is the sum of all the activities um and I just want to highlight a few things here first of all this kind of total activity loss is nothing new that's used in a lot of spiky networks (09:17) to uh to regularize the activity but when it's new that we are comparing it to a certain Target level of activity and we're going to try to see if we can adjust the stock activity on the Fly and get different level of performances uh the second thing is I want to highlight this paper from Sir Anthony from the love of Santa belter where they look at a very similar problem of how do we define precision and spiking networks and how can we adjust it and if you're more if you're interested in that check (09:42) out the talk that Santa gave the second sound is on the balticate uh two years ago in uh snoopa the snoopa workshop the difference here is that we're looking at uh as we're trying to investigate the Precision changes in terms of this loss function and also an online manner in a recurrental networks but I do recommend checking out both the paper and the tongue now there's two ways you can approach these kind of loss functions the the the natural thing a machine and everything like okay I have the loss function I can (10:11) just train it now that we have all these good propagation algorithms uh but when we're first going to look at because we also want to build a certain level of understanding of what's Happening we're going to also try to analytically solve um analytically derive a network that is really solve this loss and that's what I'm going to start with so how do you analytically solve a loss with spiking Network it seems kind of tricky but it has been done for a while now for certain losses you can do it and (10:38) this is uh shown in these papers from the labs of Sofia the never and um uh Christian muffins and what you can do is you say okay we have a loss and I'm first only going to consider the coding part of the last not the Activity part of the last if we have a certain coding loss we can say that we only want the spike to be generated if this last crosses a certain threshold and I don't have time to get today to go to other durations of what happens but just trust me what comes out of it is that you can derive that a network of integrated fire (11:08) neurons with a feedback loop that compares the output directly to the input that's then mapped back into the neurons and that feedback loop is implicitly done in the recurrence connectivity it's not a feedback loop that you do and is showing it here kind of for illustration but that this is the network that's uh that is directly derived from the slots to optimize to so that it's optimized so that spike in this network only happen when the loss is slightly too big and you can kind of interpret what's (11:36) happening geometrically so what I'm plotting here is the stimulus space X1 versus X2 and um and what happens is that the uh the network will be spiking in a way such that the the readout will be constrained in a certain kind of error allowance around the target stimulus so in order to kind of see whenever the reader has been in within this little box that nothing will happen and whenever it leaves this uh this Web Box the error allowance one of the neurons would be above threshold the spike will be generated and the readout (12:07) will be uh will be corrected and what's important here is that everything about this network is completely derived so that we know exactly what the current connectivity should be like what the 4.50 should be like or the time scale should be like and what's nice about that is that we also know exactly how to interpret all those connectivity so we know that the recurrent connectivity determines the error allowance so how big is this box and the decoder uh Waits the size of those tells you whenever a spike happens (12:35) how far will the the readout jump so how far is this Vector t and so here's what it kind of looks like in practice so in Gray I'm going to show the readout of the network in a stimulus space and the dotted line I'm going to show you what the network is getting as an input and the red dots are going to show you whenever a spike happens and so here you're going to see that the stimulus is moving and the network is trying to track it with the Gray Line and sometimes the error is too big so a spike is necessary to track and you can (13:03) see that the spike keeps happening and you can kind of think about whenever the spike jumps in a different direction it's a different neuron spiking with a different decoding but the real nice thing you see here now is that it's tracking the signal but it has a very fixed performance because whenever spy cameras you jump with a certain distance and that means that this you're just going to be tracking the signal within a certain boundary around it given by the the last um given by the maximum loss that you (13:28) define and so this means that performance is fixed in a given uh coordinated Spiker Network as they are called by the way and so then you get the sequence that can be tracked you're going to be tracking it you're going to have some error allowance and you're going to have some spikes being emitted to track it and so here you see that it really tracks it quite well over time uh but what I really want is a network that does this online we don't want to keep doing this uh and we don't want to (13:54) redefine the network because the way to to think about this network is okay we know now how to change the performance and energy use if we have a very if we change the recurrent connectivity to change the size of this kind of error allowance we can adjust how much error we have and how many spikes are being being used and you can go from a very low activity High error regime with a very large error allowance to a very high activity low error regime with very low allowance but again to do that we need to redefine all the connectivity (14:21) Works in these Networks and so we're doing this part I can say okay I wonder if we actually don't have a loss that just cares about the signal coding but also cares about the target signal that is currently there and you can use the same derivations that they had in the original papers to show that when you take this loss you say a spike should only let them happen when uh the maximum losses is is crossed when you get a network it has the same kind of feedback loop for the coding part of the loss but get the second Global feedback (14:51) loop that is shared across all neurons to to code for the the second part of the last Mr activity loss and now you have a network it has a feedback loop that's kind of taking the rate estimates and comparing it to a Target rate that is now an input into the network so what you get from observation is that you get a network that needs to set as a Target signal as an input signal you now get this network the difference now before is that the error allowance is now depends if the error allows now depends on what your target rate is and so here (15:24) I show kind of three different error allowances for the same thing I showed before that changes with uh when I change the targets right set so if you have very low Target rate set so you're only allowed to fire one spot per second for example that would correspond to having a much bigger error allowance and if you have if you're allowed to have more spikes but the the problem is that the jump distances remain constant across all of this so whenever you change that we're not adjusting anything about the decoder (15:53) and so what you end up with is actually track a signal and I'm going to change the background signals that the target signal set I'm going to lower it right now you see that the signal is no longer able to fully track the input signal so the The Gray Line is no longer able to track the black signal but it is tracking the direction and here I change the the background signal again but it does track the direction and it has a kind of fixed kind of precision around its own mean output so you get kind of the same kind of jump size as (16:23) before and so what happens is we cannot trade our performance and energy online in the sense that we can adjust the input signal Z and as we move uh across time when you change the input signal set you see that you get a lower and lower error the higher your settings until you Max the signal correctly okay but this is kind of uh it's good we can trade of energy and performance but we're trading of buyers and energy instead of the variance and the energy so we're not coding correctly anymore and so it turns out that you can correct (16:55) for that and so the way to correct for that is that you can add a decoder um a multiplicative uh term to the decoder that adjusts the magnitude of the decoded signal and then you can go from a a signal that's coding for the correct direction but has a bias to a signal that is both calling for the correct direction and has no bias however you do trade off with more variants and so lower precision and performance and just to mention that this framework that we kind of show here is quite nice and that we can also change the the time (17:31) scale at which a second feedback loop happens so at what time scale do you want to adjust your activity ads and that's what we show here you can do that both by changing the connectivity that you have but you could also for example adjust intrinsic parameters and neurons which is kind of a way to link this work to more classic models of homeostasis in uh in in biology and so when you do that what you end up with is that we now have um a system in which you have an error allowance which is kind of cone shaped (18:03) instead of just uh shown a different direction so what I'm showing here is along the X and Y axis it's kind of the classic coding space we care of but now we have a third axis which is kind of the the the direction along which the activity of the total Network changes and what I'm showing here is that when you change the target rate but also change the forward drive you kind of move up and down the screen I don't have time to go into the detail here but just you just uh believe me that when you (18:29) change the target rate you go up when you change the forward drive you go down and so what you end up with now is that we can draw the same trade of course we have been thinking about like what is not a trade-off of energy and performance in these networks so here again the x-axis population rates so the the active the energy use the y axis coding area and I'm showing in three colors three different input strengths of signal uh what the trade of is for those cases and so does networks now end up with that if you change the target rate you (18:57) can kind of move along this trade-off curve so you can really control what is the trade-offer currently want but also this network is robust to certain changes in the input strength in that activity now is stable when we change the input string with the shown by the error okay great so that's uh we have now analytically derived Network that can trade off these two things but it's not doing um it's it's it's it's multi-tracking a signal and the nice thing is it's derived so we also have a very nice (19:25) geometric understanding of what's happening but Canada also use it understanding we've built to actually use to to train networks that do the same thing and so this is work by Bill butlowski who's also in the audience and what we did is that what he did is he took inspiration from this analytical approach said well okay so we know from that approach is that when we provide a target the target rate is an additional input to the network we have a network that's put in principle changes position (19:51) right and somebody done did is represent different fixed inputs it would also present different Target rates and then just use the kind of now off-the-shelf kind of surrogate gradients for back propagation we can then train this recurrent networks to actually do that and the other thing we did is that uh we also know from this from the analytic from the analytical approach that we need to adjust the reader with a certain Factor Alpha to um to take into account any bias you might have because you're coding for (20:20) both the the signal and some Target rates and so when we do that and you train these networks you find that when you train networks with different Target rates you get a very nice trade-off of the energy and the performance whereas in contrast when you train the same network on a fixed Target rate and don't change it and then afterwards give the difference that's uh in um to the train networks you don't get the same kind of trade-off and you have kind of optimal point at which your energy is best and (20:48) otherwise you have less performance all right and so the nice thing is that uh the the coding is still reasonable okay so here we show for different Target signals that the dotted lines are still recently tracked by the signal itself but also that when you look at the network what's happening inside and you compare the networks that are trained across different Target signals so that they can actually vary their energy use quite well that you get a difference between and you compare that the networks that don't (21:16) have this variable uh background signal as a uh during training you see that the networks turn from kind of a mixed inhibitory excitatory uh population to a fully inhibitory population and so here you see and create the fixed networks and and black the variable networks and the varying the target signature and training and you see that the weights have become mostly inhibitory and so this means that this network has during training gone from kind of a recurrent forward Network to a network where there is a very clear (21:45) kind of feedback loop which is uh comparing the target rate to the Network's activity through the inhibitory connectivity okay so kind of to conclude this talk is that we show that our snms within the readers naturally have a trade-off of activity performance this trade-off can can be controlled in a single network if there's a background input as a Target signal and there's a feedback loop and it coordinated SNL that we analytically derived this results in a constraining error within the cone which allowed us to use (22:15) integration that let us train adaptive networks which hopefully in the future could also be used in networks that do more interesting computations I just want to do a quick other highlights that are kind of uh underlying this work where we kind of were started with this this target signal that we kind of as arbitrary can be seen as either a feedback Sigma or a first signal and the feedback signal you can think of it like an intentional signal which is also very similar to what was shown in some of the wrote this (22:42) paper and finally the the classic coordinated snms have a problem that they're not really stable to certain things like voltage noise excitation excitation or synaptic delays excitatory preservations whereas with this kind of feedback that we have implemented now we get networked a lot more stable and this is a kind of background thing this is kind of why we started with this project because we were trying to kind of fix these problems and it's one of these nice examples where we got to a much more broad understanding of networks from (23:09) that so I wanted to acknowledge uh my collaborators sample ml foundation with the lab of Christian muffins and uh Bill butlowski Nuna claim from the lab and also people have discussed this work with a lot at the donors Institute and uh Martha Von harken and with that Olympics and I apologize for being slightly over time thanks for the great talks yeah with the slice back on if there's questions uh faces actually I was wondering so so this like this Precision term does it I'm not sure if I fully understand like (23:55) in terms of How It's implemented does it actually affect any of the like intrinsic parameters of the neurons that are are there are those sort of fixed and all it's doing is providing some sort of additional drive onto like globally onto all of the cells in the in the recurrent Network yeah so there's kind of two ways to wait I'll uh I'll share that again right so you know in the build that operator training networks all you have is the target rate I just that's that's shared across all the neurons so you give all (24:29) the neurons a little bit of extra Innovation or extra excitation and it allows you to kind of adjust the Precision and or adjust the performance and there's two ways you can adjust the performance want to say okay we don't actually care about um the precise magnitude of the signal we only want to you know we only care about coding for the position and then you're kind of done you have a network that already gives you this kind of trade-off uh at least in terms of the error not in terms of the the variants (24:58) you can also say actually I don't like this bias I want the networks that have uh that that are coding correctly for ones that I wanted to code either for tracking an input signal or doing some computation I want to adjust the variance around that signal and at least in these networks what you don't have to do is you add you have to add uh and Alpha an alpha term that we understand that does that affect all the neurons equally or is that yes so that that affects the readout so yes it affects it's not actually affecting the (25:25) neural activity okay it's affecting the effect of the nurse activity on the downstream neurons okay yeah uh yeah and so for example that could be implemented in the forward connectivity into the dandrace of the forward neurons uh or it could be you know there's a few ways it could be done in principle but it's really talking about like what is the what do you have to do to adjust the code to to get this to this particular way of doing it yeah okay cool yeah that's cool I think Alessandro has sort of got me (26:06) thinking about um I you may have seen from Dan's lab um we had a paper of um using heterogeneous time constants in the networks so we had spiking networks one with Nicholas one of the PhD students yeah heterogeneous time constants I was wondering how that would interact with the also trading off the energy like if you would see shifts in the distribution of learn time constants when you also have to trade up energy I guess that's a very good question actually because uh so one thing we do is we adjust the time (26:40) constant of the the feedback loop that trying to you know stabilize the activity rate the total activity rate and when you make that much slower uh you get a much more you get a much stronger effect of the uh of the feedback loop and you also get things like okay maybe first get a kind of burst of a higher activity that then kind of stabilizes when you change that or change X and I have no idea how that would interact if you're actually training what the um it's actually something we should actually add to this (27:10) training loop at the end what if we actually train the time constant of the um of the different feedback if that's uh if that does something yeah I have no idea what that would do actually right now you said you're training with these like surrogate gradients and and but you're only training the weights only the weights yes only the weight and the weights are and you're are you sort of constraining yourself to sort of Adele's love kind of uh no no we're kind of ignoring girls yeah yeah that's true yeah I mean you (27:38) could implement it by having a second Loop through inhibit the inhibitory neurons but I think for this kind of when you really want to think about the code it can make a lot of sense to kind of ignore that for a bit and uh yeah well then the real question moving forward I guess is how do we do computation with this right can we do a really good computation but also it's adjustable in how precise you're doing with computation and that's uh that's open work and actually is it like really precise architecture inside of this (28:23) recurrent Loop is that something very handcrafted or is it very more yes it's handcrafted and uh in the analytical case but in the train case we don't handcraft that in right like it just it just comes from the learning that's it's just like all to all also it needs to it needs to have good performance across different Target inputs and the only thing we tell it is that you can kind of adjust with this Alpha term during training at least and then you what you get out is this inhibitory feedback loop that uh that (28:53) allows for that I think one way to think about that is that you have a lot of positive background input in the Target rates and you have any excitation in your network this can you know this this is hard to keep stable right so maybe it's learning just to be as stable as possible and that actually allows you to do this trade-off really nicely so yeah maybe a bit of a yeah made a bit of a weird question I was also thinking about if it would be possible to train a network but then during training you have a fixed energy (29:28) budget and so then you know every time you process a sample you use up some of that budget um yeah I guess I was just wondering about how that would affect the learning Dynamics so I mean that's kind of what people do in classic spiking Network training right you said you know you have to you have your target uh computational loss and then you add a regularizer to that which is either the the individual activities or the sum of all Spike activities across the whole thing and you add some cost factor for that the size of that cost Factor kind (30:00) of gives you that budget yeah I guess though what's different with that is that that is like a you know the network spikes roughly and then you penalize it for spiking too much I guess what I was wondering is if you'd be able to see something like maybe early in learning would use up more more spanking and then I would actually want to penalize learning itself actually yeah it's not about that so one difference okay I think it is a different to set this target right like you say normally say I just want to have (30:32) make you just add the activity cost and you just say that's just don't Spike too much that's how it goes whereas if you actually set that kind of the target set you're actually allow the network you actually can't spy quite a bit you know you can go go go for it a bit and as long as you don't go too high don't go too far below yeah it's a good question how that would uh interact with a lot of these things,,,,,,,,,,
https://www.youtube.com/watch?v=xIbl1HY-z1A&list=PL09WqqDbQWHGkpZ5RzNPWkvZBf4ZJKQaA&index=6,2022,SNUFA Seminars,Michalis Pagkalos,FORTH Hellas,Introducing dendritic computations to SNNs with Dendrify,Software and tools,(148) Michalis Pagkalos - Introducing dendritic computations to SNNs with Dendrify - YouTube https://www.youtube.com/watch?v=xIbl1HY-z1A Transcript: (00:01) um today we're going to be hearing from Michaelis uh his talk will be about 20 minutes and then there'll be time for questions and discussion afterwards um just please keep yourself muted during the talk but feel free to post questions in the chat um yeah that's maybe I'd mentioned a minute ago we're recording the session and you can watch it again afterwards on YouTube and yeah I think that's all the housekeeping and everyone's quite familiar with that by now uh so yeah a little bit about Michaelis Michaelis is (00:29) a PhD candidate at The Institute of molecular biology and biotechnology in Greece and today he's going to be talking about incorporating dendrites into spiking neural networks uh he had a pre-print on this recently which I'll post in the chat and if you want to learn more about it you should go and read that as well and yeah I think in the community the dance lab in particular we're really excited about the idea of being able to have smms with dendrites and also I guess from an experimental point of view (00:59) excited about the possibilities which being able to model dendritic computations better uh might open up so yeah with that I'll hand you over to Michaela's thank you very much Marcos for the introduction and also thank you for inviting me in this amazing seminar series I have been a fun since its beginning so I didn't expect I would be invited to present my work here so without losing time today for the next 20 minutes I'm going to talk a lot about dead rates I will start with um presenting you why we (01:33) think that then rates can be conceptually useful and important then what I'm going to present you some strategies on how to develop the SMS that can reproduce accurately some key identity properties and finally I'm going to present you dendrify what it is and what you can actually do with that first of all I would like to start with this typical image of a cortical pyramidal neuron you can easily distinguish its three main parts being the Soma that is the main part of the of the cell that contains genetic (02:08) information the action that transmits information to other neurons and the dendrites that actually receive information from other neurons and for many decades after the discovery of parametal neurons people had no idea what dendrites do they simply thought that they are just passive propagators of synaptic input so uh makolic and Pete in 1943 came up with a poor neuron idea of the perceptron as you may know it that actually um what it does it it doesn't it doesn't care much about that race so it simply adds uh linearly synaptic (02:47) input it's not big input so then passes into in a non-linear activation function this simple model accurately accurately mimics what actually what happens at the axonal initial segment of the Soma and it proves quite useful uh so far and until now it's uh it's a foundation of modern ANS and deep learning architectures architecture sorry and it was so useful and that actually even the spiking neuron neural networks are inspired by that and although I'm sorry I'm so on although artificial neurons and Spike neurons (03:34) have many similarities I'm here to argue that they have one major uh actually they have many differences I'm here to argue that you have one main similarity and according to newer data they're not so accurate representations of how real neurons actually compute information and whenever I hear about neural networks that don't care much about the basic computation this image comes in mind I mean they do the job they they do amazing stuff but they were not how they were supposed to be or how they were (04:07) designed by Nature so to understand why we believe that first of all I would like to know that then race like the Soma they're able to produce Action potentials but unlike the Soma these Action potentials coming in many different flavors and they operate in multiple times scales first of all they can be sodium spikes that they can last for a couple of milliseconds they can be calcium spikes that they last for tens of milliseconds and they can even be an MDA spikes that they can last for up to a second let's say (04:42) moreover the direction of these spikes is not like the action that is usually unidirectional they can progress and they can I'm sorry they can be produced at the dendritic location and then travel to the Soma enter the action or they can be generated at a very somatic domain and then traveling backwards to the dead bridge and us as such they act as feedback signals of neuronal activity moreover the situation is even more complex because we now know that Denver is can increase greatly the heterogeneity of neural computations (05:20) the passive properties like the morphology the their cable properties in conjunction with a voltage sensitive ION channel they have they can generate a plethora of different activation functions all of which can coexist in the same neuron moreover apart from the neuronal properties also synaptic properties play a major role in in the transformation function that the transfer functions of neurons since let's synaptic weights or the distance between inputs can greatly impact the linearity of the response a synaptical location kind of greatly (06:03) impact as well how neurons compute information for example when you plaster many synaptic inputs into a single Branch the probability of triggering some uh the dreading nonlinearity is much higher whereas if you spread these synaptic inputs in different branches neurons tend to respond in a linear model another key feature of real neurons is that usually they received multiple Street streams of information that they are also spatially segregated along the dendritic trees to simplify the Siemens a bit let's have this simple example here so (06:46) the whole digital domain of the of the neuron shown here in the cortex is supposed to be it is supposed to receive contextual information from uh higher order areas or and whereas the proximal domain for the basal the dendrites are supposed to receive the sensory information and what is the functional implications of this so when we have a single pathway being activated at a digital Branch we know that due to intense amount of the critical attenuation the fact that the Soma might be quite weak whereas when you have (07:27) oops I'm sorry for that when you have inputs being more proximal to the Soma they are less prone to being attenuated so you have modern semantic activation however when you combine digital and proximal inputs you have the generation of some some long-lasting events using their calcium or nmda spikes which result in the in the neural firing in bursting mode moreover apart from having an effect on the output of the neuron um the segregation of uh Pathways can have a meaningful impact at the synaptic plasticity for example when you activate (08:10) locally some Pathways you can have a local generation of dendritic spikes that can figures in a synaptic plasticity regardless of somatic activity something similar happens also at the proximal part of the Dead rates but this is more heavy and like because usually they are more coupled to the Soma whereas when you activate both Pathways both distal and proximal Pathways you will have Global and heterosynaptic ltp due to you know strong and a long lasting Plateau potentials so I just mentioned some basic uh well-known functions of dendrites and (08:49) the next question is how do all these things we mentioned impact Network level functions to answer this question we have to come up with a new model on of the address because traditionally at the when we started then trade when we started dendrix we used to work with some pump links and by physically detailed models although they are super realistic and highly accurate and they allow for low level experiments they're not so efficient they can be complex and they are impractical when we want to use them in neural networks on the other side (09:24) reduce integrated firing models can be lightweight it can be mathematically trackable they allow for building large networks however they are less accurate unrealistic and they don't have dampage so we thought why don't we try to combine Best of Both Worlds and that's how the idea behind identify image and to Showcase how we see things so this is a point neuron that we use to uh to create when we wanted to model a whole pyramidal neuron okay so we thought why don't we just use a couple more points that they can (10:06) represent whole the treating neighborhoods of the neuron so for example this pyramidal neuron can be can be broken into three territories one digital territory one proximal and the one that represents the Soma in the basal dendrites by the way this segregation is arbitrary depending on the of the experiment or the research question you can break it in more or less it's just for this example so bear with me foreign neurons by adding some extra nodes forming the Proxima and the distal then raise all of together they can create (11:00) two extra dendritic layers so um instead of having a single layer representing one neuron now you can have three different layers all of which I mean where the compartments I'm sorry of a unit extend in all these layers and what why is this important what are the key features of this architecture first of all first of all we have so much on the dratic decampling in real neurons we know that synaptic integration and plasticity do not operate in the Soma but they are semi-independent of that so this architecture can achieve this (11:42) and also another thing you can do is to experiment with coupling strength I mean you can have it as a learnable parameter and have let's say heterogeneous decoupling in a neural network another thing that is really important is that each node can have a unit set a unique set of active mechanisms you can have uh sodium or calcium or NBA Spikes all of which contribute differentially to the global function of the neuron another thing is that because these dendritic nodes are usually uh they're thinner and they are smaller they are (12:24) more excitable thus they have a lower threshold for local spiking and plasticity another implication is that we can have a more realistic interaction of multiple input streams this architecture allows us to have a single input stream that mimics what actually happens here you know if you remember that one pathway goes to the diesel Park another pathway is going to the local to the proximal pump and when they are in isolation or activated together we have very different effects of the neuronal output and lastly you can have actual back (13:02) propagation of information happening within a single neuronal unit since after the somatic activation we can have the dendritic nodes also in nodes also to fire some dynamitic spikes thus information can back propagate from the somatic layer to dendritic layers and having explained a bit of theory behind the dendrify let's see it in action let's say we want to build the three compartment model like this one we have a somatic compartment we have a single compared to the optical dendrite and the same tool for the bezel this is (13:37) just for illustration purpose is still like the three dots I showed earlier how the way we describe this with dendrify is as you see it here this is a the whole code needed the reproduce the model we saw here each compartment can be represented by a single line of code actually pyth is descriptive code you can also specify how the various compartments are connected together and and the strength of connection and some Global neuronal uh properties and then you can use this neural model pass it into Brian and run (14:12) simulations then like how would you not normally use Brian we chose Brian because they're super friendly neural simulator it has really good support it's it it was just a natural choice for us and if you work with this you will figure out that it actually makes modeling much simpler so let's see some more complicated examples let's say here we want to build a four compartment compartment model where there are two different streams of information we have something else going to the distal some snaps going to the proximal part and all (14:50) then rates can be active they can have the judic spikes again we have this approach we discussed earlier everything can become a bit tricked with single lines of code for example if you focus on the proximal dendrite you could who can activate Amber synopsis and MDA synopsis and we can activate sodium channels with just a little code it's quite straightforward and what actually identify creates for you in the background is all the equations the parameters of the models and many things that they don't show (15:24) here like custom events that work for Brian and a lot more in the past you have to do this manually by the way unless it is in action let's say we inject some current oops let's say we inject some current on the diesel part it's a five millisecond long and the intensity is barely strong enough to trigger the spiking you can see how the critic spikes are locally generated these are not integrating Fireware type of responses I will show you later how how it works and you can see that dendritic attenuation the somatic (16:03) compartment barely fills the generation but really expires in this part you can see something similar happening in the input and when the input is provided the proximal part one notable thing here as I mentioned Also earlier the the dreadic properties change a lot the input output function of the neuron so here you can see that I can trigger the dratic spike with much more current than I had to work with in the digital part and the same for the trunk compartment and some other notable things I would like to say that um (16:46) when we when you take the derivative of the voltage response the response on the dentrix versus Soma you can see how dendritic uh spiking initiation location affects the somatic compartment all of when I checked that the critic responses at the level of Denver we see that they are almost identical but you can see that the effect on the Soma varies a lot based on the initiation location also you can see here when we we plot the input output function of the distance and the proximal part they are almost identical in terms of the sigmoid (17:22) function but you can see because the digital part is much more excitable because it's thinner it requires only six synopsis to trigger spiking whereas the proximal part requires 18. uh another notable behavior of this model is you can have a realistic back provocation as I mentioned earlier you can see when the Soma files maximum potential what happens is that spontaneously the diabetic spikes can be formed at the trunk and the proximal dendrite but you don't see anything in the digital part and these are the so-called spikelets (17:57) which are also have also been observed experimentally and there are just some small events that are not enough to trigger um further the dramatic spiking and what I didn't mention that all these mechanisms we show here they do not use a hot skin hacksay formalism to replicate all this phenomena we use one invent driven mechanism that works like this when the threshold of a given dendrite is crossed for dendritic spiky we have we have the occupation of a sodium current that decays exponentially and that after a (18:33) few milliseconds we have the generation of potassium a current that also the case exponentially and to get together they try to mimic how sodium spikes um are generated with the hot skin Hackley model and we also compared it we also compared how the hot factory model Works versus this approach and as you can see here if you tune the parameters you can see they're almost identical so we can trust that this uh sodium spikes and they are very similar to how they should be modeled but the way we model them is much more efficient and requires (19:18) much less resources and parameters okay I think the time has passed in summary uh neuronal Dent rates have numerous properties with perhaps significant duplications in the fields of snns extending Point neural models within reading nodes allow simulating many keyboarding functions identify provides an easy access to such products by automating the development in brand tool the next part of this presentation is still under construction that now we have the tools and we are going to test while you know all the research questions we have on how (19:57) dendrites actually impact Network computations so you have to wait for that I'm sorry and I would like to thank my supervisors also I would like to thank Dan Goodman for his initial feedback on this whole project and myself that is still being super helpful and provides some really good feedback for our reviewers and all the lab members that pray beautiful and constructive environment they work with and especially caused us by the psychics and Simone dashoti that they were my beta testers and Nicos malacasses who (20:37) has gave has given me a lot of constructive feedback so thank you very much that was all if you have any questions please let me know thanks so much for the talk that was really great um yeah I'm happy to if anyone has any questions just uh either come on camera and ask or you can type in the chat and I can read it out thank you I'm happy to go first then so I I guess something I was wondering about was um have you thought about trying to have networks which you can train with either local rules or with surrogate gradient (21:29) descent which have these dendritic compartments yes we have um I think I don't know if we can actually Implement surrogate learning in Brian maybe you have to go to shift the pythons for this thing but of course uh all the let me show you the slab here the next step we thought would be how would some common plasticity mechanisms but when we have dendritic notes for example you can try HTTP and it could take the Riddick spiking as the as the post events or we can test the BCM and we would like to extend all the (22:11) non-plasticity mechanisms that work very well for Point neuron to this category of models and see how it works out yeah that sounds super interesting that's really cool to be able to do that it's already in the plan he identifies just the means of creating this type of models but you can use whatever learning rules you wish and actually and now you can use The Vedic spiking as the input for these rules for example in sddp as I mentioned earlier you can have the the dratic spikes not the somatic spikes so (22:46) you have super local rules of learning and I I guess sorry I think uh baby Dan wants to jump in he's turned his camera on but just a quick one more quick question was um uh could you imagine I guess so for now it makes a lot of sense to start with like a yeah essentially like three or four compartments right but could you imagine having like more like entire dendritic trees and things eventually uh actually we can do this already with tools like the neural simulator I mean uh typical biophysical models can have (23:21) hundreds of thousands of compartments but increasing the complexity the number of compartments make these Models Super computationally costly so the whole purpose of this uh project was how to reduce the amount of compartments without losing uh that really computation we wanted to look into so yes of course we could increase the number of compartments but the whole point was how to decrease them okay thanks thank you thank you ahead Marcus sure [Music] yeah of course yeah of course sorry um yes so I so we had this paper (24:10) recently about um how heterogeneity in in neural networks could be could be valuable and and we did we were just looking at heterogeneity and time constants I'm wondering is there a way to sort of with with something like this to sort of Define what that space of heterogeneity would look like or would you you need to look at experimental data on lots of different sorts of dendritic trees and think about I mean like is there something that you could do easily and quickly or is it something you'd have to (24:41) think hard about how to how to sort of set up an appropriate heterogeneous space of neurons to see what that does uh we were actually inspired by this paper your paper or heterogeneity that's why we we did a lot to include heterogeneous heterogeneous mechanisms inside a single model um so we introduce literacy in terms of that we increased the number of possible computations of the single neuron can perform however if we would like to perform an experiment similar to yours I think you use trainable um memory time constants for example in (25:23) this network we could have trainable coupling strength coupling conductance so we can have a whole network where this is a free parameter and we can just use it to you know a train I'm sorry a trainable parameter and then an experiment would be to see okay if we constrain this in a biological manner this is going to be better at a given task let's say much classification or something so it is something that will go on to actively explore how it affects the network performance uh I don't know if I answered fully your (25:56) question yeah yeah yeah um yeah I think I think it would be really interesting to I'd love to know the to know the results of generally results of that um it's true that um Brian at the moment can't do any um sort of pie torch like uh gradient descent sort of mechanisms I wonder if in this case since you presumably produce a set of equations which you then passed to Brian it might be relatively easy to generate bytouch code from that um which we haven't I mean it would be relatively easy to do we haven't really (26:29) done it just because for a lot of the Brian models it's almost not worth the effort because they're quite simple models typically but in this case the equations are pretty complicated so it may well be worth the effort to some water generate some of those exactly um the reason we started with Brian because it's it's super easy to learn it has a small learning curve and it's super intuitive it has a good documentation I mean um we wanted to start not by this approach first in Brian so because it's (27:02) a very accessible and basic tool for anyone to use and one of the future orientations of this project is how if there is a need for that of course if it makes any sense to try to replicate what we did in brand also in pythons so for now it's not supported because we still haven't tried training SMS with surrogate design but if we need it perhaps we're going to have a version of densify that works with Fighters I don't think it would be super hard to translate all this to pythons yeah I I think I tend to agree I think (27:41) it should be quite durable also by the way uh since we have this who is familiar with Fighters or you can try to translate this I mean this is completely open access for the community so if someone thinks that this is a good foundation started working they can just take it up to the I'm sorry it's here up to the neural model level here we don't use anything brain related apart from the units but we can change this also and they can just experiment how to translate this to Fighters I mean if it's not us that we do this perhaps (28:14) someone that is interested in this and look in looking into this mechanism wants to transfer them into Fighters just feel free to do it foreign on doing that as well I think some of the stuff we've written for Brian would make it easy but cool thank you thank you very much,,,,,,,,,,
https://www.youtube.com/watch?v=6PF25foNpf8&list=PL09WqqDbQWHGkpZ5RzNPWkvZBf4ZJKQaA&index=7,2022,SNUFA Seminars,Anand Subramoney,RUHR-Universität Bochum,General purpose event-based architectures for deep learning,Event-based systems,(148) Subramoney (event-based architectures) - Schrimpf (brain-score) - YouTube https://www.youtube.com/watch?v=6PF25foNpf8 Transcript: (00:00) welcome everyone back to the Smitha seminars um today we're going to hear two talks um one from Anand and one from Martin uh both talks will be about 20 minutes long and then there'll be time for questions and discussion afterwards um just the usual Zoom things so please keep yourself muted during the talks but feel free to post questions in the chat and uh yeah we're recording the session and it will be available to view on YouTube afterwards uh yeah so with that I'd like to introduce Anand uh announce did a (00:32) masters in computer science and then did some work in Industry before doing his PhD on biologically plausible learning rules and meta learning in spiking neural networks with Wolfgang Mars and then for the last few years he's been working as a postdoc in Germany and yeah I'll leave him to tell you about his work today thanks Marcus yeah hi everyone uh like Marcus I'm a post talk at lower University bookmark in Germany I'm part of this institute called Institute for neural computation uh the group of Lawrence wiscott and (01:09) today I'm going to be talking about a general purpose event-based architectures for deep learning so so uh my kind of proposition here is that uh we need to look Beyond biology based models for deep learning especially on neuromorphic Hardware uh so spiking neural networks uh that we all know and love were developed as models of biological neurons but uh I mean they have become the canonical model for neuromorphic computing especially for doing deep learning applications uh and the focus of neuromorphic devices is Shifting further (01:45) towards deep learning uh because of their Energy Efficiency advantages and with deep learning you have higher expectations of task performance so I think we need to ask ourselves are these biologically inspired spiking net neural networks really optimal for deep learning with metamorphic devices and what I propose is that we need to design deep learning architectures up initial for deep learning on neuromorphic devices because we can distill the essential advantages properties of these biological models and we can really customize (02:19) architectures for specific deep learning specific neuromorphic Hardware we can design these architectures to achieve exactly what we need in terms of longer memory or better stability properties gradient properties and so on and we don't really need to be beholden to biological models if you are just focusing on the Deep learning part right so then the obvious question that arises is what are the key properties of spiking neural networks uh and what is the decided data for neuromorphic architecture so why are spiking neural (02:56) networks so popular for the atmosphere Hardware um so I mean so as we all know neuromorphic Hardware is focused on Energy Efficiency and there are some properties from biological neural neural networks and from spiking neural networks that actually lead to this Energy Efficiency so one of them is sparsity uh both in time and in space uh so the sparsity in time is activity sparsity where activity of the units are transmitted only when needed so inspecting neural networks these are the binary spikes that are sent to other (03:29) units and then there is parameter sparsity where you just have fewer connections uh each unit is only connected to a few other units in the network and not all the other units so uh activity is really only transmitted to units that need them so the second main property that has been used a lot in neuromorphic Hardware is even based communication right and this is communication that happens only through discrete events sending messages between units so you're not sending uh you're not communicating all the time like you do with a (04:01) traditional Network uh but uh you're only sending like discrete events and uh so when you combine this with activities parsitting units only need to update their state on an incoming event uh and in between depending upon the Dynamics that you choose uh we don't really need to do anything at all so there are other properties uh such as asynchrony where you don't really have a shared clock signal across the units and maybe a few others that have not thought of uh that uh spiking neural networks have so uh so I should say that (04:35) event-based communication also implicitly implies Computing with time so you should uh so that is already a property that's included over here okay so what can we do so now that we know uh or at least we think you know what the uh property of spiking uh neural networks are important uh we can think about uh designing general purpose event-based models and uh this is a principle very very straightforward all you have to do is add an event generating mechanism to each unit and whatever model you have and the unit (05:09) Dynamics can be arbitrary right so you could take something that looks like this uh so for a live leaky integrate and fire neuron or something with an Adaptive threshold or with exponential integrated file uh so all of these standard spiking neural network models uh you have an internal State uh which is the membrane potential I mean here I'm calling it C for reasons that you will see soon and so the idea is that you have some Dynamics you have some internal State and then you have this event generating mechanism uh based on a (05:43) threshold and then whenever the event is sent the state is reset and there is a recurrence in this within this unit so that you can really use information over time so this is kind of like the general principle so you could quite just as easily use a lstm or a GRE unit over here instead of leaky David and fire Dynamics because you could just add a threshold on the uh cell state of the gru or lstm right and over there the internal state is just the entire state of Dynamics you could also use any other dynamics that you wanted to so uh so (06:26) what I do now is take this General principle and apply it to one particular example a gated recurrent unit and as I go along I'll tell you why uh which shows they get a recurrent unit because it has some very very interesting properties otherwise as well but the first thing to do is uh to kind of look at the Dynamics of the Gated recurrent unit uh this is what it looks like it has an update gate uh which is a gate that's a function of the external input X and the recurrent State Y and then you have a reset gate which is also (06:57) another gate that's with different parameters that's a function of X and Y that you have a proposed update set and the output of this gated recurrent unit is some combination of this proposed update said and the previous time step State y right uh so you both U and R are values between 0 and 1 and the function as Gates as they do when you know lstm as well uh so because the sigmoid you always have values between 0 and 1. (07:29) okay so what we want to do now is to use this principle that I described before and just add an event generating mechanism to the gru so uh I write the cell State now as this combination of the proposed update and the cell State and add a reset to the cell State and introduce a heavy side step function with the threshold so the idea is that whenever the cell State reaches the value of the threshold it sends the value of the cell state to all the other units so that is the output of the event based Gru or egru as we call (08:05) it and the cell state is exactly the same as uh what we had before over here but with the addition of a reset mechanism so every time an event is sent the cell state is reset and then it starts integrating input again so this is kind of what our uh egru looks like um and it's really as simple as that right so now each unit is only sending uh discrete messages whenever the cell State crosses the threshold and when the cell state is below this threshold then the output of the unit is zero so there's nothing being said at (08:43) all and so this very obviously uh leads to activities sparsity of the network so how do we do learning so now that we introduced uh heavy side step function which is not differentiable it looks like you continue to back propagation Through Time but uh we do know a lot of tricks uh about how to handle this from the spiking neural network literature and what we can do is introduce a pseudo derivative or a surrogate gradient for this thresholding function uh so I mean I show like the particular function that we use but so what is really cool about (09:21) this model is that uh and this is also true for spiking neural networks uh which is that if there is activity sparsity in the forward pass so if only these white units are activated as you go forward in time uh in the backward pass you get sparsity as well because you only need to propagate the gradients through the units that are active uh of course I mean when you use a pseudo derivative uh with um some support that looks like this you would have to propagate gradients through all the units that had a cell State between plus or minus Epsilon of (09:55) the threshold uh but you don't really need to propagate the gradients through the rest of the errors right so you can choose and appropriate pseudo derivative and make the backward pass pass as well and uh beyond the support of the pseudo derivative all the gradients are zero so they're not packed up again so um so which means that uh the activity sparsity the forward pass can translate into efficient backward pass training as well in this model which is a really cool property that we can use um so so this is like the basic model and (10:33) we tried this on a bunch of uh tasks uh so deep learning benchmarks uh benchmarks that come from spiking neural network literature as well the first one we did was uh this DBS 128 GSA recognition so DBS so this this is like data that's based on uh hand gestures collected by this Dynamic Mission sensor camera in terms of events so so each sample is a stream of events a stream of offer on events uh spread out over time and this describes the moment of M right so this is work done by one of my colleagues and uh so here's like a table of results (11:11) and so the first thing to look at is uh so the standard lstm based models uh so without a convolutional layer in front achieve about 86 percent accuracy and with a convolutional layer in front with the LX net achieve about 97.7 or so percent accuracy and uh so our model can actually quite easily compete with that so we have a version so da over here stands for data augmentation so it's trained with additional data augmentation as well so both the state of the art model as well as some of ours and so our model can (11:49) easily kind of beat that and get 97.8 percent accuracy uh with the CNN and data augmentation and without it gets about this it beats this and gets about 90 percent but now what is important is to look at the uh not just the number of parameters but because we are talking about activity sparsity we want to really have an estimate of how much computation that we how much computation we perform at the forward bus right so over here there's this entire column of activities per City and you see that most of the (12:20) egru models achieve about 80 percent activities parsitting and we want a good estimate of how this translates into the amount of computation that's performed uh so what we can do is we can calculate the effective multiply accumulate operations that are done in the forward pass and this takes into account the activities positive because whenever a unit is zero you just don't do enough you don't you don't have to do any operation for that unit when you propagate uh to the next time step uh so with the egru model you can really see (12:52) that we can get very very efficient models so uh for the case without the CNN and augmentation we basically are about half the state of the art in terms of computation but getting comparable accuracy and for the case with the convolutional neural network and this is kind of interesting because uh convolutional neural networks are quite computationally expensive so this model for example has like 600 million effective Mac operations for the forward bus and we are able to solve the same task with a much smaller convolutional (13:28) layer and a recurrent egru with activities Varsity of 80 percent and achieve the same amount of performance right so this is almost an order of magnitude uh reduction in the amount of Mac operations over here so um if you and and so there is also backward sparsity that is quite significant so the training is also efficient um and if you look at the activity of the network it's very reminiscent of what you see with Spike in data networks which is uh that most of the units are not active most of the time uh and as you go uh from layer to layer (14:03) the activity increases but uh you just have like overall a lot of Spar sitting okay so the uh second task that we tried on was the sequential feminist image classification task so this is one of the tasks where you take an MS digit and give input pixel by pixel uh scanning from left to right and top to down in the image and over here uh well I mean we don't we don't achieve we don't beat the state of the art yet uh but uh we do get really really efficient models that have comparable performance so uh in just (14:36) sequential amnest uh we have a model that gets uh 98.3 percent but with about like uh slightly fewer parameters in the state of the art uh permuted sequence laminates which is a much harder problem uh again we get like fewer uh operations uh and somewhat close to the state of the art performance right so it basically works well um but so what we did with this uh sequential mnist was also look at how the model scales uh in terms of the size of the uh Network so in terms of the number of units in the network and uh so here is a plot uh which which (15:17) shows uh what happens when you do this on the left side uh y-axis the orange curve is the number of operations uh on the right side is the number of epochs that it took to converge uh to some value of accuracy and the x-axis is the size of the network so what is interesting is uh you see that as you increase the size of the network for the same task the network converges faster so this is not quite unexpected right this is actually what you would expect to see and as you increase maybe uh uh it stops converging (15:51) but we just run it up to 2000 units but uh the number of operations uh calculated in terms of these Mac operations stays almost the same uh even as you increase the size of the network more than 20 times right so we've got close to 20 times um so this is quite interesting because uh you can actually over parameterize models and get like better training properties uh without doing significantly more computation so uh and then uh the other like really uh interesting uh application that we tried this on was language modeling and (16:35) uh so this is uh one of these uh tasks I mean language modeling is where uh models really seem to benefit from having really large sizes as we see a lot of deep learning today so we wanted to see how our model performs in comparison uh but mostly compared with a set of the art recurrent models so we we're still not required models are still not like close to Transformers but it does get really really close to the uh performance of lstm based state-of-the-art models so these are like essentially on the so I mean the (17:11) measure of performance over here is perplexity so Rover is better so inventory bank which is a relatively small data set we are basically able to get a perplexity that's close to the state-of-the-art models uh but with a fraction of the parameter a fraction of the computation required right and similarly for Wiki text 2 which is an even larger data set again with about half the amount of computation required we are able to get quite close to uh the performance and I should I should say here that a lot of the bottleneck of (17:43) getting good performance as it is often the case in deep learning is uh just the amount of time spent and optimizing the hyper parameters and so this was a case where we did some hyper parameter tuning based on the computational resources we had and we're still able to get quite close to STM based architectures so the second caveat over here is uh Gru models by themselves are not they have a bit of a slight disadvantage compared to lstm models so just like the base and GRE model does worse than the lstm based models uh but (18:18) uh we are working on having an event-based version of the lstms value currently so um so the other interesting property that we can see from these language modeling experiments is that you can actually trade off the backwards sparsity with the performance that it requires so you can use this surrogate gradient into parameter Epsilon so this is essentially the support of the surrogate gradient and uh so the wider you make it the lower the backwards Part City uh and then but but there is kind of like a bit of a trade-off so as you (18:50) can see with some level of backwards sparsity nodes and 20 you get like the best uh what looks like the best performance over here on average at least and you can kind of make the circle gradient narrower and narrower and still have uh uh fairly decent performance right so depending upon the resources that you have for training you can really trade this off okay so uh so the other uh so the reason that we chose the gru for the first um kind of model event-based model was that they have a very interesting property which is that the GRE model (19:27) itself can be written as continuous time uh equations quite elegantly so the GRE equations are just I mean if you just quintet them a bit you'll see that they are essentially forward either equations of some continuous time model and you can just write it as a continuous time model directly without uh much uh difficulty right and uh so so you basically uh did this uh to analyze uh what our event-based model could do uh and for this uh you essentially take the uh Gru continuous time model and make it even based in the same way so uh (20:08) except that now we can really mathematically uh Define things more formally and analyze uh exactly what sort of properties this model has so um so we essentially defined all the gates just like in the discrete time GRE model we added an activation Dynamics which is essentially a variable that integrates the inputs coming into each unit uh and uh this is the continuous time dynamics of the cell State uh and this essentially looks very similar to the discrete term equations that we're looking at before and you can also mathematically uh more (20:45) rigorously Define uh the concept of uh emitting an event um so whenever the cell state of the unit emitting the event reaches a threshold then the unit cell state is reset to zero uh and uh the other units don't really change their cell state but uh all the other units receive an input to their activations uh based on the cell state of the unit sending the spike right so this is kind of I mean I don't want to kind of go too much into detail here but uh you essentially end up with like very very simple equations that (21:22) describe what emitting the unit means and you can handle the input in the same way so uh what is now interesting about defining the model in this way is that you can also do a backward pass in Cutters time based on the adjoint method so you write the laws using some adjoint variables and the Dynamics of this continuous time model and you end up getting joint Dynamics which is essentially like the equivalent of the backward pass for the discrete time model that also look fairly simple so I mean maybe the derivative of the F with respect to C (22:00) looks like it's going to be a whole Matrix but it's actually just it's just ends up being a vector so the center uh Matrix transpose multiplied by the adjoint variable ends up being just a vector so all of these Dynamics are on a per unit basis you don't really have to consider interactions between units and you can calculate the gradient updates for the parameters of the network based only on quantities uh at the time of the events right and this is a very very cool and interesting property uh so in spiking (22:34) neural networks this was kind of uh called event prop uh which is published some time ago and the same property holds for these kind of General models as well because as you see the Dynamics of the model is defined quite generally as if um and so what this means is that uh you only really need to back propagate uh the cross-unit back propagation communication is also even based so you only need to do that at the times of the events and only within the unit you need to do some sort of uh backward pass uh in between the events right uh so which (23:11) is which can really make trading super efficient okay so um that's uh so you can actually uh look at our uh archive paper that I linked to before but I'll link again uh for more details about this uh but uh this kind of uh model uh essentially uh I mean to summarize summarize this uh talk um biologically possible spiking around Dynamics they are sub-optimal for deep learning on neuromorphic Hardware uh so you can modify the unit Dynamics to make it spiking by adding an event generating thresholding function (23:49) so and we Define this based on gated recurrent unit or Gru and so what is interesting is that uh it exhibits High activities sparsity in the forward pass but it also exhibits uh sparsity in the backward bus so in learning right so this is true for both the discrete time model where disparity is not exactly the same as the forward sparsity because of the surrogate gradient that we Define uh but uh for the continuous time model this sparsity in the backward pass is exactly the same as the forward pass and uh it which has the potential to be (24:23) super efficient so uh because we do get the event-based gradient descent updates and uh we can analyze it mathematically so for example you could really Define the Dynamics of the units based on stability conditions based on avoiding uh Vanishing gradient or exploiting gradient problems you could Define it based on modeling long term dependencies and then still get this kind of event based updates for such a network and so you could really have very very powerful uh architectures that come out of this and so well I mean I would uh argue that um (25:03) this kind of more general purpose models can potentially replace spiking neural networks for challenging and complex tasks such as language modeling but basically like almost a lot of other deep learning applications all right so uh in terms of Outlook um I mean what uh me and my group are planning to do are explore like other unit Dynamics for different use cases uh but also really look at uh which sort of Dynamics are good for specific neuromorphic devices so there are metamorphic devices which support non-binary packets for communication uh (25:42) we're working on more efficient software implementations of these models and we are actually working quite closely with uh Tu Dresden in Germany uh who developed the Spinnaker 2 Hardware uh to have an implementation of one of these models there and hopefully scale it up to way more parameters anyways so I should say this was a joint so the egru was trying to work with a bunch of people so Khalil Mark and Christian from utreston and David from University boom and I've linked my our uh Archive preprint of this GRE based event-based (26:17) models uh over here so thank you very much I'll take questions thanks so much that was a really clear talk and super interesting um so yeah I just had one quick question I guess and then anyone else can ask away um so I was wondering and have you so you showed good performance on lots of different types of tasks but do you think there's a sort of class of tasks or particular types of tasks that this architecture would really excel at compared to other types of tasks so we have mostly focused on like recurrent architectures but as far as we (26:57) have seen uh anything that uh lstm or a GRU can do our architecture works well for that as well uh so it's I mean and in principle you could do the same thing for feed forward networks as well right I mean the benefits are not as great for a feed forward Network um but uh yeah I mean I don't really see a limitation in terms of the type of tasks okay cool well yeah with that happy if anyone else to ask questions man yes hey can you hear me yeah I can leave hey sorry I had a just a little confusion maybe technical bit when you (27:37) talked about the the amount of sparsity in the back prop phase compared to that excellent parameter and I think I didn't really understand how this relation worked because in my head it would have been the other way the more the narrower function you would have used uh the more sparse you would get as a return right I don't really understand how this relation is the other way or maybe it's just confusion on my side uh no it is actually uh what you said so over here you can kind of see that so not over the (28:08) circuit function the higher the backwards possible you mean the less event you get that you need to appropriate through right exactly okay okay yeah my bad yeah okay cool I guess the other quick question I had was you showed at some point I figured with the oh sorry there's a question in the chat as well um let me just ask this quickly and you try to figure at some point with uh the spiking in a few layers could you just show that again quickly oh yeah so is it the so is the top layer is the top uh subplot here is that the first layer in (28:59) the network or is that the is that the input layer is that the yeah that's the input here exactly okay oh so then then it is like so then it is actually a bit different to spiky neural networks right because spiking neural networks we tend to see more sparsity as we go through the layers you tend to get more sparse activity deeper layers um this is kind of the opposite right you get more activity and deeper layers I mean we kind of well uh what we found was that this is like really task dependent okay so it depends on like how (29:28) the input is encoded so there were cases where uh if you use like a different input encoding then you don't really get much sparsity in the initial layers but then you get more the final layers so this kind of varies a lot there's at least like as far as I know there was no hard and fast rule that we noticed yeah I mean with Biology or anything else I guess I wouldn't want to say a fast rule I think usually becomes faster and deeper layers in spiking networks um but maybe that's not true yeah that's (29:58) a very interesting point I guess uh I mean so in some sense like these models are uh really like um kind of equivalent to complex neuron models right so uh it would be quite interesting to study this emergence of sparsity and how it correlates with Biology yeah I guess I said maybe Martin later can talk well maybe not but maybe he can talk about how activity changes as deep layers in the visual processing anyway so there's some questions which I can read out uh so Laura fandel asked um hi thanks for the great talk would egru (3,,,,,,,,,,
https://www.youtube.com/watch?v=TdNU6i-biBI&list=PL09WqqDbQWHGkpZ5RzNPWkvZBf4ZJKQaA&index=8,2022,SNUFA Seminars,Rob Mok,University of Cambridge,A multi-level account of hippocampal function in concept learning from behavior to neurons,Learning,(148) Rob Mok - A multi-level account of hippocampal function in concept learning from behavior to neurons - YouTube https://www.youtube.com/watch?v=TdNU6i-biBI Transcript: (00:00) hi everyone and thanks for joining um today we're going to be hearing a talk from Rob mock um his talk will be about 25 minutes and then there'll be time for questions and discussion afterwards um please keep yourself muted during the talk um I sleep well yeah you can you can uh if you could keep yourself in use to doing the talk for most of the time and post questions in the chat but Rob said if you have a burning question or something that needs clarifying or something that's not clear then uh feel free to (00:31) unmute yourself and jump in um I have to tell you we're recording the session um that's because we're going to put them on the sessions on YouTube afterwards um quite a lot of the talks on YouTube um but I'm a little bit behind with uploading a few of them uh so yeah anyway so Rob did his PhD in experimental psychology at Oxford and then since then he's done some work at both UCL and the MRC cognition and brain Sciences unit in Cambridge where he's currently an early career fellow and yeah with that I will pass over to Rob (01:06) thanks great thanks Marcus so yeah um as as Molly said um I'll go through the talk uh but if there's anything that's really unclear it's like oh that you that would help with a quick clarification that would be great um if you just just shout and let me know because there are bits that wouldn't make sense if you know um we just keep going uh but yes and then we'll keep uh big questions to the end of that story um so hi everyone um so I'll talk about this uh multi-level account of hippocampal (01:41) function in concept learning from Behavior to neurons so right now I'm in Cambridge working with uh John Duncan um but uh collaborate heavily with Brad love at UCL this work was you know how it was done at UCL and and still in collaboration with Brad so this um is the general talk overview I first introduced uh uh why I think multilateral explanations are kind of important in science and why we need more of them um go on to a project talking about General learning mechanisms in the sample formation uh and then go on to (02:16) talking about a multi-level account of this kind of model so uh cognitive Neuroscience is a multi-level discipline uh we're interested in the mind and brain at multiple levels from Behavior Uh to large scale brain network activity to high dimensional brain activity patterns uh down to the level of single neurons activities uh they're firing as well as like you know assemblies like these um concept cells in hippocampus or placing with cells so we typically study the system at a specific level at one of these levels (02:55) and sometimes we try to link across them right like we correlate these behavioral processes or these these accuracy Behavior accuracy with brain activity patterns um and sometimes we also build models so we can correlate these models into internal activities or their behavioral performances without outputs rather with behavior um correlate their internal representation with with the brain with interesting techniques um and this kind of sometimes tells us about what's going on or at least gives us hint as to what kind of mechanism (03:27) might be that plane so uh one thing that I'll argue in this talk is that simply examining the system that these levels doesn't make a multi-level Theory so normally we try to match your prostate levels through correlation so we try to match something like Behavior with neural patterns or maybe with the model representation then kind of that kind of suggests that maybe this model is a good description or a good uh idea of the mechanism that's going on underneath for example cognitive models might be (04:02) able to capture behavior um and correlate with the brain but typically they have these abstract mechanisms or abstract components such as like you know some kind of like reward or value lab that doesn't you know uh isn't specifically implemented in a particular way when we have stuff like neural network models uh and especially the ones these days they're very I feel very big they're very powerful they have high accuracy that might reach human level accuracy um and they even show correlation with (04:33) the brain um but often they also don't map onto some high level behaviors they kind of like map on to some fast learning curves or sometimes it's hard to understand what the mechanism what kind of correlation actually means so what I'm one major theme that I'm going to argue in this talk is that we need theories and models that capture the system across different levels and this is uh I'll just explain a bit more what uh this means um by the levels or mechanism of philosophy foreign function work (05:16) um and talk about uh learning mechanism with the hypocal formation with the carbon model and then I'll talk about a multi-level version of this model by decomposing these components into a lower level mechanism so uh first I'm going to tell you about debate some basic theories of concept learning and categorization and this is just to give you an idea of what the models of you using look like um so classic ones like the Prototype model the idea is very simple that we use uh the kind of the central tendency (05:51) of the category to to characterize the concept so in this example uh just put like let's say two two dimensions and there's these these examples as particular dots on in this kind of stimulus feature representational space um and the category prototype would be in the center and so you would be able to categorize uh you know that this is a this is a bird or or depending on how close uh is to a category prototype uh bird or a mammal in this case an example in theory you have something that's on the other side of the extreme (06:26) you rather than just one single point you would care about every single memory that you've you've seen before so I've seen every these are all the birds I've seen and you complete the some similarity um with what's in memory compared to what you're seeing right now and say oh the most similar thing to what I've seen before is a part of that kind of thing and so classic Model is the what I'll focus on a bit more and it's I always like to think of it as something in between these two extremes where you can (06:56) have a cluster or uh um that represents um a particular kind of distribution and in this case you see I kind of it with this simple category structure you would have like two cluster here which is equivalent to a prototype model but with these more complicated structures you might have um uh cluster for each particular distribution that kind of like figures that kind of reboots the cluster when it's needed uh it kind of learns based on error and so with the um the model I'll talk about are are are a bit more like this so they're (07:30) algorithmic models they can learn trial by trial uh have learned where these these these cluster positions should be and kind of output a particular category at the end well um at the end of the model so the output of the month um so briefly there's some some work from fmri uh so okay first this is um Brad loves uh uh clustering model is sustained from a while back already um the idea here is just that there's some behavioral performance learning curves here there's error curves so type one uh of this category learning problem (08:06) is to learn quickest and then type 6 is is learned the slowest and you kind of see that the model output captures this behavioral pattern quite well we've also done some fmri work and this is like the internal representation or the latent variables in the model and those correlate with the hippocampus during learning we've also shown this using representational similarity analysis um in a just a separate task so we also know that the formation is implicated across many cognitive functions right so we must know about uh (08:40) uh patient hm who had this bilateral video temporal lobe including including environmental upper campus uh and and he wasn't able to form new memories so it's also involved in learning associations and and inferring new new associations um in concept learning and uh there is cells in the hippocampus in the human hippocampus that seem to fire the particular Concepts so in this case you can see uh this was a one neuron a single neuron that fires only to the actress Jennifer Aniston and apparently nothing not to anything else (09:17) so we on the other side of the the field uh they're in rodents we've found Place cells uh that seemed in the hippocampus that seemed to fight at particular locations um in in the project environment so these are these are loading recording and these are firing rates and good cells which fire um in the middle intranal cortex that fire uh and this kind of grid-like pattern so one idea that you know has been quite popular in the last few years is talking about shared mechanisms across like spatial cell coding (09:52) um and then more high level like conceptual spaces and so a very uh um simple kind of parallel people have thought about like places I was talking about where you are whereas concept cells might be about or you're perceiving or thinking about and it's in a higher dimensional space like a different kind of features that um care about uh the cells caring about so we thought at the time that actually the clustering models are quite a nice candidate for being able to do both of these things is specifically it can kind (10:23) of do category learning if it's uh learns concept structures but maybe on a navigation task also it can create spatial representations so I'll just show you how this might work um so yeah and the idea is that of course because it's using the same kind of learning process it might actually be the same algorithm that's going on uh rather than is trying to do two different separate things it's just a different context and it's the same learning rule and so here's a uh just a poor illustration of how this would work uh (10:58) the the clustering Works um you know you have two Dimensions here but it would be higher dimensional space in reality um on the first trial the the model sees the eagle the closest cluster moves towards the the eagle so this is the basic um clustering rule of Cohen and update rule uh the next trial this the model C the cat and then the closest cluster moves forward so over time the idea is that you know these clusters move towards the center of these these category distributions and it's equal to two categorization (11:31) how about on space so uh if if we just have this kind of like circular environment and we have a bunch of clusters uh in there um now we have an agent or a rodent that kind of moves around the the environment um and you have the same rule so the closest cluster will move slightly towards the agent um over time this is what happens so this the Clusters kind of spread out over time and often uh creates this kind of really nice uh grid like hexagonal pattern and the idea here is that it's because of this display the (12:05) two-dimensional space is um uniformly um kind of uh navigatable or you can go around the whole surface that this can happen so um in a real concept space or semantic space it would be much uh sparser or or and it'll be much more clumpy in the sense that every all the kind of birds are more similar to each other but you rarely will have like a bird that's I don't know as as heavy as a or as large as an elephant um and so there's just not it's the space is not as uniformly traversable um so in the paper we talk a bit more (12:48) about interpretations about uh so we kind of like linked these to place cells or concept cells inhabiting a particular part of our residational space um and include cells monitor these these uh Place cells and therefore have this kind of like multiple um Fields uh and so which kind of like links to the anatomy of it as well where um which I can talk a bit more about if we're interested but we have this uh idea in the paper um so that's that's quite quite was very nice uh but one open question we had in (13:23) this paper was uh how um what these clusters were so I kind of talked about how cognitive models are abstract they have these components like in this case clusters and and we kind of just like wave their hands a bit and said oh this cluster is a uh probably corresponds to an a bunch of places although like a play cell assembly in the hippocampus where you know you can have a group of neurons that care about particular location um but that's kind of not enough so we kind of thought actually we need to kind (13:54) of explain this a bit more with um a model with maybe a few more neurons than just a few clusters so this is uh how we approach the problem so we kind of thought uh thought a bit and read a bit about multi-level uh accounts um and this was there's actually quite a big um set of literature from mechanistic Philosophy from in biology as well as neuroscience that's very interesting um so first uh why do we need a multi-level approach so I kind of was quite a vague about um like I said some general things you (14:37) know we need more uh think of almost levels which is kind of trivial but uh maybe there's there's actually a bit more of this so first um it's Theory based uh cognitive models capture behavior and provide like manually accounts for the behavior sometimes um but they're abstract so how do we link to these two brain mechanisms you can show these correlations like I showed with the correlation to the activations of the model with paper campus string learning but how do we go beyond these correlates (15:08) so multi-level explanations allow us to link across levels and the idea is that we can go from the model's abstract constructs it's down to the neurons whilst retaining the cognitive behavior as well and so mechanistic levels are really a more General concept rather than you know related to to Neuroscience specifically um so-called waiver is a philosophical Neuroscience any scientist and and so he talks about this um these these different levels and so you have some kind of high level uh thing that you're (15:40) interested in that you need to explain and how do you explain that you want to explain it by decomposing into the components that kind of mechanistically work with each other to create this Behavior as well so maybe the example would help so um if you have the circular system you might have different components like heart and kidney that work together in order to make you know the your oxygen and and uh energy go go around but then you can decompose these components further uh for example the kidneys down into the kidneys building units and you (16:17) can do this um as much as you want or as much as uh you need for a satisfying explanation of your your system at hand so they give this a neuroscience example a rather simple one but it works quite well so you have the behavior which is like the rat navigating an amaze and the hippocampus might have a spatial memory or map of the environment um but then you might want to decompose this the parts like how do how does this map created so maybe like long-term protection in plays a role in creating these memories or these is um (16:56) um these location maps so just one a few more relevant important things is that you know the the levels idea is is not like fixed it's not like you know one of these levels uh mapped onto each other across problems there can be more levels in between or further down depending on your question and the relevant is important but also some things may not be relevant to your explanation um so back to our problem so uh one question is how uh we can do it so actually look this way first so one way of dealing with this problem for us is (17:35) um we might have a cognitive model that is able to explain the behavior that we have at the top level but then we want to decompose this model down into a lower level mechanism that can kind of uh do the same thing I can still do a behavior but also explains a bit more as to how this column model might be able to to um work at a lower or finer granularity and so um as I mentioned uh there's this common multiple sustain and we decompose this model so uh therefore called sustained and it's multi-unit neural (18:14) more neural population renewable populations like uh customer model and so we start now instead of two clusters um we start with a million millions of units and instead of winner take all like in in statistical model it's K when it takes off and we can learn over time based on uh similar principles and so um just to give you an idea you uh with with these models you you'll have an input it can be something very simple like that binary values uh or you know continuous values with a field features and you await the attention you (18:50) have an attention rating mechanism because some features might be more important than others for a particular category learning problem and so uh now you have these units um so so in the possible I mean one cluster in this particular part of space but you have you can have like now here's three but you have hundreds of them going to uh representing particular part of feature space and so um then they output to uh categorize the current stimulus at hand so this is basically a set of Weights that um uh actually yeah so instead of (19:25) Weights the connection weights that learned by error so you can have like um uh I suppose it's basically like a single you know no hidden layer neural network trying to read out the um signals that's that the the units here are activated and so you learn the model learns the cluster or the unit positions uh learns the attention waiting and then uh outputs the category signal so it learns trial by trial and creates these learning curves and internal representation as well so one question is now that we have so (19:59) many units um we have a coordination problem so like how how is the general problem because how do you produce a neuros in your group of neurons or a new assembly that kind of has similar tuning Properties or concept cells that fire to a specific concept so we uh look to nature for inspiration and one thing that you that you might have heard of is uh the flocking mechanism is bur and birds are um based on quite simple learning rules so local learning rules and so in this case this void simulation you can see (20:33) that they basically each of these voids follow the average um uh direction of their uh neighbors and you can see this local coordinated activity that emerge uh uh just based on these local rules so um that kind of inspired by that we we thought about how we would alter our learning rules so we we still have um the simple code and learning all this kind of cluster is the the um stimuli tool or the the concept so towards the relevant stimuli so in this case uh this is an example where the stimulus is here and the K winners move (21:12) towards the stimulus but what we add here is this kind of what we call recurrent update where the unit the K winners move towards the center of themselves so this is independent of the stimulus but they're kind of trying to figure out um where where they are and with respect to the other winners and this very simple local local rule is basically how they kind of develop this much sharper tuning um and how they have called flock together uh just to hammer the point home this is an example with like apples and Pairs (21:50) and you can see that you know they developed to kind of uh get more and more attuned to these these particular instances and have interleaved learning with different concepts at the end of learning at these very a group of like a assembly of neurons that care about particular parts of the future space so in the spatial cases might be a bit more uh interesting so instead of just starting with a number of clusters you actually start with thousands of moves now right so but with this learning Rule now you can see that (22:22) um just with this additional local uh recurrent rule we you can see that there are many units uh that kind of find a similar position together and so there's doubt is there's now hundreds or maybe a thousand units at a particular location here might be a bit clearer to show you see it here uh in case that wasn't so clear um but you can see that now you can have a neural assembly here that cares about particular location without really defining a particular cluster so here are just some quantifications of (22:57) the the grid scores so basically they look a bit like with so um this shows how neural assemblies can form by very simple local rules where the neural flocking will kind of produce these similar tuned assemblies and with consequently cell like presentations so before we set these uh clusters or place cells but here we can see that the cell assemblies uh naturally form okay allowing it to represent whatever the task that requires it to and this scales as well so we can have millions of neurons and show the same (23:32) behavior kind of allowing this multi-level um kind of accounts work um so just to show how uh uh show that point um so we have um these are Shepard's category learning rules that doesn't matter too much uh what they these mean but the point here would be that type 1 is the easiest one because all uh category a is in in on the left and category B is on the right and so you only have to care about the color type six is the hardest so yeah it is when they actually kind of have to remember and memorize each particular (24:06) um feature in order to do this characterization and you can see this with human participants so it's the easiest you learn this the error goes down straight away whereas type six is quite hard and we can capture these um or The Ordering of these learning curves with this this model and so this is kind of an illustration of what that looks like process learning so you know you can see these these units um kind of moving around a bit but then they kind of form these virtual clusters even though there's a few 100 of them in (24:36) this case um but they care about the relevant Dimension right so so only they call the dimension so the type six they're just having to memorize the stimuli so it kind of recruits a bunch of units at Each corner of the stimulus uh stimulus space and so why do we need so many units right so one obvious answer is about uh um uh it's more robust to failure mode so damage or cell death or synaptic turnover and we can see that so this is what I showed you uh with animations just now but here we show if you have uh 0 25 or (25:14) 50 lesions uh at the pointing for the points uh it's basically like having those units stop working at the time so with 20 units of course the model like goes to Jack chance but with more units you're you're less affected by the lesion and at 10 000 units you're you're totally fine it's also better uh um with more uh with the current updates so if you add some noise to the position of the units um that also helps so you can see here with a lot of noise the uh kind of the behavior gets worse but then with a bit (25:47) of recurrence already recovers the behavior um so don't have too much time to talk about this but uh basically I've shown you that we can decompose this called Model into uh you know population or neuron like uh population but we can both go further if we know about some kind of functional properties of your uh of your interest your your brain area so in this case we knew about you know anterior and posterior hippocampus have different functional properties kind of anterior hypocampus carrying a bit more (26:22) gen like has a general tuning Fields whereas listeria becomes is a bit more narrow and so this kind of mapped onto some interesting uh previous fmri data that these uh tasks that required attention um to generalize across stimuli uh precluded the interior upper campus more and and ones that needed more specific memories are included the posterior of the campus more and we were able to incorporate this into our model by having two pools of neurons with different tuning Fields um and kind of competes to Output during (26:55) learning and the most appropriate ones would kind of like uh uh contribute more to outputs or and kind of become more dominant and you can see here that with the interior of the campus it really learns the the like type one where you would attend to a particular feature and then you know generalize a stimuli much faster where it's posterior this uh uh hypocrine cares more about um type six so in summary we decompose the um called in models constructs these clustered into a lower level mechanism uh neural population (27:29) and so inspired by flocking we suggested the hippocampus could do a similar thing with the recurrence which naturally leads to Virtual clusters and concept cell memes cells assemblies finally we link across these levels to from behaving neurons to give a more complete explanatory account with a model that can scale while it retains its Behavior and this is our answer to how neural assemblies that enclosed abstract representation might form like concept to location representations um so of course I wanted to add a note (28:02) on neural networks or especially spiking neural networks which I know a lot less about compared to you folks so I'd be very interesting to know what what you think about this so I do think that it really fits into the multi-level mechanistics important position framework um that is you have if you have some Behavior you kind of want the net to be able to of course capture Behavior but it might also want to do in a particular way right so color models have these abstract column components like you know you might have some memory or some uh (28:36) um specific thing that you think that uh humans do that's able to be captured by the specific neural network so of course this might be a difficult problem so it's hard to constrain any neural networks really or even especially Spike neural networks to learn like humans or with these components um so one idea could be to um kind of split these these networks of some kind of modularity where you have different brain modules or quality modules like I kind of mentioned uh in the previous uh slides with different functions or (29:13) properties might be able to constrain this so we do have one uh project that led by PhD students in Brad's group and he's um he combined a deep convolutional neural net with a clustering model at the top to kind of a coordinate and they were able to coordinate Its Behavior to work together to to constrain their activity so that's kind of coming soon as well um well so that's that's all uh thank you for your attention and this is some of the papers uh that's that's relevant um and I also have this new log that (29:51) we've been following a bit more on if you're interested in basic science stuff so thank you very much um I have to answer your questions cool well thanks so much for the talk world it's really clear and um yeah thanks for trying to also starting to make the link to spiky neural networks at the end as well um you see I I guess I'll just ask you a quick question and then open the floor to everyone else um so actually yeah I I was a bit confused about the the I guess what constitutes a neuron in your setup so uh (30:24) maybe you could just expand on that a bit I was going to ask you what the Neuron model is but then at the end we talked about the changing to deep neural networks I suddenly realized maybe I was a bit confused so yeah so so it is still um uh much higher up on I guess the level of abstraction than than an actual neuron that I guess you're thinking about so it will still be something it activates with respect to um I guess it's not so far from a a artificial neural network like it's activates uh in according to the the (31:01) input stimulus right so if it's similar to the stimulus in the sense that you know like on this stick you know three-dimensional thoughts um if it has wings and it's had it is it advise um then I can have these units that care about those features they've had like uh they live in a multi-dimensional feature space um and they activate and according to that so in in this case it's like exponential uh uh functions like offers could they can be calcium as well so that's the kind of idea all right cool I (31:36) think that makes sense so thanks um I think Rory had a question hi um yeah I was going to ask something a little bit similar to Marcus so I guess I'll I'll try to change it up a little bit um so is is it is it effectively a graph neural network then because it looks like it's doing message passing in the second step the recurrence step and then I was also going to ask um the connections assuming there are like weights and connections between the units do do they tend to follow something like Dale's law where a given (32:12) unit will only have excitatory or inhibitory effect on all of its neighbors as opposed to a mix uh so your first question I I think uh no so so it's it might be a bit simpler than anything so so it kind of the second step is really um about tuning so you have many units that kind of have like I showed simple examples where they're very close to each other but they might actually bit more more the tuning might be a lot more um diffused so that's the right word but yeah basically they're kind of trying to (32:45) pull these neurons together in order to show similar selectivities um so I don't think that's the same thing as the graph neural network um for your second question um so we don't constrain anything so so there's a few versions of this where we do have like inhibition like you whether with the the standard algorithm while you have like if one cluster is activated the others are kind of inhibited um but there is no constraint as to how uh strong or that has to be I think we have a free parameter for that um in the (33:21) model I've shown here actually there's not even uh inhibitory um component it's inhibitory and only in the sense that there's a k winners and others don't activate so so so there exists the as a parameter in our model but um it's kind of not necessary at the moment uh to fit our data but it's definitely can be part of it um yeah cool uh I think there's a question from Galena oh okay uh I'm happy I mean if you'd like to okay I can read it out unless you want to read it yourself ask it (34:00) yourself okay um so Galena says thank you for the talk um is there any evidence that representations do drift to each other according to the concept similarity um it drifts to each other as in so I I guess um this is about how uh I guess the um the model is is kind of pulling things together is that I I guess that's my interpretation of the question um I suppose there's two um sorry she means of he or she means the neural evidence yeah so so I think there's I guess there's two ways among them one is (34:52) what is the other no and so the answer is that it they these kind of cell assemblies exist right so you have you don't have like a random um I mean uh it's not like in in this if you just randomly subset of place cells um you have every single possible location but rather kind of a bit everything is a bit more clustered together in a particular way so so you have you do PCA on on your uh on play cell population you actually have groups of cells that kind of like have much more strongly tuning to a particularly (35:28) so one answer is that we are actually trying to build a model that explains that kind of phenomenon um and also in concept Styles you actually have is very sparse um you don't actually have tuning for everything that's in between you know I don't know like Cadet Ransom and and other uh actresses that they put um but they're much more specifically tuned um so yes but then there's no evidence of this particular methods are working in this this way um and actually that's I guess would be the next step I think there's some we (36:00) have some talks with some collaborators to to talk a bit more about this and I think that's right to actually test this question and I think it's actually one of the things that's hard about it is especially even in place cells which is eventually the easiest setup because you know where people where the rats are um is that it's hard to track many cells over a long period of time during especially during a learning task so now of course we all know people who are starting to do a lot of high agency (36:30) recording which I think is getting more and more possible to do this um so that's quite exciting as well so it'd be nice to see what's going on when rats or people are learning okay um I just misunderstood uh you were talking that about sales that were clustered together because um I I was thinking that it's the representations that because they also drift apart and you're talking about neural drift as well yeah yeah um yeah so I haven't followed the really interesting stuff that I've been I think (37:11) has been coming up these days but I think the initial idea of drift was how they were going away you know like uh they kind of don't look like what they do before anymore but I think um there's like some new work that I briefly saw about how drift happens less it with well-learned uh places um so I think the the early work well at least this was the claim was that when the what the drift happens when you were forgetting or or it's it's not as well um other in the environment in place else at least (37:48) um I think it kind of at least in our model it does relate to that in the sense that once it's well learned you shouldn't have much drift um and early on you will have much more but I think that that like area of research is so fast moving at the moment that I can't really uh wouldn't really interpret much more than that yeah okay thank you um I think there's a question for you Rory again that's good hey um yeah so I'm just thinking about how you map this then onto like a neural network scenario and uh am I right in (38:34) thinking that you would maybe need to have some sort of task for the network to learn that as opposed to just learning representations of of an input of an input data set and do you have any thoughts on on what kind of task might be suitable for that transition well yeah actually so all of the the things I've been talking about always have a task so um although the learning rule is local so it doesn't really necessarily get the tasks um but I guess I am a fan of having the thoughts that's kind of like tease (39:09) because the internal orientations will be I guess tasked relevant no care more about what's what's important the feature so I didn't talk too much about the attention tuning but you can also kind of like tune these widths um uh of the neuron sensitivities depending on how important it is to the task um so wait uh talking about so your question was more about whether you need or what kind of task is is helpful for I guess yeah kind of an ecological task that you might train such a network to do I guess like (39:50) spatial navigation or something yeah so yes I suppose um one obviously because because in a sense you can do its unsupervised learning here as well you're going to be like in the road and talking it's kind of like moving around kind of figuring something out so I think Brad actually had a really well I would say uh maybe a bit too ambitious idea about trying to do basically connect this to a convolutional net where you would see what kind of representation come out just through navigating um I think the details need to be ironed (40:29) out there but the idea is that uh like in the the first half of the the first paper I was talking about um the question is not necessarily what um uh what the components of the model are about what kind of representation it learns through the task so and if you were able to reconstruct for example a map of the uh a maze um just through the model I think that would be quite a nice um uh demonstration of of uh it's learning the relevant representations um and then maybe you can see somewhat something similar in the brain as well (41:13) here it's just um just on that note you got me thinking of this toolbox which someone released quite recently um which I'll put in the chat which is called um rats in a box but it's a toolbox for um yeah basically it generates movement trajectories in 2D and then also generates um like synthetic neuron data so for example with this trajectory what would the activity of place cells be grid cells boundary cells um yeah and then you can use that to train neural network models to um yeah I don't know if you wanted to (41:52) try and Implement broward's idea this could be somewhere to start yeah yeah I know I'll check that out cool yeah I'll see that cool neural network is like a generalization of a convolutional neural network I guess uh is Brad are you interested in taking it that direction as well so a what like a graph neural network is kind of a generalization of a convolutional neural network I'm just wondering had you thought about that and maybe is Broad or yourself interested in going down that direction because maybe I don't (42:26) understand a model fully but it seems like there's kind of a message passing averaging of laborers activity mechanisms in the model as it stands and that's very much the core of graph neural networks work as well which is again a generalization of a convolutional neural network where in a CNN you have this kind of rigid um spatial structure of pixels being above and below each other sorry I think it might be lagging a lot um and you're you're basically averaging this uh you know this filter over a grid (42:55) whereas in a graph you're averaging all of the Neighbors which can have you know any kind of um attributes attached to those um sorry I'm rambling a little bit but yeah maybe does that make sense and are you thinking oh it does I mean I I I know a bit about graphene Runners but I just haven't really thought about it like that actually so I need to think a bit more about um how how it maps on um but it does sound like it might might be relevant um I I guess the way I thought about graphing was always more (43:28) like binary um like oh not binary but like you know how because people talk about graphs uh in that way that and we're always talking about this kind of continuous structure but it doesn't matter because we have these nodes so yeah maybe I need to think a bit more about this before I can say anything interesting I think yeah yeah but I think about it yeah I think it seems worth looking into in my opinion because to to my own friend I it seems like the message passing and your model laughs nicely onto a graph and analogously onto a (44:06) convolutional neural network cool yeah thanks for that,,,,,,,,,,
https://www.youtube.com/watch?v=JCM1Czruyq0&list=PL09WqqDbQWHGkpZ5RzNPWkvZBf4ZJKQaA&index=9,2022,SNUFA Seminars,Ilenna Jones,University of Pennsylvania,Can a single neuron solve MNIST?,Neuromorphic-compatible algorithms,(148) Ilenna Jones - Can a single neuron solve MNIST? - YouTube https://www.youtube.com/watch?v=JCM1Czruyq0 Transcript: (00:00) and today we're going to be hearing from Alina um her talk will be about 20 25 minutes and then there'll be time for questions questions and discussion afterwards um please keep yourself muted during the talks but feel free to ask questions in the chat um I have to let you know that we're recording the videos um that's because they will eventually be on YouTube afterwards so you can go and enjoy the talk again and yeah just to introduce Alina Alina mated in neuroscience at Dartmouth College and then works as a research (00:32) technician at John Hopkins after that she started a PhD in neuroscience at UPenn with Conrad coding and her work focuses on dendritic computation and that's what she's going to tell us about today so yeah with that I will pass over thanks thank you Marcus um yeah so uh yeah uh my name is Alana Jones um I'm in the coding Lab at the University of Pennsylvania so uh the question that my work tries to answer is what's here in bold which is uh can a single neuron salt mnist and I'll Define that kind of Point by Point well not quite (01:15) Point by point but I'll be defining that in the later slides but uh the takeaway is in the subtext which is that neural computation of machine learning tasks emerges from the interaction of dendritic properties so um but first before we get into that what is the big picture or my big picture goal and that is to ask the question how do we understand the brain while constrained by our understanding of its smallest Computing units what are those units well controversy aside let's think of neurons as the smallest Computing units (02:02) so uh however when we think of that uh it's we're kind of taking a big bite out of uh the brain the brain's made up of neurons as well as other cells and uh neurons are quite complicated as you can see just in their morphology um but there are also many aspects of single neurons Beyond morphology as well that people have been able to find through various experimental investigations such as uh conductance distribution or where exactly and how many are there of voltage-gated ion channels uh along the (02:42) dendritic tree of a single neuron um and even in the dendritic tree not only can you find spiking in the Soma but in the dendritic tree you can get spiking there and how those spikes then travel down the dendritic tree or after dendroductory to be integrated for an action potential decision uh even when it comes to the inputs into the dendroductory the location of those inputs or which are at synapses um is something is a big question there can be clustering of correlating presynaptic inputs as well leading to a (03:25) very non-linear events um and there there's actually been an investigation showing that that there are certain forms of computations happening in the dendritic tree such as a coincidence detection um for example it kind of reflecting the and gate or and logic function and as well as the xor logic function uh using specific ion channels that uh people found in 2020 um looking at human neurons and modeling them lastly there's even inhibitory control there's inhibition happening at in the dendritic tree uh turning the gate (04:08) changing the gain of uh the excitatory um activity in the dendritic tree and lastly a lot of these things are plastic they change over time and experience so um and there's also many other things that are in this diagram but uh we want to know how these smallest Computing units are Computing and try to figure out how that ability to compute might be usable for constraining our understanding of the brain so how might we determine in what way any of these aspects contribute to a single neuron's ability to compute (04:53) there's so many properties what are they doing we can begin to answer this using models of single neurons but we defined so many we brought up so many different aspects of them how do you define a single Neuron model what do you include so we can define a single neuron on a spectrum of abstraction so on the far end of abstraction we can actually find uh the McCulloch and pits neuron which is uh the one of the first if not the first neuron models uh put forward that is kind of outlaying the foundation for computational neuroscience and these (05:38) neurons are literally just are very simple they're literally just a linear weighted sum of inputs uh put through some output non-linearity and that's on the far end of model abstraction on the far end of biological realism you have not only the morphology at play but all of these different aspects of neurons included in your model to try to best um to to make the most biologically realistic model of a neuron as you possibly can and simulate it uh to be able to uh learn some things about neurons um and but that can be computationally uh (06:21) resource heavy and on the other side having all of these empirical details um that we are uh modeling in our Neuron model allows us to answer certain kinds of questions so people strike a balance uh such as with the cable model um where you might have passive electrical properties and included might be a voltage-gated ion channels but that might be it right some empirical details are included but not others and this has been very useful to answer certain kinds of biological questions and it's very it's almost precise so what I want to do (07:07) here though is I want to kind of take a step into well some of my background and training is in deep learning some of the work that I decided to do is inspired by previous work where they've taken a deep learning architecture actually and change it a little bit to make it more neuron like it's very abstracted Neuron model but it has empirical Properties or in in these other papers it has empirical properties putting it on this spectrum of course now I want to backtrack a little bit what is an artificial neural (07:47) network which I posted here so what is an an and uh just briefly in artificial neural network is a network of neuron units uh like so here that are linear weighted sums mapped through a nonlinearity so this is a linear weighted sum but they're not linearity which is like the McCulloch and pits neuron actually so uh turns out that model of a neuron has been leveraged to great effect to produce uh deep neural networks that we know uh especially now uh are very powerful in being able to learn or compute uh tasks (08:31) which is very powerful um and so why don't we try to take advantage of that can we have a Neuron model that we can train to be able to compute a task and one way to best refrain beds is can't reframe this is canning artificial neural network with biological or dendritic properties be defined as a single Neuron model what might we learn from doing this right so we can ask the question can a neuron like a n even do complex machine learning tasks and if we introduce dendritic properties iteratively How does each impact (09:19) artificial neural network performance on a task what is the in what are the individual impacts of dendritic properties on an artificial neural Network's performance um while simultaneously making the artificial neural network more neuron-like so this leads us to a hypothesis um adding biological properties to move toward biological realism will impact artificial neural network performance we don't say we're agnostic to it will improve we're agnostic to if saying that it will decrease or impair performance (09:59) we're just saying it's going to have an impact let's explore so how do we do this well we have to choose what dendritic constraints uh we are adding to or imposing on an artificial neural network to make it more neuron like so uh in two papers I uh talked the first of which I talk about um these two constraints which is I think the first constraint is probably one of the most important constraints to make this analogy to making an artificial neural network more neural night but we take the morphology of a (10:43) dendritic tree and impose it onto an artificial neural network this is an artificial neural network here where if you look at just the left side here you have inputs coming in at the top layer going through the dendritic what we would then argue would be similar to Contender to compartments or these units and then coming together to an output node which will either produce a value between zero or one usually either zero or one so it's a binary uh input and binary output so a binary branching structure adds a lot of sparsity to this network (11:28) and it's very strict um second constraint is synaptic repetition um based off of previous studies experimental studies uh on average about a presynaptic neuron can synapse onto a postsynaptic neuron receives a presynaptic input on average four times from the same single other neuron and so we decided to add synaptic repetition to our model in in this way so without going into too much depth of the three other constraints I'll just say that um at each unit there is a an output non-linearity remember these are all mcculligan pits like neurons so (12:17) there's an output non-linearity I replace it with uh with a dendritic non-linearity I add a synaptic nonlinearity to the top layer and I encourage non-negative weights between the dendritic units in order to move closer to this analogy of a compartment-like model where only the adjacent compartments are connected through some sort of conductance weight or an axial resistance weight so oh and connections and resistance they're positive numbers so they're non-negative um that's a lot of detail but what I (12:59) want you to come across I'm going to go into more detail about this um moving forward but uh so don't worry about remembering all of these right now but what I want you to really take away from this is that as I add each constraint I am moving closer maybe not these huge steps but closer toward biological realism uh with each added strength so um thinking about the binary Branch instructor that I did go over a little bit so the binary branching structure of dendritic trees can be imposed onto an artificial neural network like so and (13:46) say you have these in repeated inputs so one two three and four are unique inputs you can we assume that these inputs can be repeated in the same way in other subtrees of a dendritic tree so we built a artificial neural network with repeated inputs which also corresponds to your repeated repeated subtrees or adding to the morphology of course it's like okay this is um you know a bit strict a little unrealistic but we wanted to see how the synaptic repetition had any kind of effect so we added it and you can see with the second (14:33) constraint it adds a lot more of these black lines which are weights or parameters to the model and a big rule of thumb in deep learning is the more parameters the easier for the network to learn and perform so we need a control so what we did was we took a very simple artificial neural network a fully connected neural network as opposed to this very sparse and deep Network um we have uh this one layer neural network where we scale the number of nodes in the hidden layer to be two times the number of subtrees in the K (15:16) tree model or I I call it a K3 model let me let me say k is equal to the number of subterries so um and when you do the math here they come out almost equivalent and they scale directly they scale in the same way so last but not least there's a um maybe last but least is the lower bound control that we wanted to add which was this linear Point Neuron model which is really just a single unit receiving use receiving a linear weighted sum of its inputs and it would correspond to a single compartment model of a neuron (15:58) called dendrites so um this linear Point Neuron model is our lower bound our fully connected neural network control is our upper bound and we have our catering model so let's see what the results oh but first they're performing on what they're performing on a task and this is where I get to emness so mnist is a image data set of handwritten digits so we made this a binary class up classification task where we only show the classes three and five and the neuron is supposed to produce a output of one when it's used a three and an (16:41) output of zero when it sees a five and we can calculate an accuracy measure based off of how the Neuron model responds to each input so here's our results where the x-axis is the architecture size K where K corresponds to each repetition where each subunit each subtree and we we basically double it as we go from left to right to an extreme level with 32 repetitions so um in the y-axis is our accuracy on the emness task so what I want you to focus on is the one k equals one condition where only the binary branching structure constraint is (17:38) at Play and you can see here that the fully connected Network perform or our upper bound is much higher than our K tree performance and if you look at the linear Point Neuron model performance it's actually much lower so this is kind of what we expected um where this is our lower bound this is our upper bound we're in between however when you increase the number of repetitions or subtrees same thing um you can actually see that the performance of the K tree and the upper bound are indistinguishable at uh (18:21) so in essence binary structure reduces performance if this is our vanilla Ann um this is a reduced performance and synaptic repetition improves performance so the takeaway from this is that um structural constraints can affect performance but not necessarily it's not necessarily the case that every constraint you add improves performance sometimes it reduces sometimes it improves so moving back to the constraints that we're adding let's just keep adding more so and see what happens so uh the dendritic non-linearity I'll talk about (19:08) now um so we thought that the um let me just go back uh the Leaky the relu or leaky relu activation function at each of these white nodes or dendritic nodes um is uh something that we can pick on here and replace so the dendritic non-linearity or the NACA K function is really just a linear weighted sum of sodium calcium and potassium current voltage curves adding a linear linear function as well which makes a line with a bump in it and uh you know um but uh this bump is a very interesting bump but we'll talk about (20:00) that later uh it's formalized here and it's really just a linear component which is the adjacent um the Json Upstream compartments at being received by the unit in question the sodium calcium and potassium components and uh what we're going to do here is that we're going to take this dendritic non-linearity and compare it to the performance of the artificial neural network with these other non linearities being relu and red leaky related pink sigmoid and purple and swish in green swishes this almost like continuous (20:42) version of a indifferentiable version of a relu function so what if we replace relative with a dendrite nonlinearity we've got our five different uh conditions but what I want you to focus on is what is in Gray which is the dendritic NACA K function and just look for it in the binary tree model that we are using uh with synaptic repetitions so it's the same kind of graph as before only the different conditions are activate different activation function Alpha nonlinearities and you can see that uh in Gray you actually have much (21:28) better performance than with relu and leaky rello and even sigmoid but up there still is the swish function which is very interesting and then just to remind you what this looks like um each of these nonlinearities are uh you know very different and the what you can take away from this is that the dendrite non-linearity performs well with the binary tree model as opposed to the relu or leaky relu models so what if we do the same thing with our fully connected control so we have our fully connected neural network model and (22:09) we're doing the same exact experiment just with a different uh architecture with a different kind of morphology so um in Gray you have the dendritic nonlinearity actually performing much worse than the relu and leaky relu models and but if you look closely in Gray we're around 95 accuracy and that's just a little less but just about the same as in the binary tree model so what's really seeing is that the uh that the relevant leaky relu models are actually just really good with the fully connected Network model and this might (22:55) be because the reload and leaky relu activation functions add sparsity to our densely connected neural network model and some of the benefits of sparsity can be found in the seminal paper putting forward the relu as an activation function in Gloria 2011 I'm not going to get into it here but it just so happens that the regular non-linearity sparsity seems to impact model performance where a binary tree model with relu performs worse probably because relu adds sparsity to an already sparse Network and in a fully connected neural network (23:32) model it performs much better so um lastly the last two constraints the synaptic nonlinearity and the non-negative conductance weights so I'll talk about the synaptic nonlinearity next so we have to build it so the synaptic non-linearity is added onto our K3 model or artificial neural network um as the first layer or of input where the input is received and then the output of the synaptic non-linearity is received by the rest of the dendritic tree like structure of the artificial neural network and how we built this was we had a (24:19) equation for current flow through and it has capacitive excitatory inhibitory and Link components this is not a real synaptic equation um because it has both the capacity to be excitatory or inhibitory depending on how this is parameterized uh but we allow for the synopsis to be excitatory or inhibitory based off of how they're parametrized that's the benefit of this kind of formulation and then uh the the conductance term here for excitatory inhibitory uh terms are defined by a um and a positive exponential function (25:07) where X corresponds to the uh input received by uh the model unit um where X would be a value between 0 and 1 because it comes from a normalized um it become it comes from a pixel input from mnist so in each pixel is between 0 and 1 and it is parameterized with alpha 1 and output two doing a little algebra this is the non-linearity with with steady state voltage and the takeaway here is that there are five learnable synap parameters per synapse uh these Alpha terms for in excitation and vision in a weak conductance term (25:53) and a takeaway from this also that is not depicted here is that um the the distribution of activities that might be put output from the synaptic nonlinearity is um in between the value is is in millivolts and it is between the values of 70 negative 70 millivolts and 50 millivolts very important so adding synaptic nonlinearities and non-negative conductances gives us the following results there are six different um six different conditions but I want you to focus on just two where you have both the synapses non-linearity and the (26:43) non-negative conductance weights given to a K3 model with all of the previous constraints as before and a fully connected Network control that is exactly the same in all of the constraints that is added and one's in Orange one's in red look for those in the results so again we have the x-axis um where K is increasing for synaptic repetitions you have accuracy here and um this is the performance of these models so in red which is the fully connected Network performance with all of the constraints performs (27:24) okay and then uh with orange which is the catering neural network with all of the constraints it actually performs best out of all of our different conditions why so synaptic non-linearity scales to input scales input to match dendritic nonlinearity so what I mentioned about the synaptic nonlinearity is that if you don't have a synapse the input to each unit is between zero and one but if you do have the synapse the input to each dendritic unit is scaled to negative 7e and 50. (28:07) this matches actually are dendritic nonlinearity uh range so um in this scale of negative 50 to 50 you have this Google with a bump in it the bump is pretty big it's changing between negative 50 and 50. but if you remove this line here you have only the Ion channel components and seems very interesting uh between negative 50 and 50 which is exactly how the input is scaled to be received by the network with these denture technonlinearities so there seems to be a matching of these different properties so the takeaway here is that the model (28:51) with all biological constraints results in the best performance likely because of a Synergy of uh some of the properties that we added so there's some limitations with this work uh we choose we use very highly symmetric dendritic trees which are not representative of most real neurons so further work must be done and has actually been done in oja 2022 on asymmetrical tendritic trees and our model is a feed forward artificial neural network um neurons are not feed forward there are no temporal Dynamics in our model (29:29) which are necessary for reproducing dendritic phenomena so further work of this kind must be done in temporally Dynamic dendrite models in conclusion a hypothesis was that biological constraints added to an artificial neural network affects performance on that neural network on a task and that's that came out to be true and in fact it's not necessarily the case that every constraint improves performance some constraints decrease performance but overall when you add all of these constraints together these constraints can perform better (30:13) than a controlled densely connected Network and lastly these biological constraints can synergize together leading to higher performance in their ability to learn and compute a complex machine learning task and that's it thank you so much cool well thanks so much for the great talk it was uh yeah I feel like I learned a lot and I have lots of questions um but yeah first there's a chess question from the chat um so Michelle Naughton says uh wonderful work um a question how do you did you train your a NS there's sort of two questions so (30:59) question how did you train your a MS Dubai constraints plus non-linearities influence training speed and conversions if yes how did you control uh so sort of three questions I guess the first is how did you trade your own ads yeah uh this is a great question so um these an ends were trained using the back propagation of error algorithm in uh Pi torch uh where um the everything was just all trained exactly the same the formulation of the models were just slightly different with each of the different biological constraints and (31:43) when it came to the constraints and nonlinearities I not exactly sure I don't think I kept track of the training speed and convergence but um in the gloro 2011 paper that I mentioned that talks about uh relus the benefits of sparsity imparted by relu um compares the relu non-linearity to a sigmoidal non-linearity and deep networks and they found that regular non-linearities LED to faster convergence in training speed so I think that revisiting this work it would be very interesting to see how these different nonlinearities (32:25) um would influence these so I think this is a very good question I didn't necessarily control for training speed but I did use early stopping for uh points of convergence for all of these models so I didn't stop them all at the same time I used early stopping when they stopped changing in their objective functions uh cool so yeah Michelle says thank you I think that was very yeah very clear answer so thanks um yeah I guess I had a few questions but so the first one was about the synoptic repetition um so essentially maybe I was a bit (33:09) confused but so if you have a single Pixel and end list in your sort of four repetition model it's saying that that pixel has four in synapses into the neuron into the network right or is that wrong so um I'm just gonna navigate myself over to um that particular slide so your question was if you have four different pixel inputs received by the network and then what was your question uh sorry yeah I guess it was if you have a single mnist Pixel It maps onto a single one of these um like trees so like the dark blue here (33:50) or it's mapped into multiple different how does it map into the network the structure yeah so um if you look at this cartoon of the dendrite you can see that these are four unique inputs so that would correspond to four unique pixel inputs and so um this of course is very simple um mnist is uh images are 784 pixels long um so this is actually uh it would need to be wider and deeper um and when I do the synaptic repeats I take the exact for same exact four unique inputs add another subtree and repeat those inputs exactly again so there's no (34:43) change between each subunit it's um they're all it's it's a very extreme version of synaptic repetition for example uh this could be another limitation of the work but it could open up another a line of inquiry which is if you include synaptic repetitions in a Neuron model to what extent do you want those synapses to vary and the number of those uh repeated synapses to vary and where do they go okay yeah I think I understand a bit better now so for Endless this does a kind with 700 and something so there's (35:18) like 700 and something and then every time you repeat that K times you repeat that whole Vector right yes okay cool and then so then I guess and then you have learnable parameters to each um synapse right you said you had five learnable parameters per synapse yes only in the synaptic uh non-linearity condition so not here but yeah so then I guess something that's maybe interesting is that if you look at the same pixel across different um I'm getting a bit confused with terminology if you look at the same (35:53) picture across different k3s do they learn similar and similar distribution of those parameters or is that heterogeneous across the trees yeah um so that's a really good question um which kind of gets it back at you know if each subtree is deceiving the same exact input and they have the exam sacked structure are the synapses in their degrees of freedom allowing them allowing them to use or transform the information differently and when they do learn when they do learn do they just like segregate I guess if you were to compare (36:40) repeated synapses next to each other I think that's a very interesting question and I think that I haven't necessarily done that um that analysis but I did in I think it's in the supplementary figures I I I wish I would have included in this slide in this talk but there is a uh some histograms of uh uh of synaptic inputs all of them together and you know um and synaptic outputs and what they all the all of them together and seeing how they are distributed uh after learning um which is like a more of a wider uh (37:24) output uh a wider how do I say this um after initial you haven't initialized um synaptic uh you have initialized synapses and the output of those synapses have a very narrow uh band on this histogram but if you train it this band widens to use the full range of negative 70 to 50. um it's not uniform it's still like kind of peaky at zero but so it I think it does They do change but I don't think they change you um identically right yeah yeah no that's interesting I I think yeah things that I think that (38:12) could be interesting to do some more analysis of that um because I could imagine doing things like I don't know some sort of like clustering or similarity to say like oh some of the branches more similar to the branches form like groups of types of branches and things like that because like each each branch or subtree uh seems to um seems to kind of be similar to like an ensemble or like different Assemblies of you know of uh doing different computations on each tree perhaps and you know it's kind of like maybe a winner takes (38:52) all kind of thing I yeah I guess you could imagine finding a method as well to decide on the number of subtrees to have so for example if there's I don't know 10 types of sub trees roughly then you can sort of prune to 10 sub trees because you say the rest of the subjects are basically repetitions of these substrates and stuff right there could be redundancy this would be very interesting uh line of inquiry um yeah a very good question um yeah there's another question in the chat actually people in the chat you're (39:26) very welcome to um come on video and ask your questions if you like Korean I don't know if you want to or I can read your question for you I'll read karim's question for him um so Kareem hashabi says a great talk thanks um why do you think repeating treats helps um a general question do you think the computational neurons need to have all these properties or are there various kinds of neurons yeah so um to answer the first question one of the ways uh one of these ways is that um the repeat repeating of the trees let me (40:11) see if I can get the uh the slide up here um just for a visual aid um oops oops so uh I'll just answer the question so right so when you have the synaptic repeats um in in my hands I repeated each subtree and um what that does is that each of these black lines here corresponds to a weight um that in an OG artificial neural network it's really just a series of Weights uh dealing with activations and you know put through non-linearity so the weights are learnable and provide a degree of Freedom that an additional degree of (41:09) freedom for the network to then learn and then Converge on a solution closest to your target sooner or more effectively in in ways that generalize more so what I'm doing by adding each of these sub trees is I'm adding more degrees of freedom to the model allowing it to then possibly learn the task much easier um and so you know uh I'll just say that I'll make a bit of an aside on this which is uh neurons seem to neuron like biological neurons are very complicated and seem to have uh you know all of these various details or (42:00) weights or if you want to consider it continuous it's uh very um you know it has a lot of degrees of freedom so you could say that well I guess the next question I would put forward is what weights or what parameters of a neuron model that are sufficiently detailed corresponds to a degree of Freedom that is biological neuron actually uses when it is plastic and learns uh to uh compute so that's my first sorry I kind of talked for a while about that one and do we need do I need all of the computational neurons to have all these (42:42) properties I don't know so these are constraints that um we just kind of realize wait we can formulate this and put it into a model what is it do I think that this is the beginning of a good deal of work that really does pinpoint down to what extent is this particular property um going to contribute to computation is it relevant to uh questions of computation or is it not um and I believe that using this type of method where you are taking an optimizable neuron basically uh and putting it setting it to the task of (43:29) performing a a task you are basically measuring or using that task as a bit of a metric for uh how much this particular biological property is contributing to um the neurons ability to learn and compute and if it doesn't then maybe it's not relevant to computation and but if it does in a significant way maybe it does I think that another way this could um this line of questioning could be expanded is to think about different kinds of neurons you mentioned is there is it going to are these constraints necessary for every neuron in the brain (44:11) that's a good question I don't know I think that when it comes to specifying your Neuron model um choosing Properties or finding parsimonious properties where one neuron has one type of property another neuron has a different kind of property not the previous one then maybe you can start making some theories about like arthalamic neurons computationally more powerful than uh ca1 hippocampal neurons or vice versa you know um I think this is a beginning of a lot of these are really good questions and kind of point to Future directions (44:56) yeah no thanks for that answer I I think also it sort of goes in the direction I wanted to ask a little bit about which is I guess have you have you started to think about making like yeah networks of neurons like this and then once you have networks of neurons like this you could start to explore this heterogeneity a bit more as well right yeah I think that that's also a really good future direction for this kind of work where you know you have basically a network of optimizable neurons and you want to what uh you could (45:27) optimize the neuron specifically you could optimize the whole network itself um in you know allowing for the neurons to have heterogeneous properties um that are converged on through the process of learning and um I think that that could be uh definitely a direction that we can go in in terms of exploring the space and perhaps even thinking about like uh what kind of what are the properties that are converged on when you have a network of neurons that are optimized toward a task um and yeah I think this General (46:06) framework of thinking about uh neural neuron models as a as a optimization questions allows us to be able to ask this and kind of put this normative spin on it where we say Okay a neuron should be able to perform this kind of task what does when we use this method uh from Deep learning what do we find and what properties come up like for example your question about like uh the the um perhaps separation of synaptic activities after learning and how the impact what how that might be impacted by uh synaptic repetitions (46:54) it's very interesting cool no I think that seems really exciting Direction,,,,,,,,,,